{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook assumes the data have been preprocessed by the notebook `notebooks/03-preprocess_data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "X_train, y_train = df_train[\"text\"], df_train[\"label\"]\n",
    "\n",
    "df_test = pd.read_csv(\"../data/processed/test.csv\")\n",
    "X_test, y_test = df_test[\"text\"], df_test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function for doing cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def fit_and_evaluate(model, X, y, n_splits=5):\n",
    "    \"\"\"Fit and evaluate each model.\"\"\"\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df=10)\n",
    "        transformed_X_train = vectorizer.fit_transform(X_train)\n",
    "        transformed_X_val = vectorizer.transform(X_val)\n",
    "\n",
    "        model.fit(transformed_X_train, y_train)\n",
    "        y_pred = model.predict(transformed_X_val)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_val, y_pred))\n",
    "        precision.append(precision_score(y_val, y_pred))\n",
    "        recall.append(recall_score(y_val, y_pred))\n",
    "        f1.append(f1_score(y_val, y_pred))\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": sum(accuracy) / n_splits,\n",
    "        \"Precision\": sum(precision) / n_splits,\n",
    "        \"Recall\": sum(recall) / n_splits,\n",
    "        \"F1\": sum(f1) / n_splits,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a 5-fold cross-validation on different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"logistic-regression\": {\n",
      "    \"Accuracy\": 0.7563828164717845,\n",
      "    \"Precision\": 0.7727123573719143,\n",
      "    \"Recall\": 0.6635658914728683,\n",
      "    \"F1\": 0.7137579476645841\n",
      "  },\n",
      "  \"k-nearest-neighbors\": {\n",
      "    \"Accuracy\": 0.6994407727503813,\n",
      "    \"Precision\": 0.6914216134580616,\n",
      "    \"Recall\": 0.6198522286821706,\n",
      "    \"F1\": 0.6530055670151128\n",
      "  },\n",
      "  \"random-forest\": {\n",
      "    \"Accuracy\": 0.7336019318759532,\n",
      "    \"Precision\": 0.7391082341143106,\n",
      "    \"Recall\": 0.6526768410852714,\n",
      "    \"F1\": 0.6917812418647439\n",
      "  },\n",
      "  \"gradient-boosting-machine\": {\n",
      "    \"Accuracy\": 0.7165124555160143,\n",
      "    \"Precision\": 0.7093055915651197,\n",
      "    \"Recall\": 0.6449006782945736,\n",
      "    \"F1\": 0.6754061804363788\n",
      "  },\n",
      "  \"support-vector-machine\": {\n",
      "    \"Accuracy\": 0.7314438230808337,\n",
      "    \"Precision\": 0.7149764844988908,\n",
      "    \"Recall\": 0.6901041666666666,\n",
      "    \"F1\": 0.7015886067955033\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_dict = {\n",
    "    \"logistic-regression\": LogisticRegression(),\n",
    "    \"k-nearest-neighbors\": KNeighborsClassifier(),\n",
    "    \"random-forest\": RandomForestClassifier(),\n",
    "    \"gradient-boosting-machine\": GradientBoostingClassifier(),\n",
    "    \"support-vector-machine\": LinearSVC(),\n",
    "}\n",
    "\n",
    "performance = {}\n",
    "for model_name, model_class in model_dict.items():\n",
    "    performance[model_name] = fit_and_evaluate(model_class, X_train, y_train)\n",
    "print(json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best model on the full training set and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Accuracy\": 0.7770700636942676,\n",
      "  \"Precision\": 0.7846153846153846,\n",
      "  \"Recall\": 0.7083333333333334,\n",
      "  \"F1\": 0.7445255474452555\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(min_df=10), LogisticRegression())\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "performance = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "}\n",
    "print(json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../artifacts/model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "735b1bbd8e64d5b8ac9eb5cce3af7988e476745b427477cf0ca4dda5d6ade974"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
