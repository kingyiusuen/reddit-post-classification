id,label,text
r7t0nu,0,generate and read summary of any research paper on twitter using rax bot rax bot a twitter bot to help you read research papers more effectively you can trigger bot by to replying to a research paper tweet that you want to summarize and mention with the summarize keyword and the bot will send you a summary link back on twitter bot also follows some accounts which share research papers regularly and automatically reply to them with a summary link examples
rx3vgj,1,mit s opencourseware ml courses anyone working through or have gone through mit s opencourseware courses intro to machine learning or machine learning the latter of which is a graduate level course if so how did you find the experiences i m planning on using the knowledge to do research in machine learning so i m only reading the handouts and listening to the videos i m not working through the hands on stuff
r44r7q,0,combinatorial optimization for panoptic segmentation a fully differentiable approach there is recent interest in incorporating algorithms as layer in neural network in our recent work cops at neurips 21 we tackle a similar task with the following questions 1 is it possible to train a pipeline containing neural networks combinatorial optimization 2 is such pipeline extendible to real world large scale tasks 3 using 1 2 can we create a fully differentiable approach for panoptic segmentation we answer all of the above questions with yes and show benefits insights into training such hybrid pipelines contribution 1 backprop through combinatorial optimization co layers there has been much recent work in this direction but such methods were not previously applied to a large scale tasks b non optimal co solvers we extend previous work of 1 to compute better gradient estimates and obtain faster convergence contribution 2 transformation for backward pass previous works for gradient estimation through co x argmin x in c c x apply loss on x and perturb costs c by incoming loss gradient on x this is not the case for panoptic segmentation our scenario is x z argmin x in c z in d x c x and loss is applied on z here we need to perturb the costs associated with z which does not exist to remedy this problem we solve a different co problem in the backward pass to compute gradients w r t c contribution 3 we show a differentiable surrogate of panoptic quality metric tldr 1 backprop possible through co for large scale tasks even with non optimal co solver 2 to achieve 1 we smooth gradients in backward pass 3 solve another co problem in backward pass for optimizing variables not appearing in objective 4 propose a panoptic segmentation approach with fewer hyperparams better results than comparable approaches code available at 1 black box backprop
rwm2qi,1,please suggest some resources to learn ml online preferably at no cost
qnktqk,0,league of legends patch 11 21 game playing ai reinforcement learning supervised learning dataset this dataset is meant for anyone who would like to try to create a deep learning agent either using supervised or offline reinforcement learning to play league of legends the dataset contains 72 games from patch 11 21 last patch where the game ended in an early surrender these games were chosen as the game lengths were guaranteed to be low which kept the dataset from being too large to download the dataset go to this github link and click on the google drive link the dataset is stored as an sqlite database file and the schema should be relatively self explanatory happy to answer any questions this is just a preliminary dataset which demonstrates that this is possible within the next few days the dataset will contain 1000s of replays which means 10 000s of champions worth of data for each time a player plays a champion edit database now contains all 191 early surrender games games ending at or before 3 5 minutes in the dataset this table shows the top 10 champion occurrences within the dataset champion no nami 116 miss fortune 103 lucian 61 khazix 36 viego 35 lux 34 jhin 32 yone 30 camille 29 graves 29 edit 2 larger dataset containing 987 games targeting miss fortune in the early game up to first 5 minutes with the same schema and format as the first dataset also contains all game objects recorded 4 times a second the games were chosen by getting the games where the mf player lived the longest this gave a dataset where the players overall had a 64 4 win rate in roughly euw diamond ii edit 3 a further 728 games also targeting miss fortune in the early game up to first 5 minutes with the same schema and format as the first and second dataset this brings the total number of games for the mf longevity datasets to 1 715 or 1 715 games 5 minutes 60 seconds 4 frames second 2 058 000 frames in total this should now be enough to at least create a deep learning agent which can play miss fortune for the first five minutes of a game at least to a basic level edit 4 another day another dataset a further 773 games from the mflongevity dataset have been uploaded i have now also included a jupyter notebook to analyse the data from the 191 earlyff dataset which works completely standalone from google colab feel free to also run it locally if you wish to github link open notebook in colab edit 5 very in depth explanation for the process used to create the dataset blog post
rd2ngm,1,complete production example anyone know of a great complete ml project example i don‚Äôt mean just a saved model but a data pipeline a working app etc
qv3xpt,0,cycada feature level gan loss in the cycada paper equation 5 in the paper makes use of f s however the corresponding portion in figure 2 orange only makes use of f t additionally f t makes more sense since the input is in the target domain should the f s in equation 5 be f t
r7xbw1,0,optimize gradient descent for small known problem hello i hope i m posting in the correct community because my problem isn t part of machine learning but i figured you d be the best help when it comes to gradient descent a part of a hobby project of mine is photometric stereo take images under different lighting conditions to calculate the shape of an object so i need to minimize a cost function depending on 64 measured values with variables to optimize being a direction vector and a scalar value being the albedo luminance of the object but hundreds of millions of times within a reasonable time i didn t find any fitting papers addressing what i need exactly typical photometric stereo with the added fresnel equation for s polarized light and robustness to shadows so i developed my own algorithm this works reasonably well but all optimizations i found have been more or less trying different stuff and seeing what works i have already added momentum to the direction vector part and can directly solve the luminance in one iteration hyperparameter optimization is also on the list so to my question how do i properly optimize a gradient descent algorithm that solves a small known problem and should converge with as little steps as possible or at least learn how to do it so i d also appreciate any links to research papers lecture slides
ql2qjz,0,scientific literature review generation hello everyone i ve developed an algorithm to automatically generate a literature review hopefully that could be useful for the phds and the non phds for those curious to understand how it works i ll be thankful if you have any remarks about that cheers
rhh5zr,0,project determining what a classifier thinks a rabbit looks like how it works trying to see what classifiers thought different classes looked like i ended up generating pictures for every class in imagenet those pictures did not look like what i was expecting though i should probably know better at this point lol i used an imagenet pretrained vgg 16 model for the classifier fun results of not rabbits evolving the generated picture from a gray image to something the classifier is a 100 sure is thing x200b x200b x200b i m surprised by the lack of the color orange in the generated image
riqxrq,0,do large language models understand us blog post by blaise aguera y arcas summary large language models llms represent a major advance in artificial intelligence ai and in particular toward the goal of human like artificial general intelligence agi it‚Äôs sometimes claimed though that machine learning is ‚Äújust statistics‚Äù hence that progress in ai is illusory with regard to this grander ambition here i take the contrary view that llms have a great deal to teach us about the nature of language understanding intelligence sociality and personhood specifically statistics do amount to understanding in any falsifiable sense furthermore much of what we consider intelligence is inherently dialogic hence social it requires a theory of mind since the interior state of another being can only be understood through interaction no objective answer is possible to the question of when an ‚Äúit‚Äù becomes a ‚Äúwho‚Äù ‚Äî but for many people neural nets running on computers are likely to cross this threshold in the very near future
razw0l,1,requesting help i am a beginner in ml i am working on a tuberculosis tb prediction project i am doing binary classification using tensorflow i am using chest radiography images as the dataset for cnn there are 3500 normal chest x ray cxr images and 700 tb infected images do i need to perform data sampling or can i find better dataset which optimizers activation function how many convolutional layers and dense layers to use should i use data augmentation i am looking for suggestions
qka32i,0,2d models on 3d tasks convolutions simple replace 2d tasks enjoy a vast backing of successful models that can be reused for convolutions can one simply replace 2d ops by 3d counterparts and inherit their benefits any extra steps to improve the transition not interested in unrolling the 3d input along channels pubs code help
r4rd5h,1,object detection for handwritten signatures i m trying to run object detection on pdf documents to recognize the signature position do you know any pretrained model that can recognize signatures
rcn2ha,0,pretrained models gpt 2 clip etc as api endpoints for building web apps hi all i recently built pretrained convect ml i‚Äôve been interested in the potential for building web apps on top of pretrained models that have been gaining popularity in the machine learning community one foundational piece for these apps would be access to predictions by these models with fast response times so i‚Äôve made models available via an api for a few ai tasks 1 text generation gtp 2 gpt neo 125m and pegasus for paraphrasing provide text and generate more text with a similar style and content use these models to build an ai writing assistant or even synthesize entire articles 2 computer vision clip measure the association between any sequence of images to a list of arbitrary texts use clip in an app to detect vehicles animals trees household appliances or other physical objects that you can describe with words 3 conversation blenderbot 400m distill build an ai powered chatbot that responds to user inputs tbh blenderbot‚Äôs responses don‚Äôt always make sense so i‚Äôd be careful with this one 4 article summarization bart large cnn generate a summary of the salient points in an article use this model to build tools to help people consume information faster 5 text classification bart large multinli measure the association between any sequence of words to a list of arbitrary text labels a classification model can be used to detect topics e g send customer call center transcripts to this api to detect if customers are reaching out about specific topics of interest such as product defects or payment discrepancies 6 sentiment analysis distilbert base uncased finetuned sst 2 detect the sentiment of a piece of text this model for example could be used to measure overall customer approval levels for a product from social media posts many of the endpoint response times are sub second and could be used in applications to provide a near real time experience i have also included codepens in react for each of the models to make it easy to get started with building on top of them all the endpoints handle preflight requests from any origin so applications can be purely browser based if you want to do that i‚Äôm not the first to make these models available for free over an api but am hoping to make the experience of getting started as easy as possible i‚Äôd also love to chat with anyone who has been curious about using these models in their projects or if there‚Äôs a particular model that you wish was readily available as an api endpoint
rjk88d,0,cheap conferences neurips last week was my first conference only cost 25 dollars for me as a student are there any other good machine learning conferences that are affordable aaai 22 e g i find a little expensive at 145 dollars for students
rla8ja,1,what should i use for a beginner project colab seems too slow have any of you had any experience with google colab or similar tools i m trying to train some models but i m a beginnier i m looking for something that s relatively easy to use but will work well enough for what i m trying to do i tried to run it on my macbook but it took 5 hours do any of you have any suggestions thank you
rjvmw0,1,can machine learning a hobby or is it a full time commitment hey all i m asking this question today as i m quite torn about my future studies im thinking of doing a double major with microbiology or biomed with cs but i dont really want to put myself at more stress during my time at uni but i am prepared to do so i heard about not really needing uni to learn computer related stuff and can self learn these things but is it more appealing to a company for a individual with a degree i know there is more career prospects in computer science but i dont really want to start all over again at uni i m a 2nd year science student and plus i dont even know how to program yet i m committed because i want a good future but am i getting myself in some deep waters or should i just swim away while i can any advice would be appreciated cheers
regt37,1,using amd radeon with tf in anaconda spyder hello i understand that tensorflow is geared towards proprietary nvidia cuda but is there a workaround for amd radeon gpu i m on a macbook pro with an amd radeon 580 external gpu card
rbo6s4,1,comparing bayesian linear regression model with a decision tree regression model how would i go about comparing a bayesian linear regression model with a decision tree model
rg4r3l,0,how can i decrease the response time of meanshift algorithem in sklearn currently i am using a m1 macbook pro and i want to use the meanshift clustering algorithem to segement an image but it takes like 2 3 seconds to give the output is there anyway i can reduce the time
rnyeyl,1,free python courses from udemy learn python 3 from scratch python for absolute beginners practical python python for data science ‚Äì great learning starting python 3 programming for the absolute beginner
rmuptq,1,what language to write a conversational ai so basically my ultimate goal would be to have my ai able to hold a conversation know what the words mean and answer while maintaining context even if the topic isn t clearly stated in each message also to have some amount of memory i e remembering names and relationships like who my mom is or that i have an so with a name i don t know any languages other than a working knowledge of html css and javascript but i don t think that s really helpful here so i m interested to know what language s i should learn because i m determined to make my brainchild a reality thank you in advance
rh3nj8,1,rnn predict why am i getting 13 outputs number of columns in x train set when using model predict function using keras i need one output i can‚Äôt find anything online about this issue model code regressor sequential regressor add lstm units 50 return sequences true input shape x train shape 1 1 regressor add dropout 0 2 regressor add dense units 1 regressor compile optimizer adam loss mean squared error history regressor fit x train y train epochs 10 batch size 32 predict code train predict regressor predict x train test predict regressor predict xtest test predict shape out 48 2142 13 1
qx6giu,0,does faang interviewing research interns for summer 22 already i have applied to many big tech companies for phd research intern positions mostly focusing on machine learning and deep learning i recently got several offers from non faang companies my initial goal is to get an internship position at faang but i have not received many opportunities to get interviewed by them i am having an interview with amazon and will have an interview with facebook soon that is all for faang i am curious when is the usual hiring interview period for intern students perhaps i am not attractive to those big techs and that is why i have not got many interviews from them or i just wonder if they are gathering applications and start interviewing applicants from december because i got an offer from some companies i need to decide soon whether i will accept it or not but because i don t have any idea if the hiring process at faang is almost finished or there will be more opportunities it is hard to decide 1 if you have any experience in the hiring process of research intern positions at faang could you let me know rough dates of when you had interviews and when you got offers from them 2 also because this is my first internship during my phd i don t know what to consider when choosing a position all positions are research intern positions and the topic of projects roughly aligned with my interests and most of the time i was told that the specific topic will be decided when i start internship by discussing with my mentor i hope i could get a position that has a high possibility that i could publish a paper but it is true that there are so many uncertainties could you give me any advice for selecting an intern position when you have multiple options any advice regarding internship will be very helpful thank you inadvance
r66avr,1,really noob question is there a way to look through the clip database manually i just think it d be neat to see all the images used to train clip
rbc9fd,1,does anyone have experience using riot games api to do machine learning tasks i am doing a final project in which i would like to use riot games api to do some basic machine learning analysis from my league of legends profile x200b i have been following this tutorial but there are some variables in it that are undefined when i followed the tutorial x200b i am just wondering if anyone could help me understand what i am missing or share a way that you used riot api to learn i am not doing something insanely hard or anything just want to do basic analysis
r7kj61,0,neural noise is one of the cool anyone know what causes it i ve been messing around with style transfers and a lot of them especially ones based on illustrations have this specific type of noise x200b good example of the noise it s splotchy rgb noise that varies a lot in size x200b a gif where you can see it developing and a still where you can see the noise really well
rmrifl,0,multi output generation with sparsely fixed output i am trying to use generative deep learning to synthetically generate certain biological parameters given some experimental constraints i am using gans to do this and i have been successful so far for the next step i want to fix certain parameters in the output vector to some experimentally verified values and then generate the rest of the parameters in the output vector based on this the features in the output vector of the gans are obviously coupled by some complex non linearities so changing or fixing one of them will propagate to the other outputs as well is there some way to do this what i have already tried researched 1 transfer learning on a trained generator with a curated training dataset where the output features i want to fix are already constrained it works the gan learns to fix the values of certain output features but this is because they are already fixed in the training data 2 context encoding in gans i am aware that context encoding and similar tasks have been already showcased where gans are used to fill in missing regions in an image based on the rest of the image but extrapolating this to my case is hard to make a direct comparison my case is analogous to having an image that has only a few pixels that are shown and the rest of the image is masked and need to be inferred i could not find any literature on such sparsely fixed output if anyone is aware of some literature or blog that tackles a similar problem please let me know
r13jq5,1,possibilities object recognition as a complete newbie in the ai and machine learning space i was wondering how far the possibilities currently reach i came up with an idea to recognize whether different types of glasses are filled or empty the idea is extremely novel still and therefore i m wondering if that s already possible with ai and machine learning at the same time am i wondering if something like this can be easily programmed or learned how to program by a beginner or that it requires a certain experience and can only be done by someone with experience in the field
rju3nf,1,how to detect timing anomalies using ml methods hello everyone i am really new to machine learning algorithms right now there is a research project on my desk and being expected addressed with some ml methods we would like to detect the timing anomalies in the power traces of our embedded system let s say i can sample the system voltage at some rate for 1 second exactly after the moment when the system powers on to make the scenario as simple as possible for an easy start the system embedded power on behaviors are fixed so we expect the voltage patterns should be the same for each run as well if the noises are not considered what i have done is to collect 30 traces 20 items for training while 10 for validation as the training set hoping the trained model can give me a prediction at each timestamp during the testing phase so that a threshold can be set to alert if the incoming values deviate too far from the prediction it is an anomaly the collected 30 traces would not be exactly the same considering the random noises and the different micro architectural states the main reference i am using is this tutorial i select the cnn algorithm and perform the training and retrieve the prediction waveform as shown below x200b blue is the reference trace without timing anomalies while red is the prediction trace it looks like the cnn captures some patterns but the amplitude seems to appear a proportional difference the below are the squared errors between the two traces the maximum error is around 25 x200b square errors between the reference trace and the prediction one however if i compare the prediction trace with a corrupted trace with many timing anomalies the square errors report the deviations at more timestamps but the maximum value is smaller than 25 so i cannot set a static threshold for claiming those anomalies x200b blue is the corrupted trace with timing anomalies while red is the prediction trace x200b square errors between the corrupted trace and the prediction one with that i do have a few quick questions which might look naive to you experts 1 is cnn the correct option to go with for this purpose otherwise what kind of algorithm i should use for this project in your opinion 2 does the prediction trace make sense why does the amplitude difference occur between the predictions and reference 3 is it possible to set a dynamic threshold to differentiate the timing anomalies in the latter scenario 4 i am using pytorch any suggestions you can offer to run the training procedure faster the training took me more than 1 day i really appreciate you finishing reading such a long question really looking forward to hearing from you about any suggestions and opinions thank you
r132f4,1,good ai mlcourses youtube channels and books for beginners hi guys which courses youtube channels and books do you recommend for absolute beginners learning ai ml
r07nms,0,inference server for gpt j 6b on huggingface with optimizations to fit into g4dn xlarge hi i created an inference server for gpt j 6b on huggingface using fastapi the main challenge here was making sure that the model fits in the smallest g4dn instance on aws with 16gb of ram and vram to save on the server costs check it out and hope you find it helpful here is also a write up that explains what optimizations were applied
rf7fxo,1,questions regarding cnn lstm model it is my understanding that video data must be converted to individual frames and then converted to some sort of array data before passing it through a cnn what i don‚Äôt understand is how to do that last step of converting it to array data could someone please assist
r21dxk,0,project aim 3 1 open source images tracking and images explorer hey r machinelearning i am gev co author of aim sharing with you the aim v3 1 the new version contains the following three notable changes images tracking and explorer improved ui and backend performance better runs navigation images tracking is a major item crossed off the aim roadmap images explorer on aim ui a short aim ui images explorer video code web release notes bit ly 3clz6hy x200b would love your feedback on our work how can we make aim better
qrvasc,0,handling bound constraints in cma es hi all apologies if the question is a bit naive as i only have passing familiarity with ml full stack developer by trade i m really just looking for more insight into the implementation and consequences of bound constraints with cma es optimization i did come across biedrzycki 2019 which discusses this topic and a lot of the paper s findings at least come across as fairly natural but i m not finding a lot out there and i m just wondering whether anybody else has any recommendations for further reading or personal stories of potential pitfalls in the problem i m dealing with specifically each of the coordinates in my mutant search point vectors need to be bound within the unit interval and i wanted to make sure i wasn t walking into any easily preventable mistakes background context i m currently working on a personal project inspired by this popular geijtenbeek et al 2013 paper where i ve implemented a hill type muscle model and rigged up a humanoid model with some 200 muscles approximating human skeletal muscle function now i m beginning muscle control experiments with inspiration from this paper wochner et al 2020 except i m plugging in cma es instead of the bayesian optimization used in the paper while utilizing the objective function insights
qrwuvy,0,what must every phd doing ml know before graduating i am a 3rd year phd who finally finished all program requirements classes etc and am fully focused on research my question is what are some things that your average ml phd should be good at at this point i know its subjective and depends on their research field but what are some common things that i should be well versed in
rnu744,1,recurrent neural network for time series forecasting hi i have been given a challenge for the artificial neural network course at my university which consists in forecasting 7 time series using a rnn what are some state of the art architectures i can try to improve the performance i achieve on such task thanks a lot for the help
r8gbid,0,iclr 2022 possible competing bias review my paper got 6663 the reviewer who gave 3 kept comparing our paper to a concurrent work posted on arxiv only a few days before the iclr deadline and asked us to cite acknowledge explicitly compare with this concurrent work in our paper is it common how likely is this reviewer the author of that competing concurrent work this reviewer also delivered a lot of deliberate attacks during the reviewing process we were really frustrated what can we do under this situation update pc responded to that review
rj7ivc,0,different results for the model every time i train the model with same parameters i have the following model i am facing an issue with the results as every time i run the model i get different results the train and test data remains the same in every run i can give you more details if you have any questions for me let me know note data 1 and data 2 do have a correlation between them and that s the reason for using them both x200b
r9n6rs,1,can someone please give me a breakdown of the math i have to study for machine learning and related data science hi i m 20 and from south asia sl and i think i ve studied up to pre calculus very basic graphs statistics and matrices i studied biology chemistry and physics due to unavoidable reasons in high school but my mind was always stuck with it i ll be starting my information systems bsc degree in a few months now i m working as a data science intern some data automation basic ds and ml with a very good mentor guiding me so the lack of math knowledge isn t affecting me much however i do know that i have to understand how certain functions work and matrices for dl if i want to be good at what i m doing i really love the field and i want to enter the field of deep learning ofc through ds and then ml i m very unfamiliar with math since i ve had virtually no interactions in the past 5 years but i m quite comfortable with computer science especially python now i know that for a beginner level i have to study linear algebra statistics probability and differential calculus what i don t know is what sections of those aforementioned fields i have to study i m thinking about hiring a private tutor to gain at least basic knowledge within the next 4 5 months the tutor asked what exactly i wanted to study and i didn t know hence my request could you please give me a structure of the topics i should study beginner level e g x200b linear algebra topic 1 topic 2 statistics topic 1 topic 2 is it possible to be familiar with the topics you suggested within the mentioned time frame could you please suggest some good books for self learning your advice suggested resources books sites are greatly appreciated thanks a lot for your contribution feel free to ask me any questions
rcy2tq,1,question about model stacking i m working on a small personal project and would like to implement model stacking however the approach by which i would like to do is proving to be unintuitive not sure if that s because it s not possible and or recommended or i just haven t stumbled across the appropriate method yet what my plan is is to split the records into one dataframe here would be good point to mention working in python that contains the numerical features and a second dataframe that contains the categorical features and maybe even keep a copy of the original dataframe with both and of course to split out the target variable all sharing the same index then run through a selection of models and feed the predictions to a meta learner i ve read a few articles about model stacking implementation via sklearn and the process seems to involve initiating a stackingregressor or stackingclassifier depending on task and passing the estimators and final estimator then fitting predicting etc in typical fashion my problem lies in the disparate dataframes it seems that you re only able to run a single x and y through the process you cannot tell the stacker to run models a and b on the numerical dataset and run models c and d on the categorical dataset correct but perhaps there may be a manual workaround
r8kfpf,0,dynamic batching for gpt j api hi i created a small fastapi back end for gpt j on huggingface with dynamic batching dynamic batching has the potential to increase throughput at the expense of the latency because it pads all the sequences in the batch to the length of the longest one in this project i determined the maximum amount of tokens batch size x sequence length that could fit in the memory by tuning the batch size while keeping the sequence length fixed until i would get the out of memory errors if anyone knows of a more reliable way to determine the optimal batch size i would appreciate any pointers the purpose of this project is to show how to implement dynamic batching for real production environments you should probably use c or go instead of python fastapi github link blog post
rc0coi,0,gopher 280 billion parameters language model by deepmind blog post direct paper link seems like a compilation of their findings on scaling lm s a bit more than gpt3 retro a retrieval style model
ro1ke3,1,how do you make a neural network classified fruits
qkef2i,0,is there a good guide roadmap on deeplearning with large datasets in clouds is there a good guide roadmap on deeplearning with large datasets in clouds i have around 50 200gb of data in npy format to feed into a tensorflow pipeline preprocessing itself takes a few hours too or should i completely do that offline and change the pipeline structure
r246im,1,leave columns out for training a model i have a basic classifier for a dataset which includes about 40 columns the first two are an id and the associated name i eliminated all the non numeric columns so my classifier only uses the numeric values for its prediction so i eliminated the id and name column too now i want to associate the predicted data and the test set with the ids and names which i excluded before the classifier training is there a way to either leave the ids and names in the data set and tell python not to use them during training or to associate them back after the prediction i use python with pandas sklearn etc the classifier is a logistic regression with sklearn
rs8a2z,1,how to create retraining protocol pipelines for machine learning models specifically in the case of computer vision models using cnns inevitably you will encounter data that the model is not well suited for one could keep a log store of such data points to use for later training but what is a justified way to retrain models over time especially in the case of something like face detection where the data distribution does not necessarily change over time but rather there are simply certain points that are underrepresented in the original training data let s assume that the model already performs acceptably on most data points what are the trade offs of 1 retraining on the whole dataset including those erroneous samples with good labels 2 training the model perhaps with early stopping and validation on the original new datasets only on the erroneous samples 3 training on the whole dataset preferentially sampling the erroneous samples x200b is there a name for this process where can i find best practices and theoretical discussions of this kind of process i would appreciate any help as this is a real issue that i wish to solve with a deployed model
r9soc8,1,training accuracy vs test accuracy i‚Äôm a little confused as to whether or not the difference in the training dataset accuracy compared to the test dataset accuracy shows whether overfitting has occurred or not say i‚Äôm training a mlp using cross validation to stop the learning if the validation set accuracy does not increase by a tolerance value for a set number of epochs intuitively if i then look at the validation accuracy curve i can see it increases and then remains constant however when testing the model on training and test data the training accuracy is a few percentage points higher so my question is does this small difference indicate that some overfitting had occurred or not does a better score in the training dataset compared to the test dataset generally indicate overfitting has occurred or not
rflmju,1,what is the best off the shelf model to use for question answering over internal documents with a serverless architecture hi i have many gbs of internal documents that i need to build a search tool over currently i am using haystack nlp library to do this task but i would like to know if another library tools exists where i can make haystack model into a serverless architecture i would like something that can be on demand vs turned on all the time from a computational resource perspective thank you in advance
r7n8k8,1,recommendations for creating a nlp text harmonization algorithm hello looking for recommendations tips on how to solve this issue hopefully it s allowed here this same question was deleted in stackoverflow and i don t know where to ask for help x200b let s say i have this set company kpmg usa kpmg europe microsoft corporation microsoft dhl global forwarding dhl express but i want to harmonize company names to get a result like the following x200b company company harmonized company kpmg usa kpmg europe kpmg microsoft microsoft corporation microsoft corporation dhl global forwarding dhl express dhl x200b this problem can be segmented into two core problems 1 matching fuzzy matching 2 harmonization providing the cleanest and most representative name for the matching part i know there are several pyhton packages to fuzzy match through tokenization algorithms such as python record linkage among others for the harmonization part i have no clue what is available seeking recommendation for this part additionally i am looking to implement a form of supervised nlp algorith so that it can learn with time how to output the best harmonized name and how to match correctly seeking recommendations for this part as well i already have a large dataset with around 1m rows and i can get more if needed with examples like kpmg usa kpmg
reohjf,1,backpropagation for beginners warning not for faint hearted beginners complain that they can t find posts videos for backpropagation and beginners sometimes have no idea how backpropagation works in most tutorials when it comes to backpropagation only equations are shown to beginners and tutorials directly jump to keras pytorch etc and most of the time these tutorials are from the documentation of keras or pytorch in these posts i have tried to explain backpropagation in very simple language with very neat codes building your own neural network backpropagation part 1 backpropagation part 2 if these posts are helpful to you and you think they will be helpful to others please share them you can join me on youtube are neuralthreads on reddit
rqnjst,0,how do you guys tune hyperparameters when a single training run takes a long time days to weeks training a large model for example pretraining a large bert model can take weeks how do you guys do hyperparameter tuning in such scenario
r8v4fq,0,project dall 3 generate better images with fewer tokens through clip guided diffusion link to images and code link to diffusion model colab this is a project i created that combines transformer image generation with clip guided diffusion it s named after the 3 projects it s based on dalle pytorch clip guided diffusion and vqgan btw a big thanks to lucidrains rivershavewings openai and the vqgan team for their work if in general ddpm gan vae why do transformer image generators all use vqvae to decode images wouldn t it be better to use a diffusion model i was wondering about this and started experimenting with different ways to decode vector quantized embeddings with a diffusion model see discussion here after a lot of trial and error i got something that works pretty well the resulting diffusion model basically absorbs one scaling factor so you can get similar image quality with 16x16 tokens diffusion compared to 32x32 tokens vqgan i then trained a relatively small dalle pytorch model with these embeddings and put the whole thing together in the github colab above in terms of generalization ability eg avocado armchairs there s no substitute for a large scale transformer but for common object categories people food etc the small transformer diffusion works surprisingly well so this is kind of a proof of concept the conditional diffusion approach should provide a flat boost in quality to any transformer model including cogview ru dalle vq diffusion and openai s original dall e the parameters for this architecture is mostly dictated by the pretrained models i m leveraging there are a lot of potential optimizations that i haven t explored for training from scratch such as removing the final unet downsampling layer but i ll leave it to someone with a gpu cluster
rkw26f,0,aws a visual interactive introduction and explanation to double descent i hope this is allowed here given it s not an arxiv link though the derivation in the second article can easily be thrown into one two articles about double descent the first introduces the concept in a visual manner second provides an explanation for linear models as a relation to energy in natural cubic splines both designed to be quick for consumption and understanding
qsi0u2,0,prune then quantize or quantize then prune for post training optimization of computer vision models as a student that is interested in improving the efficiency model size throughput energy of pre trained deep learning models in the computer vision domain i was wondering if there was a clear winning approach on in what order we should prune and quantize a pre trained model so basically if you were given a pre trained deep learning model e g resnet would one of the following approaches lead to better solutions in terms of the accuracy to efficiency ratio e g model size throughput energy consumption quantize then prune with finetuning retraining after every stage prune then quantize with finetuning retraining after every stage i have trouble finding related works that answer this kind of question to me it seems to be valid question but maybe i m missing something obvious any input would be appreciated
rggtdu,0,exciting new effort to develop synthetic data for genomic research
rjybto,1,regularization techniques for beginners l1 and l2 penalties dropout and layer normalization i hope that these posts are helpful to someone who wants to understand how these regularization techniques work l1 and l2 regularization dropout layer normalization part 1 layer normalization part 2 you can join me on youtube and reddit
rljh5w,1,is there a github repository that lists out topics and resources to learn them i saw this repository for data structures and algorithms so i was wondering if there s something similar for a beginner wanting to learn machine learning a quick google search returns lots of repositories so does anyone have experience with any of the repos i have also heard of microsoft ml for beginners which looks like a good resource and i will definitely start the lessons does anyone have any opinions on this it looks interesting
qmln6l,0,washington u google study reveals how attention matrices are formed in encoder decoder architectures in the new paper understanding how encoder decoder architectures attend researchers from the university of washington google blueshift team and google brain team propose a method for decomposing hidden states over a sequence into temporal and input driven components revealing how attention matrices are formed in encoder decoder networks here is a quick read washington u google study reveals how attention matrices are formed in encoder decoder architectures the paper understanding how encoder decoder architectures attend is on arxiv
rb3tfn,0,data augmentation in nlp hi i d like to ask what you think or is your experience with data augmentation in nlp particularly in intent based chat bots i know it s a common practice in computer vision but as to whether some downsides with synonym replacement resulting in thousands of examples within one intent can occur i m dubious ü§î my common sense tells me it can help overfitting and as long as i keep dialog balanced i can t see any downside other than training time i d love to hear all your inputs üôÇ
qk5avf,0,how is mlops done in your current workplace i joined a startup recently where the the necessary backend to support ml deployment is pretty much non existent all we have are some simple templates for ci cd modified from those designed for generic microservices currently it takes data scientists at least 3 5 working days post r d for to put a model into production as a prediction end point with logging and observability this excludes setting up the necessary data pipelines between the models and other backend services whole process can take as long as 2 weeks my team and i are looking into setting up some framework and automation to cut the turn around time for putting models into production trying to establish some reasonable goals for this project and hope to get some insight from others have been through the same x200b which part of the production processes are automated by your mlops teams and tools how much effort do these tools help save and how much time does it currently take to put up a piece of r d work into production
qkyyno,0,did anyone check ykilcher s video of siraj raval s interview i love yannic s video but i did not see any point of this interview i mean even in the interview siraj seemed like someone who has just started learning machine learning when he mentions about superintelligence digital organism god seems like he imagines ml as a hollywood movie much like the general person
r93h2k,0,dealing with missing values for anomaly detection with numerical data i have a small numeric dataset with around 400 attributes all numeric and 200 instances the target is a categorical attribute with 4 different categories indicating the state one class represents normal condition and the other 3 represent anomaly types the instances representing the normal state no anomaly have no missing values however the instances representing anomalies have missing values for most of the attributes in addition the names of the attributes for which there are missing values correlate with the anomaly type e g for all instances of anomaly class 2 attributes from 10 to 400 are missing while for all instances of anomaly class 3 attributes from 300 to 400 are missing what would be the best way to deal with the missing values in this case for the supervised and the unsupervised case i m not sure which methods i m going to use but i would need to cover both supervised and unsupervised cases
raobgu,0,research what deep learning algorithms is best for forecasting covid 19 cases using exogenous variables for our research we want to forecast the covid 19 cases using exogenous data for our exogenous data we are planning to use time series data of the cumulative number of vaccinated individuals change in mobility and weather is it possible to incorporate these variables for univariate forecasting we are also looking to incorporate the data of population density of each location but this is not time series data can we still include this we are currently considering lstm but i m not really sure if it is the best algorithm for this kind of algorithm any suggestions would be greatly helpful
rsqktc,0,what are the recent breakthroughs for the generative models for art hey everyone i am interested in the recent developments or models in the area of neural style transfer i am also interested in other applications in art not only neural style transfer so feel free to point those as well what are the mostly used models in this area nowadays can you point me to the papers thanks a lot
r70stj,0,how a feature store be useful for my scenario i recently came across feature stores as a mechanism to operationalize ml pipelines in a commercial setting it sounds good but i m finding it hard to understand when and where to use it when doing exploratory data analysis for example consider a simple use case of prediction house prices for a given geographical location i source the raw data from a remote server that contains historical house prices with some columns features as below latitude longitude total rooms house size total bedrooms year of construction this is just a small representation of the feature set as a data engineer one has to probably look into the raw data do some simple statistical analysis like 1 identify null or nan values and impute them 2 identify the co relation of the features with respect to the target variable and determine if some features be dropped or not 3 identify the unique count for a numeric variable and determine to remove that feature or column if the unique count is below a certain threshold 4 delete duplicate rows 5 perform onehotencoding for categorical data 6 identify and remove outliers 7 perform dimensional reduction feature scaling now assuming that i would be performing just the first few steps or i would be performing all the above steps i would like to know how employing a feature store would speed up or rather operationalize my ml pipelines
remf8e,1,ocr for handwritten devanagari script hi everyone i have to do a project for handwritten word recognition in devanagari script using deep learning but i can t find good resources or even datasets can somebody please help me out here edit i am trying to implement a cnn rnn hybrid model which does not require segmentation of characters from a word and takes whole word as model input
r8zwc5,1,what deep learning model would work for this kind of string translation task if i have a dataset which looks something like this nlvpmvatv casspvtggiygytf glctlvaml csardgtgngytf nlvpmvatv casrpdgretqyf nlvpmvatv cassetgfgnqpqhf nlvpmvatv casslapgatneklff where the thing before the comma is the input and the thing after is output what would be good dl model to learn this kind of structure the data is always in capital letters and doesnt have any special characters i think a character level model would made sense here but i really have no idea what to start with does anyone have any experience with similar task of string translation anything would be helpful thanks
ru2pcb,1,local explainability using shap after feature engineering i am using shap to explain model predictions for a particular instance and was wondering how to interpret them when feature engineering is applied to data i can think of three scenarios 1 no features are dropped or added in this case shap would simply give a value for each feature indicating how a particular feature affected the result 2 some features were dropped shap would again output a value for each features but does it make sense to say that features that were dropped did not affect the model output sounds silly but not sure if it statistically correct to use shap in this case 3 new features were generated from existing features lets say you generate a bunch of features from original ones while retaining the original original a b c new a b c ab bc abc thanks in advance
rkqfjc,0,how shopify applies ml for anomaly detection and forecasting at scale with dr ella hilal head of data science engineering revenue and growth at shopify at enterprise data ai jan 6 at 11 30 am hi r machinelearning i wanted to share a webinar coming up in january 2022 at enterprise data ai i put the info from the website below along with the link if you re interested i m interested in hearing how they built their anomaly detection engine and how that has been performing featured guest speaker dr ella hilal head of data science engineering revenue and growth at shopify at shopify we have over 1 7 million merchants across over 175 countries with hundreds of millions of consumers shopping at their stores we‚Äôre focused on leveraging the scale of our data to not only empower shopify but to create new experiences for our merchants that are impossible without data in our daily operations at shopify we are highly data informed some of the ways we‚Äôre leveraging advanced analytics is by building an anomaly detection engine that allows us to process over hundreds of thousands of metric segment combinations in a very accessible way in her talk dr hilal will share key tips on how you can apply machine learning for anomaly detection and forecasting at scale agenda 11 30 12 30pm featured presentation 12 30 13 00pm your q a and interaction link to website
r8v65d,1,career advice how can i best prepare myself to get a purely r d data science position i am currently in the last semester of my master s and i was hoping to get a taste of industry for a couple years before pursing a phd or perhaps to pursue it part time either way my goal is to secure a data science position focused on performing research and with the potential to publish papers not just deploy and maintain models big data i have an offer to work as an associate data scientist at a local startup but they made it clear i would be spending half my time doing development and the other half r d the data science team is just two people and is just starting out so i m somewhat concerned that i won t have much opportunity to expand my ml skill set there however i also have a good chance of securing a full time research intern position through a government organization that my research advisor is involved with but the position is only for six months even so another opportunity could arise after this or i ll have an extra six months to hunt for jobs i m wondering a couple things 1 is a research intern position through a government org considered industry experience in regards to hiring managers i d like to not be restricted to applying to entry level positions 2 would it be better to obtain industry experience at the start up even if there s a chance i mostly won t be doing r d or to get more experience doing full time research even if it s temporary 3 is it plausible to secure a position doing 100 r d without a phd which of these options would be a better stepping stone towards that
qsvzio,0,tsflex flexible and efficient feature extraction for time series are you looking for a time series feature extraction package that is both efficient and flexible tsflex has got you covered they just published a release that allows integration with tsfresh as well go check it out üëâ
qphg92,0,amd launches mi200 ai accelerators 2 5x nvidia a100 fp32 performance source more info for today‚Äôs announcement amd is revealing 3 mi200 series accelerators these are the top end mi250x it‚Äôs smaller sibling the mi250 and finally an mi200 pcie card the mi210 the two mi250 parts are the focus of today‚Äôs announcement and for now amd has not announced the full specifications of the mi210
r6fzxo,0,discussion sharing of node information in mcts runs in scenario of a single player game with a pretrained value and prior probability model if it is given that a state can be reached through different order of actions imagine something like a knight move followed by a bishop move and vice versa where both the series of moves lead to the same state what are the different ways used today to reuse the information about states already explored is it possible to connect nodes of different branches of search tree when it is known that those states are identical with some sort of a hash function in an effort to save the roll out time is it possible to also reuse the current approximation of q s a based on w and n for a particular action when two actions lead to the same state
rnhyeo,0,how to visualize ground truth boxes on images hello guys as you might have guessed from the topic i want to visualize the ground truth boxes on my images from the pascal voc dataset can anyone of you help me out with this dilemma i have been trying to find out ways on how to display the ground truth boxes on the images any help would be good
r6314s,1,how do you feel about job recruitment in ai survey hey everyone my name is davis and i work for a consulting organization called illinois business consulting we‚Äôre working for a company in the ai sector and are hoping to improve their recruitment we made a survey about ai recruitment so if you guys wouldn‚Äôt mind filling out the survey below it would be awesome thank you again
rqm5y6,0,how do you measure fairness without access to demographic data hi all i m working on a paper about measuring algorithmic fairness in cases where you don t have direct access to demographic data for example if you want to see whether a lender is discriminating against a particular race but the lender is not collecting releasing race data of loan applicants if you have 10 minutes and work in the ethical ai space it would be a great help to hear from this community on whether how often you have faced this issue in practice and what you think should be done to mitigate survey link is here
ruj3ja,0,iclr 2022 open discussion quality first time submitting to iclr i m wondering how is the open discussion on openreview net really different from the review rebuttal procedure used in other conferences for the papers i m reviewing about half the reviewers reacted to the authors responses clarifications modifications additional experiments etc as to my submission 5568 i run extra experiments and answered each of the concerns directly but received 0 feedback from the reviewers as a reviewer i think it doesn t matter if the rebuttal changes your mind about the quality of the submission but it s very basic manner to reply to the authors responses a simple thank the authors for the responses but i don t think these addressed my concerns would work saying nothing only means you are uncertain if the responses make sense and you just doesn t care to figure it out the authors spent a whole week running experiments to answer some of your questions and if you don t give about their responses just keep the questions with you and don t submit your review i was hoping for a different experience submitting to iclr and then i realized the discussion is basically broken
qvc3cb,0,how do you create new neural architectures blocks or layers i keep using the models that others invent and come up with how can i learn how to create my own type of layers or blocks how did they come up with squeeze and excitation layers in efficient net for example where do i start
r84reh,1,common uses of ml hello i m trying to recap all the very common main real world usage of ml things that a company would need or find helpful here is the list of what i have for the moment time series prediction classification image text pattern recognition text summarization anomaly detection voice recognition text keyword extraction chatbot do you have any other ideas of what can i add to that i want to see other s perspectives i m sure i missed some thanks for consideration
rg61dp,1,best machine learning resources for beginners i am planning on studying machine learning and i want some of the best resources courses books etc to get started andrew ng s ml course on coursera is an exception
rocen2,0,gans and probability distributions on images when training gans either with the classic loss or wasserstein loss we try to minimize the distance between the probability distribution of the real data and the probability distribution of the generated data in the case of gans for images e g trained on celeba how does a probability distribution over images look like what is an intuitive way to understand this concept
rlhwve,1,i know python but ml code seems meaningless to me i was trying to learn ml in a long time and i know python and math but every time i started a course on youtube or udemy about introduction to ml after tensors things get really confusing for me like loading data training model i can t understand what s going on i recently watching statquest and i really liked the ml videos but i wanna do my own projects and for that i need coding
rv4u2w,0,paper that mathematically proves that gradient descent can achieve zero training error i think this is a well known paper but i have not been able to find it i am interested in the paper that mathematically proves neural nets can fit any set of datapoints so far what i have found mostly is papers that show empirically that or something related to that like this one i d appreciate any help edit u the new scientist shared this paper which is what i was looking for also i apologize for my vague description now that the paper is shown i hope it is more clear to future readers what kind of results i meant but in case that is not case i was wondering about this question under what conditions can a neural network achieve zero training error and in particular i am interested in papers with mathematical even without empirical results
ra4er4,1,how to capture words order in a sentence hi guys i m data science student and i m trying to capture the words order in a sentence for checking if in n triples subject predicate and object this order is respected for example given the phrase rougue is a comedy movie and given these 3 triples 1 rougue is movie 2 rougue movie is 3 movie is rogue in this example only the first triple is correct for my task i guess that in order to achieve my goal i have to vectorize the reference sentence but i don t understand how to capture the correct order so that only the first triple turns out to be right how can i do this thanks all edit my dataset for more than 90 is composed of simple sentences where the order s v o is respected so even the triples that are extracted as a second check should follow this order as a first check i thought about using the bag of words or tf idf to check the presence of the words contained in the extracted triple within the reference sentence however it is still not clear to me how to check if the word order within the triple is respected i know it s a coarse job however it serves as a basic control for skimming
r1du84,1,forecasting using lstm in pytorch hi i want to use an lstm in a time forecasting problem actually i want to replace the convolutional layers in the rainbow algorithm rl network with an lstm to consider time series i have seen many examples on the internet but none of them helped me with my confusion my input is divided into an encoder part and decoder part which are both divided into continuous variables and categorical variables what is the best way to build an architecture that takes into consideration all the types of variables can anyone share any helpful resources also my confusion is with the loss function will i need to do anything like in the picture attached thanks a lot x200b
qlbye5,0,text to image models rudall e kandinsky xxl 12 billion parameters and rudall e malevich xl 1 3 billion parameters a demo for the latter is available technical report russian technical report translated to english by google translate demo for rudall e malevich xl github repo for rudall e malevich xl more links from my other post
rvw32g,1,beginner learning path question i m a python and c developer and i m starting to learn ml i have a question regarding which path will be the most convenient for my porpuses i have a project in mind which is the automatic placement of labels in cad following certain rules see image this is a very time consuming task specially when we have thousands of objects example image i have finished the ng course but now i m confused what should i learn next should i learn ml and then reinforced learning can i start directly with reinforced learning i do not want to skip any stage but i would like to learn as i progress with my project x200b thanks
qm2ov5,0,project discover ongoing ml ai competitions looking for feature suggestions for mlcontests com it s been two years since i posted here about my then new project ml contests it was well received and since it s been a while i thought i d post an update and ask for feedback main page mlcontests com the main page just lists ongoing competitions there s also a newsletter where i occasionally send out updates about the competitive ml space and a separate page which compares cloud gpus for ml you can visit the site at mlcontests com traffic is steady the newsletter is growing there are no ads and i d like to figure out where to take it next i d love to hear your thoughts on what you want from the site ps if you want to contribute it s all open source
rl5j1e,1,what other things i need to concentrate on other than my course curriculum hi i have started my master s in computer science with a specialization in artificial intelligence and i aspire to become a machine learning engineer it would be helpful if anyone can suggest things other than my course curriculum that i should concentrate on thank you
r1bau8,1,model for credit payment probability i was asked to work on a model to predit a credit payment probability i know there are models to predict credit default which gives you true or false in the outcomes but in this case i need a number as a probability which model could give me that
rb7cs3,1,can someone explain some code of vqgan clip for art generation here s the link i read a few articles that explained how vqgan worked like a gan and clip as a discriminator i looked at the code but didn t understand too much i just want to know which code block is doing what the fifth block for example defines functions like sinc lanczos and i actually don t know what they re being used for thank you
rmtcvh,0,shape changing and conformal mapping i am looking for shape changing algorithm meanly from linear to nonlinear shapes i think conformal mapping is related here does anyone has an experience with shape changing how it works
qukqtz,0,knowledge graph applications with ml and ai and open source database links in 2022 a new terminology is coined by google in 2012 ‚Äúknowledge graph‚Äù this knowledge graph has its own significance in the field of machine learning due to which performing capabilities of machine learning techniques are getting better day by day with a high accuracy rate read more
qr6bu6,0,discussion plaforms frameworks for backtesting and regression testing lots of models i have a need to test lots of models submitted by different teams there will be baseline curated datasets but there will also be updates as new data comes in from the field models may have different preprocessing requirements we ll need to retrain models on the updated data evaluate the models and archive the reports and models configuration management most of this will probably need to be queued up something like slurm along with the need to asynchronously monitor performance of multiple dgx servers are there commercial tools to manage testing of a fleet of models and the data must work offline
qvvd9c,0,benchmarking scaledyolov4 on out of dataset images scaledyolov4 is the go to model for object detection we decided to test how well it does on a dataset different from the one it was trained on we used the citypersons dataset for this experiment it is a subset of the popular cityscapes dataset which only consists of person annotations we found precision and recall values of 0 489 and 0 448 we also found that object detection on this dataset was pretty good even though the classes assigned to them were lacking at times checkout details of the experiment at you can also checkout the notebook we used for this experiment at
r5kjoq,0,oversquashing and bottlenecks in gnns and graph ricci curvature x200b over squashing is a common plight of gnns occurring when message passing fails to propagate information efficiently on the graph in a new blog post i discuss how this phenomenon can be understood and remedied through the concept of ricci curvature see the paper for details the second installment of this post will discuss whether and when diffusion improves graph learning analyzing the popular digl rewiring method of klicpera et al this post is part of a new series on graph neural networks through the lens of differential geometry and algebraic topology
r5rxbr,0,has anybody tried using openai gym to automate using a gui application can it do something simple like ‚Äúcreate a new macro in excel ‚Äù or is there any pretrained model that can translate natural language to mouse actions over an image a desktop
rrydgm,0,ecco language model analysis and visualization toolkit hi r machinelearning over the last couple of years we ve been building this toolkit to explore and visualize transformer language models it brings together a wide variety of tools and methods to visualize and analyze model inner workings and activation spaces features support for a wide variety of language models gpt2 bert roberta t5 t0 and others ability to add your own local models if they re based on hugging face pytorch models feature attribution integratedgradients saliency inputxgradient deeplift deepliftshap guidedbackprop guidedgradcam deconvolution and lrp via captum capture neuron activations in the ffnn layer in the transformer block identify and visualize neuron activation patterns via non negative matrix factorization examine neuron activations via comparisons of activations spaces using svcca pwcca and cka visualizations for evolution of processing a token through the layers of the model logit lens candidate output tokens and their probabilities at each layer in the model x200b we just released v0 1 0 which brings encoder decoder model support t5 t0 feature attribution via integrated gradients and many other methods provided by captum github paper
rmcp62,0,why does convolution lead to translation equivariance i asked a similiar question before it is my understanding that translational equivariance is one of the main properties that allows convolution to be so powerful at finding patterns in images however i am having trouble finding concrete proofs for how this happens does anyone have any papers that explains why convolution leads to translation equivariance preferably from a linear algebraic perspective secondly does anyone have any papers that explains why translational equivariance allows convolutional neural networks to be so successful at image recognition or explains how this idea of translation equivariance relates to what is happening at each layer thanks
qk9uet,0,what makes multi armed bandit problems contextual hi everyone i dive straight into my problem what makes a multi armed bandit problem contextual i read on tensorflow agent tutorial that the agent receives the context vector which is just the observation at every step that makes a bandit setting contextual isnt every agent in an bandit setting doing this since in the mab problem the agent needs to know on which machine bandit he is and how much he knows of the probability of the machine so how does contextual mab defer from the standard mab is it for example extra information ontop for example he knows wether a machine bandit has a higher probability if the wether is raining or not and the second part of my question is i m currently working with stable baselines 3 is here the normal observation function the correlating observation function context vector from tf and using the observation in every step making it contextual couldnt find any information in the sb3 documentation how the contextual settings work to be more specific my extra context in my mab problem is a state machine the bandit uses and each state is an one armed bandit i hope this isnt a beginner question and i am tolerated here
rhnnaw,1,how to approach a scheduling problem i ve got a problem whereby i m trying to match resources to tasks think of planning the maintenance of a train and i need to know which people go to which trains i understand this is more of an optimization problem but i m struggling to understand how to frame the problem any pointers or papers or topics would be appreciated
rec0nk,0,karpathy on the consolidation of the field i‚Äôve definitely noticed a trend in the papers i‚Äôm seeing this year with people combining building blocks in creative ways i wonder how far this trend will go and what it will unlock
qka6p0,0,does cuda latest version support all version of pytorch and tensorflow greetings sorry i could not think a better place to ask this question where i can get response regarding pytorch tensorflow and cuda version i want to to know if i install cuda 11 5 will it support lower version tensorflow or torch packages such as tensorflow 2 4 or pytorch 1 71 which is supported by 11 0 cuda version actually i want to install both tensorflow and pytorch the best option is to install cuda 11 0 or 10 1 but i want to know can i install latest version of cuda and whether will it support both frame works
qyxxcs,0,simple questions thread please post your questions here instead of creating a new thread encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread
rn27l0,1,android studio with tf lite hey guys anyone experienced with using tensor flow lite in android studio i have trained a model exported in tflite and then getting and error while uploading it to studio that meta files are not included any suggestions
r6bttm,1,back to basic linear regression with python code in 2 minutes one of the biggest fields of application of python these days is machine learning and one of the first things anyone learns about machine learning is how to do linear regression linear regression is attractive because it is very simple to understand at least compared to other learning models we also know how to implement it efficiently and more importantly we can make sense of the results i made a 2 minutes video exactly about this topic by design a 2 minutes is never exhaustive but hopefully this will serve as a good intro to the topic and will give you the motivation to dive deeper if it sounds like something you are interested in i know that when i started out i wished there were resources like that available so i would love to hear what you think about this format
r1zsaw,0,graph as an output of ml modelling hi i am currently thinking about tackling a rather specific problem using ml or any kind of statistical approach really i have the problem that for a given set of nodes with their names i want to predict an acyclic graph of how these nodes will be arranged i also have a set of meta attributes that put the graph into context and i also have a set of historical graphs together with their meta attributes the basic idea is that we assume that graphs with similar meta attributes will follow a similar pattern also wrt to their node names ultimately i want to build a model that is able to forecast the resulting graph the only solution i could think off is building a model to forecast the single entries of the adjacency matrix essentially fitting a function f meta node1attributes node2attributes 1 if node 1 node 2 else 0 is there any smarter way of doing this
qorekl,0,simple questions thread please post your questions here instead of creating a new thread encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread
r17z2y,0,deepmind google brain world chess champion explore how alphazero learns chess knowledge deepmind and google brain researchers and former world chess champion vladimir kramnik explore how human knowledge is acquired and how chess concepts are represented in the alphazero neural network via concept probing behavioural analysis and an examination of its activations here is a quick read deepmind google brain world chess champion explore how alphazero learns chess knowledge the paper acquisition of chess knowledge in alphazero is on arxiv
rlc7b7,1,machine learning andrew ng on courseera i would like to learn machine learning upon research this seems to be the most popular is it the same cs229 course says 12 weeks to finish but my winter vacation is just 4 weeks long
qpw3br,0,recursive ml strategies i m looking for ideas on how to use recursive ml strategies possibly utilizing multiple individual models where one model uses the output of another model to make more accurate predictions for example i use two sklearn randomforestclassifier models to provide a simple signal about the direction of the stock market the first takes n inputs and outputs a prediction the second takes the original n inputs plus the output of the first to make a new prediction it doesn t provide earth shattering results but it appears to be slightly better than only using the one model random forests also provide the ability to use out of bag samples which could also be used i m just curious if there any established methods papers i should look at etc that discuss meta or recursive strategies to get the most out of ml models
r8v6rk,1,career change into programming data at 30 y o ‚Äì options in europe hi everyone before starting just a little bit of background about myself i am 30 years old french and therefore a citizen of the eu i already have a master s degree in engineering in chemistry materials polymer i have been working for 6 years as a process engineer in the automotive industry 2 years in france 2 years in slovakia 2 years in germany i have ended my job in germany but i am currently learning part time german in a school there to pass b2 i have a lot of free time 6 7 hours day i also speak english if necessary i can consider passing my c1 certificate and french so now after many months of reflexion i would like to change my career the field in which i can work mainly related to my studies does not suit me i have a great attraction for programming and computer science and even if i only have a very basic knowledge about it i would like to change into this field i m not totally sure yet but i would like to do and am therefore targeting one of the following jobs data analyst or data scientist and or probably later on a job related to machine learning ai i m just discovering it but i am getting super excited about it for info i have been learning python data science by myself for a couple of months now so finally here are my questions what are the best learning options for me to be employable or to have certified or company recognised knowledge in order to find a job in data science data analyst for example to start and which ones would you recommend i am looking to study in europe online if possible or in person in germany to find a job in germany switzerland austria for example it can be fast or long free or not i have some time and money to invest now but i don t want to if i realise it is not necessary different options i found so far self learning a couple of portfolio projects free but difficult to prove competences no certifications and no supervision bootcamps online expensive but quite fast and intense however i m not sure if this is recognized by companies and if it will really help me find a job master degree do you think i have a chance to find a master online in europe starting 2022 knowing that i don‚Äôt have any educational background in cs master conversion course i have heard about it maybe it is only in uk i am not totally sure about how it works but knowing that i have already a master degree i probably don‚Äôt have to start from the beginning bachelor or should i start first with a bachelor is a bachelor enough online would be better any city or country in europe or are there other schools which are not bootcamps not universities but something between that are recognized or certified and might help me a lot if you have any ideas or information that could help me i would be very grateful i am motivated and i can invest a lot in this project but i am not totally sure what would be the best option at the moment or what qualification is really necessary for this job thanks in advance
rdefe9,1,any idea of a model to use my data is like this and i want to predict the next letter is for a and z it is like a loop for example after b it can go only for the next letter c or after it can go for b or y bcdcbcbcdedcbcdcbcb y yxyxyxyxwxy bcb yxy yxwxwxyxy yxwxwvwxwvwxwxy yxyxwvuvutuvutsrqpqpqponmnopqrqpqrqrqponmnopqrsrqrtutuvutututstuvutstututsrsrsrqrstutstrqrqrqpqpopqrqpnmlklmlkjkjkjihgfedcbcb bcb yxy b yxyxwvutsrqrsrqrqrstutuwxyxy y bcdcdedefedefgfdedefghihgfghijijkjihgfedckjkjkjkjihihiklkjihijihijklkjijijkijijkjihgfghghgfghghijijklmlmlklmlkjijihghihghijijihghghihgfedededcbcb y xy bcb bcb y yxwvwvwxyxyxwutsrstutsrqpqponmlmnopqrsrqrqpqpqponopqrststuvwvututstutstsrqpqpqpononlmnopqpqpopqpqrstsrqrststsrsrqpqrqpqpsrststuvuvutsrqrqrqrsrqonmnonoponmlmnmlkjijihghihihihgfedefefgfghghghghgfdefefefedcbcbcb b bcdedefghghghihghghgijkjkjijijkjkjklkjihihghijihijihikjihghijijkjijlmlmnmlkjijihihijhghihijkjlmlklmnonmlmlkjkjijijkjkjijihijkjihgfgfghgfefghijijijijijihghgfghihghijijijihfededcbcb bcbcdcbcb b bcb yxwxwxy yxyxwvwvutstsrstsrqrqpqrqrstvwvwvuvwxyxy yxy b bc y b y ywy bdcdcdcedefefgfghghgfefgfededefhghihijijkjklklkjmlmnmlmnonmnopopqrqrqpopqonmlmnopopqrqrststststutststutusrqrqpqrqrstststuvuvuvwxy yxyxyxwvuvutstststuvwxyxyxyxwvutuvwxwxwxyxwvuvuvtsrsrqrqrststuvwvwvwyxwvwxy b bcbcbcb bcdededefghghghgfghihihgijijihghghgfhijklmnmnopqrqpqrsrstsrststutsrqponoponoponmlmnonmnopqrqpqrsrststuvwvwvwxy b yxyxy bcdedefghgfefhihghihghihghgfededededefefghihghghgfgfgfefghghihgjihghgfededcbyxy y yxyxwxy b y b b b yxyxyxyxwvwvwyxyxy y bcbcbcb yxyxwvwvwvwvututuvwxwxwxwxyxyxwvwvwxwvuvuststsrqrsrsrsrqrqrsuvututututsrqrqpopopqrqrqrqpqpnmnmlkjihijijklkjkjijijkjijkjkjihghgfdcdcdedefgfghijklmlkjihgfdefgfedefgfefefghghgfghghgfedcdcdcbcb yx y b y bcbdededefghgfgfgfhghihghghgfghijijijklkjihijihihgfgfghihjihgfgfgfededefgfgfededcb b y yxy bcdededcbcdcdedcdefdefefefefghijijihghghgfedcbcbcb b y bcdcbcdedcb yxyxwvwvuvwvutstststststuvututsrsrststsrqrqrstuvwvuvwxwxwxwxyxyxyx yxyxyxy bcbcdedcdedefghghghgfghihghghghghihijkjijijijihgfgfgfgfededefghijklklmlmlmlklmnmlmnononopqpqponmnoponopopopqrqrstsrqrqrqponononmnonpqrsrstuvuvutututsrqpopqpqrsrststutstututstsrqpqpopqrqrsrstsrqrqrqrqrststuvututsrqrqrqrstutsrststutuvwvututsrqrqrqrstutuvuvuvwxy bcdcbyxyxy bcdedededcbcdedcdcb yxwvwvuvwvutsrsrqpqrsrqponopqpqrqpqrqrqrqpqrststsrqponopoponopqrpqrqrsrstststsrqrsrsrqpononmnmnonoponopqponmlklmlmlmlkjijijkjijijkjkjklmnononmnmlkjijklmlmnonononlmlklmnopqrsrstsrqpqrqrqpqrstutststutstvwvusrqpqrqrqrqrstututsrqrsrststsrqpqpqrqrqrqrstsrqrsrqrsrqrqrqrqpqponmopqrstututstsrststsrqpqrsrqpopopqrqpqrqrqpqrstututsuvwxy y bcbcb y y yxy ywxwxwvwvwvwvwvwvutstsrststutuvuvwvuvwxyxwxy yxwxyxy y bcdcdcbcdefghghghgfgfefghijkjkjijihijhghgfghghgfghghjkjkjijijijklmlmnopopqrqrsrqpqpopqrqrsrqrqpqrqponopqrsrqrqrqpopqrqrqrqrstsrstututststsrqponopqrqrstsrqpononmlklmnonopqrstutsrqpqrstststsrqrqrqrstststutututstuvwxyxy y bcdededcbcbcdcb b bc y bcbcb yxwvwvtsrqprstsrstutuvwvuvwvuvwvwvututsrqrqrsrqpqsrsrqrqrstuvwxy yxy b y yxwvwxyxyxywvwvututstututststsrqrqrqsrpqpqpqrqrstsrstststststsrqpqrqpononmnopqpqrqpqpqrstststststutstsrqstutututstsrsrqrstuvwvwvutututututuvwvutsrqruvwvpqrqrqpqrsrqpqrstuvwvwxyxyxwxwvwxyxwvwxyxy bcdedefgfghghgfededefghikjihihihijihghijijijkjihgfefedefedededefghihgfghghihgfefgfefededcbcbcbcb y yxwxy b bcbcdededefedcbcdedefghijijijijihijijijijkjihijkjihgfgfededededc yxy yxyxy y yxyxyxwvutststutstststsrqpqpopqpononopopqpqrstutsrqrqpopqronmlmlklmnmlmnmlmnonmlmlmlmnmlkjkjklkjihijklklmlmnonmljklmnmlmnopqrsrststutsrqrqrqrqrstutsrsrqrstututstsrsrqrsrqrstututstsrqrqrqpqrqpqrqrqrqststuvwxwvwvwxwxyxwvwxyxyxwxwxy b xyxyxy yxwvwxy bcdefghgfededefedefgfgfghijihghgfgfghghghihijihghihijijihgfgfghgfghghihghgfedcbcdededefghihijijijkjijkl
rm4xps,1,best ml and ai courses on yt using python tensorflow and google collabratory hi i am a beginner in ml and i want a good course which uses python tensorflow and google collab i hv been searching for a course like this for a long time now and i really want someone to help me and link me the best course that is interactive and fun as well pls help
qo5in1,0,gpt 3 is no longer the only game in town hey there i just put out a little article that you might find interesting gpt 3 is no longer the only game in town it catalogues the appearance of models akin to gpt 3 over the course of 2021 like hyperclova and such hope you enjoy it tldr organizations face significant challenges in creating a model similar to openai‚Äôs gpt 3 but nevertheless a half dozen or so models as big or bigger than gpt 3 have been announced over the course of 2021
rr6eb8,1,can there be a set of questions that can give an end user an idea if machine learning can be implemented in his business case i m looking to build ml as a service in my org and needed to understand if any use case validation questionnaire which answered can give us an idea if implementation of ml in this case is valid
r89r8r,0,are neurips authors required to purchase a ticket to register question in title first year accepted should i be purchasing a ticket the regular way
r15mte,1,has anyone used algorithmia to deploy models i m unconvinced algorithmia advertises themselves as an mlops platform for data scientists and they provide an easy way to host models on a scalable rest api this sounds like a perfect solution for a data scientist or hobbyist who wants to host models for cheap and not worry about the devops but as i ve gotten more familiar with it i have more questions for the base tier algorithmia requires you to host your model s request handling code on a github repository owned by them a separate repository for your request handling code seems like a strange pattern to develop in they also encourage you to develop in their web ui again another pattern that feels forced they also have an ominous section in their terms of service that says you do not transfer ownership of the software to algorithmia but you do hereby grant algorithmia a fully paid up and royalty free license to use and permit others to use the software which feels overly aggressive for forcing you to use their source hosting between an unnatural development environment and a sketchy ownership clause i m reluctant to continue using algorithmia has anyone had similar experiences with algorithmia am i just being overly skittish and misinterpreting the ownership clause are their better repository patterns git subtrees that other people have used with them are there better companies to host models or should i have never even attempted leaving the aws and gcp hosting land
ria7qt,1,training multiple regressors with independent weights on same dataset pytorch hi i d like to train multiple linear regressors 20000 odd in pytorch that take the same input features but have different y true ground truths also i d like to have different weights for every one of these predictors the architecture that i m supposed to use for this task is a simple 2 layer neural net i m stuck with how to come up with a way to train these classifiers independently i thought of making a list of nn module objects and then invoking one by one with different y s however i can t seem to find any documentation against the same could someone point out to such resource
rakeii,1,i want to do product recommendations for an online shop no idea where to start any model suggestions what data i need to collect this is for my school coursework
quv04i,0,paper explained gradients are not all you need full video walkthrough more and more systems are made differentiable which means that accurate gradients of these systems dynamics can be computed exactly while this development has led to a lot of advances there are also distinct situations where backpropagation can be a very bad idea this paper characterizes a few such systems in the domain of iterated dynamical systems often including some source of stochasticity resulting in chaotic behavior in these systems it is often better to use black box estimators for gradients than computing them exactly x200b outline 0 00 foreword 1 15 intro overview 3 40 backpropagation through iterated systems 12 10 connection to the spectrum of the jacobian 15 35 the reparameterization trick 21 30 problems of reparameterization 26 35 example 1 policy learning in simulation 33 05 example 2 meta learning optimizers 36 15 example 3 disk packing 37 45 analysis of jacobians 40 20 what can be done 45 40 just use black box methods x200b paper
rnegp0,1,data science machine learning interview participation request good evening among current circumstances i hope this message finds everyone well i am current high school senior student in the state of illinois seeking potential data science professionals or prospective data scientists willing to participate in an interview for my ap research course to provide a general overview my institution is currently partnering with college board s ap capstone diploma a diploma program that develops student‚Äôs skills in research analysis evidence based arguments collaboration writing and presenting skills based on two long year courses ap seminar and ap research as a student currently enrolled in the ap research course and an expected requirement i am tasked with the year long process of exploring an individual area of interest that may be an academic topic of choice idea or circumstantial issue this year i am centering my research on the effects traditional mathematics subjects retain in minority students academic success primarily latino a students and students of hispanic origin as well as assessing the measure of academic success of collegiate students or professionals in attaining a post secondary education degree and or career it is worth noting the state of illinois does not offer any data science education within its public school districts and is an objective i would like to have implemented in my community i have tried to establish contact with potential participants but have had no success therefore i have decided to post my objective here in hopes to gain participants though i am willing to take 20 participants who are interested i am seeking those who have been previously enrolled in data science course in their secondary high school career or post secondary if you are interested in participating or know of those who may be interested please do not hesitate to contact me for further information i am more than willing to set up a date time through either platform zoom and google meets and address any questions or concerns thank you for reading this lengthy post and happy holidays
r7cvi6,0,how important are publications in research scientist interviews sorry if this question is rather dumb but i just want to have hear some first hand account on how important are publications at top venues i e iclr neurips icml respective top conferences in cv nlp in research scientist including internship interviews at industrial labs how important are these compared to for e g leetcode behaviourial qns so on i understand the first foremost thing is probably whether there is a team fit let s assume there exists a team doing things roughly in the same area of the interviewee any comments are highly appreciated thanks
qviuar,0,post undergrad paths for machine learning i m an econ major graduating in the spring from a top 40 uni just found out i really like machine learning and ai i m not too tech savvy or particularly good at math but i can get by i m a really fast learner currently learning python econometrics has probably been my favorite class where can i go from here i graduate so soon should i be looking at grad programs in finance data science etc or should i just try to find a job immediately any particular tips on how to break into the finance world with machine learning what kinds of firms should i be looking at for jobs would really appreciate any advice or tips
r0ezps,0,discussion what is the biggest computer vision model ever opensourced i m wondering that everyone is telling that they trained a multi billion parameter model but none of them opensourced like fbs seer what is the biggest computer vision model ever released only ru dalle is in my mind
qv5nbi,0,interview with raquel urtasun of waabi and best of iccv papers on computer vision news dear all have a peek at computer vision news of november many articles about ai deep learning computer vision and more html5 version recommended pdf version dilbert on page 2 free subscription on page 74 enjoy
qvueo6,0,is microsoft cmt down for cvpr 2022 good god i m dying wtf i cannot access to the cmt official page for cvpr 2022 anyone else
rd609b,0,3d printing process parameters optimization hi i am doing my dissertation and i have to make a machine learning model to optimize 3d printing process parameters any 3d printing process the probelm is i can t seem to find any data online all i have is 2000 records of data of an l pbf process 4 predictor variables which is largely synthetic i have been trying to research if i can actually make an ml model based on so less data any help would be appreciated p s i know this is a machine learning subreddit but any leads regarding 3d printing process parameter dataset would also be appreciated thanks
qw0rxa,0,organizing ml reproducibility ‚Äì the reproducibility scale hey r ml a lot has been said ranted about reproducibility in ml it always seems like everyone agrees that reproducibility is important but still many projects are difficult or impossible to reproduce part of the reason is that reproducibility is hard to quantify and different people define it very differently i wrote a blog trying to provide a concrete scale for reproducibility with a practical rating system and a checklist that can help project creators maintainers validate the reproducibility of their work the scale consists of 5 criteria a 5 star system 1 code 2 configuration 3 data artifacts 4 environment 5 evaluation with specific requirements for each one i tried to order them in a growing level of complexity so that a 3 star project is lower effort but less reproducible than a 5 star project i also add a format for a reproducibility md file that can be filled out and added to projects to help the community assess the reproducibility of a project they want to use check it out here üëâ i know this might be controversial so i d honestly love to have an open discussion ‚Äì do you think i m missing something should the order be different would also love to get a pr to the format of reproducibility md you can do that here
rwmvn7,0,blogs on fundamentals of score based and diffusion probabilistic models this two part blog describes the theoretical fundamentals of score based models diffusion probabilstic models and their relationship it is written to be a coherent documentation of the theoretical developements in this new class of generative model rigorous mathematical proofs are excluded in order to make it more readable sharing it in case anyone finds it useful part 1 score base models part 2 diffusion probabilistic models
qqcrbh,0,intel optimized facebook dlrm with 8x speedup deep learning recommendation model intel leveraged sigopt s hyper parameter optimization platform to achieve a software speedup for dlrm additionally intel leveraged vertical split embedding lamb optimization and parallelizable data loaders
rh942h,1,random variable vs instances in ml stats lets say i am talking about the dataset used as input to a stats ml algorithm for example in this paper they have the passage x200b should this dataset be considered a sequence of iid random vectors or a instances of those vectors i assumed it was the first but then all of the people in this stats stackexchange discussion claims its the 2nd
r3hb3j,1,is there any overview of what specific layers groups of layers do i m in a strange situation i m working on a program that should help people to learn about neural networks by showing pretty much everything i can that goes on inbetween like the outputs of layers visualized if they look like images the data that goes through the layers and so on while i m not very experienced with creating nns myself i know this is a strange situation writing a program to help people to understand nns without understanding them myself but this is just how it is now i do this with tensorflow js so people can do it in the browser without having to write any code you can think of my program as a gui for tfjs in which you can drag drop layers around and that automatically generates graphs like the corresponding python code and the tf model in the browser and so on for example from the structure of the network in the gui this part works fine by now so people who know about nns can already use my program and train the network in the browser what i want to add is something like this this is a real albeit modified screenshot of my working program prototype my question is is there any overview of what groups of layers like some conv2d s followed by a maxpooling or something do so i can add bracket notations like that one that make it easier for people to understand what s going on since data can be very diverse i m aware that no single way of describing thouse groups will be correct all the time but i d be fine when it s correct in most default use cases i d really appreciate any links and as i ve said please assume i have no idea what nns really are because except for a very high level description of them i don t
qz3qtv,0,5 considerations for deploying machine learning models in production ‚Äì what did i miss i wrote a post about considerations for deploying machine learning models in production below are the considerations what did i not consider i know the first consideration seems obvious but i thought it was worth mentioning 1 use your laptop for development as a best practice consider your development environment first most data scientists or ml engineers invariably use their laptops for development testing or debugging code because of simplicity easy to access and install the latest ml libraries practitioners overwhelmingly prefer laptops over clusters for development we are spoiled by ides and syntax highlighted editors for good reason python developers like to customize their environments to match their staging environment with library dependencies using conda or python virtual environments ideally as a best practice if the same code developed on their laptop can run with minimal changes on a staging or production environment on the cluster it immensely improves the end to end developer productivity consider your laptop as a preferred choice of development environment with the possibility of extending or syncing your code to the cluster environment in the cloud consideration number 1 use your laptop for development as a best practice 2 training at scale and tracking model experiments unlike the traditional software development cycle the model development cycle paradigm is different a number of factors influence an ml model‚Äôs success in production first the outcome of a model is measured by its metrics such as an acceptable accuracy second achieving an accuracy that satisfies the business goal means experimentation with not only one model or ml library but many models and many ml libraries while tracking each experiment runs metrics parameters artifacts etc as vital as accuracy is so is a developer‚Äôs choice of ml libraries to experiment with third accuracy is directly linked to the quality of acquired data bad data results in a bad model data preparation feature extractions feature selection standardized normalized features and data imputations encoding are all imperative steps before the cleansed data lands into a feature store accessible to your model training and testing phase or inference in deployment fourth a choice of programming language that is not only familiar to your data team ‚Äî data analysts data scientists and ml engineers ‚Äî but also supported by many ml libraries employed during model experimentation and training phases python seems to be the de facto choice alongside a choice of a programming language is the choice of an ml framework for taming compute intensive ml workloads deep learning distributed training hyperparameter optimization hpo and inference ‚Äî all at horizontal scale ‚Äî from your laptop single node multiple cores to multiple nodes with multiple cores and finally the ability to easily deploy models in diverse environments at scale part of web applications inside mobile devices as a web service in the cloud etc consideration number 2 consider using model life cycle development and management platforms like mlflow dvc valohai weights biases or sagemaker studio and ray ray tune ray train formerly ray sgd pytorch and tensorflow for distributed compute intensive and deep learning ml workloads 3 managing machine learning features feature stores are emerging pivotal components in the modern machine learning development cycle as more data scientists and engineers work together to successfully put models in production having a singular store to persist cleaned and featurized data is becoming an increasing necessity as part of the model development cycle feature stores address operational challenges they provide a consistent set of data between training and inference they avoid any data skew or inadvertent data leakage they offer both customized capability of writing feature transformations both on batch and streaming data during the feature extraction process while training and they allow request augmentation with historical data at inference which is common in large fraud and anomaly detection deployed models or recommendation systems aside from challenges and considerations of putting models in production operationalizing ml data is equally important model accuracy depends on good data and feature stores help manage precomputed and cleansed features for your model training and production inference during model serving consideration number 3 consider feature stores as part of your model development process look to feast tecton sagemaker hopsworks and databricks for feature stores 4 deploying serving and inferencing models at scale once the model is trained and tested with confidence that it met the business requirements for model accuracy seven crucial requirements for scalable model serving frameworks to consider are framework agnostic a model serving elected framework should be ml framework agnostic that is it can deploy any common model built with common ml frameworks for example pytorch tensorflow xgboost or scikit learn each with its own algorithms and model architectures business logic model prediction often requires preprocessing post processing or ability to augment request data by connecting to a feature store or any other data store for validation model serving should allow this as part of its inference model replication some models are compute intensive or network bound as such the elected framework can fan out requests over to model replicas load balancing among replicas to support parallel request handling during peak traffic request batching not all models in production are employed for real time serving often models are scored in large batches of requests for example for deep learning models parallelizing these image requests to multiple cores taking advantage of hardware accelerators to expedite batch scoring and utilize hardware resources is worthy of consideration high concurrency and low latency models in production require real time inference with low latency while handling bursts of heavy traffic of requests the consideration is crucial for best user experience to receive millisecond responses on prediction requests model deployment cli and apis a ml engineer responsible for deploying a model should be able to use model server‚Äôs deployment apis or command line interfaces cli simply to deploy model artifacts into production this allows model deployment from within an existing ci cd pipeline or workflow patterns of models in production as ml applications are increasingly becoming pervasive in all sectors of industry models trained for these ml applications are complex and composite they range from computer vision to natural language processing to recommendation systems and reinforcement learning that is models don‚Äôt exist in isolation nor do they predict results singularly instead they operate jointly and often in four model patterns pipeline ensemble business logic and online learning each pattern has its purpose and merit machine learning engineers adopt two common approaches deploy these patterns of models in production one is to embed models into a web server and the other is to offload to an external service each approach has its own pros and cons with respect to the seven considerations above consideration number 4 look to seldon kfserving or ray serve for all these seven requirements 5 observing and monitoring model in production model monitoring often an overlooked stage as part of model development lifecycle is critical to model‚Äôs viability in the post deployment production stage it is often an afterthought at an ml engineer‚Äôs peril models have an afterlife of viability that viable life in production needs a constant watchful or sentinel eye in fact monitoring as a phase is simply a continuation of the model serving why consider model monitoring for a number of practical reasons this stage is pivotal let‚Äôs briefly discuss them data drifts over time as we mentioned above our quality and accuracy of the model depends on the quality of the data data is complex and never static meaning what the original model was trained with the extracted features may not be as important over time some new features may emerge that need to be taken into account for example seasonal data changes such features drifts in data require retraining and redeploying the model because the distribution of the variables is no longer relevant model concept changes over time many practitioners refer to this as model decay or model staleness when the patterns of trained models no longer hold with the drifting data the model is no longer valid because the relationships of its input features may not necessarily produce the model‚Äôs expected prediction hence its accuracy degrades models fail over time models fail for inexplicable reasons a system failure or bad network connection an overloaded system a bad input or corrupted request detecting these failures‚Äô root causes early or its frequency mitigates user bad experience or deters mistrust in the service if the user receives wrong or bogus outcomes systems degrade over load constantly being vigilant of the health of your dedicated model servers or services deployed is just as important as monitoring the health of your data pipelines that transform data or your entire data infrastructure‚Äôs key components data stores web servers routers cluster nodes‚Äô system health etc collectively these aforementioned monitoring model concepts are called model observability this step is now an acceptable imperative in mlops best practices monitoring the health of your data and models should never be an afterthought rather it ought to be part and parcel of your model development cycle consideration number 5 for model observability look to evidently ai arize ai arthur ai fiddler ai or whylabs ai thanks to this excellent pytorch reddit post for inspiring the formatting of this post
r9yjtq,1,minimum support hi all a basic question from me when working on a data set i ve been told the minimum support value is 0 3 what would this mean any help is greatly appreciated thanks
rab6lt,0,pytorch distributed training libraries what are the current options currently when i do distributed training i either use some manual implementation with torch distributed or just use pytorch lightning which also has some nice bonuses like fp16 training then there s also deepspeed however i m unsure if deepspeed is only beneficial for multi node training and when my model does not fit into gpu ram or if deepspeed would also bring benefits for standard data parallel multi gpu but single node training where the model would fit into gpu ram do any of the practitioners here have insights into this which other libraries frameworks am i missing
rulr8h,1,model consistently under forecasting i am working with time series data and trying to do forecasting for the next 90 days the model is an ensemble of prophet and arima the model does a pretty good job in terms of accuracy but it is almost always under forecasting consistently what suggestions would you have to fix that client is expecting some sort of ups and downs between actual and forecast
rdd5f9,0,automl conf 22 we are excited to announce that after 8 years of automl workshops at icml in 2022 we ll hold the first international conference on automl website amazing speakers anima anandkumar jeff clune chelsea finn timnit gebru julie josse alex smola co located with icml 3 days currently planned in person submission deadline feb 24 2022 great co organizers frank hutter mihaela van der schaar marius lindauer isabelle guyon please spread the word submit your best work and see you all at the conference
ruobs9,1,an interesting post in deep learning for beginners wild cats image classification using deep learning wild cats image classification using deep learning x200b
r8bbsb,1,requesting help for my situation hello i am an undergraduate researcher in my senior year of my computer science and engineering degree the research is focused mainly on computer vision i am currently working with pose estimation image segmentation and object tracking i have been working on this research for about 3 months i have had enough machine learning background to complete my tasks so far but the last 3 months have made me realize i have some gaps in my knowledge about 2 years ago i completed a deep learning course on udacity using pytorch it went through all of the basics for machine learning including a lot of the essential mathematics however i didn t apply what i learned for awhile after the course was over and i m a bit rusty on some of the details additionally i took an autonomous vehicles course at my university which included some basic introductions to computer vision i have also learned a lot over the past 3 months basically i m comfortable doing things like utilizing existing models to solve a specific problem and tuning models hyperparameters structure to boost performance however the mathematics and theory behind what i m doing is fuzzy in my memory and i would really like to rebuild my understanding from the ground up next semester i will be required to do some more advanced work using computer vision techniques to either fine tune an existing animal behavioral analysis network or finish building one that has already been started that will most likely benefit from some additional learning on my part and i would like to use my winter break a little over 3 weeks to do it my question is how can i best utilize this time i know 3 weeks isn t a ton of time but i want to be as efficient as possible with the time i have i know the coursera stanford machine learning course is highly recommended however i am concerned it is too broad introductory for my case as it covers a decent amount of topics i am already comfortable with on the other hand there is a good chunk of information in that course that will be great to fill in the gaps in my knowledge would it be better to do a more advanced course that focuses on computer vision specifically even though some of my fundamentals are missing rusty thanks
rtvqdl,1,any idea of how could one create a local and personalized ai pair programmer what kind of tools and algorithms could be required the title ¬øwhy because why not also considering possible limitations there could be conditions such as 1 the ai would be trained from scratch by the pc user 2 i can only work with one programming language maybe there s stuff i m missing here anyway i will be pleasured to read your insights i m personally more curious about whether one could create such program using modern tools like julia to work with modern and complex languages like rust to accelerate development in the most personalized way possible
r5pjtp,1,started learning machine learning today enrolled in andrew ng s course how to approach the course and get on with it how to get from theory to projects any particular sources etc for a beginner
rpirvh,1,machine learning use cases in telecom industry apart from churn prediction customer segmentation and anomaly detection how is data science used in the telecommunications sector are you aware of industry research use cases in that field
ro1ebu,0,redditors who work at big tech does 0 1 improvement matter to your company i have seen from time to time that when a paper is on the borderline of acceptance because of marginal improvement 0 1 0 2 accuracy of some sort the authors can always argue that a marginal but consistent improvement can be a large sum of revenue for companies that make billions of dollars ml in industry is not so simple although it is just a new method redeploying a whole pipeline can be very time consuming i want to ask people who are working at big tech does that improvement really matter are your companies willing to redeploy this improvement
r5ktec,0,which one do you prefer you had an idea you already implemented and tested it in pytorch now you want to test it on architecture a which is publicly available but in tensorflow would you 1 implement your idea on a s framework or 2 implement a on your framework would you change your answer if you want to further test your idea on a few more architectures
r8jea7,1,what specific ml technique should i use for predicting a country s religion through the attributes of its flag colors stripes crosses etc it s my 2nd year in the computer science field and machine learning already broke my brain just trying to learn it don t get me wrong the concept of machine learning is so cool and that s why i gambled myself into learning it and making something out of bit we are required to create any system that can predict something out of a dataset my idea was to have a dataset of countries with its flag and its attributes still trying find it somewhere online or i ll create it myself and predict the country s religion either nationally recognized or practice by the largest population however i can t seem to think of a technique that would help this project i m thinking of neural networks but it might be a bit difficult technique to start but i won t mind doing it as long as it is the best option that s why i m here asking the humble but powerful redditors to guide me peace
r6h3h8,0,i created an auto updating kaggle dataset that collects high frequency crypto market data updates daily 20 related trading notebooks i am happy to announce that i finally finished cleaning organizing creating baselines and developing an automated collection pipeline that collects minute by minute market data for cryptocurrencies it updates on kaggle every day and will keep doing so until the competition is over maybe even more the whole project took me a lot of time to develop and is not easy to maintain so please if you find this of value your feedback support is highly appreciated the competition as some of you know there is crypto forecasting competition is running on kaggle g research crypto forecasting in this competition we need to use machine learning for forecasting short term returns of popular cryptocurrencies such as bitcoin ether dogecoin we are provided a dataset of millions of rows of high frequency market data dating back to 2018 which we should use to build our models on once the submission deadline has passed the final score will be calculated over the following 3 months using live crypto data as it is collected auto updating kaggle dataset to make things more interesting i created an auto updating kaggle dataset that collects high frequency market data for multiple cryptocurrencies updates daily on kaggle available for anyone to play with also i also released 20 starter notebooks each demonstrating a different model or method for forecasting future returns this project was meant to be for the currently running crypto forecasting competition by g research however since it is publicly available i assumed many others would like to also have a look mimics real life better than typical datasets this is a unique opportunity to work in a much more real life setup than usual kaggle because the datasets update daily so if you mess up and overfit you see it tomorrow üòÇ anyway this is an ongoing project that is also beginner friendly since it is highly documented many more time series finance related notebooks will be released in the future so this can also serve as a first stop when studying time series analysis baselines starter notebooks cv model hyperparam optimization time series models feature engineering neural network starter ae analysis 1 lightgbm starter analysis 2 catboost starter written from scratch series agg xgboost starter supervised ae janestreet 1st ae janestreet 1st engineering transformer volatility features reinforcement learning ppo starter about the validation grouptimeseriessplit ‚è≥ in the making fork them as you please enjoy yourself auto updating full price datasets i created an up to today auto updating dataset which contains the full historical data for all assets of the competition so you can easily build models that utilize it the datasets are split to each asset since they are much heavier than the competition data the datasets have also been labeled as described in the competition overview and had been organized in a way that they are at the exact format of the competition data the goal of this is to provide a dataset that 1 contains the full history for each asset currently the competition data goes back to 2018 this dataset contains data from even earlier 2 auto updating daily due to the high volatility of the cryptocurrency market we should train our models on the most recent data available these datasets have a backend pipeline for collecting formatting and reuploading to kaggle they are scheduled to be updated daily every single day until the end of the competition 3 preprocessed the datasets had been ffilled to overcome any missing values issue that is present in the original competition dataset the datasets binance coin bitcoin cash bitcoin cardano dogecoin eos io ethereum ethereum classic iota litecoin monero maker stellar tron bonus dataset i ve also uploaded a dataset containing the most powerful source for predicting cryptocurrencies movement elon musk s twitter üòÇ it is simply an updated dataset of all elon musk s tweets üòÇ i must check if elon musk can help us win üëå you can play with it yourself here technical details about the data for every asset in the competition the following fields from binance s official api endpoint for historical candlestick data are collected saved and processed 1 timestamp a timestamp for the minute covered by the row 2 asset id an id code for the cryptoasset 3 count the number of trades that took place this minute 4 open the usd price at the beginning of the minute 5 high the highest usd price during the minute 6 low the lowest usd price during the minute 7 close the usd price at the end of the minute 8 volume the number of cryptoasset u units traded during the minute 9 vwap the volume weighted average price for the minute 10 target 15 minute residualized returns see the prediction and evaluation section of this notebook for details of how the target is calculated 10 weight weight defined by the competition hosts here 11 asset name human readable asset name indexing the dataframe is indexed by timestamp and sorted from oldest to newest the first row starts at the first timestamp available on the exchange which is july 2017 for the longest running pairs enjoy yourself and thank you in advance for your support this is not an easy system to maintain
qk6h7n,0,how does ai fit into the metaverse future what are popular applications and research topics of ai relevant for vr ar as an ml engineer i am interested in learning more about ml topics that are could be useful for building vr software and hardware this is meant to be an open ended question so all kinds of opinions and perspectives will be appreciated thanks
qrpx36,0,integrate your ml model with your favorite apps from a single python file hi all many here can build a simple machine learning model to predict whether a customer will churn if they get a nice pandas dataframe with customer data however it gets really complicated if you want this model deployed and integrated in production say a procedure as such 1 pull data from a new customer from shopify 2 predict for this customer whether they will churn 3 if we predict churn true 4 send a discount code to this customer with mailchimp suddenly we have to code data integrations etl pipelines deploy our original machine learning solution spin up an http server etc a huge pain indeed we are building a framework that takes care of exactly all the boring stuff described above we really believe this will bridge the gap between research and real world ml super excited to share this with all of you please let me know if you have comments or feedback
rqwf4e,1,classification and object detection question i have built an object detector that is detecting birds at my bird feeder it is trained only for birds in general and without any regard for species in order to classify my data i am running a classification model on another computer with the data retrieved from the database of the detections x200b i am wondering if this is counterintuitive should i be trying to train my object detection model yolov4 running on a jetson nano to also perform the object detections with respect to species or am i on point with developing a classifier on a more powerful pc to handle the species classification
rw3nba,1,ml at home hi dudes i would like to know if you do ml at home what do you do if the answer is yes do you compute in the cloud or on your pc
rrxtnj,1,question about ml approaches hello guys a bit of context i am currently searching for a way to estimate the sex m f and he age slice kid young adult adult old of a person based on a full body picture with mask 80 success would be enough i have found many approaches giving a sufficient result analyzing the face without mask but based on the current situation this is out of the question the result on masked people are obviously terrible question are there existing repositories out there solving this particular problem and if there are not as i am a beginner do you believe that problem could be solved by training a model i e will i be able to get a working solution after learning how the whole process works
rab8fe,1,discussion about applications of deeplearning i have to questions related to each other i have just completed my course in deeplearning without any background about ai or machine learning and i really understand it so when i made my model is that has any affect like do i have not enough informations when i design my models and the second thing as i told you i have just finished my course can anyone suggest to me a ink or page for a suggestions ideas or projects for the types of models application idea for ann cnn rnn som autoencoder rbm so i can expand my ideas about real life situation application
r7wdou,1,i need help understanding the meaning of the loss values of wgan with gradient penalty hey guys i am currently working on training a auxiliary classifier wasserstein gan with gradient penalty i based my implementation off of to which i added the auxiliary classifier functionality i have a model trained off of quite a few epochs of emoji images and i am now trying to filter out bad or vice versa good samples from the set of generated examples i understand that the best way to automatically do this is to utilize the trained discriminator and its loss values to evaluate the fakeness of the images in order to be able to select ones that are able to fool the discriminator now i understand that the discriminator using the wasserstein distance attempts to separate the loss values of fake samples as much as possible from the ones of real samples given that my discriminator output for a randomly chosen set of generated images looks something like the below table i think that the images with maximum or minimum values should be the highest and lowest graded examples 22 96732 12 37780 23 39248 44 45711 14 15668 11 19169 35 99777 9 65943 16 71531 9 35125 25 98240 4 36232 8 58446 24 78805 7 47653 19 14746 28 33695 30 18404 2 67499 8 63077 this should mean that my most fake and most real generated image are the samples with 44 4 or 2 67 but neither of these outliers are particularly more real looking than the other and both look much worse than randomly chosen examples see here how should i interpret these loss values would it make sense to go for a median loss value to get more of the good looking average loss images if so why would it make sense to run a 2 means clustering algorithm on the losses to try and separate realistic and fake samples anyways thanks in advance for your help
r6789x,1,how to autusave or resume training after google colab shutting down brutly i am new to google colab and have bought a colab pro member i found it can run around 24 36 hours but brutly shut down each time you know after that i have to retrain all my gan sometimes i would download the pkl file manually and upload it to retrain but it looks stupid is there a way to autosave pkl files in google drive during each gan training snapcount thanks a lot
