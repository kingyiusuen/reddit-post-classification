id,created_utc,title,selftext,subreddit_name
o74v9y,1624553413.0,[D] What is your preferred way to access columns in Pandas?,"In a Pandas Dataframe it is possible to access columns as a class member (if the column is also a valid Python identifier) or by a  'dict-like' interface.

What is your preferred way to access it?

[View Poll](https://www.reddit.com/poll/o74v9y)",MachineLearning
o74quc,1624553053.0,[D] How do I do Sentiment Analysis and Classification for an unlabelled dataset,"I am trying to implement sentiment analysis and classification on tweets of ABC organisation using Machine Learning.

&#x200B;

\> NOTE: The data set is unlabelled. I only have a bunch of tweets.

&#x200B;

for example:

&#x200B;

INPUT: ABC company provides the best and quick service.

&#x200B;

OUTPUT: Sentiment: POSITIVE, classification: SERVICE

&#x200B;

&#x200B;

I am stuck on how to implement this problem. I tried using pre-trained models for sentiment analysis like TextBlob and vadarSentiment but got an average result. I still know anything about how I will implement the classification part.

&#x200B;

I am stuck. Can anyone please help and provide insight on How can I tackle both problems.

Should I try any other pre-trained model (If yes, which one) OR

Should I label the dataset manually and train a model OR

anything else?",MachineLearning
o748gs,1624551561.0,Feasibility of building a reliable gun detection model [Discussion],"I'm trying to understand the barriers to building a computer vision model for detecting a gun in a person's hand in real time. I've played with a dozen or so repos for gun detection, and they all share the ability to detect a gun held directly in front of the camera (ideally in profile), however they perform poorly when tested with a typical security camera setup.

Is building a reliable model to detect a ""gun in hand"" possible and how would you approach it?

Would you optimize training data for a consistent camera angle and distance (ie 45 degrees and 20')? Would you include pose detection?
Finally, is there a framework that lends itself best for this application (ie YOLO v4)?


&#x200B;

https://preview.redd.it/gisld0z8o8771.png?width=1615&format=png&auto=webp&s=11236706372b83bacab8020bb4238944e324d746",MachineLearning
o7489r,1624551544.0,[D] Fuzzy Learning Vector Quantization for Classification,"Hello,

I'm in the middle of my final project creating classification model using Fuzzy Learning Vector Quantization [(Karayiannis, 1997)](https://www.researchgate.net/publication/3335719_An_integrated_approach_to_fuzzy_learning_vector_quantization_and_fuzzy_c-means_clustering). But i'm having a problem regarding turning it into a classification. Karayiannis created the method for clustering, but some people have been using it as a classification method by measuring the euclidean distance between test data and the final cluster which generated from the training phase.

The problem is, i couldn't find the perfect value for the initial fuzzy number (mi) and final fuzzy number (mf). Also, everytime i changed the initial cluster for the first iteration, the accuracy seems to change, but never reached past the point of 0.40 (40% accuracy). I couldn't seems to find the reason between low accuracy result.

If anyone could help me understanding the issue would be nice! I've been using human activities recognition dataset from UCI (UCI-HAR, available at kaggle). Adding PCA with n\_component is 200.",MachineLearning
o71xr9,1624544703.0,[R] Distilling the Knowledge from Normalizing Flows,"[Paper](https://openreview.net/pdf?id=fEPhiuZS9TV) (ICML workshop INNF+2021)

[Code](https://github.com/yandex-research/distill-nf)

Conditional normalizing flows demonstrate competitive performance in several vision and speech synthesis tasks. In contrast to other generative models, normalizing flows are latent variable models with tractable marginal likelihoods and stable training. However, these benefits usually come at the cost of inefficient model architectures, compared to feed-forward alternatives (e.g. VAEs, GANs).

This work allows us to significantly speed up the inference of normalizing flows by transferring knowledge from flow-based models to efficient feed-forward architectures.

[Overall scheme of the proposed knowledge distillation approach.](https://preview.redd.it/8ohgh2vqd7771.png?width=1331&format=png&auto=webp&s=86d22f1b0f121677b9d53387cb2fc5bef32c1e6d)",MachineLearning
o71awl,1624542720.0,[D] Transformer model which predicts probability distribution,"Hi everyone,

I'm working on a problem, where  I need to predict human activities in a time window.

 I have a context, which is a sequence of human activities (and objects) and I want to predict the human activities in the next 20 seconds. The prediction should be a distribution like (0.2, 0.6, 0.1, 0.05, ...) which can be interpretated as: The predicted time window consists of activity A (20\*0.2) 4 seconds, activity B (20\*0.6) 12 seconds, etc.

So far, I have fed the activities in the form of word embeddings into various neural networks (e.g. LSTMs) and used Softmax to give me probabilities. That has worked well so far.

I was now wondering if there are pre-trained transformer models that I can use to achieve something similar. I have already found multi-label classification models, but these always have a target vector consisting of 0 or 1 per class and are not able to predict a distribution like I want.

I am grateful for any advice!",MachineLearning
o70swj,1624541059.0,[R] Improving Genomic Discovery with Machine Learning,"Original source:  [https://ai.googleblog.com/2021/06/improving-genomic-discovery-with.html](https://ai.googleblog.com/2021/06/improving-genomic-discovery-with.html)

&#x200B;

Similar AI / ML / Data Science articles in a form of a newsletter [here](https://thereshape.co/join?utm_source=reddit_ml_3).",MachineLearning
o70oyn,1624540689.0,"[R] Google Survey Explores Methods for Making DL Models ‘Smaller, Faster, and Better’","Researchers from Google conduct a survey on how to make Deep Learning models smaller, faster, and better. The team focuses on core areas of model efficiency, from modelling techniques to hardware support, and open-sources an experiment-based guide and code to help practitioners optimize their model training and deployment.

Here is a quick read: [Google Survey Explores Methods for Making DL Models ‘Smaller, Faster, and Better’.](https://syncedreview.com/2021/06/24/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-48/)

The paper *Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better* is on [arXiv](https://arxiv.org/abs/2106.08962).",MachineLearning
o70afq,1624539266.0,[R] Seminal papers on machine learning for audio processing,"Anyone have recommendations for seminal/interesting papers or researchers in the field of machine learning for audio processing? Also papers that are not explicit on audio processing, but that might also be helpful!

Thanks!",MachineLearning
o7092t,1624539123.0,[P] Advanced Python + NLP introduction course,"We are publicly releasing all class material for our **Advanced Python + NLP introduction** course at the Budapest University of Technology and Economics.

Feel free to share it. All feedback is welcome.

[Course page on Github](https://github.com/bmeaut/python_nlp_2021_spring)",MachineLearning
o6ztc3,1624537464.0,[Research][Project] How to read more research papers?,"In this article, I am sharing the best tips and practical tools I use daily to simplify my life as a research scientist to be more efficient when looking for interesting research papers and reading them

[https://www.louisbouchard.ai/research-papers/](https://www.louisbouchard.ai/research-papers/)

Please, let me know if you use any other tools that I did not mention in my article that could be of great addition.

Quick summary of the tools discussed:

* [42 Papers](https://42papers.com/)
* [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/)
* [Papers With Code](https://paperswithcode.com/)
* [Crossmind](https://crossminds.ai/video/swin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80/)
* [CatalyzeX](https://www.catalyzex.com/)
* [Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew)
* [What’s AI](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg)
* [Letitia](https://www.youtube.com/channel/UCobqgqE4i5Kf7wrxRxhToQA)
* [Two Minute Papers](https://www.youtube.com/user/keeroyz)",MachineLearning
o6zc4f,1624535619.0,"[D] What do you think of ""Boundary Matching Networks"" - Trimming videos on actions","I have been looking *""Temporal Action Localization"".* These are methods that automatically trim longer videos into smaller videos, where the smaller video solely contains a specific action that happens. Additionally, they can also provide a class label for the action that is happening in the trimmed video.

Example: A 1 minute video of a driveway filled with snow, where at some point a person starts to shovel snow for 5 seconds, gets trimmed to just the 5 second video where a person is shoveling snow.

&#x200B;

While looking at all the different methods  available, I saw that the current ""most popular"" one already dates back from 2019. Namely: [Boundary Matching Network](https://paperswithcode.com/paper/bmn-boundary-matching-network-for-temporal), I also came across some other (more recent) methods like [MUSES](https://github.com/xlliu7/MUSES) and [Temporal Context Aggregation Network](https://github.com/qingzhiwu/Temporal-Context-Aggregation-Network-Pytorch) (TCAN).

&#x200B;

When I'm looking at these methods, they all seem fairly complex (I do not mean that I cannot understand their workings, I mean that they generally require a complex architecture). TCAN claims that it only needs 201ms to process a 9 **minute** video clip (on a 1080Ti). This sounds pretty fast to me!

&#x200B;

What I would like to have some input on:

\- Are there any other methods that I should consider for temporal action localization

\- Does anybody have experience with using this on fine-grained actions? Example: Actions within a domain -- A soccer player running on the field should not be trimmed, but a soccer player performing a tackle **or** a soccer player shooting the ball should be trimmed. (AFAIK this all just depends on how we label the training data of what actions are important).

\- I couldn't find any Google/AWS/IBM APIs that allow you to do a task like this, does anybody know whether they do exist, or are my findings correct?",MachineLearning
o6xwtr,1624529253.0,[P] Live Demo: Analyze Product Hunt Data Using Plain English Questions (NL to SQL),"Hello everyone

As part of our Product Hunt launch we just released a live demo that lets you explore and analyze Product Hunt data using plain English questions - which get automatically translated into SQL using a Semantic Parser that we've built.

You could ask for instance:

* What were the top 10 posts in Crypto this year
* What's the average number of votes for Analytic posts?
* Which weekday has the most posts?
* Show me the top 10 Hunters in Analytics

Live Demo: [https://app.veezoo.com/chat?id=veezoo-producthunt&demo=true](https://app.veezoo.com/chat?id=veezoo-producthunt&demo=true)

Product Hunt post: [https://www.producthunt.com/posts/veezoo](https://www.producthunt.com/posts/veezoo)

&#x200B;

Looking forward to hearing your feedback!",MachineLearning
o6x88y,1624525936.0,[D] Deep clustering survery," Hi!

<new here>

I am performing image (deep) clustering survey and I am trying to pinpoint impactful papers from recent years.

I am aware of the great survey [here](https://github.com/zhoushengisnoob/DeepClustering) but I have a hard time discriminating which paper is impactful and which isn't. Checking number of citations is helping, but I was hoping the community here could pinpoint me to important papers from the field.

&#x200B;

Thanks :)",MachineLearning
o6wggh,1624522150.0,"[R] Finally, Actual Real images editing using StyleGAN","In the last years I have been interested in different technologies that enable facial editing. One of the promising directions was editing faces using StyleGAN. Nevertheless, each method that came up while succeeding in editing a small number of celebrities, always failed to edit my face and many of the faces I wanted to edit. I assumed the problem was with an inherent bias inside StyleGAN and decided to wait for its third version which just came up! See [https://nvlabs.github.io/alias-free-gan](https://nvlabs.github.io/alias-free-gan). So excited about the new opportunities it will bring to the world of graphics and editing. In the meanwhile, a very interesting paper called “Pivotal Tuning for Latent-based editing of Real Images” was released. With many papers stating that they can edit real images, I was not much optimistic about this paper as well. But boy was I wrong. For the first time, I could actually edit facial images using StyleGAN! The authors provide an inference notebook which I used to edit 2 Machine Learning legends. See the results by yourself…

The notebook: [https://colab.research.google.com/github/danielroich/PTI/blob/main/notebooks/inference\_playground.ipynb](https://colab.research.google.com/github/danielroich/PTI/blob/main/notebooks/inference_playground.ipynb)

The github repository: [https://github.com/danielroich/PTI](https://github.com/danielroich/PTI)

What do you think, Will this paper and the advances in the field will affect our lives? (Hollywood, DeepFake, etc) So much potential

&#x200B;

&#x200B;

[Younger](https://preview.redd.it/fdtndqla96771.jpg?width=1024&format=pjpg&auto=webp&s=3bcd679eea8c775a9313c339891c661b562f908b)

[Original Image](https://preview.redd.it/hn4rkqla96771.jpg?width=1024&format=pjpg&auto=webp&s=96a0c2568145779879601a9754a50335dd60b0ca)

[Smiling](https://preview.redd.it/60qjkqla96771.jpg?width=1024&format=pjpg&auto=webp&s=84382d9b1f79dabed63017979a534634a3e5362b)

&#x200B;

[Younger](https://preview.redd.it/35s7l8xe96771.jpg?width=1024&format=pjpg&auto=webp&s=d56d0f26ff5596c34ac4a20a8726bf92a68e831d)

[Original Image](https://preview.redd.it/ypdxr9xe96771.jpg?width=1024&format=pjpg&auto=webp&s=897bee31c23cd0944e0155f7f7f5f6bf64f468ec)

[Rotation](https://preview.redd.it/jlfslgxe96771.jpg?width=1024&format=pjpg&auto=webp&s=2179ba199da6e53b5cb5c1995679547c350feca2)",MachineLearning
o6vj1p,1624517710.0,[R] Revisiting Deep Learning Models for Tabular Data,"Hi! We introduce our new paper ""Revisiting Deep Learning Models for Tabular Data"" and the ""rtdl"" package that enables easy access to the main models from the paper.

Paper: [https://arxiv.org/abs/2106.11959](https://arxiv.org/abs/2106.11959)
Code:  [https://github.com/yandex-research/rtdl](https://github.com/yandex-research/rtdl)

[FT-Transformer](https://preview.redd.it/sn941byiu5771.png?width=2984&format=png&auto=webp&s=f1279cb072dd503c3ff9ff84ad667ef7c37e0f6d)

TL;DR:
\- we show that two simple architectures can serve as strong baselines for Tabular Deep Learning: (1) a ResNet-like architecture and (2) FT-Transformer - an adaptation of the Transformer architecture for tabular data
\- the problems where Gradient Boosting dominates should be prioritized when developing DL solutions targeted at beating Gradient Boosting",MachineLearning
o6u34b,1624511183.0,[R] The Dimpled Manifold Model of Adversarial Examples in Machine Learning,"Very, very interesting new work by Adi Shamir et al: [https://arxiv.org/abs/2106.10151](https://arxiv.org/abs/2106.10151)

It proposes a new mental model for why adversarial examples exist. The central claim is that adversarial examples come from the fact that we fit high-dimensional decision boundaries to low-dimensional images. This leaves a lot of space for the adversarial examples to exist perpendicularly from the true location of the low-dimensional object (the natural image).

More precisely: the decision boundary is like a thin, horizontal sheet of metal that is being bent up and down to fit clusters of training examples. This creates dimples in the sheet around where the training examples lie. The sheet can be thought of as the space in which natural images exist; the dimples go into the extra dimensions because we represent those natural images in a very high-dimensional form (RGB images).

Adversarial examples? Well, these are just unnatural images above and below the sheet , i.e. off the manifold of natural image.

Robustness accuracy trade-off? This just comes from the fact that you have to bend the sheet way more out of shape than normal to fit adversarial examples, so you end up missing the details/small clusters.

Being able to fit a model with good clean test-set performance by training on adversarial examples with target labels? That comes from the fact that you end up recreating the manifold by moving around the labels.

Humans being insensitive to adversarial examples? They have just learned to do projections into the low-dimensional space, so anything that lives above/below the dimple gets projected onto the dimple.

This mental model seems to provide a lot of compelling explanations and there is good experimental work. What do you think about it?",MachineLearning
o6txxi,1624510585.0,[N] Facebook AI Releases ‘HuBERT’: A New Approach For Learning Self-Supervised Speech Representations,"Many AI research projects have been striving to improve their ability to detect and interpret speech merely by listening and engaging with others, much like babies learn their first language. This needs not just assessing what someone says but also a variety of other clues from how those words are delivered, such as speaker identification, emotion, hesitation, and interruptions. Furthermore, the AI system must recognize and interpret noises that overlap with the speech signal, such as laughter, coughing, background vehicles, or bird tweeting, to fully comprehend a situation as a person would do.

Article: [https://www.marktechpost.com/2021/06/23/facebook-ai-releases-hubert-a-new-approach-for-learning-self-supervised-speech-representations/](https://www.marktechpost.com/2021/06/23/facebook-ai-releases-hubert-a-new-approach-for-learning-self-supervised-speech-representations/)?

Paper: https://arxiv.org/pdf/2106.07447.pdf

Github: [https://github.com/pytorch/fairseq/tree/master/examples/hubert](https://github.com/pytorch/fairseq/tree/master/examples/hubert)

FB Blog: https://ai.facebook.com/blog/hubert-self-supervised-representation-learning-for-speech-recognition-generation-and-compression",MachineLearning
o6moi5,1624484468.0,How to decouple classifier output from associated risk [D],"Hi all, I have the following problem and I hope you can help me. I have a classifier that needs to be retrained every once in a while. As the model take action on a stream of payments, every time we perform a retrain, we need to recalibrate all the thresholds of the business logic. I would like to decouple the classifier output score from the risk associated, in order to provide always the same risk associated with a score and avoiding the need of recalibrating every time. The only thing that comes to my mind is to stacking my model with k-means and fixing once for all the number k, in order to create buckets of risk. I would like to know what is the proper way to solve this problem in your experience/opinion?",MachineLearning
o6mjyi,1624484078.0,"[D] Image search, chatbot and chemical structure demo","Hi all,  we recently updated our demo page showcasing examples of vector search for image search, chatbot and chemical structures using Milvus open-source software.  I'm looking for feedback, suggestions or questions you may have to make this relevant for any applications or use cases you may be developing.  Thank you all, I look forward to hearing your feedback!

[Demo Page](https://zilliz.com/milvus-demos)

[GitHub Repo](https://github.com/milvus-io/)",MachineLearning
o6m9bf,1624483168.0,Randon forest - can I identify the best tree? [R],"So I have a large database of patients with long follow-up and high mortality. I ran random forest and obviously it performs better than conventional clinical score for mortality prediction. In addition to area under roc curve and importance of variables, can I identify the best tree that predicts the best the outcome?

If not, what other tangible result could I get using RF? I need more materials to add to a paper I plan on writing.
Many thanks!",MachineLearning
o6kjin,1624477941.0,[R] Should I submit a critique paper to CVPR?,"I have a critique paper that pretty convincingly critiques papers one of which was published in CVPR.

Should I submit my critique paper to CVPR?

More context: the papers I am critiquing mostly introduced very marginal changes to existing methodology and applied it to an Affective AI task. I critique the dataset (show there is large dataset bias) and show several methodological flaws (e.g. significant random errors unreported).",MachineLearning
o6kguq,1624477728.0,[R] The Difference Between a Blurring Matrix and a PSF in Image Reconstruction,"I'm working on a research project related to deblurring images and I don't fully understand the difference between a blurring matrix and a PSF. I understand that to apply them to an image you use two different operators, but why is that, what is the difference between them. Is a PSF not a matrix? How are they related to each other? Do they affect the image the same way?",MachineLearning
o6j8qf,1624474038.0,[R] Alias-Free GAN,"[https://nvlabs.github.io/alias-free-gan/](https://nvlabs.github.io/alias-free-gan/)


Abstract:

We observe that despite their hierarchical convolutional nature, the synthesis process of typical generative adversarial networks depends on absolute pixel coordinates in an unhealthy manner. This manifests itself as, e.g., detail appearing to be glued to image coordinates instead of the surfaces of depicted objects. We trace the root cause to careless signal processing that causes aliasing in the generator network. Interpreting all signals in the network as continuous, we derive generally applicable, small architectural changes that guarantee that unwanted information cannot leak into the hierarchical synthesis process. The resulting networks match the FID of StyleGAN2 but differ dramatically in their internal representations, and they are fully equivariant to translation and rotation even at subpixel scales. Our results pave the way for generative models better suited for video and animation.


paper:
[https://nvlabs-fi-cdn.nvidia.com/alias-free-gan/alias-free-gan-paper.pdf](https://nvlabs-fi-cdn.nvidia.com/alias-free-gan/alias-free-gan-paper.pdf)",MachineLearning
o6hs1z,1624469659.0,[D] 5 minute paper digest: Towards Real-World Blind Face Restoration with Generative Facial Prior (GFP-GAN) by Xintao Wang et al,"Have you ever tried restoring old photos? It is a long tedious process since the degradation artifacts are complex, and the poses and expressions are diverse. Luckily the authors from ARC Tencent came up with GFP-GAN - a new method for real-world blind face restoration that leverages a pretrained GAN and spatial feature transform to restore facial details with a single forward pass.

Read the [full paper digest](https://t.me/casual_gan/54) (reading time \~5 minutes) to learn about the degradation removing module, generative face prior, and channel-split feature transform.

Meanwhile, check out the paper digest poster by [Casual GAN Papers](https://t.me/casual_gan)!

[GFP-GAN](https://preview.redd.it/hrb8mr1pw1771.png?width=975&format=png&auto=webp&s=29e7cbc4621c7f532300f0d2158827f2094c6237)

\[[Full Explanation Post](https://t.me/casual_gan/54)\] \[[Arxiv](https://arxiv.org/pdf/2101.04061.pdf)\] \[[Code](https://github.com/TencentARC/GFPGAN)\]

More recent popular computer vision paper breakdowns:

>[CIPS](https://t.me/casual_gan/51)
[SimSwap](https://t.me/casual_gan/52)
[GANs N' Roses](https://t.me/casual_gan/53)",MachineLearning
o6hh3i,1624468758.0,Most Effective Algorithms For Multi-Output Classification Tasks [Discussion],"

Based on benchmark datasets what algorithms perform the best in an array of multi-output classification problems? I have found limited research papers exploring a diverse spread of algorithm families on multioutput problems.

I would like to guess the the best in the industry is a convolutional neural network or simply a deep neural network. All the same I would like some input! Thank you.",MachineLearning
o6h9vb,1624468202.0,[D] How to do multi-task learning intelligently,"We have a new article out, [How to Do Multi-Task Learning Intelligently](https://thegradient.pub/how-to-do-multi-task-learning-intelligently/), that may be of interest to you - it covers the concept of Multi-Task Learning, and provides a summary of some cool recent papers about it (AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning , End-to-End Multi-Task Learning with Attention , and Which Tasks Should Be Learned Together in Multi-task Learning?).

Would love feedback!",MachineLearning
o6f0bw,1624461765.0,[R] Facebook AI & Mila Propose ALMA: Anytime Learning at Macroscale,"A research team from Facebook AI Research and Mila - McGill University explores deep learning model accuracy versus time trade-offs in anytime learning, which they term Anytime Learning at Macroscale (ALMA). The team evaluates various models to gain insights on how to strike different trade-offs between accuracy and time to obtain a good learner.

Here is a quick read: [Facebook AI & Mila Propose ALMA: Anytime Learning at Macroscale.](https://syncedreview.com/2021/06/23/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-47/)

The paper *On Anytime Learning at Macroscale* is on [arXiv](https://arxiv.org/abs/2106.09563).",MachineLearning
o6dxz1,1624458587.0,"[D] Should we trust cloud ML platforms (aws, azure, gcp)?","Hi all,
I am in the early stages of a deep learning project with medical images and videos. Due to the large size and quantity of these, the use of cloud computing platforms such as AWS, Azure, GCP is imposed.

However, in my team we have the well-founded suspicion that at least google and probably the others are *very interested in our data*. For this reason we are reluctant to use them.

Do any of you know how are the contractual policies of these big platforms with the data deposited in them? Should we trust them? Are some of them more trustable than others?

Thanks",MachineLearning
o6d02g,1624455520.0,[N] Open Catalyst Challenge: Using AI to Find Catalysts for Renewable Energy Storage,"[https://opencatalystproject.org/](https://opencatalystproject.org/)

&#x200B;

>The  Open Catalyst Project is a collaborative research effort between  Facebook AI Research (FAIR) and Carnegie Mellon University’s (CMU)  Department of Chemical Engineering.The  aim is to use AI to model and discover new catalysts for use in  renewable energy storage to help in addressing climate change.  Scalable  and cost-effective solutions to renewable energy storage are essential  to addressing the world’s rising energy needs while reducing climate  change.
>
>As we increase our  reliance on renewable energy sources such as wind and solar, which  produce intermittent power, storage is needed to transfer power from  times of peak generation to peak demand. This may require the storage of  power for hours, days, or months.
>
>One  solution that offers the potential of scaling to nation-sized grids is  the conversion of renewable energy to other fuels, such as hydrogen. To  be widely adopted, this process requires cost-effective solutions to  running chemical reactions.
>
>An  open challenge is finding low-cost catalysts to drive these reactions at  high rates. Through the use of quantum mechanical simulations (density  functional theory), new catalyst structures can be tested and evaluated.  Unfortunately, the high computational cost of these simulations limits  the number of structures that may be tested.
>
>The  use of AI or machine learning may provide a method to efficiently  approximate these calculations, leading to new approaches in finding  effective catalysts.
>
>To enable the broader research community to participate in this  important project, we are releasing the  [Open Catalyst Dataset](https://github.com/Open-Catalyst-Project/ocp/blob/master/DATASET.md)  for training ML models. The dataset contains 1.2 million molecular  relaxations  with results from over 250 million DFT calculations. In  addition to the data, baseline models and code are provided on [our Github page](https://github.com/Open-Catalyst-Project/ocp). View the [leaderboard](https://opencatalystproject.org/leaderboard_is2re.html) to see the latest results and to submit your own to the [evaluation server](https://eval.ai/web/challenges/challenge-page/712/overview)! Join the  [discuss forum](https://discuss.opencatalystproject.org/) to join the discussion with the community and ask any questions.

&#x200B;",MachineLearning
o6ce13,1624453412.0,[D] Machine Learning Interview book by Huyen Chip.,"[https://huyenchip.com/ml-interviews-book/](https://huyenchip.com/ml-interviews-book/)

I have just skimmed part of the book but it looks very good and contains lots of insight from a recruiter point of view that I would never know otherwise and is applicable to more than just ML interview IMO. What do you think?

Quote from the Github page:

This book is the result of the collective wisdom of many people who  have sat on both sides of the table and who have spent a lot of time  thinking about the hiring process. It was written with candidates in  mind, but hiring managers who saw the early drafts told me that they  found it helpful to learn how other companies are hiring, and to rethink  their own process.

The book consists of two parts. The first part provides an overview  of the machine learning interview process, what types of machine  learning roles are available, what skills each role requires, what kinds  of questions are often asked, and how to prepare for them. This part  also explains the interviewers’ mindset and what kind of signals they  look for.

The second part consists of over 200 knowledge questions, each noted  with its level of difficulty -- interviews for more senior roles should  expect harder questions -- that cover important concepts and common  misconceptions in machine learning.",MachineLearning
o6c42r,1624452454.0,[D] Paper Explained - XCiT: Cross-Covariance Image Transformers (Full Video Analysis),"[https://youtu.be/g08NkNWmZTA](https://youtu.be/g08NkNWmZTA)

After dominating Natural Language Processing, Transformers have taken over Computer Vision recently with the advent of Vision Transformers. However, the attention mechanism's quadratic complexity in the number of tokens means that Transformers do not scale well to high-resolution images. XCiT is a new Transformer architecture, containing XCA, a transposed version of attention, reducing the complexity from quadratic to linear, and at least on image data, it appears to perform on par with other models. What does this mean for the field? Is this even a transformer? What really matters in deep learning?

&#x200B;

OUTLINE:

0:00 - Intro & Overview

3:45 - Self-Attention vs Cross-Covariance Attention (XCA)

19:55 - Cross-Covariance Image Transformer (XCiT) Architecture

26:00 - Theoretical & Engineering considerations

30:40 - Experimental Results

33:20 - Comments & Conclusion

&#x200B;

Paper: [https://arxiv.org/abs/2106.09681](https://arxiv.org/abs/2106.09681)

Code: [https://github.com/facebookresearch/xcit](https://github.com/facebookresearch/xcit)",MachineLearning
o6bzvd,1624452022.0,[D] Purchasing a $40K gpu server for a new lab,"I was tasked with finding our lab a good GPU server that is **built by an outside company** (I know it is much cheaper and more cost-effective to build it ourselves. Unfortunately the outside assembly part is a requirement).

So far I found Lambda Labs, ThinkMate and System76, but I'm sure there are more. Based on [Tim Dettmers' helpful blog](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/), I think we should combine 67% RTX 3080 and 33% RTX 3090, but I welcome other opinions.

Do you have a recommendation for any company that builds small (\~$40K, servicing 2-5 students working mostly on CV and generative models) GPU servers, and how should such a server look like?",MachineLearning
o6b9sr,1624449298.0,[D] Make use of validation data ( without label ) when predicting values.,"Lets suppose a model where:
\- I have a train dataset (labeled) which I can use freely
\-  Can only predict values in batch ( you have to feed it N validation tests and the model will attribute a label to all of them ), which means the model cannot predict each validation case, but need to predict all of them at once ( taking into consideration their values but OBVIOUSLY not their label - which may be unknown).



Would you guys consider this model biased? I really would like a discussion about this or maybe even some literature references. I honestly dont think this should be considered biased.",MachineLearning
o6ayi6,1624447948.0,"[D] How many ideas do you ""try out"" before finding something that's actually pursuable to something that's publishable?","As a master's student who's just now starting to take on research projects on my own, I've always heard that one of the most important qualities to doing research (in machine learning) is to ""try ideas out."" Many people have given me this advice and have told me that it's the same advice their supervisors or seniors gave them.

I'd follow accordingly and think of ideas that I could try (e.g., performing error analysis and trying out a new modeling approach) but for the past 4-5 months it's usually been ending up in results that are not pursuable (performance is mediocre and/or there aren't any surprising/interesting points to analyze) and definitely not publishable.

I'm starting to wonder if I'm even approaching research correctly. Btw, before anyone says it, I _have_ been going to my PI for help. Many of the ideas that I've tried out were his, but he's more of an entrepreneur than a researcher and has been out of touch with the current research landscape for a while.

Any tips or opinions are appreciated. Thanks.",MachineLearning
o6awsa,1624447756.0,[D] Oversampling for Multivariate Time Series," Currently working on oversampling for time series and have looked into methods like SPO(Structure-Preserving Oversampling) and OHIT, but both of them are univariate/working only for time series with one feature. Are there any oversampling techniques for multivariate time series (I am unable to find any)? Also, please suggest some papers that I can look into.",MachineLearning
o6akl5,1624446301.0,[D] Spacy Transformers wrapper for newer transformer model,"Hello All,

I am working with Spacy Transformers, which is essentially a wrapper for huggingface transformers. It already supports few transformers model out of the box, My question is how can I use this for other transformer models within spacy?

If you need any other input from me, please let me know.

Your help is really appreciated, thank you for you time.",MachineLearning
o6a3lz,1624444096.0,Is it possible for a model to increase overfitting when seeing new training examples for the first time? [D],"So I was running a CNN over a large image dataset (94k images) and I was concerned about overfitting, so I implemented early stopping. But if I set 1 epoch to be all the training data, I found it overfit a lot before early stopping had a chance to stop it. So I reduced the epoch steps to about 10k so it would check after each time. I found that even after 3 epochs, the early stopping trigger when it measured that the validation MSE was increasing(even with a patience of 2 epochs).

But 3 epochs is only 30k samples, so the model hasn't even seen all the data points.  It's being given new data points and some how the validation MSE is increasing, even as the training MSE is decreasing.

If I were training over the same training data many times, I understand why the model would overfit, but I don't see how giving it new training examples is reducing its ability to generalize. My guess is one of two things is happening:

1. The model overfitting isn't increasing, and it just got lucky on the first run somehow.

2. The model is overfitting due to some other purposes.

The validation set I'm using is the same each epoch, so that shouldn't be an issue. Has anyone experienced this before?

Update: I just did another test, and the validation MAE is way better than the training MAE in the first epoch, but stays roughly consistent and the training MAE eventually overtakes it. Similar situation with the MSE.",MachineLearning
o69ao4,1624440154.0,[D] Is there any feature for ranking most popular arXiv.org papers?,"It would be useful to see which papers were most read or downloaded in [arxiv.org](https://arxiv.org), which has been a de-facto publishing platform for CS-related research. So I was wondering if there was any portal or platform that ranked popular [arxiv.org](https://arxiv.org) submissions (or maybe there's some feature in [arXiv.org](https://arXiv.org) itself that I don't know about). If there isn't any feature of this sort, then perhaps it should be?",MachineLearning
o68pxh,1624437244.0,NLP Feedback System [R],"For eg, if we are provided with an NLP sentiment analysis model that has already been trained. like if we provide this model with some word like “Excellent”, it knows that this particular word is to be classified as positive. Now, if we provide this model with a new set of words that might contain new as well as words that the model already knows, but with some different labels. for eg, the excellent word which the model knows to be positive is labelled as negative in this new set. Then can the model adapt and change?
Is there any work done similar to this or can someone explain to me a way to achieve this?",MachineLearning
o68mxa,1624436800.0,[N] AI Researchers From MIT Lincoln Lab Developed RIO (Reconnaissance of Influence Operations) System That Would Counter The Spread Of Disinformation By Making Use Of Machine Learning,"Disinformation manipulates accurate information deliberately to mislead the masses, and the spread of such information is not new. It has been in practice for quite some time, right from the imperial war propaganda and now in this digitalized world. Social media has brought with it its perils, and one of them is its usage to spread false information. It has the power to change opinions altogether, for example, the entire dynamics of the public elections. However, it is now being claimed that artificial intelligence systems could efficiently detect and simultaneously counter the spread of this disinformation on digital platforms. The Reconnaissance of Influence Operations (RIO) program built at the MIT Lincoln Laboratory promises to do just the same. It would automatically detect and analyze all the social media accounts used to spread disinformation across a network.

[https://www.marktechpost.com/2021/06/23/ai-researchers-from-mit-lincoln-lab-developed-rio-reconnaissance-of-influence-operations-system-that-would-counter-the-spread-of-disinformation-by-making-use-of-machine-learning/](https://www.marktechpost.com/2021/06/23/ai-researchers-from-mit-lincoln-lab-developed-rio-reconnaissance-of-influence-operations-system-that-would-counter-the-spread-of-disinformation-by-making-use-of-machine-learning/)

Paper: https://www.pnas.org/content/118/4/e2011216118",MachineLearning
o68dmg,1624435477.0,[D] Why is LSTM/GRU not mentioned in time series classification state-of-the-art review?,"I'm reading up on state of the art of time series classification, and I just read [Deep learning for time series classification: a review](https://arxiv.org/abs/1809.04356) (Fawaz et al, 2019) which summarizes and compares different modern deep learning approaches. However it doesn't mention LSTM or GRU, which surprises me a lot, since they would be among the first approaches you'd read about in any recent introductory textbook or course on sequence modelling. I cite the only section that mentions RNN:

>""Another popular type of architectures for deep learning models is the Recurrent Neural Network (RNN). Apart from time series forecasting, we found that these neural networks were rarely applied for time series classification which is mainly due to three factors: (1) the type of this architecture is designed mainly to predict an output for each element (time stamp) in the time series (Längkvist et al., 2014); (2) RNNs typically suffer from the vanishing gradient problem due to training on long time series (Pascanu et al., 2012); (3) RNNs are considered hard to train and parallelize which led the researchers to avoid using them for computational reasons (Pascanu et al., 2013).""

Do you agree? And do you think LSTM and GRU are becoming obsolete with the emergence of convolutional approaches?",MachineLearning
o672vz,1624429203.0,"[D] I’m Ilya, Team Principal of Acronis SIT Autonomous racing team, current N1 in Roborace – Ask Me Anything!","Hi Reddit!

SIT Autonomous is a machine intelligence consulting firm, based at the Schaffhausen Institute of Technology (SIT) in Switzerland. We also have an autonomous racing team – Acronis SIT Autonomous – of which I am Team Principal. If you’ve heard of Roborace, the world’s first extreme competition of teams developing self-driving AI for autonomous vehicles, you’ve probably heard about us.

**Tomorrow**, **June 24, from 4 pm to 7 pm CEST (10 am EDT to 1 pm EDT)**, I’ll be answering all your questions about ML in self-driving cars and autonomous racing. Already eager to ask? Send me your questions now so I can be sure to answer them all!

**The discussion is happening in** r/SelfDrivingCars **:** [https://www.reddit.com/r/SelfDrivingCars/comments/o484jg/im\_ilya\_team\_principal\_of\_acronis\_sit\_autonomous/h2fsko0/?context=3](https://www.reddit.com/r/SelfDrivingCars/comments/o484jg/im_ilya_team_principal_of_acronis_sit_autonomous/h2fsko0/?context=3)

See you there!",MachineLearning
o644ei,1624417267.0,[D] How are computational neuroscience and machine learning overalapping?,"Hi, I am an undergrad with a background in neuroscience and math. I have been very much interested in the problem of AGI, how the human mind even exists, and how the brain fundamentally works. I think computational neuroscience is making a lot of headwinds on these questions (except AGI). Recently, I have been perusing some ML labs that have been working on the problems within cognitive neuroscience as well. I was wondering how these fields interact. If I do a PhD in comp neuro, is there a possibility for me to work in the ML and AI field if teach myself a lot of these concepts and do research that uses these concepts?",MachineLearning
o626og,1624410873.0,[P] Jina - Cross Modal Search System (Open source search engine),"Jina is a Neural Search Framework that provides large-scale indexing and querying of different kinds of data, including video, images, text, music, source code, and PDFs.
Try it now!

Google I/O and Jina Video :

[https://www.youtube.com/watch?v=lJogWSnl5Es](https://www.youtube.com/watch?v=lJogWSnl5Es)",MachineLearning
o604zo,1624404349.0,[D] Mixed Precision Training Tips,"Recently upgraded to a 3000 series card and have been playing around with mixed precision training. I notice some model architectures train just fine while others become unstable and collapse. Outside of a couple basic tutorials to implement mixed precision training, I haven't been able to find any general tips on how to keep training stable. Things to change or avoid about a model or training loop when switching to mixed precision.

Does anyone know of any good references like these?",MachineLearning
o5yfcl,1624399171.0,"[D] neural network based ""association rules""","https://en.m.wikipedia.org/wiki/Association_rule_learning

Has anyone ever looked into more advanced applications of ""association rules mining""? ""Association rules"" can also be used for prediction/classification purposes (e.g. https://rdrr.io/cran/arulesCBA/man/CBA.html) - this allows you to obtain a fully interpertable algorithm that can provides ""a set of conditions"" for making predictions. However, these rules are usually not very ""powerful"".

Does anyone know if there are more recent spinoffs of this algorithm, perhaps where a neural network or ensemble models can be used to ""learn"" these rules? Or in general, does anyone know any machine learning based algorithms that provide ""rules""?

Thanks",MachineLearning
o5y8mq,1624398630.0,[D] ML workstation vs Google Colab Pro,"Hi,

I have been using Google Colab for some time now and it was convenient. However, we would like to check if building a workstation (e.g can be found [here](https://www.youtube.com/watch?v=S0-lM6mZJn0)) worth it.

Those who build their own workstation, could you please chime in on what are the benefits that you gain of using your own workstation vs Google Colab/Amazon SageMaker",MachineLearning
o5tw5o,1624386802.0,[D] Struggles when reading AI/ML papers,"Hey everyone,

I was wondering with what are you struggling the most when reading AI/ML papers? What do you find are the biggest obstacles in understanding those papers and what is your way of dealing with them?",MachineLearning
o5tok1,1624386239.0,"[D] Deep Learning for AI by Bengio, Lecun, and Hinton","Discussion of the origins of deep learning, a few of the more recent advances, and future challenges by deep learning godfathers.

Original article here: [https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext](https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext)

More hard-to-find, independent stuff related to AI & Data Science [here](https://thereshape.co/?utm_source=reddit_ml_1).",MachineLearning
o5j2hj,1624354697.0,[R] New work linking Partial Differential Equations and Graph Neural Networks,"Hi everyone,

Sharing some work from the graph ML team at Twitter showing how a new class of GNNs can be constructed by discretising diffusion PDEs.  Was  on arxiv today and it will be at ICML21.

Thinking of GNNs as partial differential equations leads to a new broad class of GNNs that are able to address in a principled way some of the prominent issues of current Graph ML models such as depth, oversmoothing, bottlenecks, and graph rewiring. 

Many popular GNNs can be formalised as discretised diffusion PDEs with explicit single-step Euler scheme with a time step of 1, where an iteration corresponds to a convolutional or attentional layer of the graph neural network, and running the diffusion for multiple iterations amounts to applying a GNN layer multiple times. In the Neural PDEs formalism, the diffusion time parameter acts as a continuous analogy of the layers—an interpretation allowing us to exploit more efficient and stable numerical schemes that use adaptive steps in time.

Blog post: [https://bit.ly/3gUOEL8](https://t.co/dNaibcliBR?amp=1)
Paper: [https://arxiv.org/abs/2106.10934](https://t.co/wSyHNemQ9x?amp=1)
Code: [https://github.com/twitter-research/graph-neural-pde](https://github.com/twitter-research/graph-neural-pde)


https://preview.redd.it/68zohy4ebs671.png?width=647&format=png&auto=webp&s=439f7b1428bd5fd9b5751ecbe4975140084eb677",MachineLearning
o5sbkh,1624382525.0,"[D] Statistics refresher: Bengio & Goodfellow, Bishop, or Murphy?","All these books have a couple of chapters devoted to statistic, which one would you pick as an introduction to statistics?",MachineLearning
o5r3rc,1624379263.0,[R] New Milestone for Deep Potential Application: Predicting the Phase Diagram of Water,"A research team from Princeton University, the Institute of Applied Physics and Computational Mathematics and the Beijing Institute of Big Data Research uses the Deep Potential (DP) method to predict the phase diagram of water from ab initio quantum theory, from low temperature and pressure to about 2400 K and 50 GPa. The paper was published in leading physics journal Physical Review Letters and represents an important milestone in the application of DP.

Here is a quick read: [New Milestone for Deep Potential Application: Predicting the Phase Diagram of Water.](https://syncedreview.com/2021/06/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-46/)

The paper *The Phase Diagram of a Deep Potential Water Model* is on[*Physical Review Letters*](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.126.236001) and [arXiv](https://arxiv.org/abs/2102.04804).",MachineLearning
o5qrub,1624378399.0,"[D] 5 minute paper digest: GANs N’ Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!) by Min Jin Chong et al.","[Your dream Anime waifu!](https://i.redd.it/mn3ty4acdu671.gif)

Did you ever want to see what you look like as an anime waifu? Thanks to the authors of GANs N' Roses you can animefy (pretty sure this isn't a real word) selfies and even videos with a multitude of unique styles. The authors from the University of Illinois propose a new generator architecture that combines a content code computed from a face image and a randomly chosen style to produce consistent, diverse and controllable anime faces with attributes matching the content image.

Read the [full paper digest](https://t.me/casual_gan/53) (reading time \~5 minutes) to learn about the encoder-decoder architecture of the authors' content-style image generation method, the tricks for ensuring style diversity, and the losses required for high fidelity anime image synthesis.

Meanwhile, check out the paper digest poster by [Casual GAN Papers](https://t.me/casual_gan)!

[GANs N' Roses](https://preview.redd.it/yy1w8k42du671.png?width=1877&format=png&auto=webp&s=f2607d49f1b6aea21edec9f15870ae01aad5f4a9)

\[[Full Explanation Post](https://t.me/casual_gan/53)\] \[[Arxiv](https://arxiv.org/pdf/2106.06561v1.pdf)\] \[[Code](https://github.com/mchong6/GANsNRoses)\]

More recent popular computer vision paper breakdowns:

>[CIPS](https://t.me/casual_gan/51)
[SimSwap](https://t.me/casual_gan/52)
[Decision Transformer](https://t.me/casual_gan/50)",MachineLearning
o5ojq5,1624372443.0,[D] Most valuable skills for Data Scientists and Machine Learning Engineering roles,"Hi, I have almost finished my master degree in CS (with a special  curriculum on Data Science and Machine Learning). The majority of my  knowledge are theoretical and at academic level. Since I want to be  prepared for my future jobs, what are the most valuable skills for Data  Scientists and ML Engineering roles that are not taught or  underestimated? Or what are those skills and knowledge that you would have learned before starting to work?

 I have two months off this summer and I want to use this  time at the best.",MachineLearning
o5lmwo,1624363836.0,[P] FastDS - Quality-of-life wrapper for Git and DVC,"I want to share a [new open source command line tool, FDS](https://github.com/dagshub/fds), which aims to help users do Fast Data Science by streamlining version control for ML projects. FDS is a command line wrapper around Git and [DVC](https://dvc.org/), meant to minimize the chances of human error, automate repetitive tasks, and provide a smoother landing for new users.

# Quickstart:

[https://github.com/dagshub/fds](https://github.com/dagshub/fds)

    pip install fastds
    fds -h

Full blog post on the motivations and goals of the project:

[https://dagshub.com/blog/fds-fast-data-science-with-git-and-dvc](https://dagshub.com/blog/fds-fast-data-science-with-git-and-dvc)

# Summary:

Why is it called fds?

Just take a look at your keyboard - it's so silky smoove to type fds! This is important for a command line tool that exists to improve ease of use and delight users.

**In fact, due to popular demand, you can also type** **sdf** **instead of** **fds** **for an even more epic experience!** 🤩

[so smoove](https://preview.redd.it/h2clzec16t671.png?width=659&format=png&auto=webp&s=8654e4f757032dec54313a2b84c9c90fe7380480)

# Why did we do this?

As we were developing Open Source Data Science projects using DVC, we often found ourselves making the same mistakes over and over again, and constantly repeating pairs of commands like ""git status"" and ""dvc status""

So, we set about creating FDS with these goals in mind:

1. Automate common tasks when working with git, DVC, and, later on, potentially other tools which work well together.
2. Provide a more interactive and opinionated UI and UX. Git and DVC are low level utilities which need to work well in scripts and support all possible use cases - this means interacting with them feels like interacting with a command line API, rather than a wizard or app. FDS orients itself to be used by humans, for convenience rather than total flexibility.
3. Provide a smoother landing for new users by making things easy by default and explaining what's going on.

We took inspiration from [gitless](https://gitless.com/) \- ""a Git-compatible version control system, that is easy to learn and use"" - a project which works on top of Git and attempts to make it more intuitive. Check it out!

Would love to get your feedback, feature requests are welcome, pull requests even more so!",MachineLearning
o5lehy,1624363082.0,[D] Similar Image Retrieval,"I am trying to build a similar image retrieval system where given an image, the system is able to show top 'k' most similar images to it. For this particular example, I am using the [DeepFashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) dataset where given an image containing say a shirt, you show top 5 clothes most similar to a shirt. A subset of this has 289,222 diverse clothes images in it. Each image is of shape: (300, 300, 3).

The approach I have includes:

1. Train an autoencoder
2. Feed each image in the dataset through the encoder to get a reduced n-dimensional latent space representation. For example, it can be 100-d latent space representation
3. Create a table of shape m x (n + 2) where 'm' is the number of images and each image is compressed to n-dimensions. One of the column is the image name and the other column is a path to where the image is stored on your local system
4. Given a new image, you feed it through the encoder to get the n-dimensional latent space representation
5. Use something like cosine similarity, etc to compare the n-d latent space for new image with the table m x (n + 2) obtained in step 3 to find/retrieve top k closest clothes

How do I create the table mentioned in step 3?

I am planning on using TensorFlow 2.5 with Python 3.8 and the code for getting an image generator is as follows:

    image_generator = ImageDataGenerator(
        rescale = 1./255, rotation_range = 135)

    train_data_gen = image_generator.flow_from_directory(
        directory = train_dir, batch_size = batch_size,
        shuffle = False, target_size = (IMG_HEIGHT, IMG_WIDTH),
        class_mode = 'sparse'

How can get image name and path to image to create the m x (n + 2) table in step 3?

Also, is there any other better way that I am missing out on?

Thanks!",MachineLearning
o5kar0,1624359356.0,[D] How long of sequence to train LSTM/GRU on?,"Wondering if there is a general rule of thumb for how long of a sequence I should train my GRU/LSTM on?  Also is there any research on the upper limit of how far back in time a GRU and LSTM can realistically look?

What I am trying to do is create a decoder for my VQVAE audio auto encoder using raw audio.  I know RNNs are not the best for generating raw audio due to the extremely long range dependencies in audio signals, however, my decoder consists of a bunch of convolutions before I expand out to the original length of the audio and use an auto regressive RNN network to finish the decoding.  This way I think the RNN can focus only on the higher frequency short term signals.

Currently I have a stack of 2 GRUs with 512 cells each.  I am training it on sequences of 1024 sampled from the output of the expander portion of my decoder.  When it comes to actually running this in inference I plan to just carry the state of the RNN forward from one prediction to the next never resetting the state for hundreds of thousands of samples.  I am unsure if this is a valid thing to do since it was only trained on sequences of 1024.  Maybe I should run it for 1024 steps.  Then reset the state, go back 256 steps for a warm up and repeat this over the full sequence.",MachineLearning
o5k7v0,1624359057.0,[D] Object detection: Is it detrimental to retrain but only focusing on one object type?,"Hi,

I'm currently working on an object detection model using gluoncv/autogluon. My model is at about 80% for some objects, but much worse for others.

When I'm updating/retraining my model is it harmful to only train with certain image types? So if I know I have a set of images which contain objects A and B, will only tagging and retraining with images that tag object B increase accuracy for B, and/or decrease accuracy for object A?

Thanks!

P.S. if it helps here are some of the current model parameters:

`{ 'amp': False,`

`'base_network': 'resnet50_v1',`

`'data_shape': 512,`

`'filters': None,`

`'nms_thresh': 0.45,`

`'nms_topk': 400,`

`'ratios': ( [1, 2, 0.5],`

`[1, 2, 0.5, 3, 0.3333333333333333],`

`[1, 2, 0.5, 3, 0.3333333333333333],`

`[1, 2, 0.5, 3, 0.3333333333333333],`

`[1, 2, 0.5],`

`[1, 2, 0.5]),`

`'sizes': (30, 60, 111, 162, 213, 264, 315),`

`'steps': (8, 16, 32, 64, 100, 300),`

`'syncbn': False,`

`'transfer': 'ssd_512_resnet50_v1_coco'}`",MachineLearning
o5je80,1624356006.0,[D] How would you approach creating a paraphrase dataset?,"I have been trying to create a paraphrasing dataset for a non-English language (Arabic), which has no datasets for this task. However I am not sure on how to approach it.

My hacky way was to take a translation dataset (Arabic - English), set the Arabic sentences as the target, and translate English sentences (using pretrained models, or goolgle translation) to Arabic and set them as the source. My impression was that this might workout since in translation phrasing might changed but the meaning is preserved.

However when fine tuning gpt on that dataset, the model does not perform well, as it changes the meaning of text often, and add extra info that didn't exist in the first place. My theory is that this is coming for the dataset - maybe many mistranslated sentences ?

What I am thinking of trying now is overfitting a pretrained translation model on my dataset, so I be sure the translations are not wrong, and generate a new dataset.

&#x200B;

What are you thoughts on my approach? And how would you approach it yourself?

Thank you.",MachineLearning
o5i6nv,1624350762.0,[D] Looking for a paper/result about NN trained on language doing math,"I have a vague memory of a result where a NN was trained on language (I can't recall whether it was for generation or classification etc.) that when prompted with mathematical expressions did surprizingly well. Does anyone have a link for this sort of paper/article?

Edit: u/InterArtiGen correctly identified the result as section 3.9.1 from the [GPT3 results](https://arxiv.org/pdf/2005.14165.pdf#page=21)",MachineLearning
o5h8za,1624346993.0,[Discussion] C++ Usage for Machine Learning," Hi all,

I'm wondering if I should learn C++ if I want to get a job as an ML engineer or other DS role. I am currently comfortable with Python and R.

1. Would learning C++ be beneficial to getting a job in the ML industry?
2. Are more and more ML jobs today requiring C++ proficiency?",MachineLearning
o5h157,1624346132.0,[N] Extensive (N=1250) survey on ML/DS salaries in Israel. Thorough analysis!,"Disclaimer: Unaffiliated with MDLI, although I am an active member of that community.
(Arabic and Hebrew versions available through the link!)

From the link:
As in previous years, this year we ran the MDLI community’s annual survey, so as to map various trends among those who work in the data science and machine learning fields. This year, an exceptional number of respondents completed our annual survey – 1,250 people – a respectable achievement by all counts. Omri Goldstein, an algorithm developer, data scientist, and creator of the “Data-driven” blog analyzed the survey’s findings. We used his analysis to generate the MDLI community’s 2021 annual payroll report. We also developed a dedicated salary calculator for data professionals in Israel.

https://machinelearning.co.il/8280/mdli2021reportenglish/",MachineLearning
o5ggz9,1624344025.0,[D] What best-practices are folks using to make sure their data-labeling guidelines are effective?,"My team's helping computer-vision and NLP companies label training data and it's quite common for team's to not have comprehensive guidelines.

Issue here is that there's often a lag between deciding what type of labels you need and having them prepared while you hash out all the details.

&#x200B;

Question if your annotating videos, images, texts, how long do you spend preparing your labeling guidelines and discussing edge-cases with your annotators?

&#x200B;

https://preview.redd.it/qy3tjb1bir671.jpg?width=720&format=pjpg&auto=webp&s=0fa6bbc3816d6114200d813c45fe56d128444ae6",MachineLearning
o5dm09,1624333781.0,Just a fun idea [Project],"This is not super high on my list of priorities, but if nobody tries it, I’ll give it a shot at some point. I’d like to see a manifold or gradient 3D printed (with support structure) from an actual AI model you’ve fit or a function that’s been optimized. And then...a marble may be involved... it would be kind of next level awesome to compare two optimization methods, like Adam and SGD. I would like to see how the path an object rolling down the gradient would differ between optimizers. If you send me an ndarray of some project you ran, that you could represent the fitting of in Euclidean space, I’ll happily turn it into a mesh and print it.",MachineLearning
o53b03,1624303753.0,[P] Skim : Platform to help people skim through papers in this fast moving research world,"🎉 FEATURE UPDATE 🎉

We are extremely excited to announce a new feature! [Skim](https://skimhq.tech/) now shows Acceptance Rates of more than 50 conferences 📊. Take a sneak peak into the updated conference page 👇

Also we are sending out 100 invites this week, request an invite by filling this form: [http://tiny.cc/7zg2uz](http://tiny.cc/7zg2uz)

https://preview.redd.it/d4znnbk77o671.png?width=1770&format=png&auto=webp&s=fb1150875b5943e0a4d4a1962528220ccfec09c7

https://preview.redd.it/ceo474k77o671.png?width=1777&format=png&auto=webp&s=beab74cfaf1658d490446a5791a7039a9fc3731f",MachineLearning
o5bnjp,1624327547.0,[D] Advice on Dodging Grad School Poverty?,"Does anyone have any advice for how to make decent income while earning one's PhD in ML? I'm open to all suggestions - consulting, year-round company funding, blogging, etc. Personal experiences would be most appreciated!",MachineLearning
o59p0f,1624321386.0,[D] Karpathy @ CVPR 2021 Workshop on Autonomous Vehicles,"[Video here](https://www.youtube.com/watch?v=NSDTZQdo6H8). [Full workshop stream here](https://youtu.be/eOL_rCK59ZI?t=28293).

Karpathy discusses how radar bugs were holding Autopilot performance back, and how removing it from the stack to go vision-only ultimately improved performance (though it seems they did use radar to some degree in automatic labeling/triggering events to train on in an active learning style).

He also discusses Tesla's supercomputer for training (5,760 A100 GPUs), and some data engine and team management processes at Tesla. Still nothing new about their Dojo project (NN training accelerator chip).

It's still unclear to me to what extent they use all these predicted semantic features like object detection/other agent kinematics to plan with classically, and how much they use things like the ""predicted future path"", or how these are merged to actually act in the FSD beta.",MachineLearning
o4v52e,1624282071.0,[R] Disrupting Model Training with Adversarial Shortcuts,"It’s not always great that people can train machine learning models on your data! In this new work, we create adversarial shortcuts to prevent neural network training. Adversarial shortcuts are hand-crafted modifications to images in the training set that exploit simplicity biases in models to prevent them from capturing the semantics of the dataset. Adversarial shortcuts are also easily ignored by human perception.

&#x200B;

https://preview.redd.it/4k4ehbupem671.png?width=1850&format=png&auto=webp&s=bdfdbced226c52de7143ae99fbd1c8822b66e091

While this idea is more broadly applicable, we begin its study in the context of a well-known machine learning problem: supervised classification. Adversarial shortcuts all share a common idea: fixing a pattern for each image in a particular class encourages models to fit that pattern over anything else. It turns out that even fixing a few pixels prevents the model from fitting the semantics. Here is an example of an ImageNet-sized image with a pixel-based adversarial shortcut.

This is neatly illustrated by these plots of ImageNet validation and training accuracy progression: notice how, with the adversarial shortcuts applied, the training acc@1 reaches close to 100% while the validation is stuck close to 0.

&#x200B;

https://preview.redd.it/4pkaynunem671.png?width=432&format=png&auto=webp&s=0add3889230dfc05ec943d999f0064a682e1b659

&#x200B;

Of course, the pixel-based pattern may be easily disrupted, so we also explore more complicated patterns: watermarks with the class index made up of MNIST digits and brightness modulations.

&#x200B;

https://preview.redd.it/s47ztm9vem671.jpg?width=1024&format=pjpg&auto=webp&s=2435b29833457911997b3b3114aba8afc4b2a844

https://preview.redd.it/0sozgh9vem671.jpg?width=1024&format=pjpg&auto=webp&s=a06087f309594d1ab2bdef2bc0b939d4a051bcff

Read more - including ablation studies and comparisons to related work - in our new arXiv preprint: [https://arxiv.org/abs/2106.06654](https://t.co/l6D6rysdxw?amp=1) Joint work with Ian Covert, Aditya Kusupati, and Tadayoshi Kohno.",MachineLearning
o55gh9,1624309308.0,[D] What Is the Successor to Convolution Autoencoders?,"Obviously, from the title, I am quite behind in Machine Learning Literature and the SOTA works.

Last time I checked, CNN autoencoders were SOTA(so a long time ago). However now, what would be more recent/accurate Autoencoder architectures? GAN Autoencoders with a discriminator for more accurate results? Autoencoders with Transformer layers?  If possible, could someone link papers/code?",MachineLearning
o559zx,1624308849.0,Implementation of AI into healthcare systems - pros and cons [D],"I am working on a school project centred around the effect of AI on the healthcare system (specifically the NHS but can be viewed in a more general context). I wanted to explore different opinions on this - do you think AI could potentially lead to a poorer quality of healthcare? There is no doubt that the use of AI in these systems will only increase but are we ready for this? I have been researching a bit about issues with AI (eg. in the context of a diagnostics tool) and have found a bit about biased algorithms which arise from a lack of input data (please correct me if this is wrong). What sorts of repercussions would an issue like this have on peoples' health?

What do you think the greatest danger that AI poses on patients and clinicians is? And are there certain groups of people who are more at risk to these problems?

Any opinions and discussions would be greatly appreciated to help me gain more insight into this topic! Thank you.",MachineLearning
o50nh7,1624296867.0,[D] Shap value for LSTM model,"

I have lstm model named lstm\_model
 and I am using shap value to explain model. have tabular data.

     import shap    explainer = shap.DeepExplainer(lstm_model, X_train)   shap_values = explainer.shap_values(X_test)

From My knowledge in order to calculate the shap value, It uses a 2\^(number of features) model. I am interesting in what is kind of algorithm it uses for each individual model.
This question comes from the following fact:

When I am plotting of effect x
 feature on output, this effect is linear(increasing or decreasing). For example when x
 increasing the effect increases (decreasing). What is the reason behind this?

One additional question:
Is it possible to use shap to plot partial dependence plot for the LSTM model?",MachineLearning
o4ykq8,1624291472.0,[P] Train a GAN and Keep Both Your Kidneys,"Hey guys!

&#x200B;

A while ago I trained StyleGAN2 to generate artificial overhead imagery on a dataset of aerial imagery of Italy which I compiled. It was a fun project and the results are kind of neat, so I thought I'd share the process.

&#x200B;

Link to post: [https://jakenicholasward.medium.com/train-a-gan-and-keep-both-your-kidneys-bcf672e94e81](https://jakenicholasward.medium.com/train-a-gan-and-keep-both-your-kidneys-bcf672e94e81)

&#x200B;

This is also my first time writing a blog post and posting it publicly, which was arguably harder than training the actual network. I'd love some feedback on writing style and content!",MachineLearning
o4x5lj,1624287844.0,[R] Jürgen Schmidhuber & Swiss AI Lab Team Boost Linear Transformers With Recurrent Fast Weight Programmers,"A research team from the Swiss AI Lab IDSIA leverages fast weight programmers (FWPs) to advance linear transformers and explores the connection between linearised transformers and outer product-based FWPs to release the power of improved FWPs.

Here is a quick read: [Jürgen Schmidhuber & Swiss AI Lab Team Boost Linear Transformers With Recurrent Fast Weight Programmers.](https://syncedreview.com/2021/06/21/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-45/)

The paper *Going Beyond Linear Transformers With Recurrent Fast Weight Programmers* is on [arXiv](https://arxiv.org/abs/2106.06295).",MachineLearning
o4wd3f,1624285702.0,[N] CVPR '21 Best Paper: GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields,"Michael Niemeyer's work **GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields** has just been given the Best Paper award at CVPR 2021. 10k submissions but you made it. Congrats Michael and Andreas! It's an honor to work with you.

Abstract:

Deep generative models allow for photorealistic image synthesis at high resolutions. But for many applications, this is not enough: content creation also needs to be controllable. While several recent works investigate how to disentangle underlying factors of variation in the data, most of them operate in 2D and hence ignore that our world is three-dimensional. Further, only few works consider the compositional nature of scenes. Our key hypothesis is that incorporating a compositional 3D scene representation into the generative model leads to more controllable image synthesis. Representing scenes as compositional generative neural feature fields allows us to disentangle one or multiple objects from the background as well as individual objects' shapes and appearances while learning from unstructured and unposed image collections without any additional supervision. Combining this scene representation with a neural rendering pipeline yields a fast and realistic image synthesis model. As evidenced by our experiments, our model is able to disentangle individual objects and allows for translating and rotating them in the scene as well as changing the camera pose.

&#x200B;

* Project page: [https://m-niemeyer.github.io/project-pages/giraffe/index.html](https://m-niemeyer.github.io/project-pages/giraffe/index.html)
* Paper: [http://www.cvlibs.net/publications/Niemeyer2021CVPR.pdf](http://www.cvlibs.net/publications/Niemeyer2021CVPR.pdf)
* Twitter: [https://twitter.com/AutoVisionGroup/status/1406973670740922368](https://twitter.com/AutoVisionGroup/status/1406973670740922368)",MachineLearning
o4wbgg,1624285574.0,[R] Disrupting Model Training with Adversarial Shortcuts,"It’s not always great that people can train machine learning models on your data! In this new work, we create adversarial shortcuts to prevent neural network training. Adversarial shortcuts are hand-crafted modifications to images in the training set that exploit simplicity biases in models to prevent them from capturing the semantics of the dataset. Adversarial shortcuts are also easily ignored by human perception.

&#x200B;

https://preview.redd.it/h8wc1miapm671.png?width=1850&format=png&auto=webp&s=e2132be680902b5d891fe6bd6e7bc3812c13e1e2

&#x200B;

&#x200B;

While this idea is more broadly applicable, this work begins its study in the context of a well-known machine learning problem: supervised classification. Adversarial shortcuts all share a common idea: fixing a pattern for each image in a particular class encourages models to fit that pattern over anything else. It turns out that even fixing a few pixels prevents the model from fitting the semantics. Here is an example of an ImageNet-sized image with a pixel-based adversarial shortcut.

&#x200B;

https://preview.redd.it/043p4z75qm671.jpg?width=1024&format=pjpg&auto=webp&s=456cf50b5c34dbb2c6d89e45f6f4f36bfaf484b1

This is neatly illustrated by these plots of ImageNet validation and training accuracy progression: notice how, with the adversarial shortcuts applied, the training acc@1 reaches close to 100% while the validation is stuck close to 0.

&#x200B;

&#x200B;

&#x200B;

https://preview.redd.it/olrx44fbpm671.png?width=432&format=png&auto=webp&s=3ac13ed1092af77b402d41084272e1a65bff8e22

&#x200B;

&#x200B;

Of course, the pixel-based pattern may be easily disrupted, so we also explore more complicated patterns: watermarks with the class index made up of MNIST digits and brightness modulations.

&#x200B;

https://preview.redd.it/73uyv9bcpm671.jpg?width=1024&format=pjpg&auto=webp&s=43e9dced8ce51329d03095d45b071576dab4f4a7

&#x200B;

&#x200B;

&#x200B;

https://preview.redd.it/r5gsm7tcpm671.jpg?width=1024&format=pjpg&auto=webp&s=c492d705a94e4b8eb7051a3f9c6c5a4c340f059b

&#x200B;

Read more - including ablation studies and comparisons to related work - in the new arXiv preprint: [https://arxiv.org/abs/2106.06654](https://arxiv.org/abs/2106.06654) by Ivan Evtimov, Ian Covert, Aditya Kusupati, and Tadayoshi Kohno.

&#x200B;

\[I'm posting this for my friend /u/ivanevti (who is the first author of the paper) whose posts keep getting mysteriously removed. He'll be reading the comments here and will be able to answer any questions you might have.\]",MachineLearning
o4wb73,1624285553.0,Gpt 2 - fine tuning 124 M vs 355M [D],"Can someone please explain me what difference does it make to fine tune gpt2 124M and 355M.
I get it that 355m was pretrained on larger dataset.
But when I am fine tuning it, how does the model size matter.?
Thanks",MachineLearning
o4w4cb,1624285032.0,[D] Are machine learning models theoretically designed to make predictions about individuals?,"Are statistical models in theory able to make predictions about individuals? Suppose you have an individual with observed covariate information (x = a, y = b, z = c) : in theory, can a regression model (trained well on some data) predict the expected value of this individual's response variable?

I heard today that statistical models are not designed to make predictions about individuals. They are only designed to predict the average behavior of a large group of individuals - and in theory, should not be used to make predictions about individuals.

Is this correct? Does this mean that any time statistical models are used to make individual predictions, this is going against the intended use of statistical models?

If I understand correctly: this means that when a statistical model makes a prediction about an individual with observed covariate information (x = a, y = b, z = c) - it's making a prediction for the behavior of ALL individuals in the universe with observed covariate information (x = a, y = b, z = c) . Is this correct? Does this mean by definition, the idea of  making predictions for individuals is a fallacy?

Thanks",MachineLearning
o4uoyx,1624280769.0,[P] ML Model Server,"📢 You can 𝗖𝗿𝗲𝗮𝘁𝗲 𝗔𝗣𝗜 𝗳𝗼𝗿 𝗔𝗻𝘆 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴 𝗠𝗼𝗱𝗲𝗹 (ML, DL, Image Classification, NLP, Tensorflow or PyTorch) 𝗼𝗻𝗹𝘆 𝗶𝗻 𝗳𝗲𝘄 𝗹𝗶𝗻𝗲𝘀 𝗼𝗳 𝗰𝗼𝗱𝗲𝘀 𝘄𝗶𝘁𝗵 𝗮𝗹𝗹 𝗻𝗲𝘄 𝗖𝗛𝗜𝗧𝗥𝗔 𝟬.𝟭.𝟬 🔥

Powered by FastAPI and Pydantic 🤓

𝗜𝗻𝘀𝘁𝗮𝗹𝗹: pip install chitra==0.1.0a0

𝗦𝗼𝘂𝗿𝗰𝗲: [https://git.io/Jn6Hv](https://git.io/Jn6Hv)

𝗘𝘅𝗮𝗺𝗽𝗹𝗲 𝘁𝗼 𝗵𝗲𝗹𝗽 𝘆𝗼𝘂 𝗚𝗲𝘁 𝗦𝘁𝗮𝗿𝘁𝗲𝗱: [https://chitra.readthedocs.io/en/latest/examples/model-server/model-server.html](https://chitra.readthedocs.io/en/latest/examples/model-server/model-server.html)",MachineLearning
o4tsss,1624277979.0,[D] Multiple Products Time Series with Singlevariate LSTM,"**Project Description**

\- My project is to pre-order movies online (people receive them at release date) and also to sell them after release date as well.

\- I have historical for many movies.

\- Their historic sales plot looks like a bell shape like curve with the symmetric center at the middle when the movie is released.

\- I use LSTM from the following \[project\]([https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)) with Python 3.7, Keras, TensorFlow.

\- The goal would be to train the model based on all the previouse plots without just averaging all the sales.

\- All of my historical data contains 2 parameters: 1.) sales date in the following format:  negative integers represent dates before release, 0 date when the release of the movie happening and than positive numbers maxing out at +30 to count the dates after release.

&#x200B;

**How to do this**

\- What I want to do is multiple products timeline with the only feature numebr of sales. With LSTM, Python 3.7, Keras, TensorFlow.

\- Prediction should be on a brand new product until day +30, Not just continuing each product.

&#x200B;

**What I have found so far**

\- My issue is that all the recomendation and project that I have found are for 1 product so 1 time line and maybe for multiple features (temperature, revenue, GDP at that time of the country ...) \[example\]([https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/))

&#x200B;

**What I have done at the end I am happy to get feedback on my solution**

I have tried to connect the time scales after each other in training and if the training data have a wide variety of events than the test sets have pretty good response.

Whit this methodology I am going to turn the problem to a Multivariant problem to get better results with tons of features like ""added to favorites list, viewed, movie rank...""",MachineLearning
o4td2l,1624276461.0,[D] Minimum number of devices for a federated learning environment,"Hi all, I am currently researching Federated learning on TinyML. I would like to know the minimum amount of devices you would suggest I have for researching. I'm currently working with 2 devices. Would it suffice? If not, would you suggest I emulate a few raspberry Pis? Or purchase a few extras?",MachineLearning
o4qu07,1624265535.0,[D] Self-supervised learning in vision recent papers (DINO/Barlow Twins/PAWS etc) video interview,"Dr. Ishan Misra is a Research Scientist at Facebook AI Research where he works on Computer Vision and Machine Learning. His main research interest is reducing the need for human supervision, and indeed, human knowledge in visual learning systems. He finished his PhD at the Robotics Institute at Carnegie Mellon. He has done stints at Microsoft Research, INRIA and Yale.

Today though we will be focusing an exciting cluster of recent papers around unsupervised representation learning for computer vision released from FAIR. These are; DINO: Emerging Properties in Self-Supervised Vision Transformers, BARLOW TWINS: Self-Supervised Learning via Redundancy Reduction and PAWS: Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples. All of these papers are hot off the press, just being officially released in the last month or so. Many of you will remember PIRL: Self-Supervised Learning of Pretext-Invariant Representations which Ishan was the primary author of in 2019.

YouTube: [https://youtu.be/EXJmodhu4\_4](https://youtu.be/EXJmodhu4_4)

Pod:  https://anchor.fm/machinelearningstreettalk/episodes/55-Self-Supervised-Vision-Models-Dr--Ishan-Misra---FAIR-e1355js",MachineLearning
o4onlz,1624256023.0,[D] What is the current SOTA for extracting a knowledge graph from images?,"I am looking to get a knowledge graph of an image using some pre-trained model.

What is the current SOTA work that has a reproducible implementation?

Can you share some pointers from your experience trying to extract KG from images?

Thank you",MachineLearning
o4o0xw,1624253565.0,[D]What are the current ways to compress time series data into a feature?,"I'm working in taking time series data over a span of 4 months and compressing it into a single feature as an input into another model. I know there are things like LSTM and GRU, but I don't know if the memory cell is large enough to hold a good latent representation. I was considering VAE, but I think converting tabular data to an image is probably tricky.",MachineLearning
o4mlle,1624248149.0,[D] managing compute for long running ML training jobs,"Hi r/MachineLearning

I have been curious to see what the community’s biggest issues are around running large training jobs. We run a modest sized GPU kubernetes cluster but there seem to be a fair gap of functionality when it comes to fair resource access (HPC style backfill, time estimates etc) and general usability to many of our scientists.

For instance some of the issues I’ve seen;

 - GPU machines being fragmented (lots of single GPU jobs, making full width jobs very hard to land)
 - Interactive sessions being much harder than traditional HPC schedulers like SLURM
 - in the absence of a cloud parallel file system like lustre, dealing with dataset location and loading.

What are some things you guys have run into re: resource access for training?",MachineLearning
o4ko8j,1624241509.0,"[R] How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers","Paper Link: [https://arxiv.org/abs/2106.10270](https://arxiv.org/abs/2106.10270)

JAX Code: [https://github.com/google-research/vision\_transformer](https://github.com/google-research/vision_transformer)

PyTorch Code: [https://github.com/rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models)

A study in order to better understand the interplay between the amount of training data, AugReg, model size and compute budget for ViTs.

The authors have trained ViT on ImageNet-21k with ""AugReg"", which either matches or outperforms their counterparts trained on the larger, but not publicly available JFT-300M dataset.",MachineLearning
o48klb,1624204290.0,PhD Studentship for UK/International Applicants in AI Driven Population Health Study,"

**PhD Studentship in AI Driven Population Health Study : Improving medication verification for cancer patients**

  Applications are invited for a three-year PhD studentship. The studentship will start on **1 October, 2021,** or as soon as possible after that.

 **Project Description**

Medication errors, including those in prescribing, dispensing, or administration of a drug, are the single most preventable cause of patient harm. They have a significant impact on the efficiency of the workflow in pharmacy, raise safety concerns for patients, and result in a financial burden on the healthcare systems. Within cancer treatment, emphasis on reducing the number of medication errors has been an active research area for many years, with understanding that interdisciplinary approaches are vital to assure continuous improvement. Opportunities created by the reduction of transaction times for complex computational processes and use of machine learning to support clinical decision making, create a potential catalyst for the development of tools for reduction in medication errors.

This PhD studentship offers an exciting opportunity of exploring AI and machine learning with large clinical data sets residing within electronic health records to create methods to assure the effective use of systemic anticancer treatment (including traditional cytotoxic chemotherapy, immunotherapy, novel oral therapies etc.) without compromising patient safety. The studentship will require application of interdisciplinary skills to enable cooperation between the research, clinical, industry and patient communities in the development of a novel approach which could enhance clinical outcomes.



**Supervision Team**

&#x200B;

* [Professor Shang-Ming Zhou](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Fstaff%2Fshang-ming-zhou&data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156834666%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=NU%2B2%2FwhEbyaHJGWCUqR88H6gqpDPNcNkZ4%2FJj6vivLw%3D&reserved=0) ([shangming.zhou@plymouth.ac.uk](mailto:shangming.zhou@plymouth.ac.uk))

[https://scholar.google.com/citations?user=iWiXGWMAAAAJ&hl](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fscholar.google.com%2Fcitations%3Fuser%3DiWiXGWMAAAAJ%26hl&data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156844629%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=Kn%2BzLefaEB6GOF%2B2us6NB4827AyxCrO9yhn%2B6u%2FbLBM%3D&reserved=0)

&#x200B;

* [Dr Edward Meinert](mailto:Dr%20Edward%20Meinert)([edward.meinert@plymouth.ac.uk](mailto:edward.meinert@plymouth.ac.uk))

[https://scholar.google.com/citations?hl=en&user=7V-WsrwAAAAJ](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fscholar.google.com%2Fcitations%3Fhl%3Den%26user%3D7V-WsrwAAAAJ&data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156854582%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=BXVX6qyDbxbjm1XZMtA25hWh4qKAKGbKI6riCcK3Jnw%3D&reserved=0)

&#x200B;

* Mrs Andrea Preston ([Andrea.Preston@uhbw.nhs.uk](mailto:Andrea.Preston@uhbw.nhs.uk))

This PhD student will be academically advised by Professor Shang-Ming Zhou and Dr Edward Meinert, research scientists with research interests in applied artificial intelligence and machine learning, computing science in health and care. The student will also be advised by Mrs Andrea Preston, a Macmillan Divisional Lead Haematology & SW Cancer Commissioning Pharmacist. This supervision team will assure the execution of a world-class PhD embedded into the wider digital health ecosystem at the University of Plymouth.

**Eligibility**

· This PhD studentship is offered for UK and international applicants.

· Applicants should have:

1) A first or upper second-class honours degree, and a relevant Master’s qualification in Computing Science, Data Science, Statistics, Health Informatics, Medical Informatics, Bioinformatics, or any areas related;

2) Interest in working with real-world problems and large data sets;

3) Excellent proficiency in English and outstanding communication skills;

4) Strong analytical and programming skills;

5) A “can do”, positive attitude with an aspiration to change the world.

· Experience in machine learning is advantageous.

· Experience in publication of peer-reviewed literature is desirable.

**International Students**

International applicants should meet the English language requirements, please see the details from the University’s website [https://www.plymouth.ac.uk/international/how-to-apply/english-language-requirements](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Finternational%2Fhow-to-apply%2Fenglish-language-requirements&data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156854582%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=4FaDHBSrZV6ltDctnE8my9o5Ik2yuYjfYSQ9riBA%2BMo%3D&reserved=0). IELTS Academic 6.5 or above (or equivalent) with 5.5 in each individual category is commonly required by the University’s Doctoral College.

**How to Apply**

**To apply for this position,** please visit: [https://www.plymouth.ac.uk/student-life/your-studies/research-degrees/postgraduate-research-studentships/improving-medication-verification-for-cancer-patients-a-pragmatic-ai-driven-population-health-study](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Fstudent-life%2Fyour-studies%2Fresearch-degrees%2Fpostgraduate-research-studentships%2Fimproving-medication-verification-for-cancer-patients-a-pragmatic-ai-driven-population-health-study&data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156864540%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=evqRV6atr9XH02c9YiKStoxc4uPVEn2DPIC2ti82Ojo%3D&reserved=0).

**Please clearly state the name of the studentship that you are applying for on your Personal Statement.**

A research proposal is required.

Please see: [https://www.plymouth.ac.uk/student-life/your-studies/research-degrees/applicants-and-enquirers](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Fstudent-life%2Fyour-studies%2Fresearch-degrees%2Fapplicants-and-enquirers&data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156864540%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=6Jh5krrUDKqNz3B%2BjWs3Hff5ItLuUCY2KxONptebPAE%3D&reserved=0) for a list of supporting documents to upload with your application.

**Enquiry**

If you wish to discuss this project further informally, please contact Professor Shang-Ming Zhou ([shangming.zhou@plymouth.ac.uk](mailto:shangming.zhou@plymouth.ac.uk)), Dr Edward Meinert ([edward.meinert@plymouth.ac.uk](mailto:edward.meinert@plymouth.ac.uk)), or Mrs Andrea Preston ([Andrea.Preston@uhbw.nhs.uk](mailto:Andrea.Preston@uhbw.nhs.uk)).

For more information on the admissions process, please contact [doctoralcollege@plymouth.ac.uk](mailto:doctoralcollege@plymouth.ac.uk).

**Closing Date**

**The closing date for applications is 30 July 2021.** Shortlisted candidates will be invited for interview.",MachineLearning
o4dz50,1624219959.0,"Master thesis - Multidimensional Spectral Clustering [Project], [Research]","I am about to choose my topic for Master thesis and I just thought about spectral clustering algorithm. I am not much into this topic and I am wondering if somebody has more experience with this and could help me.I was thinking about taking this algorithm to multidimensional level e.g. take multiple pairs of classes in huge dataset and try to take decision of clusters based on results of each pair.

Maybe somebody know if there are some algorithms using this or similar approach with additional weights.Maybe you could tell me shortly if mine thinking of using this algorithm is correct and is there any sense to dive deeper into this topic. There are some ideas in my mind but I am not sure if this can give any positive clustering outcome.

I am also wondering if PCA method not using similar concepts?",MachineLearning
o4dph1,1624219205.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 115,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)|[Week 112](https://reddit.com/n8m6ds)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)|[Week 113](https://reddit.com/njfsc6)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)|[Week 114](https://reddit.com/ntu6lq)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)||

Most upvoted papers two weeks ago:

/u/nerdninja: [deep reinforcement learning platform at Facebook](https://arxiv.org/abs/1811.00260)

/u/DL_updates: [ByT5: Towards a token-free future with pre-trained byte-to-byte models](https://arxiv.org/abs/2105.13626)

Besides that, there are no rules, have fun.",MachineLearning
o4ajvl,1624210003.0,[D]What do you think about this „Don‘t learn Deep Learning“ post?,"Here is an interesting post I have found:

https://towardsdatascience.com/dont-learn-deep-learning-d23485e4c1c4

I am grad student by the way. I thought about taking a course on DL after two ML courses but now i am not quite sure if it wouldn‘t be better to take something else…",MachineLearning
o46gbk,1624198067.0,"[P] TorchSR, Image superresolution for pytorch","Hi all,

I started [torchSR](https://github.com/Coloquinte/torchsr/), a package for super-resolution networks written in Pytorch. It's inspired by torchvision, and should feel familiar to torchvision users. Check it out!

[Low-resolution image, super-resolution \(x4\) and ground truth](https://preview.redd.it/11pkdv2cif671.png?width=804&format=png&auto=webp&s=a92835a1727d2925b1317a5b324ac9b6eee2d387)

At the moment, I implemented many datasets, the most popular models (EDSR, RCAN, ...), and a number of network improvements and data augmentation method. Plus the training script for people who want to develop their own!

Next steps: GAN training and multiscale networks

Github repo: [https://github.com/Coloquinte/torchsr/](https://github.com/Coloquinte/torchsr/)

Python package: [https://pypi.org/project/torchsr/](https://pypi.org/project/torchsr/)",MachineLearning
o45df5,1624194644.0,[D] How to create a pre-training model for three different datasets?,"

I know a simple way, if I a dataset, I train a CNN model and I get a pretraining model.

But if I have three different datasets, x-ray, ct-scan, MRI. I cant combine them to a single dataset as the model will learn the dataset instead of classes as data characteristics are different. So if I train the model on one dataset, then 2nd, then third. Will all the training weights of three different datasets is preserved or weights will be overwritten.

Or what is the right approach to get overall embeddings",MachineLearning
o44dnp,1624191232.0,[N] Image Similarity Challenge - Facebook AI,"[https://www.drivendata.org/competitions/79/competition-image-similarity-1-dev/](https://www.drivendata.org/competitions/79/competition-image-similarity-1-dev/)

&#x200B;

>Welcome to the Image Similarity Challenge! In this competition, you  will be building models that help detect whether a given query image is  derived from any of the images in a large reference set.
>
>Content tracing is a crucial component on all social media platforms  today, used for such tasks as flagging misinformation and manipulative  advertising, preventing uploads of graphic violence, and enforcing  copyright protections. But when dealing with the billions of new images  generated every day on sites like Facebook, manual content moderation  just doesn't scale. They depend on algorithms to help automatically flag  or remove bad content.
>
>This competition allows you to test your skills in building a key  part of that content tracing system, and in so doing contribute to  making social media more trustworthy and safe for the people who use it.",MachineLearning
o43wgj,1624189655.0,[D] Deepmind's 'Reward is enough' or 'Environment is enough',"Deepmind's paper about 'Reward is enough'\[1\] only gives half the answer. We need the appropriate Environment(E)—an (E) that can simulate all the feedback to the agent. Humans already live in the real world that is the (E) to learn starting from the baby. What will be World-like (E) for Human-like A.I.?

We can achieve narrow A.I. because the (E) is easy to create, such as Chess-like or Game-like. But I am not sure how we can create this World-like (E) if we can't even understand all the physics phenomena. If we found a Human-like algorithm ready for training, we need a World-like environment to provide the so-called 'Reward.' And do we have enough computation power to run the World-Like(E)?

If 'Reward is enough' for Human-Like AI(or Artificial General Intelligence). Why can't be '(World-Like)Environment is enough'?

Let me know your comment :)

\[1\] [https://deepmind.com/research/publications/Reward-is-Enough](https://deepmind.com/research/publications/Reward-is-Enough)",MachineLearning
o41in6,1624179856.0,[R] Looking for Data Labelling Tool for Volumetric Multifeature Datasets,"

Dear all,

we are currently working on 3D medical imagery with 6 layers of different information, a sample has a size of around 120 Gb.

We are looking for a way to label these conveniently according to the following criteria:

\- extraction of individual z-sections of the XYZ volume (we have this covered)

\- labelling of one of these z-sections with the ability to turn on- and off- the individual 6 layers while there is always a merged picture of all the activated layers visible

\- adjusting gamme & histogram of these layers individually

Later on we would like to do this with volumetric data the same way, labelling structures with a volume based on several z-sections of the volume.

We couldn't find a standard solution and are evaluating we should adjust one of the open source solutions out there.

Does anyone know if any other data labelling tool has some of the above mentioned features?",MachineLearning
o40tqx,1624177151.0,[P] 🐝 CVPR Buzz - Discover Trending Papers at CVPR 2021,"Website: [https://mattdeitke.com/cvpr-buzz/](https://mattdeitke.com/cvpr-buzz/) (Best viewed on Desktop)

GitHub: [https://github.com/mattdeitke/cvpr-buzz](https://github.com/mattdeitke/cvpr-buzz) | MIT License

&#x200B;

[Demo](https://preview.redd.it/q2jgvyznld671.png?width=3552&format=png&auto=webp&s=7b9a700cd2e84dbeaca2191a5e94bf2b646e4d91)

With CVPR 2021 starting this week, I scraped the interwebs to put together a quick site to help discover some of the papers that have been talked about and cited the most.

Pretty excited with how it came out! It's helped me skim through some new work that I hadn't previously seen.

Let me know if you have any thoughts/suggestions. (You can also missing data on the [GitHub repo](https://github.com/mattdeitke/cvpr-buzz).)",MachineLearning
o40t48,1624177090.0,[P] ML Optimizers from scratch using JAX,"Github link (includes a link to a Kaggle notebook to run it directly) -  [shreyansh26/ML-Optimizers-JAX](https://github.com/shreyansh26/ML-Optimizers-JAX)

Implementations of some popular optimizers from scratch for a simple model like Linear Regression. The goal of this project was to understand how these optimizers work under the hood and try to do a toy implementation myself. I also use a bit of JAX magic to perform the differentiation of the loss function w.r.t to the weights and the bias without explicitly writing their derivatives as a separate function. 

This can serve as an excellent tutorial for beginners who want to explore optimization algorithms in more detail.",MachineLearning
o3z63e,1624170015.0,[N] Facebook AI Open Sources AugLy: A New Python Library For Data Augmentation To Develop Robust Machine Learning Models,"Facebook has recently open-sourced AugLy, a new Python library that aims to help AI researchers use data augmentations to evaluate and improve the durability of their machine learning models. AugLy provides sophisticated data augmentation tools to create samples to train and test different systems.

AugLy is a new open-source data augmentation library that combines audio, image, video, and text, becoming increasingly significant in several AI research fields. It offers over 100 data augmentations based on people’s real-life images and videos on platforms like Facebook and Instagram.

Article: [https://www.marktechpost.com/2021/06/19/facebook-ai-open-sources-augly-a-new-python-library-for-data-augmentation-to-develop-robust-machine-learning-models/](https://www.marktechpost.com/2021/06/19/facebook-ai-open-sources-augly-a-new-python-library-for-data-augmentation-to-develop-robust-machine-learning-models/)

Github: [https://github.com/facebookresearch/AugLy](https://github.com/facebookresearch/AugLy)

Facebook Blog: https://ai.facebook.com/blog/augly-a-new-data-augmentation-library-to-help-build-more-robust-ai-models/",MachineLearning
o3qch1,1624138268.0,[D]Is knowledge about Probabilistic Graphical Models a core competence in ML?,"I have read a thread a while ago where the question was whether one should take deep learning as a course in university after taking a ML course.

Lot of people said, that it is better to focus on the foundations and to learn more about ML in general.

""Deep Leanring isn't the universal remedy people are making it out be. Stick to the basics and learn them very well and if your job wants you to do something with DL than you can begin to learn it. ""

Is the same true for PGMs?",MachineLearning
o3meco,1624126809.0,[P] VkFFT now supports Discrete Cosine Transforms on GPU,"Hello, I am the creator of the [VkFFT](https://github.com/DTolm/VkFFT) \- GPU Fast Fourier Transform library for Vulkan/CUDA/HIP and OpenCL. In the latest update, I have added support for the computation of Discrete Cosine Transforms of types II, III and IV. This is a very exciting addition to what VkFFT can do as DCTs are of big importance to image processing, data compression and numerous scientific tasks. And so far there has not been a good GPU alternative to FFTW3 in this regard.

VkFFT calculates DCT-II and III by mapping them to the Real-to-Complex FFT of the same size and applying needed pre and post-processing on-flight, without additional uploads/downloads. This way, VkFFT is able to achieve bandwidth-limited calculation of DCT, similar to the ordinary FFT.

DCT-IV was harder to implement algorithm-wise - it is decomposed in DCT-II and DST-II sequences of half the original size. These sequences are then used to perform a single Complex-to-Complex FFT of half-size where they are used as the real and imaginary parts of a complex number. Everything is done in a single upload from global memory (with a very difficult pre/post-processing), so DCT-IV is also bandwidth-limited in VkFFT.

DCTs support FP32 and FP64 precision modes and work for multidimensional systems as well. So far DCTs can be computed in a single upload configuration, which limits the max length to 8192 in FP32 for 64KB shared memory systems, but this will be improved in the future. DCT-I will also be implemented later on, as three other types of DCT are used more often and were the main target for this update.

Hope this will be useful to the community and feel free to ask any questions about the DCT implementation and VkFFT in general!",MachineLearning
o3m3ah,1624125985.0,[R] Trash/Garbage dataset for waste detection,"Hi Guys, We've published Trash/Garbage dataset which can be used for waste detection and sustainibility based projects.

Check then now: [https://www.kaggle.com/dataclusterlabs/domestic-trash-garbage-dataset](https://www.kaggle.com/dataclusterlabs/domestic-trash-garbage-dataset)

If you like it, you can give upvotes into our kaggle platform. We're trying to make custom dataset and open-sourcing on Kaggle to make AI models more robust.

Thanks",MachineLearning
o3kd5g,1624121518.0,[R] Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap,"&#x200B;

[When attempting to mimic an expert, a learner could learn by \(a\) rolling out their policy and comparing generated trajectories to expert trajectories, \(b\) producing actions on expert states and attempting to match action-conditionals, or \(c\) performing rollouts and attempting to match corrections provided by a queryable expert. We provide, for each of these settings, bounds for how well the learner can do, reduction-based algorithms for efficiently finding strong policies, and simple yet competitive practical instantiations that can scale to high-dimensional tasks.](https://preview.redd.it/8s24ad6016671.png?width=678&format=png&auto=webp&s=61d9a5518a9912cd97b8ddf5d7005e233f51e328)

Paper: [https://arxiv.org/abs/2103.03236](https://arxiv.org/abs/2103.03236)

Code: [https://github.com/gkswamy98/pillbox](https://github.com/gkswamy98/pillbox)

Videos: [https://www.youtube.com/playlist?list=PL51kEpt5uSsbZSaGyUMsLsOoFP8-hyx0R](https://www.youtube.com/playlist?list=PL51kEpt5uSsbZSaGyUMsLsOoFP8-hyx0R)",MachineLearning
o3i4gh,1624115297.0,[D] The PDLT document from Facebook is currently worthless as a scientific text and exemplifies the serious problem we are facing with reproducibility within the community.,"https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/


From the preface:


""First and foremost, in this book we’ve strived for pedagogy in every choice we’vemade, placing intuition above formality. This doesn’t mean that calculations are incomplete or sloppy; quite the opposite, we’ve tried to provide full details of every calculation– of which there are certainly very many – and place a particular emphasis on the toolsneeded to carry out related calculations of interest. In fact, understanding how the calculations are done is as important as knowing their results, and thus often our pedagogicalfocus is on the details therein.


Second, while we present the details of all our calculations, **we’ve kept the experimental confirmations to the privacy of our own computerized notebooks**. Our reasonfor this is simple: while there’s much to learn from explaining a derivation, there’s notmuch more to learn from printing a verification plot that shows two curves lying on topof each other. **Given the simplicity of modern deep-learning codes and the availabilityof compute, it’s easy to verify any formula on your own**; we certainly have thoroughlychecked them all this way, so if knowledge of the existence of such plots are comfortingto you, **know at least that they do exist on our personal and cloud-based hard drives**.""


I can't speak for everyone reading this.  I can only speak for myself. That said, I have a PhD in physics and I currently work as a deep learning research scientist and engineer for a major tech company. I have dedicated my entire life to the study of natural law, science, and the nature of scientific inquiry as a whole. Never once in more than two decades of my time as a graduate student, a scientist, and an engineer have I ever read a text book that began...


""We know you want to see the evidence.  We know you want to know what experiments we ran to appropriately test these theories.  We know you want to know to what degree of significance we have rejected various other hypotheses, and how that was done.  We know you want to know **but we aren't going to tell you.  We leave the verification of this work as an exercise to the reader. Trust  us** ""


What are we even supposed to do with this?!


No WONDER we have an issue with reproducibility in the field when deep learning ""scientists"" are publishing documents without any actual science in it! No wonder we have literal collusion rings in our peer review process!


There is a full litany of mathematical assumption that form the foundation of the deductions made in this document and the author's claim to their validity stand solely on their trustworthyness.  Need I remind you all that they work for a corporation, Facebook specifically, that isn't exactly known for its honesty.


I am reminded of the motto of the Royal Society, one of the most well established scientific institutions in modern history.


Nullius in verba

Words are empty.


Take nobody's word for it",MachineLearning
o3hkd5,1624113733.0,[D] Understanding of batch renormalization,"

Hello!

I was going in details through paper about batch renormalization [(arxiv link)](https://arxiv.org/abs/1702.03275).  I don't quite understand two things there. Maybe there is anyone who  faced similar issues / knows the answer and could give me some hints?

1. Why  in the formula here we don't multiply by the derivative of sigma\_b over  mi\_b? The standard deviation is not a constant but it's a function of  the mean (mi\_b). However the final formula for dl/dx\_i it's the same as I  get, so the equations are overall fine.

&#x200B;

https://preview.redd.it/2ndycfmdi8671.png?width=249&format=png&auto=webp&s=1e3e83549a105b64da9a2a835d2dbd545364fad0

2.  Also I have a problem with the underlined sentences. It would be nice  to know at least what should I calculate step by step to reach this  conclusions.

&#x200B;

https://preview.redd.it/oxwmwr7ei8671.png?width=991&format=png&auto=webp&s=f7989136b58e6ff336e1dcf62dcd6a6f39377ffb

My  idea is that we have to find the ortogonal basis of the kernel of a  matrix with 2 columns: p0 and p1 and later project scaled dl/dx\_dashed  onto it? Or maybe there is better way to do it?

The next sentence is also not clear to me.",MachineLearning
o3g30j,1624109234.0,[R] MLP Mixer paper explained,"MLP Mixers is a recent [paper](https://arxiv.org/pdf/2105.01601.pdf) from Google Brain team which shows vanila neural networks designed wisely can perform as good as Convolutional Neural Networks or Transformers. We think the idea is quite promising. So we have made a video on MLP Mixer. Hope its useful:

[https://youtu.be/GStFwC\_Cr88](https://youtu.be/GStFwC_Cr88)",MachineLearning
o3crak,1624097264.0,[P] Paper recommendation on causal reinforcement learning,"

Hi guys,

So I'm currently a master's student in machine learning (computer vision specialisation) and it's about time I start with my thesis. The thing is, my knowledge so far has been heavily emphasized on computer-vision-related deep learning but I'm still a virgin regarding causal inference.

However, my ultimate goal, for now, is to do PhD in causal AI, especially in causal reinforcement learning. I am very interested in AI in games as well so ideally, I would love to try to teach AI how to play basic games in a simulated world and learn through reinforcement learning as well as having the concept of causality. So I want my master thesis to be the first stepping stone towards my PhD proposal. The thing is, I'm not sure if this sounds too simple or if its sounds too much. I have read and studied about causal inference and I have done projects on reinforcement learning, but I think I'm still stuck on how to combine the two together at this point.

I have been looking through papers in the past few days but I don't think I have looked deep enough yet. If anyone here has any recommended papers, interesting projects that could help me, or even ideas on how to improve my current master's proposal, I'll be extremely appreciated it. Thank you in advance.",MachineLearning
o3chs3,1624096360.0,[P] An experimental machine learning package for easy and fast prototyping,"Hi all,

[igel](https://github.com/nidhaloff/igel) is a fairly new machine learning package that allows you to create ML prototypes on the fly. You can use igel from the terminal without writing any code or from python if you want to. I tried to keep the API simple enough and flexible as possible.

Recently, igel supports serving trained models by exposing a REST server (using FastAPI and uvicorn for production use). Hence, you can train, evaluate, test, generate predictions, serve and use your model in production. I'm pretty excited what users will think about the last release. I wanted to share it with you all.

Github repo: [https://github.com/nidhaloff/igel](https://github.com/nidhaloff/igel)",MachineLearning
o3c7p0,1624095079.0,[P] KubeSurvival - Easy K8s Cost Optimization - Useful for clusters with a lot of ML training jobs & model servers,"Just wanted to share a cool new open-source tool I built to **significantly reduce Kubernetes compute costs**, by finding the cheapest machines that successfully run your workloads.

It's designed for clusters with a lot of ML training jobs & model servers - these can get really expensive (especially if you use GPUs).

Check it out: [https://github.com/aporia-ai/kubesurvival](https://github.com/aporia-ai/kubesurvival)",MachineLearning
o395fy,1624081033.0,[Research][Discussion] Roadmap for a Research Scientist position,"Hello everyone,  I'm currently in my 4th year of a PhD in CSE(AI/ML). I'm very much interested in the position of a research scientist. Since I have hardly one year for graduation, I would like know the roadmap to achieve a good role after graduation. I would like to ask  suggestions, advices and recommendations from the experts.",MachineLearning
o38thr,1624079567.0,[D] CNN on mel spectrograms vs. WaveNet for audio recognition?,"So I am creating an app in which I intend to rank a user-inputed song according to its similarity to Jimi Hendrix songs. Similar projects have been done before and, from what I've seen, the go-to approach is to train a CNN on mel spectrograms. This is also what was suggested to me.

Well, today I was talking about this in an AI discord and someone told me that the CNN on mel spectrogram approach is dead, and that using WaveNet is superior. However, I have found no literature nor resources on using WaveNet for audio recognition.

I'm still in the stage of needing my hand held on these types of projects. I don't have enough experience under my belt to extrapolate for this kind of thing, having only done a few machine learning projects. Is WaveNet truly superior for audio problems? Its focus seems to be on generating audio.

What are you all's thoughts?",MachineLearning
o37iqb,1624074763.0,"[D] How do models like ARMA and ARIMA fare against ""sporadic memory""?","Is it fair to assume that standard time series models like the ARMA and the ARIMA model are not well designed to handle ""sporadic and irregular"" memory patterns? As I understand, these models are usually used to handle data with well-behaved notions of ""trends"" and ""seasonality"" (e.g. you specify these in a given ARIMA model) . When you start to deal with more complicated and irregular patterns, do ARMA/ARIMA models tend to perform poorly? Was this the motivation for eventually moving towards neural network based models (e.g. RNN, LSTM) for time series analysis?

&#x200B;

Thanks",MachineLearning
o303nw,1624049931.0,[P] Megatron-LM - Annotated Paper!!,"Megatron-LM provides a simple yet innovative approach on how to parallelize models to train large (multi-billion parameters) language models and efficiently use GPU memory during scaling. The key point is that it does not require any major modifications (like compilation or an entirely new framework) to implement this in the existing code. It also suggested a small modification in the BERT architecture which allowed BERT to scale effectively to parameter sizes that did not perform well on before.

I will focus more on papers on model scaling techniques in the upcoming few annotated papers as I want to gain more idea about this area. Check out the annotated paper below -

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/MegatronLM.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/MegatronLM.pdf)",MachineLearning
o2u2cm,1624035433.0,[P]wyGPT: improved small GPT model in C++ from scratch,"Dear All:

&#x200B;

  I coded a small GPT model for CPU from scratch in C++. See the following links:

&#x200B;

[https://github.com/wangyi-fudan/wyGPT](https://github.com/wangyi-fudan/wyGPT)

&#x200B;

The major improvement compared to minGPT is that the MLP layer increase to 3 hidden layers.

&#x200B;

2012.14913 says the MLP layer is a key-value map. 2010.14075 says three hidden layer is enough. Thus now we have a ""enough key-value map"".

&#x200B;

Also sin activation is used as suggested by [https://vsitzmann.github.io/siren/](https://vsitzmann.github.io/siren/)

&#x200B;

Have funs!",MachineLearning
o2t66t,1624033374.0,"[D] CPU AMD and GPU NVIDIA RTX for machine learning, is it OK?","I need to build a PC with the following set up and I like to know if there is any issue regarding the Machine Learning frameworks etc.

* CPU:  AMD Ryzen 9 5950X Processor
* Motherboard:  Asus ROG X570 Crosshair VIII Hero WI-FI ATX AM4 Motherboard
* GPUs: (1). NVIDIA RTX 2070 Super Windforce. (2). NVIDIA RTX 3090

Until now, I am using Intel-based CPU and supported motherboard but as I now want to use AMD-based CPU and supported motherboard, I am a bit confused about if it is ok for machine / deep learning frameworks such as TensorFlow, PyTorch. Any compatibility issue or anything like that?",MachineLearning
o2sdls,1624031824.0,[D] Serverless GPU?,"I need to deploy a vision model that will run a small inference job (1-5s) per request. Is there a serverless offering out there that does this?

There are other previous posts on this subreddit but I know this space is moving fast so thought it worth asking again.

So far I’ve seen AWS Sagemaker kind of allows for a situation like this, but would rather not deal with all that config. Algorithmia and Nuclio are too enterprise focused. [Neuro](https://getneuro.ai) is new and looks great, but from my understanding I would still need to create a lambda instance myself that then calls neuro’s servers - too indirect. Is there a total solution out there for this?

Ideally something that is as straightforward to use as neuro but also handles http requests.",MachineLearning
o2rxd7,1624030635.0,"[R] Game On! MIT, Allen AI & Microsoft Open-Source a Suite of AI Programming Puzzles","A research team from MIT, Allen Institute for AI and Microsoft Research open-sources Python Programming Puzzles (P3), a novel programming challenge suite that captures the essence of puzzles and can be used to teach and evaluate an AI's programming proficiency.

Here is a quick read: [Game On! MIT, Allen AI & Microsoft Open-Source a Suite of AI Programming Puzzles.](https://syncedreview.com/2021/06/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-44/)

The paper *Programming Puzzles* is on [arXiv](https://arxiv.org/abs/2106.05784).",MachineLearning
o2qrho,1624027576.0,"[D] can someone please explain what the ""white color shades"" mean in this picture?","[https://martin-thoma.com/images/2016/01/ml-classifiers-2.png](https://martin-thoma.com/images/2016/01/ml-classifiers-2.png)

These pictures are supposed to show the decision boundaries of different machine learning algorithms on a binary classification task. There are two classes for the response variable: ""red"" and ""blue"".

Shouldn't all the decision boundaries either be fully red or fully blue? What do the shades of white mean? Does this mean ""an overlapping decision boundary""?

Thanks",MachineLearning
o2q1h8,1624025599.0,[R] Complex-Valued Neural Networks,So what do you think about Complex Valued Neural Networks? Can it be a new interesting field to look at? Mostly for the Signal Processing or Physics community.[https://arxiv.org/abs/2009.08340](https://arxiv.org/abs/2009.08340),MachineLearning
o2pqfa,1624024782.0,[D]: Random Forest vs Gradient Boosting out of distribution,"Hello everyone,

I'm working on a classification task where I have data from a certain company for years between 2017 and 2020. Trying to train different models (Random Forest, XgBoost, LightGBM, Catboost, Explainable Boosting Machines) on separate data with one year at a time from 2017 to 2019 and looking at the results for 2020, I see a curious behavior and I would like to understand whether it is a normal one in the literature or dependent on the particular data.

In particular, while training with data from 2019, all the boosting algorithms obtain better performances than random forest (0.78-0.79 AUC vs 0.76). This dramatically changes, when I train a model on 2017 or 2018 data for 2020. This data is slightly out of distribution, as there is for sure label shift and data is quite different. (and the learned models' feature importances/PdP are quite different between the years). But here Random Forest still learns to generalize decently (for 2020 data we have a AUC of 0.704 if trained on 2017 and 0.706 if trained on 2018), while the boosting algorithms have on average worse performance, with a big difference for LightGbm between the two datasets ( For 2017 Xgboost 0.567, LGBM, 0.565, Catboost 0.639, EBM 0.521; for 2018 Xgboost 0.661, LightGBM 0.734 (??), Catboost 0.639, EBM 0.685).

Provided I have not performed extensive hyperparameter tuning and further testing and this might be a really particular case dependent on data and hyperparameters, still, I was wondering:

**Does there exist some literature (I cannot find) on the robustness out of distribution of Random Forest vs Boosting algorithms which might explain this behavior?**

Because intuitively, it might make sense that the variance reduction obtained by bagging would help even out of distribution, as some learners might still have learnt something relevant, but I am not sure it is enough.

PS As a sanity check I also tried with a logistic regression and a gaussian NB, which have the same consistent decrease in performance (0.7 to 0.45-0.6).",MachineLearning
o2o3cr,1624019722.0,[D] For combating AI bias for people of different skin colors,"I was thinking about this problem, and I was wondering - what do you guys think is the best approach to solve this? Would we need to tweak network structures, or is correct dataset evaluation more important?

One of the most obvious solutions is to have a pre-trained GAN as a pre-processing step for facial images that augments the colour space in such a way that all the faces in a big dataset converge on a single randomly chosen colour - thus ensuring no bias for the model to exploit.
My take is that pre-processing ensures the skin colours received by the model is the same, and then reverses it if outputting/storing results would counteract the bias in a naive form. while the diversity of datasets is important, it may not be achieved in every use-case. So I think such a method would be very generalizable to all datasets as well as reduce computation load.

what do you all think?",MachineLearning
o2nba9,1624017100.0,"""[Project]"" My own Open-Source AutoML Library","My name is Daniel, and I'm excited to introduce you my (and another great developer) school diploma project. Fully open-source, Automated Machine Learning Library! We are beating built-in AutoML in SAP famous product.
GitHub repository:
https://github.com/dan0nchik/SAP-HANA-AutoML
Web-application for users who don't want to code:
https://share.streamlit.io/dan0nchik/sap-hana-automl/main/web.py",MachineLearning
o2mrbu,1624015153.0,[D] Darknet YOLO v4 with CUDA 11,Hello everyone! Has someone managed to build [yolo\_v4](https://github.com/AlexeyAB/darknet) (darknet) with latest Cuda versions (11.2 or later)? I am stuck in dependency loop of older drivers not supporting 3000 series and newer Cuda requiring latest drivers.,MachineLearning
o2jmrc,1624002302.0,[D] Network science applied to images (structure/community analysis),"I am working with a large image dataset embedded via a CNN model with the goal of clustering the images in an unsupervised manner.

The majority of works on clustering in the embedding space tend to use classical clustering methods (e.g. K-means, agglomerative), but those are often limited in the types of structures they can detect in the data. I have also looked into Deep Clustering, but it seems like there the methods assume non-overlapping or non-hierarchical structure, which is quite a limitation. I was therefore wondering if someone tried converting the image embeddings into a graph and applying some network analysis methods on top of it, e.g. community detection ones.

Surprisingly, after a week or so of research, I couldn't find papers that did so (especially on a large scale). Has someone encountered a similar idea or can help me understand why are there no or just a few works on it? Would appreciate any links or hints.",MachineLearning
o2i730,1623996383.0,[D] Modern Machine Learning Models for Time Series Analysis,"Does anyone know what are the most modern statistical models being used for time series analysis? I have heard of transformer and attention mechanisms models that are used for modelling sequential data - but these seem to be more relevant for modelling data from the NLP domain. When it comes to classical time series modelling (e.g. a vector of temperature measurements) : does anyone know what are some of the more modern models being used for this? I did some searching online : it seems like ARIMA style models were some of the first ones, followed by state space models/hidden markov, and the more recent ones being RNN and LSTM.

Are LSTM and RNN the most modern models that are being used for classical time series problems?

Thanks",MachineLearning
o2gpjk,1623990957.0,[N] AugLy: a new multimodal data augmentation lib from FB Research,"FB Research just released a new data augmentation library!

It supports audio, image, video, and text with over 100 augmentations.

It was developed with near-duplicate detection use case in mind and features unique augmentations like:

> one of our augmentations takes an image or video and overlays it onto a social media interface to make it look like the image or video was screenshotted by a user on a social network like Facebook and then reshared


[Post](https://ai.facebook.com/blog/augly-a-new-data-augmentation-library-to-help-build-more-robust-ai-models/)

[Code](https://github.com/facebookresearch/AugLy)

You can find docs for each domain in respective dirs README https://github.com/facebookresearch/AugLy/tree/main/augly",MachineLearning
o2eoi7,1623984188.0,[D] Anyone attended the Oxford Machine Learning Summer School?,"Has anyone attended the Oxford Machine Learning Summer School in the past? I got accepted and am curious what the experience is like. It's a little bit difficult for me to attend since it's occurring in a difficult time zone for more than two weeks and I am wondering if it's worth it to attend. To those who have attended, what was your experience like? Is it more than just a bunch of seminars? Are there hands-on tutorials? Also, overall, is the summer school well-known or prestigious and would it be valuable to a graduate student who is interested in a career in academia?",MachineLearning
o2bgiz,1623973971.0,"[D] Is highly imbalanced classification largely considered a ""solved"" problem?","I've recently moved on from a position where I built fraud prevention models.  Our typical class ratio was something like 2500:1 negative:positive.


Our typical method was to use Xgboost with positive weight scaling in our hyperparam search space (amongst other params).  We got decent results but I always felt there was more we could do. However, almost all recent news and publications seem to surround unsupervised learning, deep learning, transformers etc.

I'm wondering if there have been any semi recent advancements in this field of study?  Engineering new features is an obvious next step but I'm wondering if there's anything we've been missing on the training algorithm side of things.",MachineLearning
o28n63,1623966024.0,[N] Introducing Distributed XGBoost Training with Ray,"In the past months we've been working on a Ray-based backend for distributed XGBoost. Features include **multi node/multi GPU training**, advanced **fault tolerance** (e.g. **elastic training**), loading from **distributed data sources**, as well as integration with **hyperparameter optimization** framework [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).

See here for the full blog post: [https://www.anyscale.com/blog/distributed-xgboost-training-with-ray](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray)

And the GitHub link here: [https://github.com/ray-project/xgboost\_ray](https://github.com/ray-project/xgboost_ray)

Happy to hear any comments!",MachineLearning
o26l57,1623960705.0,[D] Relative Robustness on Adversarial Attacks,"While testing several defensive models against Carlini Wagner (CW) attack, I am wondering what would be a good way to measure relative robustness of defenses.

Let's say that I have defensive models A and B. When they are attacked by CW attack, both models' accuracy end up becomes 0%, which means the attack is so effective that the defenses are not useful. However, is there any way that measure relative robustness between A and B against CW in this case? Although A and B are of no use against CW attack, there can be difference on robustness providing information that A is relatively more robust than B (or in other way).

In case of PGD attack, amount of perturbation (epsilon) can be controlled. Therefore, although a defense becomes useless when epsilon is large, we can still see and compare robustness of defenses with smaller epsilon. But, for CW attack, I don't think limiting the number of iterations or other parameters are valid ways to limit the degree of CW attack.

I wonder what you think about this.",MachineLearning
o26ks9,1623960682.0,"[N] IBM Releases UQ360 AI tool, An Open Source Tool To Measure Model Uncertainty","Deep learning-based Artificial Intelligence (AI) systems have a history of generating overconfident predictions, even when they are inaccurate, which can have significant repercussions. If a self-driving car firmly misidentifies the side of a tractor as a brightly illuminated sky and refuses to brake or alert the human driver, would you prefer to travel in that? I doubt it. Self-driving cars aren’t the only issue. There is a slew of additional applications where AI’s ability to convey doubt is essential. For example, if a chatbot is uncertain when a pharmacy shuts and gives a false answer, a patient may not receive the medicines they require.

Here’s where IBM’s Uncertainty Quantification 360 (UQ360) comes in to rescue the day. UQ360 allows the AI to communicate its uncertainty, making it more intellectually humble and increasing the safety of its deployment. Its goal is to provide data scientists and developers with cutting-edge algorithms for quantifying, analyzing, enhancing, and exposing the uncertainty of machine learning models.

Article: [https://www.marktechpost.com/2021/06/17/ibm-releases-uq360-ai-tool-an-open-source-tool-to-measure-model-uncertainty/?\_ga=2.217770833.636390090.1623335762-488125022.1618729090](https://www.marktechpost.com/2021/06/17/ibm-releases-uq360-ai-tool-an-open-source-tool-to-measure-model-uncertainty/?_ga=2.217770833.636390090.1623335762-488125022.1618729090)

IBM Blog: [https://www.research.ibm.com/blog/uncertainty-quantification-360](https://www.research.ibm.com/blog/uncertainty-quantification-360)",MachineLearning
o2626r,1623959428.0,[R] Improving Language Model Behavior by Training on a Small Curated Dataset,"Interesting research results by [OpenAI](https://openai.com/blog/improving-language-model-behavior/). It seems possible to improve the behavior of  a  GPT-3 language model  by fine tuning it  on a very small dataset. Of course, we are talking about undesirable biases (hateful, agressive, racist, sexist, etc.). They only used 80 texts. On the other hand, they neglect to say that someone can very well adjust the generated texts to favor biased texts with again a very small corpus. The [scientific paper](https://cdn.openai.com/palms.pdf) (PDF).",MachineLearning
o25jr6,1623958134.0,Predicting Human Randomness with Machine Learning [P] [R],"This is my first post to Machine Learning, so I'm not completely sure what I should write. Recently I have been experimenting with neural networks and machine learning and I wondered how accurately a neural network could recognize patterns in human-generated \*random\* sequences of numbers. So I tried as hard as I could to create a randomly generated sequence and I inputted around 1200 numbers.

The sequence was made of numbers 1-9 (no ten or zero), so randomly guessing the numbers would give you an 11.11% accuracy. To my surprise my neural network guessing them with up to 27% accuracy. I was shocked by how accurate the neural network was with relatively little test data.

This discovery opens many other possibilities and I have many ideas for how this can be applied. Using this neural network you can measure how random a number sequence. I have a done a test with my sister, and the accuracy of the AI varies depending on who's number sequence inputted. Why do people have different degrees of randomness? Is it correlated to intelligence? This is one of the many questions I had while working on this experiment.

If you would like to help me with this project (programming/generating sequences) please PM me. Any help would be appreciated thanks for reading this post. The link to GitHub is here: [HumanRandomness](https://github.com/DragonDmoney/HumanRandomness)",MachineLearning
o22nxg,1623950869.0,[D] history of non-parametric models in machine learning,"I have been reading about the use of non-parametric models in machine learning (e.g. kernel methods like svm, kernel regression ... decision trees, gradient boosting, random forest) - and I tried to contextualize the reasons why these methods emerged (in my head). This is the conclusion I reached:

1) Parametric models (like standard regression models) are tricky. Parametric models require certain assumptions about the data to be true, also require the analyst to manually specify interaction terms within variables - but the biggest drawback: regression models tend to require more beta coefficients to capture more complex patterns within the data. A regression model with many beta coefficients behaves similar to a higher order polynomial function: and higher order polynomials are notorious for behaving in very unpredictable ways outside the range of observed data (runge phenomenon) - this basically explains why higher order regression models have a bad reputation of overfitting training data and generalizing poorly to new data. This is all related to the bias-variance tradeoff.

2) Non-parametric models do not require interaction terms between variables to be manually specified (e.g. in a decision tree, you don't need to specify this - the decision tree will try to recover these interactions by itself), and have less stringent assumptions about the data (e.g. choice of kernel). The appeal of non parametric methods was an attempt to defy the bias-variance tradeoff: the idea of trying to make a less complex model with the ability to make predictions comparable to a complex model, with the hope that the lack of explicit complexity leading to better generalization on test data.

3) the popularity of neural networks (a parametric model) is due to the fact that researchers found out ways to make these explicitly complex models generalize to unseen data (e.g. effective regularization methods).

Is my interpretation of the history correct?

Thanks",MachineLearning
o1ziev,1623942538.0,[R] Does Knowledge Distillation Really Work? NYU & Google Study Provides Insights on Student Model Fidelity,"A research team from New York University and Google Research explores whether knowledge distillation really works, showing that a surprisingly large discrepancy often remains between the predictive distributions of the teacher and student models, even when the student has the capacity to perfectly match the teacher.

Here is a quick read: [Does Knowledge Distillation Really Work? NYU & Google Study Provides Insights on Student Model Fidelity.](https://syncedreview.com/2021/06/17/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-43/?_thumbnail_id=29495)

The paper *Does Knowledge Distillation Really Work?* is on [arXiv](https://arxiv.org/abs/2106.05945).",MachineLearning
o1zgjo,1623942405.0,[R] MLP Singer: Towards Rapid Parallel Korean Singing Voice Synthesis,"Hey r/MachineLearning,

I'm excited to introduce ""MLP Singer: Towards Rapid Parallel Korean Singing Voice Synthesis."" It's K-POP singer in the making (a baby step forward in that direction).


Paper: https://arxiv.org/abs/2106.07886 \
Demo: https://mlpsinger.github.io \
Code: https://github.com/neosapience/mlp-singer


**Motivation** \
Many singing voice synthesis (SVS) models use an autoregressive design in which acoustic features produced from the previous time step are fed into the model to generate the next set of mel-spectrogram frames. While AR models have their advantages, they are prone to exposure bias and can be time-consuming to train and sample.

**Solution** \
We were inspired by [MLP-Mixer](https://arxiv.org/abs/2105.01601), an architecture exclusively composed of multi-layer perceptrons introduced in the CV literature for efficient image classification. We experimented with the model and found that MLP-Mixer can also be used in a generative context in the audio domain. Since the Mixer block works with transposed latent features, it gains a receptive field equal to the size of the input chunk. This can be helpful for generating context-aware representations.

**Advantages** \
MLP Singer is a non-autoregressive, parallel SVS model. Hence, its generation time is much faster than conventional AR SVS systems. We found that the inference latency of MLP Singer on a CPU is comparable to that of an AR model on GPU. MLP Singer achieved a real-time factor of around 3400 on an NVIDIA RTX 6000 GPU.

**Limitations & Remedies** \
Since MLP Singer is a parallel model that generates mel-spectrograms in chunks, audible artifacts can be produced when generated chunks are sequentially put together. To mitigate this issue, we employ an overlapped batch segmentation method that gives the model more frames to look at near frame edges. Detailed explanations and experiment results can be found in the [paper](https://arxiv.org/abs/2106.07886).

Looking forward to feedback and discussion!",MachineLearning
o1zbyf,1623942075.0,Youtube Discussion Tree API [P],"Hey there!


This last days, i've been working on a python API that allows you to obtain the discussion that occurs in the comments of a YouTube video as a tree structure.


YouTube Data API doesn't give enough information in order to construct the full conversation tree, because when you enter a reply to a comment that is a reply to another comment, YouTube doesn't match the parent reply Id as the one that you are replying to. Instead, it automatically puts the Id of the top level comment!


So I made a library that, using YouTube Data API and an algorithm that automatically resolve this kind of conflicts,  let you download the full discussion tree that happens on a YouTube video.


This has been made as my Final Degree Project for a Research Group of my Uni, as a module of one of his projects that is about analyzing the argumentative and the discussions that take place on Social Media. I thought that could be cool posting it here in case there is someone looking for something like this.


You can go check it out at:


[https://github.com/quimpm/youtube_discussion_tree](https://github.com/quimpm/youtube_discussion_tree)


or:


[https://pypi.org/project/youtube-discussion-tree-api/](https://pypi.org/project/youtube-discussion-tree-api/)


If you have any comment on the implementation, or you want to share some features that can be added to de library, hit me up! Any kind of feedback will be pleasantly accepted!",MachineLearning
o1z8x8,1623941871.0,"[D] CVPR Panels with Richard Socher, Olga Russakovsky, HuggingFace, W&B, Anyscale, MSFT, Google, etc. What should we ask them?","Hi [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)! :)

CVPR is starting this week! We're holding two CVPR panels on the future of datasets and next-gen ML infrastructure. If you could ask one question to one of those attendees, what would it be? Comment below if you want to ask a question on the topics mentioned and we will do our best to include it in the discussion!

**1. CVPR pre-game: the Future of Datasets**When: **tomorrow, June 18th at 12 pm EDT / 9 am PST**. [**Clubhouse link**](https://www.joinclubhouse.com/event/PAD2Nnen)**.**

*Topic: Currently, when companies train their ML models, they focus on optimizing their models rather than the actual data. But data sits at the core of a good model. How can we be more data-centric in ML?*

Guests include:

* Olga Russakovsky, ImageNet Challenge co-author, Princeton,
* Richard Socher, ImageNet co-creator, CEO You.com,
* Jeff Boudier, HuggingFace Chief of Product, 
* Joseph Gonzalez, UC Berkley RiseLab,
* Jianing Wei, Google AI,
* Siddhartha Sen, Microsoft Research.

**2. CVPR Panel: Next-Gen ML Infrastructure For Computer Vision**

When: **Monday, June 21st at 3 pm EDT / 12 pm PST**. [**Clubhouse link**](https://www.clubhouse.com/event/mWV902w6).

*Topic: There are few existing solutions for data-centric ML. In this discussion, we explore tooling and infrastructure to get the most out of data*Guests include:

* Tobi Knaup, CEO & Co-Founder at D2iQ,
* Lukas Biewald, CEO at Weights & Biases, 
* Waleed Kadous, Head of Engineering at Anyscale,
* Glenn Jocher YOLOv5 creator, CEO at Ultralytics,
* Tianqi Chen, CTO at OctoML,
* Dillon Erb, CEO at Paperspace,
* Josh Tobin, ex-Open AI, CEO at Gantry,
* Davit Buniatyan, CEO at Activeloop,

BTW, Clubhouse is now available both on [Android](https://play.google.com/store/apps/details?id=com.clubhouse.app&hl=en&gl=US) and [Apple](https://apps.apple.com/us/app/clubhouse-drop-in-audio-chat/id1503133294). If you'd like your question to be asked, please comment below and we'll pick the most voted questions/try to cover as many of them as possible. Also let me know if you'd like to attend and need an invite!

See you at CVPR and thanks for the tips!",MachineLearning
o1xf74,1623936966.0,[D] Paper digest - SimSwap: An Efficient Framework For High Fidelity Face Swapping by Renwang Chen et al (reading time ~5 minutes),"**🔑 Keywords:**
\#ACM\_MM\_2020 #encoder\_decoder #face\_swapping #feature\_matching #identity\_transfer

**🎯 At a glance:**
FaceSwap apps have been around for ages, hence you might be thinking that swapping the faces of two people is trivial but in reality is far more complicated. The authors from Tencent suggest that the existing approaches are limited in two main ways: they cannot either generalize to arbitrary faces or fail to preserve attributes like facial expression and gaze direction. The proposed method - SimSwap leverages a new ID Injection module and the Weak Feature Matching Loss that aim to solve both of the aforementioned issues.

**⭐️ Complexity**: 🌕🌕🌑🌑🌑

**🔍 Main Ideas:**
*1) Limitations of the DeepFakes:*
Due to the nature of the model (encoder and two identity specific decoders) and the training procedure, the encoder features contain the identity and attribute information of the target face, yet the decoder can convert the target's features to the source identity, which means that the identity information is stored in the decoder's weights. That is why it cannot generalize to an arbitrary person.

*2) ID Injection Module:*
Seeking a way to separate the identity information from the decoder's weights the authors propose an ID Injection Module between the encoder and the decoder. This module first extracts an identity vector using a face recognition network and then uses this information to inject the identity information into the encoder features via AdaIN layers. The PatchGAN discriminator is used to improve the quality of the generated images.

*3) Weak Feature Matching Loss:*
Just replicating the source identity is not enough to create a face swap. It is also required to keep various attributes such as the expression, position, lightning, etc from the target image. The authors use a variation of the feature matching loss for exactly this reason.
The idea of the feature matching loss originated in Pix2PixHD which used the L1 norm between the discriminator features extracted at multiple layers from the ground truth and the generated images. Since there is no ground truth in the face-swapping task, the authors only use the last few layers of the discriminator for the loss since that is where most of the attribute information is contained.
The overall objective is comprised of identity, adversarial, weak feature matching, and reconstruction losses.

**📈Interesting Numbers / Main takeaways:**

* The model was trained on images of size 224x224
* The qualitative results in the paper blow the baselines out of the water

**✏️My Notes:**

* (4/5) for the name, I guess SimSim was already taken, and this was the next best thing
* IMHO the teaser image is quite poorly chosen, I can barely tell the difference between the target and result images
* Surprisingly there is no mention of training the model at higher resolutions such as 512x512 or 1024x1024
* There are examples of video face-swapping that look really neat in the code repository (and a little bit in the appendix), however, they are not discussed in the paper.
* Have you dabbled with DeepFakes before? Let me know in the comments!

**🔗Links:**
[Paper](https://arxiv.org/abs/2106.06340v1) / [Code](https://github.com/neuralchen/SimSwap)

**👋 If you found this paper explanation useful, consider subscribing to** [my telegram channel](https://t.me/casual_gan) **for early access to deep learning paper digests twice a week!**

Here is a paper poster with some important figures from the paper!

[SimSwap](https://preview.redd.it/4a9r1airwt571.png?width=2074&format=png&auto=webp&s=a3f0563ab25e4b6de9e2eed0d90a5e6673a56441)

By: [Casual GAN Papers](https://t.me/casual_gan)
P.S. Send me paper suggestions for future posts",MachineLearning
o1w5hs,1623933201.0,"[N] CVPR Mobile AI Workshop: Presentations from Google, Samsung, Qualcomm, MediaTek, Huawei, Imagination and OPPO - Free & Live on YouTube!","The largest CVPR event on deep learning for edge devices will take place this Sunday. During the workshop, you will see tutorials from all major mobile SoC vendors including Google, Samsung, Qualcomm, MediaTek, Huawei, Imagination Technologies, OPPO and Synaptics telling you how to efficiently deploy machine learning models on edge hardware:

[https://ai-benchmark.com/workshops/mai/2021/](https://ai-benchmark.com/workshops/mai/2021/#schedule)

An introductory talk from AI Benchmark will additionally provide all basic concepts related to ML inference on smartphones, mobile deep learning libraries and SDKs, acceleration options, edge NPUs and their performance, as well as will show how to run any TensorFlow or PyTorch model on any Android smartphone in less then 5 minutes.

The event will start at 7am Pacific Time on the 20th of June (2nd CVPR date) and will be streamed live on YouTube for everyone:

[https://ai-benchmark.com/workshops/mai/2021/#live](https://ai-benchmark.com/workshops/mai/2021/#live)

https://preview.redd.it/pqr5hmo1mt571.png?width=2094&format=png&auto=webp&s=da380a22c67258ef786912149413553df20330ec

[Workshop schedule](https://ai-benchmark.com/workshops/mai/2021/#schedule) (Pacific Time):

* 07:00 - \[AI Benchmark\] Deep Learning on Smartphones, an In-Depth-Dive:  Frameworks and SDKs, Hardware Acceleration with NPUs and GPUs, Models Deployment, Performance and Power Consumption Analysis
* 08:20 - \[MediaTek\] Edge AI Technology – from Development to Deployment 08:50 - Learned Smartphone ISP Challenge:  Results and Top Solutions
* 09:10 - \[Imagination Technologies\] Imagination Technologies Approach to Overcame the Challenges of Deploying AI in Mobile
* 09:40 - Smartphone Image Denoising Challenge:  Results and Top Solutions
* 09:50 - \[Samsung\] Samsung Exynos Mobile NPUs and SDK: Hardware Design, Performance, Models Deployment and Efficient Inference
* 10:40 - \[Google\] Android Neural Networks API - What's New and Best Practices
* 11:10 - Quantized Image Super-Resolution on NPUs Challenge:  Results and Top Solutions
* 11:30 - \[Synaptics\] AI on the Edge at Synaptics : HW and SW Products and Development
* 12:30 - \[Huawei\] AI Deployment from Hardware to Software – Challenges and Opportunities
* 13:30 - Video Super-Resolution on Smartphone GPUs Challenge:  Results and Top Solutions
* 13:15 - \[OPPO\] Learning to See the World Clearer
* 13:40 - Single-Image Depth Estimation on Mobile Devices Challenge:  Results and Top Solutions
* 14:20 - Quantized Camera Scene Detection on Smartphones Challenge:  Results and Top Solutions
* 14:30 - \[Qualcomm\] Hate it or Love it, Your SW Stack Defines Application Performance and Reach",MachineLearning
o1vr17,1623931896.0,[D] Multi object tracking (MOT),"Which are the best MOT models available?
Papers with code (https://paperswithcode.com/task/multi-object-tracking) has a few top methods but the GitHub repo or the corresponding models are unavailable.",MachineLearning
o1tp4e,1623924560.0,[R] Full Page Handwriting Recognition via Image to Sequence Extraction,"The authors propose a model that does not require prior segmentation however achieves state-of-the-art accuracy.

Original paper here: [https://arxiv.org/pdf/2103.06450.pdf](https://arxiv.org/pdf/2103.06450.pdf)

More hard-to-find, independent stuff related to AI & Data Science [here](https://thereshape.co/?utm_source=reddit).",MachineLearning
o1tb2x,1623922989.0,"[D] Morphological operations that use template shapes to find ""desired shapes"" from voxel spaces? How to?","I was reading this paper that discusses methods to extract tree stems from LIDAR point clouds.

[https://pdfs.semanticscholar.org/c01c/cfadd6ea4afb283493fd45f0766710e4079b.pdf](https://pdfs.semanticscholar.org/c01c/cfadd6ea4afb283493fd45f0766710e4079b.pdf)

Around page 9 they discuss ""morphological operations"" applied on voxelized point cloud that use ""template shapes"" in order to figure out what shapes to look for.

This seems intuitive, but I'm unable to grasp, what the method of ""matching to a template"" means. It sounds like doing a model on the templates and then maybe inputting parts of the cloud there. But I am not sure.

Does one compare the entire cloud to the template or parts of it? What kinds of parts, how does one get them?",MachineLearning
o1t11j,1623921840.0,"[D] Taxonomy issue: what is the opposite of ""learning-based methods""","Hi, I work in robotics, unmanned vehicles etc and I have the following doubt while I am preparing a presentation: how would you call the class of systems which is not using any learning for their functioning?


An example to understand what I am talking about is computer vision: there are ways to detect edges in an image which are based on image moments and stuff like that. Other methods are entirely based on CNNs and received a lot of attention.

What I am trying to say in my presentation is: I know that to solve problem X we could use *learning-based methods* but I won't discard looking into and using *\_\_\_\_\_\_\_\_\_\_\_ methods* if I find that they are more effective.

I am thinking about the following:
\- **analytical** methods (not sure it is correct)

\- **formal** methods (maybe too narrow)

\- **classical** methods (too broad)


Some other ideas?


Thanks!",MachineLearning
o1sgt1,1623919574.0,[P] Evaluating a Recommendation System,"I am still a beginner so please bear with me.

So I am currently creating a simple video game recommendation system using a content based approach for a data science course assignment, however, I am stuck with the algorithm evaluation and hypothesis testing, my question is: what are the best methods that I can use to test my hypothesis (which is that content based recommendation systems provides an x% accuracy) .",MachineLearning
o1sar2,1623918889.0,[R] Contrastive Visual Representation Learning Is More Robust Than You Might Think (Paper + Analysis),"Title: ""Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations""
ArXiv: [https://arxiv.org/abs/2106.05967](https://arxiv.org/abs/2106.05967)
Code: [https://github.com/wvangansbeke/Revisiting-Contrastive-SSL](https://github.com/wvangansbeke/Revisiting-Contrastive-SSL)

Most people assume that current SOTA contrastive self-supervised methods (e.g. MoCo, SimCLR) don't work well on non-curated, domain-specific or long-tailed datasets. This paper discovers interesting properties about the learned representations and disputes claims from recent works.

**Key findings:**

1) **Do we need object-centric pretraining data?** **No.** Recent studies \[A, B\] claim that object-centric datasets (e.g. ImageNet) are crucial to learn powerful representations with contrastive self-supervised learning. They argue that the standard cropping (augmentation) strategy is detrimental for non-curated datasets (e.g. COCO, OpenImages).  However, this new paper disputes this claim and shows that training on COCO/OpenImages can even outperform ImageNet pretraining (when compared fairly). Thus, the amount of data is much more important than whether your data is object-centric or not.

2) **Do we need priors to learn dense representations? No.** The cropping (augmentation) strategy already allows the model to learn spatially structured representations. This strategy is simple and often outperforms recent methods which proposed additional (complex) losses at a denser level in the image. The representations can be used for semantic segment retrieval and video instance segmentation without any finetuning. In fact, it enables to find semantic segments from images without annotations! So try to avoid priors and let the data speak for itself.

3) **How can we further boost the transfer performance (w.r.t. MoCo)?** **Impose additional invariances** by exploring different data augmentations and nearest neighbors. This boosts the transfer performance on various tasks. (e.g. semantic segmentation, video instance segmentation, depth prediction). For example, this strategy outperforms MoCov2 on PASCAL VOC by +2.4% mIoU and +4.9% mAP (after 800 epochs of pretraining on COCO).

4) **Is universal pretraining solved? Not yet.**  Models that obtain improvements for the downstream classification tasks (e.g. ImageNet), are not guaranteed to outperform on other tasks as well (e.g. semantic segmentation) and vice versa. So, don't limit yourself to pretraining and finetuning on the same dataset (often ImageNet), this does not paint the full picture. (This is in line with the findings of another recent study.)

To wrap up: It would be interesting to see if these findings hold up when training on billions of images. Also, what is the influence of inductive biases on these findings? (see the *limitations* section in Appendix G of the paper). This work was done on 2 x V100 GPUs, so it took some time to get these numbers :)

**Let's discuss further:**
\- Will the future of ML be: general pretraining (on billions of images) + domain-specific finetuning? I believe so.
\- It is known that contrastive methods can learn powerful representations on ImageNet. However, I didn't expect it to simply work on the Berkley Deep Drive dataset. This came as a surprise to me. I thought that datasets --from which the classes are ""easy to discriminate""-- were a must.
What are your thoughts?

&#x200B;

\[A\] Purushwalkam, S and Gupta A., Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases, NeurIPS, 2020.
\[B\] Selvaraju, R.R. et al., Casting your model:  Learning to localize improves self-supervised representation, CVPR, 2021.",MachineLearning
o1r795,1623914292.0,"[D] Schmidhuber's blog post on Kurt Gödel's 1931 paper which laid the foundations of theoretical computer science, identifying fundamental limitations of algorithmic theorem proving, computing, and artificial intelligence.","link to the article: https://people.idsia.ch/~juergen/goedel-1931-founder-theoretical-computer-science-AI.html

**Abstract.** In 2021, we are celebrating the 90th anniversary of Kurt Gödel's groundbreaking 1931 paper which laid the foundations of theoretical computer science and the theory of artificial intelligence (AI). Gödel sent shock waves through the academic community when he identified the fundamental limits of theorem proving, computing, AI, logics, and mathematics itself. This had enormous impact on science and philosophy of the 20th century. Ten years to go until the Gödel centennial in 2031!",MachineLearning
o1ou1m,1623905488.0,"[D] In NEAT(NeuroEvolution of Augmenting Topologies) algorithm, is speciation really effective?","I tried implementing NEAT algorithm from scratch, and it successfully solves XOR problem. I followed [the original NEAT paper](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf).

However, when I run XOR problem solving test and calculate average convergence generations, it converges slowly \*\*with\*\* speciation, and it is much better and faster without speciation. Complexity of the solution was also smaller \*\*without\*\* speciation.

Original author of NEAT emphasizes the importance of speciation, so my implementation or parameters must be incomplete somewhere. But I failed to find the evidence that speciation actually helps the algorithm to work better. Is there any performance evaluation resources regarding effectiveness of speciation?

Thank you very much.

Here are my parameters:

    input_number = 2
    output_number = 1
    population = 150

    hidden_activation = 'Sigmoid'
    output_activation = 'Sigmoid'

    [mutation]
    weight_perturbation = 0.8
    weight_assign = 0.1
    add_connection = 0.5
    remove_connection = 0.5
    toggle_connection = 0.0
    add_node = 0.2
    remove_node = 0.2

    weight_min = -15.0
    weight_max = 15.0

    perturb_min = -1.0
    perturb_max = 1.0

    [speciation]
    c1 = 1.0
    c2 = 0.5
    compatibility_threshold = 8.0
    elitism = 1

    survival_rate = 0.07

Implementation source repository : [https://github.com/suhdonghwi/neat](https://github.com/suhdonghwi/neat)",MachineLearning
o1e424,1623874015.0,[P] GPT J 6B on GPUs (through HuggingFace PR),"Hi all,

I've created a Jupyter notebook with everything you need to convert+run GPT J from Jax over to work with the new HuggingFace PR for GPT J. I've also got the model working on our production environment that you can play around with/use in production here:
[https://hub.getneuro.ai/model/nlp/gpt-j-6B-text-generation](https://hub.getneuro.ai/model/nlp/gpt-j-6B-text-generation)

Average inference speed is surprisingly fast running on our T4s, around 5s for 50 tokens. Will be trying with a V100, and Quadro 8000 (full precision model) tomorrow. To fit the model on GPUs that are sub \~24GB the model in the demo and notebook are half precision in torch. This was kinda painful to get working, so hopefully you find it useful.
[https://github.com/paulcjh/gpt-j-6b/blob/main/gpt-j-t4.ipynb](https://github.com/paulcjh/gpt-j-6b/blob/main/gpt-j-t4.ipynb)

&#x200B;

Cheers",MachineLearning
o1dab7,1623871938.0,[D] Neural networks inside an unconstrained optimization problem,"Suppose there is a **black-box** unconstrained optimization problem, the objective it to _minimize_ a given function `F`, which is a scalar function (several inputs, one output).
By _black-box_ I mean that it is difficult to compute the gradient, or even impossible, of the function and every evaluation of this function is quite costly.

Inside this _black-box_ function there is a _neural network_, `N`, that serves as a parametrization in a specific section of the computation of the _black-box_ function.

The idea is to find the weights of the neural network that can minimize this _black-box_ function.
Unfortunately, there is no data set that could be used to train the neural network.
In this case, the idea is just to adjust the weights such that the optimization problem is solved.

I have some questions:

1. Is this feasible? If it is, what is the best way to approach such a problem?
2. Maybe neural networks are not the best way to approach such problem. Instead of a neural network, can any other machine learning method approximate the parametrization inside the _black-box_ function, such that the unconstrained optimization is solved?
3. Is there a research field which I could look into for similar problems?",MachineLearning
o1cug5,1623870812.0,[D] What are the best metrics to evaluate VAE performance?,"Hello all!

I  start to work on generative models (especially VAEs) and I find the  reported metrics a bit confusing. There is not any problem regarding the  very basic ones such as squared error etc. I find the likelihood  metrics a bit confusing.

\*There is the conditional loglikelihood of a datapoint which is given as q(z|x)\[log(p(x\_hat|z))\]

\*There is the marginal loglikelihood log(p(x)) which is calculated by importance sampling.

My  first question is which one is the correct one to use. What do they  represent? And, is it okay to use importance sampling to compute  conditional log-likelihood too i.e. is it okay to sum 10 samples of  loglikelihood values for all datapoint then average them, or the log  term is a problem?

Thank you",MachineLearning
o1atw9,1623865780.0,[R] Best drone simulator for ML purposes," Hello, can You recommend some drone simulators? . I am trying to create ML algorithms for autonomus flying. There is AirSim, but it would be nice to use more than one simulator and compare results.

Thanks in advance!",MachineLearning
o19yz6,1623863668.0,[D] DMD isn't as flexible as you think... (Koopman operator discussion),"Since my ""Anti-Koopmanism"" post, where I shared a document addressing many misconceptions in the field, I have been talking to a lot of people about Dynamic Mode Decompositions and Koopman operators. One thing that I found is that many people take an agnostic point of view to the underlying vector spaces that the Koopman operator acts on.

There are a bunch of issues with this approach, where a given function space not only governs which Koopman operators are bounded, but also function spaces themselves define what limits mean. For instance, a space of real analytic functions force ""Koopman generators"" to be real analytic. I go over this in a video I put out yesterday here: [https://youtu.be/NNjMqZyhdSk](https://youtu.be/NNjMqZyhdSk)

But you can't just select any space, and frustratingly, L\^2 spaces don't work. The principle reason? They aren't actually function spaces. They are spaces of equivalence classes of functions that can differ on measure zero sets. This means, from the data driven standpoint, that samples don't actually carry any meaning, since they constitute sets of measure zero.

What is your take on this? I'd be curious to hear what the overall community thinks.",MachineLearning
o1942e,1623861545.0,[D] Potential Test for AI Ethicists,"Before I get to the meat of the matter, I'm going to clarify my stance on AI Ethics: it is an incredibly important domain that will help define the future we seem to be hurtling into, courtesy of AI (generically speaking). I just wish that the loudest voices weren't, well, what they currently are: willing to use poor methods, obsessed primarily with impact in the first world, and incapable of taking criticism.

Right, so this post primarily stems from the brief period I spent working on debiasing large language models and becoming cynical about the field of AI Ethics as it currently exists. It has become a very easy way to demand respect, at least on AI social media, by being unnuanced and vicious, and calling yourself an AI ethicist.

So I propose a small test to see which AI ethicists actually care about ethics and are not trying to ride a wave for clout (academic and social) or are fanatics: Did they oppose students and early-career researchers being blacklisted in December by Dr. A, as loudly as they seem to oppose every other tiny injustice? Or did they make no comment, thereby tacitly approving unbelievably vicious behaviour by someone arguably in their clique, which would be deeply unethical behaviour on their part? Or, did they support it, which would be pretty vile...

How can those who didn't oppose the blacklist claim to be representing any ethical norm in AI when they are unwilling to apply one of the simplest ethical principles (Stand against tyrannical behaviour) in a context where it was trivially easy to do so?

It is as likely as not that I am missing some nuance here. If so, I will be glad to learn.

Cheers.",MachineLearning
o18khr,1623860096.0,[P] Similarity Score of a Document and Keywords,"I have a list of documents (which are online articles) and I would like to test their similarity against a list of keywords. The trick is that the documents were scraped from the internet using those keywords, so more often than not, they have some sort of similarity.

The problem is, sometimes articles are not exactly what you're looking for (e.g an advertisement that had one of the keywords or a completely different topic article but it unfortunately had the same keyword)

I have tried huggingface's ""zero-shot-classification"" to try to see which keywords the model classifies that document as, but this gave me 2 problems:

1. The model was taking very long to classify (because the labels are a lot)
2. I realized this still doesn't help me with the underlying problem of trying to find which document is more likely to be relevant to those keywords

Any guidance or help would be appreciated. Thank you.",MachineLearning
o181c8,1623858678.0,[P] Deepnote – a collaborative Python notebook in the browser. We just made it free for small teams (and it's always been free for academic use!),"Hi everyone! I'm a software engineer working on Deepnote. We are building a collaborative python notebook that runs in the browser. We have just made the platform free for teams of up to 3 people. Our CEO wrote an article explaining our reasoning behind this: [https://medium.com/deepnote/data-science-beyond-data-science-teams-a5a90ff0fec2](https://medium.com/deepnote/data-science-beyond-data-science-teams-a5a90ff0fec2)

Let me know what you think or if you have any questions. Looking forward to your feedback!",MachineLearning
o15i5m,1623851849.0,[D] Analyzing Model Response for Peaks and Values (Optimization?),"Hello everybody :)

I studied biomechanics and I'm kind of new to the world of machine learning. Nevertheless it would be great to get some feedback from some experts, what is possible and what is not possible with ML.

So: I would like to know if it's somehow possible to detect ""problem spots"" in a model response. And with problem spots I mean the peaks and valleys that can be seen in the attached picture. In this picture, a model response is shown depending on the variation of two model input parameters.Here I would like to know: Are there any kind of tools or algorithms that can be used to find this kind of problem spots in a model response? And if so, what can be recommended? Or literature that I should have a look to?

&#x200B;

Maybe some information about the background: I'm working with high non-linear, explicit finite element simulations (approx. 1 Million Nodes). By generating a lot of data from these FE-simulations, I apply different surrogate modeling techniques to this data to finally predict a model response (scalar responses or vector responses by using for example Gaussian Processes, Neural Networks, etc..). Another option is to first apply a dimensional reduction method (like PCA) and then use a meta modeling approach like regression, neural networks, etc..

After all this model reduction steps I would like to further investigate the model response (especially the peaks and valleys) that is predicted by the surrogate model and is shown as a simple example in the attached picture. I hope it's clear what I'm asking for. Feel free to ask and I'm happy about every feedback :)

Thanks in advance for your help :)

&#x200B;

Kind regards,

chiaburr

&#x200B;

&#x200B;

https://preview.redd.it/5aworwfuvm571.png?width=662&format=png&auto=webp&s=3c742f6776d7ec22535d7fa7eaf52abbc8b84064",MachineLearning
o155wa,1623850899.0,[R] Prior image-constrained reconstruction using style-based generative models [ICML 2021],"**Paper:** [https://arxiv.org/pdf/2102.12525.pdf](https://arxiv.org/pdf/2102.12525.pdf)

**Code:** [https://github.com/comp-imaging-sci/pic-recon](https://github.com/comp-imaging-sci/pic-recon)

 Obtaining a useful estimate of an object from highly incomplete imaging measurements remains a holy grail of imaging science. Deep learning methods have shown promise in learning object priors or constraints to improve the conditioning of an ill-posed imaging inverse problem. In this study, a framework for estimating an object of interest that is semantically related to a known prior image, is proposed. An optimization problem is formulated in the disentangled latent space of a style-based generative model, and semantically meaningful constraints are imposed using the disentangled latent representation of the prior image. Stable recovery from incomplete measurements with the help of a prior image is theoretically analyzed. Numerical experiments demonstrating the superior performance of our approach as compared to related methods are presented.",MachineLearning
o14sfk,1623849839.0,[D] Interesting Reinforcement Learning Applications,Can you mention any interesting application of Reinforcement Learning you have heard of or read about. I have experience in the topic and wanted to see what applications I could pursue.,MachineLearning
o14j30,1623849084.0,[Research] Evaluating a convolutional neural network on an imbalanced (academic) dataset,"I have trained a posture analysis network to classify in a video of humans recorded in public places if there is a) shake-hand between two humans, b) Standing close together that their hands touch each other but not shake hand and c) No interaction at all. There are multiple labels to identify different parts of a human. The labels are done to train the network to spot hand-shaking in a large dataset of videos of humans recorded in public. As you can guess, this leads to an imbalanced dataset. To train, I sampled data such that 60% of my input contained handshaking images and the rest contained different images than hand-shaking. In this network, we are not looking at just labels but also the relative position of individual labels wrt to one another. We have an algorithm that can then classify them into the three classes.

&#x200B;

I am stuck on how to evaluate the performance of this network. I have a large dataset and it is not labeled. So I have decided to pick 25 from class A) and B) and 50 from class (C) to create a small test dataset(with labels) to show the performance of the network. And to run the network on the large dataset without labels, but because classes A and B are quite rare events, I would be able to individually access the accuracy of the network prediction of True positive and false-positive cases.

&#x200B;

Is this a sound way to evaluate ? Can anyone having experience or opinion share their input on this? How else can I evaluate this?",MachineLearning
o13x1k,1623847208.0,[P] Model Playground: machine vision ML Ops tool,"Hey peeps, Tristan here, [hasty.ai](http://hasty.ai/) cofounder.

Check out our ModelPlayground at: [https://hasty.ai/model-playground/](https://hasty.ai/model-playground/) – We'd love to hear your thoughts and feedback!

**Aim**

We are building a smooth transition from our annotation tool to MLOps for data-centric ML, as you cannot know *a priori* where improvements in performance will come from.

We believe in building a good process for ML dev ([https://www.youtube.com/watch?v=06-AZXmwHjo](https://www.youtube.com/watch?v=06-AZXmwHjo)), rather than chasing SOTA. And we hate the ML Frankensuite.

**Problem**

When starting with Hasty no one talked about data-centric ML, we had to learn our lessons the hard way. Kostya, Alex—my co-founders—, and I worked on several projects in the German industrial space and we felt the burn.

Given our domain, standard approaches to jump-start learning with unsupervised or semi-supervised learning, synthetic data, GANs, pre-trained models \[inset random technique here\], etc. weren't cutting it. So, we ended up spending evenings labeling data.

*There had to be a better way!*

**Solution**

First, we build an annotation tool that scales up custom-trained models for annotation automation and QA – that is working well.

NOW, we are launching MP for you to be able to experiment, prep, and deploy models. Bringing the worlds of ML Ops and Annotation together.",MachineLearning
o13t0q,1623846841.0,Should I implement every famous DL paper? [D],"I found a really great list of introductory and popular dl papers ([github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)) and I would absolutely implement every paper on this list if I had the time (at least a mini version e.g. CIFAR10 instead of ImageNet). Is is essential for me to implement every single paper on that list to become a good DL researcher and to start reading/implementing more recent ones? All the papers on the list are from before 2017 and I can't wait to start exploring the latest research! Would I be able to get away with just implementing a handful of papers from that list?

Thank you!",MachineLearning
o12x3l,1623843842.0,[D] How much Linear algebra ?,How much Linear algebra do i have to know before i can understand machine learning and AI ?,MachineLearning
o126vy,1623841205.0,[D] Neumann Series for Matrix Inversion and Its Approximation,"Have you heard of the Neumann series? 🤔

""Neumann Series for Matrix Inversion and Its Approximation""
(6 min 45 sec)
[https://youtu.be/DM6brJrJYbM](https://youtu.be/DM6brJrJYbM)

&#x200B;

A short summary:

* Neumann series is the matrix generalization of geometric series, which can be used for the approximation of matrix inversion.
* But, the caveat is that the contraction condition and the time complexity are important for successful applications.
* As a real-world example, we briefly show that the Neumann series can be used to optimize the millions of hyperparameters in deep neural networks through the work from Lorraine et al. (AISTAT 2020).

&#x200B;

Cheers!",MachineLearning
o10mry,1623834767.0,[D] Improving BART text summarization by providing key-word parameter or topic-aware component,"Hi all,

I am experimenting with hugging-face's BART model, pre-trained by Facebook on the large CNN / Daily mail dataset.

Below is an example snippet of code that achieves the task.

    from transformers import BartForConditionalGeneration, BartTokenizer

    model = BartForConditionalGeneration.from_pretrained(""facebook/bart-large-cnn"", force_bos_token_to_be_generated=True)

    tok = BartTokenizer.from_pretrained(""facebook/bart-large-cnn"")

    article = """"""Text to be summarised.""""""

    batch = tok(article, return_tensors='pt')

    generated_ids = model.generate(batch['input_ids'])

    tok.batch_decode(generated_ids, skip_special_tokens=True)

I am now thinking about how I could insert an intermediary layer or keyword parameter which would indicate to the model to focus on particular words and words associated with the keyword.

For example, if I insert a block of text which talks about different countries and the cars commonly found in those countries, and specify the key-word: ""Cars"", I'd expect the summary to talk about which cars are found and in what quantity rather than information on the different countries.

For this, I see one of three potential approaches which I have embedded into the overall process flow:

1.	BART encoder transforms text into a tensor of numbers

2.	One of three options for this step

a.	Run a topic-aware model (e.g. Top2Vec, Genism, TF-IDF, other) on the encoded article to produce a topic-aware summary in tensor form

b.	Run a BART model on the encoded article to produce a summary in tensor form. Then, run a topic-aware model (e.g. Top2Vec, Genism, TF-IDF, other) on the BART model summary to produce a topic-aware summary in tensor form (i.e. a two-step model/pipeline)

c.	Run a BART model on the encoded article to produce a summary in tensor form. Train the BART model to be biased to select topics, or introduce a global parameter in an attempt to have the BART model focus on summarizing the article based on the topic

3.	BART decoder transforms the tensor output from step 2. into a text summary

Open to discuss which would be a good path for implementation and also discuss ideas on how to actually write code for this.",MachineLearning
o0zqt9,1623830734.0,[D] Any way to train models on phone using pytorch?,"I'm currently doing a research in federated learning which requires training a lightweight model on a mobile device.

I read about Pytorch Mobile, but it apparently cannot be used to perform backprop on the phone itself (correct me if I'm wrong).

Is there any workaround for this task?",MachineLearning
o0z5ij,1623828058.0,ICML 2021 Volunteer [D],"Hi guys,
I have been selected to be a volunteer at ICML 2021. Any advices on how to make the best use of this opportunity ?",MachineLearning
o0puej,1623794729.0,[D] Is there a difference between composite class prediction or merging multiple classes into one?,"Hi all, so i’m not sure if it’s the right place to ask this but I don’t know any better places for it either. Might be a bit silly as I’m not a machine learning engineer myself.

We are currently annotating data and building models for object detection from images and our solution at the moment is that first we would want to predict the object itself and then its different properties like size, color, material etc, depending on the domain of the objects.

And we recently had a bit of a disagreement, which one would be more accurate:

1. Having the objects’ classes as high level and generic as possible, like “trousers” and “dresses” for garments or “tables” and “chairs” for furniture and then have “style/type” as a separate property with values like “suit pants” and “jeans” and “sundress” or “office table”, “dining table”, “coffee table”.

2. Having the objects already more specific, so basically already defining the style/type in the first level of labels by just having “dining table” and “coffee table” as object labels and then predicting properties like material and leg count etc.


One valid argument for the second option was that object detection happens based on the whole image but as this process also selects the area of the object, the property prediction only works with that area. So for example if you can’t see from the table itself that whether it’s an office or a dining table, it shouldn’t be a property but those should be separate objects because during object detection the model is working with the whole image and can consider the context, like the table being inside the kitchen for example (although i wouldn’t know how the model would know about this context if this isn’t present in the training data in any shape or form).

But other than that, from the annotation point of view, it made more sense to me to have the object classes as generic as possible and separate everything that somehow describes this specific object in a separate property.

I was told this composite prediction might grant lower accuracy because you need to do 2 predictions instead of one.
But for me this sounds like BS because we would still have different properties that need second prediction.. otherwise we’d just create all combinations of properties to form a single level set of classes, for example merge “gender” and “material” as well while we’re at it..
“Male Cotton Suit Pants”, “Female cotton suit pants” etc..

I don’t want to believe this separation if objects and properties would somehow cause lower accuracy during prediction.

Any professional experienced feedback on this topic :)?",MachineLearning
o0lcd6,1623782290.0,[D] Tabular Data: Deep Learning is Not All You Need,"Not that surprising - XGBoost still rocks when the underlying data is in a tabular form.

Original article here: [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf)

More hard-to-find, independent stuff related to AI & Data Science [here](https://thereshape.co/?utm_source=reddit).",MachineLearning
o0kixr,1623780151.0,Improving BART text summarization by providing key-word parameter,"Hi all,

I am experimenting with hugging-face's BART model, pre-trained by Facebook on the large CNN / Daily mail dataset. I have the below code which instantiates a model, can read text and output a summary just fine.

    from transformers import BartForConditionalGeneration, BartTokenizer

    model = BartForConditionalGeneration.from_pretrained(""facebook/bart-large-cnn"", force_bos_token_to_be_generated=True)

    tok = BartTokenizer.from_pretrained(""facebook/bart-large-cnn"")

    article = """"""Text to be summarised.""""""

    batch = tok(article, return_tensors='pt')

    generated_ids = model.generate(batch['input_ids'])

    tok.batch_decode(generated_ids, skip_special_tokens=True)

I am now thinking about how I could insert an intermediary layer or keyword parameter which would indicate to the model to focus on particular words and words associated with the keyword.

For example, if I insert a block of text which talks about different countries and the cars commonly found in those countries, and specify the key-word: ""Cars"", I'd expect the summary to talk about which cars are found and in what quantity rather than information on the different countries.

I see a handful of potential ways to implement this, but I am open to discussion:

1. Insert a topic-aware step e.g. Top2Vec/Gensim/etc. whereby the encoded text is then adjusted further to reflect the importance of the word 'car'
2. Train models to be biased to certain keywords, but maintaining a lot of models seems like high-maintenance
3. Somehow re-fine the output layers of either the encoder or decoder to stress importance of the weights/tensors of the vector towards words related to the key word

I am a little stuck on how I would incorporate those - I also have taken some inspiration from this paper who unfortunately have removed their code from their GitHub link: [https://arxiv.org/abs/2010.10323](https://arxiv.org/abs/2010.10323)

All suggestions on implementation/papers to read / or other guidance would be greatly appreciated to help me on my journey.",MachineLearning
o0j995,1623776845.0,"[D] PyTorch 1.9 Released with new Mobile Interpreter, Inference Mode and new Packaging Format","A ton of new updates, I'm mostly excited about the updates to the mobile stuff.

https://pytorch.org/blog/pytorch-1.9-released/",MachineLearning
o0hf27,1623771977.0,[R] Google's Launchpad Programming Framework Simplifies the Distributed Computation Learning Process,"A research team from DeepMind and Google Brain proposes Launchpad, a programming model that simplifies the process of defining and launching instances of distributed computation.

Here is a quick read: [Google's Launchpad Programming Framework Simplifies the Distributed Computation Learning Process.](https://syncedreview.com/2021/06/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-41/)

The paper *Launchpad: A Programming Model for Distributed Machine Learning Research* is on [arXiv](https://arxiv.org/abs/2106.04516).",MachineLearning
o0gm8g,1623769855.0,[P]Is anyone aware with the working of mmdetection framework for object detection?,How exactly do I use my epoch.pth files for inference?,MachineLearning
o0fci1,1623766425.0,[R] Gifsplanation via Latent Shift: A Simple Autoencoder Approach to Counterfactual Generation for Chest X-rays,"To be presented at MIDL2021!

**Motivation**: Traditional image attribution methods struggle to satisfactorily explain predictions of neural networks. Prediction explanation is important, especially in medical imaging, for avoiding the unintended consequences of deploying AI systems when false positive predictions can impact patient care. Thus, there is a pressing need to develop improved models for model explainability and introspection.

**Specific problem**: A new approach is to transform input images to increase or decrease features which cause the prediction. However, current approaches are difficult to implement as they are monolithic or rely on GANs. These hurdles prevent wide adoption.

**Our approach**: Given an arbitrary classifier, we propose a simple autoencoder and gradient update (Latent Shift) that can transform the latent representation of a specific input image to exaggerate or curtail the features used for prediction. We use this method to study chest X-ray classifiers and evaluate their performance. We conduct a reader study with two radiologists assessing 240 chest X-ray predictions to identify which ones are false positives (half are) using traditional attribution maps or our proposed method.

**Results**: We found low overlap with ground truth pathology masks for models with reasonably high accuracy. However, the results from our reader study indicate that these models are generally looking at the correct features.
We also found that the Latent Shift explanation allows a user to have more confidence in true positive predictions compared to traditional approaches (0.15±0.95 in a 5 point scale with p=0.01) with only a small increase in false positive predictions (0.04±1.06 with p=0.57).

Method overview: https://i.imgur.com/GxCjcjF.gif

Demo code:
https://colab.research.google.com/github/mlmed/gifsplanation/blob/main/demo.ipynb

Paper: https://openreview.net/forum?id=rnunjvgxAMt

Ridiculous promo video: https://www.youtube.com/watch?v=yWQ_JGHwqQw",MachineLearning
o0ex35,1623765278.0,[D] fast.ai's Jeremy Howard on Why Python is not the future of machine learning - Gradient Dissent Clip," [https://www.youtube.com/watch?v=4I1ejhQqD4c](https://www.youtube.com/watch?v=4I1ejhQqD4c)

**TL;DR** Python is nicely hackable, not fast enough unless you do some tricks with external (C) code. Python is also not parallel enough. Python is good for a lot of things, but not for ML/DL. Julia may be an option because it is compiled language with a nicely designed typing and dispatch system and you also can write your own GPU kernels and other low-level features (like autograd).

I know that production stuff is already mostly python-free (like tensorRT, C++, etc) - we need our models to work fast and efficiently, especially on embedded devices. But will research shift from python in near future? I mean, all the fancy modern packages are on python, all courses as well.

What do you guys think about this?",MachineLearning
o0euxg,1623765113.0,[D] Theoretical Performance of Machine Learning Algorithms on Imbalanced Datasets,"Suppose you are working on a supervised binary classification task. You have patient medical information (e.g. age, weight, gender, height, blood pressure, etc) and whether they have a certain disease or not (this is the response variable, ""yes"" or ""no""). Let's imagine that determining if patients have this disease is time consuming and costly - so a machine learning approach is being considered.

Let's assume that this disease is very rare. In your data set, only 1% of patients have this disease. Thus, the dataset is imbalanced.

Intuitively, we know that any machine learning algorithm trained on this data will likely perform poorly. That is, the performance will likely be deceptive: you might get an accuracy of 99%, but misclassify all of the patients who have the disease.

Mathematically speaking: is there any mathematical explanation for this very logical concept?

 E.g. if only study 1 hour for a chemistry exam, I might only learn how to solve 2-3 types of problems - thus, on a true/false style chemistry exam, there will be many questions that I don't know how to answer because I never saw them before, and I will be likely to perform badly on material that I have not prepared for. Do machine learning models work the same way?

For popular algorithms like neural networks, xgboost and random forest - can it be shown that for classification problems, you need a minimum number of observations or a minimum proportion of the minority class to probabilistically achieve a certain model performance?

On a more abstract side, I have heard that researchers are interested in trying to make machine learning models generalize without seeing thousands and thousands of examples. E.g. a 5 year old child can ""learn"" what is an ""elephant"" after seeing a few pictures of an elephant (e.g. it's perfectly reasonable to expect that a young child would see a picture of the cartoon character Dumbo and identify Dumbo as an elephant after coming back from a zoo), but a machine learning algorithm would likely need thousands and thousands of pictures of elephants (and likely require to see the same pictures upside down, inverted, with added noise, different color scheme, etc) prior to be able to generalize and learn the concept of an elephant. Perhaps the same analogy applies to machine learning models struggling to correctly classify patients with a rare disease, since there are so few of them?

Does the above concept have anything to do with the ""bias-variance tradeoff""? Or is it just logic - if there is not enough variability and information within the data, the machine learning model just learns the ""noise"" within the dataset? I am really curious to see if such a threshold for measuring ""minimum level of variability within the data"" has ever been studied?

PS: in a 1 dimensional sense, on a number line, if you have a ""point"" at 3 and another ""point"" at 5 - you could consider all inferences outside of 3 and 5 as ""extrapolation"" and all inferences between 3 and 5 as  ""interpolation"". When dealing with higher dimensional data, could you simply consider observations from the test set that have a smaller euclidean distance to other observations from the training set as ""interpolation"" and observstions that are farther away as ""extrapolation""? In reality, can you just consider all prediction as extrapolation - small scale extrapolation for closer points, large scale extrapolation for further points?

Thanks",MachineLearning
o0bvio,1623755616.0,KNN vs LINEAR REGRESSION [Discussion],"When should I use KNN and when should I use Linear regression like Gradient Descent for regression?

How is KNN better than Linear regression and how is linear regression better than KNN?",MachineLearning
o0bkfv,1623754535.0,Reverse Attention for classification task [Discussion],"Are there any papers (except for [DRANet](https://ieeexplore.ieee.org/abstract/document/8804419?casa_token=qzgSOlKfphkAAAAA:PpZ3KwrkIQ9VOiP3JbVmxgShdpUloFo5Evoug82n_yGISMFuHzmtVAp6gu3KGoNo2MdMMgFPt5wz)) , where reverse attention(RA) is used for classification task. There are couple of papers which used RA for segmentation but hardly any which I could find that are used for classification purposes.

Any leads ?",MachineLearning
o0b5ho,1623753002.0,[D] When will a non ResNet/EfficientNet CNN derivative improve accuracy for ImageNet?,"Currently the top 3 pure CNNs on the ImageNet leaderboard are just modifications of ResNet or EfficientNet which improve accuracy by either increasing the number of parameters or by mass pretraining with massive datasets. (I'm not including transformer based networks in this.)

Why arent we seeing any new interesting CNN architectures? Why aren't we seeing modifications of other architectures which had once achieved state-of-the-art? And **what architecture ideas do you guys propose which could show promising results?**

My latests idea is to take Xception nets and augment them with dense skip connections using concatenation instead of addition. Following the popular naming schemes this would be called DenseNeXt. I found DenseNet to be incredibly promising, however with most ML frameworks it's inefficient to train due to the concatenation steps not happening inplace. Exploiting seperable convolutions in a DenseNeXt architecture will massively reduce parameter count per layer which should improve memory compactness, reduce fragmentation and improve cache efficiency.

What ideas do you have?",MachineLearning
o0b0le,1623752467.0,[D] Forecating problem,"I'm working on a binary classification problem where the goal is to forecast the demand and dispatches powers (encoded as class labels... demand>dispatches encoded as 0, and demand<dispatches encoded as 1).

I have a year dataset every hour. I already selected the features more relevant to the problem, and I tried two methods: decision tree and Random Forest.

The problem is that when I split the train and test sets randomly (70% for training and 30% for test), I get 80% of accuracy, but when I consider 180 days for training and try to predict the next 24 hours with a sliding window process, I only get 60% of accuracy.

Has anyone solved a similar problem?

Thank you!",MachineLearning
o0acre,1623749771.0,[D] Question concerning Taxonomy about training / static ML models in Production,"Hi all!

I'm trying to clear up some misconceptions of machine learning (""AI"") in my organisation. My main point is to make clear that a ML-model is an artifact of the training algorithm that can be put into production and then, generally, doesnt change anymore (until it is exchanged by a new model). Also I want to know when this is not the case, i.e. the model  changes while deployed, in production.

1.) So, my first question would be, if this assumption (models usually don't learn/change in production) is correct?

2.) Is this called offline learning and would online learning be the (rare) case when a ML-model is trained in production?  How else would you label these difference?

3.) Concerning Reinforcement Learning: How do the terms off-/on- policy reinforcement learning refer to this distinction between learning gradually in production or updating the model ""in bigger steps"".

\- my assumption here was, that while a RL-model being in production, it usually gets updated in bigger batches with new training data, making it offline learning and necessarily off-policy. When it is trained online in production it could be either on-policy or off-policy learning.  The more I read, the more I think I'm incorrect here, but it would be great to know the relation here.

Thanks in advance everyone taking the time to clear up my confusion! I appreciate it very much!",MachineLearning
o09y2g,1623748033.0,[D] tips for quick image tagging?,"Hi, I'm currently using vott to tag objects for an image detection model. Obviously the more images the better, and it's better if they're more accurate.

I'm currently using a laptop touch pad for this. I've also tried using the touch screen, a wacom tablet with pen and an iPad, but settled on the touch pad as the most efficient, and simply tagging with rectangles.

Does anyone have any suggestions for how to further improve efficiency? Is it worth using a pen on my laptop screen or iPad screen?

Also when does it become ""worth it"" to use polygons instead of rectangles? Most of my objects are rectangular, but some are triangles or other polygons.

Any other tips are appreciated!",MachineLearning
o09qxo,1623747167.0,AdaBoost algorithm [D],"

Can AdaBoost algorithm return the same weak classifier after round 1 and round 2?",MachineLearning
o04ort,1623727972.0,[D] Hugging Face has released an official course,"Link: [https://huggingface.co/course/](https://huggingface.co/course/chapter1)

The incredible team over at hugging face has put out a course covering almost the entirety of their ecosystem:

\- Transformers
\- Datasets
\- Tokenizers
\- Accelerate
\- Model Hub

They also plan on hosting live office hours and facilitating study groups via their forums.

&#x200B;

PS: If there's enough interest from APAC regions, I would love to help organise a study group. (I do not work at HF, but I'm excited to dive into this course)",MachineLearning
o02xv1,1623722443.0,[D] Assumptions of K-Means Clustering,"I have often seen blog posts like this

:

https://blog.learningtree.com/assumptions-ruin-k-means-clusters/


http://varianceexplained.org/r/kmeans-free-lunch/

Which show that K-Means Clustering Algorithm is unable to handle complicated data, and can only recognize clusters within ""spherical clusters"".

I have often seen this shown empirically (like in these blogs), but are there any mathematical justifications that explain why K-Means is unable to recognize clusters in more complicated data (e.g. concentric circles, crescents, etc.).

Why is k-means only good for specifically spheres? Beyond empirical demonstrations, are there any reasons why K-Means receives a lot of criticism?",MachineLearning
o02i90,1623721078.0,[D] Generating New Points with SMOTE,"

There is a well-known algorithm in statistics called SMOTE (Synthetic Minority Over Sampling Technique) which is often used to ""balance"" and ""imbalanced"" data set:

[https://en.wikipedia.org/wiki/Oversampling\_and\_undersampling\_in\_data\_analysis](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis)

[https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python](https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/#:~:text=SMOTE%20(synthetic%20minority%20oversampling%20technique)%20is%20one%20of%20the%20most,instances%20between%20existing%20minority%20instances)

[https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)

If I have understood correctly, the premise of the SMOTE algorithm is as follows: Suppose you have a dataset containing information for medical patients that are ""healthy"" and ""not healthy"". But, let's assume that the majority of the patients within your dataset are ""healthy"" (the composition of healthy: not healthy being 95:5) . If you want to make a statistical model for this data, the data does not contain enough information for ""not healthy"" patients, and it will be very challenging to build a reliable statistical model that can make accurate predictions for ""not healthy"" patients. Thus, the SMOTE algorithm can fix this problem by:

1. ""rebalancing"" the data set (e.g. after SMOTE, your data set can have a composition of 70:30)
2. creating ""new"" data points from the ""existing"" data : as I understand, this is done by multiplying a given vector corresponding to a randomly selected individual observation, by some random number between 0 and 1.

This leads me to my question: Suppose you have already have a balanced dataset (e.g. the healthy: not healthy has a composition of 60:40), but let's assume that you have a relatively small dat set to begin with (e.g. 500 rows). Can you use the SMOTE algorithm to create new data points so that your dataset is bigger? I understand that no algorithm can magically compensate for data quality issues, but at the same time I don't see any major flaws with using SMOTE on already balanced data?

For reference, I illustrated this process below using R:

I would be interested in hearing a second opinion - Thanks!

    #load and install libraries
    remotes::install_version(""DMwR"", version=""0.4.1"")
    library(DMwR)

     #create some fake data and put them into a data frame called ""f""
     var_1<- rnorm(100,1,4)
     var_2 <-rnorm(100,10,5)
     var_3<- c(""0"",""2"", ""4"")
     var_3 <- sample(var_3, 100, replace=TRUE, prob=c(0.3, 0.6, 0.1))

     response<- c(""1"",""0"")
    response <- sample(response, 100, replace=TRUE, prob=c(0.3, 0.7))

    #put them into a data frame called ""f""

    f <- data.frame(var_1, var_2, var_3, response)

     #declare var_3 and response_variable as factors

     f$var_3 = as.factor(f$var_3)
     f$response = as.factor(f$response)

     #SMOTE algorithm  #simulate new points from the first class

    smoted_data_over <- SMOTE(response~., f, perc.over=100)

     #simulate new points from the second class

     smoted_data_under <- SMOTE(response~., f, perc.under=100)

     #combine everything together into a final new data file

     final <-rbind(f, smoted_data_over, smoted_data_under)",MachineLearning
o01w9b,1623719146.0,[D] Rise and Decline of Regression Models,"We all know that in the past century, regression models (linear and non-linear) were very popular for data modelling. And we also know that neural networks have become synonymous with the ""go-to algorithm"" for modern data modelling.

Does anyone know at what point did this transition happen between regression models and neural networks? Was it the simple fact, that regression models require strong assumptions to perform well (e.g. distribution of errors, directly specifying interaction terms within variables) as well regression models with too many coefficients (parameters) are known to overfit the data? (I never understood why regression models with too many coefficients are known to overfit - is this empirical, or is there math behind this?)

On the other hand, was the rise of neural networks based on the fact that neural networks did not require statistical assumptions and for interaction terms in the variables to be manually specified? Did neural networks show any promise of not overfitting? Were there any arguments that suggested neural networks weren't as likely to suffer from overfitting compared to higher order polynomial regression models?

Thanks",MachineLearning
o01ox7,1623718507.0,[D] Unfair Comparison: Neural Networks vs Taylor Polynomials and Fourier Series,"This is a question I have always had : Early on in machine learning history, the perceptron algorithm was invented for classification tasks (the perceptron being the predecessor to the multi layered perceptron, i.e. the modern neural network). Later on, the Universal Approximation Theorem was developed that showed a simple neural network is able to well-approximate any continuous function.

A few hundred years before that, both Taylor Polynomials and Fourier Series were developed -  both of these are also able to approximate continuous functions as well.

I know this sounds like a stupid question: but at what point did people abandon the idea of using Taylor Polynomials and Fourier Series for function approximation? Were there certain problems associated with using these methods for function approximation? What lead to the decline of these methods?

Thanks",MachineLearning
o00v73,1623715810.0,[N] ICCV 2021 Challenges/Contests,"There  are 84 workshops this year in ICCV. Here's a list of all 40+ challenges/contests from among them. Please feel free to add to the list in case I missed something.

Challenges - [https://github.com/skrish13/ml-contests-conf#iccv-2021](https://github.com/skrish13/ml-contests-conf#iccv-2021)

All Workshops - [Official link](http://iccv2021.thecvf.com/node/44)  / [Markdown link](https://gist.github.com/skrish13/682c7fa0b888fe088da91677f2d7dd6f)",MachineLearning
nzykh9,1623708933.0,Machine Learning Games [D],"Hey guys, hope you are all good.

I'm teaching Machine Learning fundamentals to young kids and I'm looking for cool ways to do it. Maybe games, videos or so on.

I would really appreciate it if you could help me out with this!

Thanks!",MachineLearning
nzx2se,1623704889.0,[D] best infrastructure options for large corpus training,"I want to do transfer learning on a news corpus of 1M news using BERT multilingual model. Currently, I have colab and kaggle TPU, you know the limits of these more than me. 😊. I am also planning to buy RTX 3070. Is it a better choice than colab TPU? What are the cloud alternatives for this sort of task.",MachineLearning
nzuzr4,1623699434.0,[R] Reconnaissance Blind Chess - Join our NeurIPS Competition!,"Create a bot for our [NeurIPS 2021 competition in Reconnaissance Blind Chess](https://rbc.jhuapl.edu)!

Reconnaissance Blind Chess is a chess variant designed for new research in artificial intelligence. RBC includes imperfect information, long-term strategy, explicit observations, and almost no common knowledge. These features appear in real-world scenarios, and challenge even state of the art algorithms. Each player of RBC controls traditional chess pieces, but cannot directly see the locations of her opponent's pieces. Rather, she learns partial information each turn by privately sensing a 3x3 area of the board. RBC's foundation in traditional chess makes it familiar and entertaining to human players, too!

There is no cost to enter this tournament. Winners will receive a small monetary prize and authors of the best AIs will be invited talk about their bots at NeurIPS, the world's largest AI conference.

Reconnaissance Blind Chess is now also a part of the new Hidden Information Games Competition (HIGC - [http://higcompetition.info/](http://higcompetition.info/)) being organized by DeepMind and the Czech Technical University in Prague.

Learn more, play a game of RBC yourself, and join our research community at [https://rbc.jhuapl.edu](https://rbc.jhuapl.edu) !

&#x200B;

https://preview.redd.it/2qki5x7l9a571.png?width=150&format=png&auto=webp&s=4ca5e51440f6f2d757764ae4a82b4d04e78a6aef

Organized by:

Johns Hopkins University Applied Physics Laboratory

with

Ashley J. Llorens (Microsoft Research)

Todd W. Neller (Gettysburg College)

Raman Arora (Johns Hopkins University)

Bo Li (University of Illinois)

Mykel J. Kochenderfer (Stanford University)",MachineLearning
nzuyoe,1623699353.0,[R] Measuring similarity between datasets," So I have two different datasets X and Y obtained in two different settings but using the same sensor systems and I want to quantify how a model trained on X will perform on Y without evaluating the trained model on Y. Basically I am trying to quantify the generalization capability of the trained model.

One answer to this problem is to measure the similarity or distance between X and Y. Looking at the literature, only this paper Geometric Dataset Distances via Optimal Transport ([https://papers.nips.cc/paper/2020/file/f52a7b2610fb4d3f74b4106fb80b233d-Paper.pdf](https://papers.nips.cc/paper/2020/file/f52a7b2610fb4d3f74b4106fb80b233d-Paper.pdf)

) seems like a good fit.

Do you guys have any experience or ideas along these lines? Thanks :)",MachineLearning
nzunp0,1623698541.0,[P] Secure collaborative analytics and ML on encrypted data using MC²,"Hi All,

Our team @ UC Berkeley has been working on a platform for secure analytics and machine learning called MC^(2) \-- and today we are excited to announce the initial release v0.1 of the platform! With MC^(2), you can take encrypted data and run various analytics and machine learning workloads at near processor speeds, while keeping the data confidential.
MC^(2) also enables *secure collaboration* \-- mutually distrustful data owners can jointly analyze / train models on their data, but without revealing their data to each other.
Github: [https://github.com/mc2-project/mc2](https://github.com/mc2-project/mc2)

We just published a blog post that provides more information on MC^(2): [https://towardsdatascience.com/secure-collaborative-analytics-and-ml-using-mc%C2%B2-4be376cfaba0](https://towardsdatascience.com/secure-collaborative-analytics-and-ml-using-mc%C2%B2-4be376cfaba0)

The project currently provides a Docker quickstart and also supports deployments on Azure Confidential Computing -- please check out our project, would love feedback / contributions!",MachineLearning
nzu3uj,1623697089.0,[D] Are Self-Driving Cars Really Safer Than Human Drivers?,"[More than $250 billion has been invested](https://insights.roboglobal.com/the-how-why-of-investing-in-self-driving-vehicles) in self-driving vehicles over the last three years. More than [35,000 people die every year](https://www.nhtsa.gov/technology-innovation/automated-vehicles-safety)  in motor vehicle crashes in the US alone. Since self-driving vehicles  can theoretically react faster than human drivers and don’t drive drunk,  text while driving, or get tired, they should be able to dramatically  improve vehicle safety. But will self-driving vehicles actually be safer?


Check out [our new article](https://thegradient.pub/are-self-driving-cars-really-safer-than-human-drivers/) on this topic!",MachineLearning
nzu2fi,1623696979.0,"[DISCUSSION] Fitting or filtering method for data points that seem to ""group"" into some volume, sometimes gaussian-like or triangle-like, but may have multiple peaks?","Fitting or filtering method for data points that seem to ""group"" into some  volume, sometimes gaussian-like or triangle-like, but may have multiple peaks?

Particularly, if it's changing, whether it has one peak or more peaks or whether it's more   gaussian or paraboloid. Then is there some general method to discover   best fit in this kind of ""family of shapes""?",MachineLearning
nzsut6,1623693794.0,[D] How to improve my object detection model?,"Hi, I'm an experienced software dev but have limited experience with ML. I'm currently trying to train a model to detect objects in the output of a 3D mobile game.

Here is a couple of example images:

[https://imgur.com/a/lofPwJS](https://imgur.com/a/lofPwJS)

The first is just an example, the second is the result of my model being applied and objects being tagged. There is only one object tagged though (bottom left) when clearly there's lots of other objects that should be.

How should I best go about improving my model? I suspect the difference in orientation and background is throwing it off, so are more inputs and training the answer?",MachineLearning
nzspr7,1623693431.0,Ensemble methods for One class classifiers [D],"I'm working on an anomaly detection project. We have normal datapoint and datapoint that are anomalous, so as you can imagine its a very imbalanced dataset.

For the supervised pipeline, my team has decided to use OneClass Classifiers like OneClass SVM, Elliptic Envelope, Local Outlier Factor and Isolation Forest. 'sklearn' has pretty standard libraries but the syntax is not .fit(X,y), its .fit(X) where X contains all the ""normal"" datapoints. So any new point that doesn't fit its definition of normal will be classified as anomalous.

It all worked fine until we started looking for ensemble methods(because these classifiers alone didn't give us enough performance) where we can combine the performance of 4 classifiers we have in mind. The ensemble methods on sklearn don't work because of syntax, so we're wondering if there's a different library we can work with. (We considered majority voting which seems good but we are looking for a sequential ensemble method instead of parallel. )

I've been looking at Adaboost and Gradient boost. Adaboost seems direct enough from what I learnt about it since we can declare/define our own weak classifiers in the meta-algorithm. Gradient boost on the other hand uses residuals and decision trees are used as classifier. I'm unable to find a way to replace decision trees with any other classifying method in the meta-algorithm,

So my question is this:

1. Apart from majority voting, is there any other way to ensemble multiple one class classifiers?
2. If there's a library out there that can help us out with this, that would make my life so much easier.

Thanks in advance!",MachineLearning
nzrk30,1623690341.0,"[D] are all machine learning models based on the concept of ""similarity""?","Do all machine learning models indirectly work based on the concept of ""similarity""? E.g. two data points that are very close to each other share more similar properties with each other compared to some point that is further away? Is this one of the ""inductive biases""?",MachineLearning
nzrigt,1623690227.0,[Research] Preferential Temporal Difference Learning,"Hello everyone,

I am excited to announce [Preferential Temporal Difference Learning](https://arxiv.org/abs/2106.06508)  \- a TD style algorithm to learn the value function in the presence of  preferences. A joint work with my supervisor Prof. Doina Precup and it will appear at the ICML this year. The algo is very simple and it has many interesting  properties.

I am happy to answer your questions here.",MachineLearning
nzrbhq,1623689720.0,"[P] pytorch-widedeep, deep learning for tabular data: Deep Learning vs LightGBM","[A thorough comparison between Deep Learning algorithms for tabular data](https://towardsdatascience.com/pytorch-widedeep-deep-learning-for-tabular-data-iv-deep-learning-vs-lightgbm-cadcbf571eaf) (using [pytorch-widedeep](https://github.com/jrzaurin/pytorch-widedeep) ) and LightGBM for classification and regression problems.

V1 of [pytorch-widedeep](https://github.com/jrzaurin/pytorch-widedeep) coming soon!",MachineLearning
nzr6s2,1623689381.0,[Discussion] Phonemes Alignment in Automatic Speech Recognition (ASR)?,"Hello Everyone.

I am really scratching my head to get this topic inside my brain, It's obvious that even stackoverflow and google can't give me something satisfactory on this.
So I could use your help guys.

I know about NN, CNN, RNN , LSTM, HMM and other heavy terms used in deep learning, but still can't connect how exactly this works (Phonemes Alignment).

It will be so helpful if you could provide me something on this.
Thanks in advance.",MachineLearning
nzqrxf,1623688277.0,"[D] Is supervised (binary) text classification considered ""solved""?","Given a sufficiently large dataset with binary labels based on a (reasonable) arbitrary human concept, are we at a point where solving that is no longer considered to be of ""research interest"", and only interesting from an engineering and domain-specific perspective?",MachineLearning
nzqb4s,1623687033.0,[P] Czech Speech-to-Text,"Hi, I need speech recognition from microphone for Czech language. I'm looking for either pretrained neural network model or usage of online API (preferable from Google). But I cannot find good example how to use it. I only found [this](https://github.com/dawntcherian/Google-speech-to-text-python-websocket-server-using-microphone-stream) but it didn't work.",MachineLearning
nzq9c4,1623686893.0,[R] Reconstituting T cell receptor selection with neural decision trees,"Because T cell receptor (TCR) antigen recognition can drive cytotoxic and other T cell responses, autoreactive TCRs that recognize autoantigens can drive the destruction of healthy cells and tissues with those autoantigens.  Autoreactive TCRs are removed by T cell selection, which protects against autoimmune diseases.  We predict which TCRs are removed *(or retained)* by combining high-throughput TCR sequencing and machine learning. Our trained machine learning models may therefore be able to identify autoreactive TCRs.

We use *neural decision trees* (NDTs) for the machine learning. With NDTs, we encounter scaling issues reminiscent of the vanishing gradient problem. We introduce an architectural change to correct the scaling issue, achieving strong results *(see MATERIALS AND METHODS)*.

Paper:  [https://rdcu.be/cmt4E](https://rdcu.be/cmt4E) *(Genes & Immunity)*

Paywalled PDF: https://www.nature.com/articles/s41435-021-00141-9",MachineLearning
nzptwa,1623685695.0,[P] Fun and Dystopia With AI-Based Code Generation Using GPT-J-6B,"GPT-J was released a few days ago, and in testing I noticed it did code generation rather well, so I ran it through a few more tests and the results are...chaotic, to say the least.

https://minimaxir.com/2021/06/gpt-j-6b/

Some example generated code:

    def is_bird(img):
        """"""Check whether an image is a bird""""""
        with tf.name_scope('get_bird'):
            a = vgg16.select_roi_feat(img)
            h, w, _ = tf.image.extract_image_patches(
                a, 7, 7, 4, 4, 1, 1)
            b = tf.reshape(h, [1, 7, 7, 256])
            c = tf.reshape(w, [1, 7, 7, 256])
            bird_img = tf.subtract(b, c)
        return bird_img

---

    def is_cake(cake):
        """"""Check whether the cake is true""""""
        if not cake:
            print(""It's a lie!"")
            return
        else:
            print(""It's a true fact!"")
            return True

---

    def is_ai_generated(text):
        """"""Check whether a text was generated by an AI language model (e.g. GPT-2)""""""

        # See gh-196 for details about why we do this.
        # Note: this relies on the fixed set of standard AI terms and the logic that
        # standard AI-generated texts share certain words.
        return re.search(r""^(#[A-Za-z]+):$"", text) or \
               re.search(r""^Generated by:$"", text) or \
               re.search(r""^All your base are belong to us$"", text) or \
               re.search(r""^$"", text)",MachineLearning
nzoyr6,1623683421.0,[R] Project for my Masterthesis,"First I’ll explain what my thesis is about:
It’s about quality control in car manufacturing.
Currently a person with a tool needs to go around a finished car and needs to measure all the gaps between the metal sheets of the bodywork of the car. Now I want to write in theory, If this can be automated with AI, cameras are on the assembly line and take photos of the car while it passes by, the photos are analyzed and checked if all the gaps are perfectly wide and parallel.
I’m aware that AI is not strictly necessary, Laser scanning (3D-scanning) of the car could do the same job. I’m writing if the AI is helpful and can do it better or more precise.

My masterthesis is not coding this, it’s just writing about it. I want to research all the needed components though, so someone could easily Code it after reading my thesis, I do all the research.

So ideally I need a dataset of car bodies or other objects like furniture, where gaps are visible. But I’m doing just prototyping, so an AI that can just recognize lines and tell if they are parallel is enough.

Thanks a lot, if you have any questions, feel free to ask, if you have help, comments, criticism, please tell me.",MachineLearning
nzohs0,1623682148.0,[R] Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation,"A Google Research team proposes MergeDistill, a framework for merging pretrained teacher LMs from multiple monolingual/multilingual LMs into a single multilingual task-agnostic student LM to leverage the capabilities of the powerful language-specific LMs while still being multilingual and enabling positive language transfer.

Here is a quick read: [Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation.](https://syncedreview.com/2021/06/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-40/)

The paper *MergeDistill: Merging Pre-trained Language Models using Distillation* is on [arXiv](https://arxiv.org/pdf/2106.02834).",MachineLearning
nznvgp,1623680449.0,[R] Dynamic Mode Decompositions for Higher Order Systems with New Operators and Function Spaces,"So this is probably to coolest project I've worked on. This is a totally different perspective on dynamic mode decompositions for time series, and  it is both deep theoretically  and very satisfying.

The analysis of high order dynamical systems often involves state augmentations, where an n-th order system for a single variable is converted to a first order system of n-variables. If the analysis is done with respect to this data, then what would have worked well with 10 samples for a single variable approximation problem now requires 10\^n samples (the curse of dimensionality).

Dynamic mode decompositions are designed for first order systems, so its use leverages these state augmentations. We designed new spaces and operators to analyze these systems, and recently posted a paper to arXiv!

The big change is that the space of functions act on continuous signals rather than points in state space. This lets us analyze directly systems of the form d\^n/dt\^n x = f(x). That is, we do require that the dynamics only depend on the state, and none of the intermediate derivatives. One example of a system of this form is the duffing oscillator: \\ddot x = x - x\^3.

I gave a semi-plenary talk at the Southeast Analysis Meeting this year, which is honestly one of the videos I am most proud of: [https://youtu.be/pboWfFS53\_I](https://youtu.be/pboWfFS53_I)

You can find the paper on arXiv at [https://arxiv.org/abs/2101.02646](https://arxiv.org/abs/2101.02646)

The code itself isn't really ready for dissemination, but we will share it at a later time :)

Curious to hear everyone's take on this. This has been a great community, and I value the input I have received here.",MachineLearning
nzngzw,1623679319.0,[D] Predicting the next day of someone's life,"Hi. This is an idea i had recently. Hear me out! What if we registered in a spreadsheet every event of everyday of someone's life. After some years, with that ton of data, we could finally predict the next day. Now, is this possible?",MachineLearning
nzlop7,1623673794.0,[D] Does anyone know of a github or notebook that Classification\NLP to predict what language a sentence is in?,I want to see how someone would use classification to predict what language  a sentence is in. Does anyone know of a project that has worked on that? Ideally a simple one,MachineLearning
nzkr49,1623670432.0,[D] Image Generators with Conditionally-Independent Pixel Synthesis (CIPS) by Anokhin et al.,"Generative models have become synonymous with convolutions and more recently with self-attention, yet we (yes, I am the second author of this paper, yay 🙌) ask the question: are convolutions REALLY necessary to generate state-of-the-art quality images? Perhaps surprisingly a simple multilayer perceptron (MLP) with a couple of clever tricks does just as good (if not better) as specialized convolutional architectures (StyleGAN-2) on 256x256 resolution.

Check out the [full paper digest](https://t.me/casual_gan/51) (reading time \~5 minutes) to learn about the architecture of our MLP-based generator, the two types of positional encoding used to increase the fidelity of generated images, and how CIPS can be used to generate seamless cyclical panoramas without ever training on full panoramic images.

Meanwhile, check out the paper summary poster by [Casual GAN Papers](https://t.me/casual_gan)!

[CIPS: Conditionally Independent Pixel Synthesis](https://preview.redd.it/96wnl0w8w7571.png?width=680&format=png&auto=webp&s=85c085e6f44e365c5dd87c52d057108e79bacea4)

\[[Full Explanation Post](https://t.me/casual_gan/51)\] \[[Arxiv](https://arxiv.org/abs/2011.13775)\] \[[Project page](https://github.com/saic-mdal/CIPS)\]

More recent popular computer vision paper breakdowns:

>[DALL-E](https://t.me/casual_gan/48)
[VQGAN](https://t.me/casual_gan/46)
[Decision Transformer](https://t.me/casual_gan/50)",MachineLearning
nziumg,1623662763.0,Combining images and other numeric features in a CNN [D].,"I have been working a little bit on a traffic problem. I have been given a dataset of intersections with a bunch of numeric features with crashes as the response variable. However, in the dataset, I was also given the latitude and longitude. So I wrote a script to query the Google Maps API to generate images of each intersection.

Once that was done, I went about trying to combine the features I already had with the features I already had. But when I sat down to write up the CNN, I realized I had no way of combining the image with the other features. I searched around for a bit, but didn't find anything concrete, which was surprising.

So from what I did read you have two options:

1. Somehow imprint the the other feature data into the image, and run it through a normal CNN.

2. Run just the image through the CNN to compress it down to a 1D array of information, then combine that array with the other feature data in another NN.

Has anyone had any experience with this?",MachineLearning
nzicnk,1623660568.0,[R] Is there a particular reason why TD3 is outperforming SAC by a ton on a velocity and locomotion-based attitude control?,"I have adopted a code from Github to suit my needs in training an MLAgent simulated in Unity and trained using OpenAI Gym. I am doing attitude control where my agent's observation is composed of velocity and error from the target location.

We have prior work with MLAgent's SAC and PPO so I know that my SAC OpenAI version that I have coded works.

I know that TD3 works well to on continuous action spaces but I am very surprised how tremendous the difference is here. I have already done some debugging and I am sure that the code is correct.

Is there a paper or some explanation somehow **why TD3 works better than SAC** on some scenarios especially on this? Since this is locomotion based of the microsatellite trying to control the attitude to its target location and velocity, is that one of the primary reason?

Each episode is composed of fixed 300 steps so it is about 5M timesteps.

&#x200B;

https://preview.redd.it/ykikls9y27571.png?width=1215&format=png&auto=webp&s=46dc59dceb90e411b6baff63106698623af98174",MachineLearning
nzhl6t,1623657134.0,[Discussion] Single word recommendation with NLP?,"I have the following NLP problem:

Imagine short snippet of text, no longer than 30-40 words, an advertisement text to be precise. There are certain important words, e.g. ""sale"", ""-40% off"" etc., which translate to either sales value directly, or promo link click-through-rate (CTR). Either way, the resulting metric can be measured and I have the dataset with measurements.

The idea is to recommend better words, i.e. create an NLP model to suggest better words to increase the metric. The single word model would be enough, so the model would take the planned input and suggest changing single word (or a few words separately) to increase the metric.

Does this make sense? Is this possible? What models / neural network architectures could be useful? Pointing me in the right direction / keywords would be greatly appreciated.",MachineLearning
nzfsm6,1623649462.0,[D] help me understand how VAEs assign probability density (r.e. posteriour collapse),"I am trying to get a better understanding of how VAEs model  data *in abstract*, and how this relates to posteriour collapse.

Can you tell me which of the following statements are true, or not:

0. The VAE optimizes a lower bound on p(x) = \\int p(x|z) p(z) dz.   Typically the derivation starts from log p(x), but I'm not asking about the ELBO derivation; let's assume that the lower bound ""works"" and suppose the bound is fairly tight.

1. The integral \\int p(x) dx over all p(x) is 1, where p(x) means the marginal density assigned by the model, but this is true only if the bound is tight. In fact it will be below 1 due to the gap, but hopefully not too far below.
2. Now suppose the model is flexible and we ""overtrain"" it, so that it assigns as much probability as possible to the given data. No early stopping or evaluation on held-out data.

The training should produce ""spikes"" around the datapoints.

3. If we integrate the density in a small radius around each spike, this should capture most of the probability density. We might expect that with N datapoints, the probability density around each point would be about 1/N, although random weight initialization could produce some other result.

4a. In concept, a flexible decoder network can model this density of N spikes, each with 1/N probability, regardless of whether it makes use of the encoder. Thus posteriour collapse can happen.

4b. However this is not possible if the decoder produces a gaussian probability distribution at its output, since the Gaussian is unimodal and cannot model the N spikes without referring to the input.

I.e. posteriour collapse does not happen; q(z|x)!=p(z) and the decoder makes use of z\~q(z|x) to produce a conditional p(x|z) that changes for each datapoint.

5. Unlike a VAE, a plain autoencoder can be interpreted as assigning an overall probability density **larger than 1** to the data.

Using the equivalence between gaussian density and least squares reconstruction loss, imagine an autoencoder that produces near perfect reconstruction, maybe up to floating point roundoff (e.g. perhaps it is a linear autoencoder, and the data is generated from the subspace spanned by the decoder).  This produces arbitrary high density, however the Gaussian normalization results in the overall density integrating to 1 *for that datapoint*. When summed over all datapoints, the total probability density will be approximately N, rather than 1.

Edit: comment and clarification. The overall question is about how the VAE assigns probability to the data x (rather than probability on the latent space). The VAE decoder ends by generating a density, which is usually just set to a independent predicted mean and constent variance, with no correlation across dimensions. I'm thinking about how the probability implied by this density is assigned across the training data.

My main confusion is considering the case without and with posterior collapse. a) Without collapse, if the model is working well, it should assign high p(x|z) to that particular datapoint, and low density to other datapoints.  But p(x) still has to integrate to one across all the data, so I think the probability assigned in the region of that datapoint (integrating around its spike) should be 1/N.
b) In the case of posteriour collapse, it the model has to assign probability 1/N to each spike.  So is the probability density assigned by the model the same regardless of whether posteriour collapse happens?",MachineLearning
nzdywk,1623642861.0,[D] What should I do after building a baseline solution?," I'm new to neural network. I am really curious to know what will you guys do after building a baseline model. When participating a competition (Kaggle), I often build an end to end baseline solution to ensure it work without bug. For example, in image classification competition, I usually do something check list below.

**Data preparation**

* Resize and Normalize only
* No special augmentation

**Setup neural network**

* Learning rate: 3e-4
* Adam Optimizer
* Cross Entropy Loss or Binary Cross Entropy Loss
* Pre-train neural network ( such as resnet18, resnet34)
* Turning off all regularization hyper-parameters

**Training**

* Sampling one batch to overfit easily
* No learning rate scheduler
* Training and validating one fold only
* Early stopping
* Plotting loss and metric scores

**Testing**

* Running above model with test set
* Exporting test predictions to submission.csv then submit to public Leader Board (LB).

If the result makes sense, the baseline seems work without bug.
Then, I train all samples with all folds and submit again to check baseline score.

After that, I struggle to figure out what should I do further (to improve LB score).
I've tried to adjust learning rate to overfit train dataset. Then, adding some augmentations (such as random resize crop, flip, transpose…) then check LB score again. The score was improved a little but it was still far from top LB, of course. Some time, it was not much different from baseline score.

I read some Kaggle forum discussions, some nice guys shared their solutions to get higher score in LB. They usually used different parameters than me, such as:

* Fancy augmentations
* Bigger pre-train model or adding some layers/blocks to pre-train model
* Custom Loss function
* Modern learning rate scheduler
* Ensemble many models
* Etc, etc…

I want to reproduce their solutions to learn their knowhow. But I don't know what to do first.
Should I try switch to bigger model first? Or switching loss function first? Or adding fancy augmentation first? Or changing loss function first? etc…

Since there are too many black boxes in neural network, it is not easy to understand or interpret how a network works. But I think there are some strategies or disciplines to help.

What will you do to overcome this problem? Please share your own wisdom. Any comments and suggestions will be appreciated.

Best regards,

P/S: My baseline checklist is inspired by this famous blog:
[http://karpathy.github.io/2019/04/25/recipe/](http://karpathy.github.io/2019/04/25/recipe/)",MachineLearning
nzdiox,1623641335.0,[D] What are your challenges when improving ML models?,"Hi, I am very enthusiastic about ML/DL (I worked in this space for 4-5 years myself) and wanted to help fellow ML practitioners with building their models. Please, can you help me to validate the problem that I am trying to solve?

Specifically, do you find the model improvement slow right now? Does it take you long to identify edge cases and re-train your model on those?",MachineLearning
nza8tg,1623630769.0,[D] Good books or material on optimization algorithms?,"I'm trying to find a good book on optimization algorithms. I'm not referring specifically to the theory, but a good resource on a list of differing optimization functions and their properties for example:
adversarial loss: has properties _____
L1 distance between 2 vectors: Is _____",MachineLearning
nz7uoc,1623623599.0,[R] A Practical Guide to Counterfactual Estimators for Causal Inference with Time-Series Cross-Sectional Data,"This paper introduces a unified framework of counterfactual estimation  for time-series cross-sectional data, which estimates the average  treatment effect on the treated by directly imputing treated  counterfactuals. Its special cases include several newly developed  methods, such as the fixed effects counterfactual estimator, interactive  fixed effects counterfactual estimator, and matrix completion  estimator. These estimators provide more reliable causal estimates than  conventional two-way fixed effects models when the treatment effects are  heterogeneous or unobserved time-varying confounders exist. Under this  framework, we propose two sets of diagnostic tests, tests for (no)  pre-trend and placebo tests, accompanied by visualization tools, to help  researchers gauge the validity of the no-time-varying-confounder  assumption. We illustrate these methods with two political economy  examples and develop an open-source package, fect, in both R and Stata  to facilitate implementation.

Liu,  Licheng and Wang,  Ye and Xu,  Yiqing, A Practical Guide to  Counterfactual Estimators for Causal Inference with Time-Series  Cross-Sectional Data (June 21, 2020).  Available at SSRN: [https://ssrn.com/abstract=3555463](https://ssrn.com/abstract=3555463) or [http://dx.doi.org/10.2139/ssrn.3555463 ](https://dx.doi.org/10.2139/ssrn.3555463)",MachineLearning
nz5n26,1623617390.0,[D] ML in Digital Marketing Company,"Hi guys,

I was wondering if any of you was working as DS/DE/Data analyst in company specialised in digital marketing.

I would be curious to see how data can be used in this field? (increase impression share, decrease CPL budget optimization etc..)",MachineLearning
nz19bd,1623605017.0,[P] Error due to Colab RAM depletion when implementing Multi-label classification with BERT and Pytorch,"**Background:** I'm implementing **multi-label classification for tones (7 types of tones)**.

Dataset shape: **train\_df=(5392, 8); val\_df = (1348, 8)**

The modelling approach remains the same as this [multi-label classification with BERT & pytorch](https://curiousily.com/posts/multi-label-text-classification-with-bert-and-pytorch-lightning/)

I'm getting an error in **training the model where Colab's RAM is being depleted :**

&#x200B;

    N_EPOCHS = 10
    BATCH_SIZE = 12

    data_module = ToneDataModule(
        train_df,
        val_df,
        tokenizer,
        batch_size = BATCH_SIZE,
        max_token_len = MAX_TOKEN_COUNT
    )

Our model will use a pre-trained [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and a linear layer to convert the BERT representation to a classification task. We'll pack everything in a [LightningModule](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html):

    class ToneDataTagger(pl.LightningModule):

      def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):
        super().__init__()
        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)
        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)
        self.n_training_steps = n_training_steps
        self.n_warmup_steps = n_warmup_steps
        self.criterion = nn.BCELoss()

      def forward(self, input_ids, attention_mask, labels=None):
        output = self.bert(input_ids, attention_mask = attention_mask)
        output = self.classifier(output.pooler_output)
        output = torch.sigmoid(output)
        loss=0
        if labels is not None:
          loss = self.criterion(output, labels)
        return loss, output

      def training_step(self, batch, batch_idx):
        input_ids = batch['input_ids']
        attention_mask = batch['attention_mask']
        labels = batch['labels']
        loss, outputs = self(input_ids, attention_mask, labels)
        self.log(""train_loss"", loss, prog_bar=True, logger=True)
        return {""loss"": loss, ""predictions"": outputs, ""labels"":labels}

      def validation_step(self, batch, batch_idx):
        input_ids = batch[""input_ids""]
        attention_mask = batch[""attention_mask""]
        labels = batch[""labels""]
        loss, outputs = self(input_ids, attention_mask, labels)
        self.log('val_loss', loss, prog_bar = True, logger=True)
        return loss

      def test_step(self, batch, batch_idx):
        input_ids = batch[""input_ids""]
        attention_mask = batch[""attention_mask""]
        labels = batch[""labels""]
        loss, outputs = self(input_ids, attention_mask, labels)
        self.log(""test_loss"", loss, prog_bar=True, logger=True)
        return loss

      def training_epoch_end(self, outputs):

        labels = []
        predictions = []

        for output in outputs:
          for out_labels in output['labels'].detach().cpu():
            labels.append(out_labels)
          for out_predictions in output['predictions'].detach().cpu():
            predictions.append(out_predictions)

        labels = torch.stack(labels).int()
        predictions = torch.stack(predictions)

        for i, name in enumerate(LABEL_COLUMNS):
          class_roc_auc = auroc(predictions[:, i], labels[:, i])
          self.logger.experiment.add_scalar(f'{name}_roc_auc/Train', class_roc_auc, self.current_epoch)

      def configure_optimizers(self):
        optimizer = AdamW(self.parameters(), lr=2e-5)

        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=self.n_warmup_steps,
            num_training_steps=self.n_training_steps
        )

        return dict(
            optimizer = optimizer,
            lr_scheduler = dict(
                scheduler=scheduler,
                interval='step'
            )
        )


&#x200B;

    model = ToneDataTagger(
      n_classes=len(LABEL_COLUMNS),
      n_warmup_steps=warmup_steps,
      n_training_steps=total_training_steps
    )

Multi-label classification boils down to doing binary classification for each label/tag. We'll use Binary Cross Entropy to measure the error for each label. PyTorch has [BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html), which we're going to combine with a sigmoid function (as we did in the model implementation). Let's look at an example:

    criterion = nn.BCELoss()

    _, predictions = model(sample_batch['input_ids'], sample_batch['attention_mask'])
    predictions

>tensor(\[\[0.2637, 0.6621, 0.3690, 0.3400, 0.5255, 0.5604, 0.4574\], \[0.2863, 0.6707, 0.3608, 0.3159, 0.5064, 0.5195, 0.4597\], \[0.3011, 0.6806, 0.3491, 0.3200, 0.5160, 0.5008, 0.4566\], \[0.2632, 0.6532, 0.3484, 0.3600, 0.5162, 0.5607, 0.4416\], \[0.2674, 0.6449, 0.3435, 0.3526, 0.5223, 0.5434, 0.4429\], \[0.2981, 0.6899, 0.3588, 0.2996, 0.5088, 0.4698, 0.4766\], \[0.2695, 0.6288, 0.3351, 0.3649, 0.5389, 0.5892, 0.4257\], \[0.3226, 0.6841, 0.3424, 0.3193, 0.4977, 0.4534, 0.4946\]\], grad\_fn=<SigmoidBackward>)

&#x200B;

calculate the loss of the predictions:

    criterion(predictions, sample_batch['labels'])

>tensor(0.6812, grad\_fn=<BinaryCrossEntropyBackward>)

&#x200B;

    trainer = pl.Trainer(
      logger=logger,
      checkpoint_callback=checkpoint_callback,
      callbacks=[early_stopping_callback],
      max_epochs=N_EPOCHS,
      gpus=1,
      progress_bar_refresh_rate=30
    )

>GPU available: True, used: True TPU available: False, using: 0 TPU cores

    trainer.fit(model, data_module)
    // Execution is stopped due to depletion of available RAM in Colab.

**Best guess point of failure**: Infinite loop due to incorrect hyperparameters",MachineLearning
nz0hrq,1623602881.0,[D] Video - Deep learning with dynamic graph neural networks,"I'm a PhD student studying machine learning and applications in transportation systems and autonomous systems (think RL and robotics). While there are several ""GCN made easy"" videos out there on Youtube, I feel like these videos often miss the forest for the trees (especially since GCN is just 1 algorithm that was developed in 2016...) and videos often don't cover the broader historical context of how GNNs were developed and don't cover how different variations of these models allow them to model new types of systems.

This is the fourth video in a series I'm making about graphs, graph neural networks, and the application areas where they have the potential to make big impacts. Please let me know what you think of the video and if you learned anything new from it!

https://youtu.be/01EP23yHSwU",MachineLearning
nyydim,1623597070.0,"[R] Need dataset Images of lines, recognizing if lines are parallel","For my masterthesis I need image classification, images of (2)lines and need to recognize if the lines are parallel.

Any help appreciated! Thanks in advance!",MachineLearning
nyycms,1623597004.0,[D] What is the best package for combined speech recognition and diarization on long conversation audio files?,"I have maybe 1000 hours of audio recordings I want to convert to text with timestamps to match diarization timestamps. Or at the minimum, at least convert to text without diarization. The files are a few hours each and add up to maybe 200 5hr sessions. Quality isn't always great but a human can clearly understand what is being said. Approaches I have tried:

Mozilla freespeech: convoluted installed, no diarization

Kaldi: also somewhat convoluted install, could revisit

SpeechBrain with Huggingface pretrained: got working, but attention model may need 30 second or less inputs, worried about splitting 6 hour session into 30 seconds and the information loss.",MachineLearning
nyxqls,1623595270.0,[D] Conv2D Filter Progression - Grow or Shrink?,"I'm experimenting with simple Conv2D-based CNNs.  These are typically 4-6 layers.   I believe the conventional wisdom is that the first/early layers typically encode primitive features (color gradients, lines, etc) and later layers encode more complex features like the eye of an animal.

I want to compare two hyperparameter strategies relating to the number of filters per layer.  One is growing filters an the other is shrinking filters.   For a 5 layer CNN I might pick 16, 32, 64, 64, 128; and for comparison I'd pick the opposite 128, 64, 64, 32, 16.  I run these two models using the same dataset (kaggle cats and dogs dataset ) and configuration of data generators.

Empirically, it seems that I get better performance with the second approach, shrinking filter size.   Maybe my data has a larger number of primitive features, and fewer complex features?  Is this a data dependent observation or is it generally true?  Or is this just a matter of ""try it and see what works""?",MachineLearning
nyx5qz,1623593479.0,[D] Model to detect abnormal behaviour in animal CCTV videos (Horses),"Hi !

We have cameras to monitor our horses in stables or in fields, all fed to /r/blueiris software  (hosted on a i7 Windows Box ) ,, blueiris app, works like a charm.

I'm looking for a way to detect abnormal behaviour and alarm about it. Not simple motion detection, not person detection, but something that would trigger a ""something is not going as usually"", things like:
\- a lot of movement compared to usual

\- sleeping/resting for too long

I would image a model that would learn on like a week worth of video, and triggers if something is different.

Do you folks know about something similar, or where I could look for this?

Running on Windows, ideally locally to keep cost to minimum


Happy to discuss !

EDIT : Thanks for the answers so far!! I understand that it's actually a way harder problem that I initially thought.
I also thought something would exist already.
Unfortunately, Not competent enough in ML to dive into some solutions proposed...",MachineLearning
nyvw19,1623589448.0,"[DISCUSSION] What's the implementational difference between RANSAC on line, circle or some other shape?","\[DISCUSSION\] What's the implementational difference between RANSAC on line, circle or some other shape?

If a package says just RANSAC, then what is it? Line version?",MachineLearning
nyrioh,1623571086.0,[D] Suggestions for a model to determine vaccine priority,"Hi Everyone, I am working on a proposal to create a model and to guide the ministry of health to determine priorities for COVID vaccination( I am from Nepal, and we have a second wave and not enough vaccines), based on pcr test data, covid spread, demography, location and age. Please suggest me what can I do to make this more effective.",MachineLearning
nyn5or,1623552781.0,[D] Am I missing any MLP vision architectures here?,"I've been trying to catch up on some papers, and I'm pretty interested in the whole MLPs for vision thing that boomed last month. So far I was able to gather:

&#x200B;

|**Model**|**Paper**|
|:-|:-|
|MLP-Mixer|MLP-Mixer: An all-MLP Architecture for Vision|
|ResMLP|ResMLP: Feedforward networks for image classification with data-efficient training|
|no name for this one I think|Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet|
|RepMLP|RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition|
|gMLP|Pay Attention to MLPs|
|EAMLP|Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks|

&#x200B;

Just want to ask if there are any more that I missed that have also gained traction? Admittedly though I don't know how many of the ones I listed here have made a splash, aside from MLP-Mixer. Thanks!",MachineLearning
nyiyex,1623538646.0,[D] An incorrect claim in a paper which the authors will not acknowledge/respond to (Time series anomaly detection),"

A recent paper \[a\] claims that the Matrix Profile does not work well on a particular dataset, NASA SMAP G7. We can test to see if this is true, with a single line of publicly available code, lets do it.

\>> interactiveMatrixProfileVer4\_website( G7+\[1:length(G7)\]'/1000000 ,50);

Hmm, the Matrix Profile results are perfect. The yellow circles highlight the fact that the three peaks of the Matrix Profile coincide with the labeled ground truth.

You can double or half the parameter and get the same results.

I did point this out to the authors, but they don’t answer emails ;-(

There are quite a few papers that do this, cripple the Matrix Profile to make their approach look better. Including papers in good venues like VLDB. As a community, as authors and reviewers, we need to do better.

\[a\] Local Anomaly Detection for Multivariate Time Series by Temporal Dependency Based on Poisson Mode. IEEE Trans Neural Netw Learn Syst. 2021 Jun 2

&#x200B;

&#x200B;

https://preview.redd.it/1ykyeperzw471.jpg?width=2205&format=pjpg&auto=webp&s=75d17587758fbe407167fca978dffba8076395a5",MachineLearning
nyf7rg,1623528493.0,[D] Survival Analysis - How to calculate the concordance index on a test dataset?,"Hi guys! I have fitted different types of survival models with a training dataset, and the output of these models provide a concordance index. However, this concordance index is calculated in the training dataset. I then used these fits in a test dataset to make predictions of time-to-event, and I want to calculate the concordance index on the predictions made on the test dataset, because obviously a model should be evaluated on a test dataset instead of a training dataset. I've searched online but I didn't find how to compute the concordance index on a test dataset. How can it be done? Thanks!",MachineLearning
nye7a7,1623525665.0,[N] Raquel Urtasun - Founder and CEO Waabi - Podcast,"&#x200B;

We (IEEE Soft Robotics Podcast) going to have Raquel Urtasun  the founder & CEO  of Waabi, and professor at University of Toronto. If you have any questions, please let us know through the following link:

[https://docs.google.com/forms/d/e/1FAIpQLSebRJVDHIyFflSfP7XLNwNxHNQYp5bY4J9fjlniw9yGH56iXg/viewform?vc=0&c=0&w=1&flr=0](https://docs.google.com/forms/d/e/1FAIpQLSebRJVDHIyFflSfP7XLNwNxHNQYp5bY4J9fjlniw9yGH56iXg/viewform?vc=0&c=0&w=1&flr=0)

&#x200B;

https://preview.redd.it/1rfcruh5wv471.png?width=1600&format=png&auto=webp&s=f214cd06e9bb14295484ec4d5162943f0e1773e3",MachineLearning
nye651,1623525587.0,[D] Selecting the right algorithm,"I am a student learning more about ML, so please excuse my limited knowledge. While learning about how to select the right ML model, I understand there are hundred different factors involved. On this, I found a KDnugets article which includes size of the data as a factor in selecting the right algorithm.

The article says:

>It is usually recommended to gather a good amount of data to get reliable predictions. However, many a time, the availability of data is a constraint. So, if the training data is smaller or if the dataset has a fewer number of observations and a higher number of features like genetics or textual data, **choose algorithms with high bias/low variance like Linear regression, Naïve Bayes, or Linear SVM.**
If the training data is sufficiently large and the number of observations is higher as compared to the number of features, one can go for **low bias/high variance algorithms like KNN, Decision trees, or kernel SVM.**

In this explanation, I don't understand why or how did they come to this conclusion of choosing these algorithms for such a dataset size, can someone please explain?",MachineLearning
ny9tvh,1623513230.0,[D] What can AI/ML contribute to a crowdfunding site?,"Hi, I'm designing a crowdfunding site (personal project) that would help to provide financial services to the poor & financially excluded people. Any advice on how can I leverage crowdfunding using AI or ML?


Thanks in advance",MachineLearning
ny7r3c,1623507425.0,[P] [R] LSTM for Fault Detection & Diagnosis with time series classification," I'm working on a fault detection and diagnosis using an time series data  set which has both normal and faulty data (7 faulty types) where i will  predict the the class label of a given sequence of inputs ( a selected  window of current incoming data).

I used sequential model with KerasClassifier and implemented a NN model  which gave me an predicted class label based on the input sample (one  array of data sample).

https://preview.redd.it/yvl8vz4s8v471.png?width=1182&format=png&auto=webp&s=908bd821d6e9558dba8581ada124d82e556bc69a

But  here i have used only a single input of data. The scenario i want to  achieve is providing a specific window of latest incoming (a window of  10 inputs within 10 seconds ) and predict a class label based on the  provided sequence of multiple samples to the predict function. ",MachineLearning
ny5kg2,1623500554.0,[P] Neural Style Transfer Applied on Classic Retro Video Games in Real Time,"Have you ever seen a 𝗠𝗼𝗿𝘁𝗮𝗹 𝗞𝗼𝗺𝗯𝗮𝘁 𝗳𝗮𝘁𝗮𝗹𝗶𝘁𝘆️ painted 𝗶𝗻 𝗩𝗮𝗻 𝗚𝗼𝗴𝗵’𝘀 𝘀𝘁𝘆𝗹𝗲 by a 𝗗𝗲𝗲𝗽 𝗡𝗲𝘂𝗿𝗮𝗹 𝗡𝗲𝘁𝘄𝗼𝗿𝗸?

This snapshot ([short video clip here](https://www.youtube.com/watch?v=HsAhwAN3qso)) has been 𝗲𝘅𝘁𝗿𝗮𝗰𝘁𝗲𝗱 𝗳𝗿𝗼𝗺 𝗼𝗻𝗲 𝗼𝗳 𝗼𝘂𝗿 𝗹𝗮𝘁𝗲𝘀𝘁 𝗧𝘄𝗶𝘁𝗰𝗵 𝗹𝗶𝘃𝗲 𝘀𝘁𝗿𝗲𝗮𝗺: we implemented a 𝗗𝗲𝗲𝗽 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴 model to perform 𝗻𝗲𝘂𝗿𝗮𝗹 𝘀𝘁𝘆𝗹𝗲 𝘁𝗿𝗮𝗻𝘀𝗳𝗲𝗿 𝗶𝗻 𝗿𝗲𝗮𝗹 𝘁𝗶𝗺𝗲, testing it on video games currently interfaced in 𝗗𝗜𝗔𝗠𝗕𝗥𝗔 𝗘𝗻𝘃𝗶𝗿𝗼𝗻𝗺𝗲𝗻𝘁 𝗳𝗼𝗿 𝗗𝗲𝗲𝗽 𝗥𝗟 ([GitHub here](https://github.com/diambra/DIAMBRAenvironment))

In the [full video](https://www.twitch.tv/videos/1044884198/) you’ll see 𝗮𝗹𝗹 𝟮𝟯 𝗱𝗶𝗳𝗳𝗲𝗿𝗲𝗻𝘁 𝘀𝘁𝘆𝗹𝗲𝘀 taken from very famous paintings in action, the 𝗲𝗳𝗳𝗲𝗰𝘁 𝗶𝘀 𝘀𝗼 𝗰𝗼𝗼𝗹 𝗮𝗻𝗱 𝗳𝘂𝗻! Experimenting with these technologies is really exciting️, 𝗳𝘂𝘀𝗶𝗻𝗴 𝘁𝗼𝗴𝗲𝘁𝗵𝗲𝗿 𝗱𝗶𝗳𝗳𝗲𝗿𝗲𝗻𝘁 𝗲𝗹𝗲𝗺𝗲𝗻𝘁𝘀 𝗮𝗹𝗹𝗼𝘄𝘀 𝘆𝗼𝘂 𝘁𝗼 𝗲𝘅𝗽𝗹𝗼𝗿𝗲 𝗻𝗲𝘄 𝗱𝗶𝗿𝗲𝗰𝘁𝗶𝗼𝗻𝘀 𝗲𝘃𝗲𝗿𝘆𝗱𝗮𝘆

To know more: [Twitch Channel](https://www.twitch.tv/diambra_at) \- [Discord Server](https://discord.gg/tFDS2UN5sv) \- [Website](https://diambra.artificialtwin.com/)

[Neural Style Transfer Applied on Classic Retro Video Games in Real Time](https://preview.redd.it/hn9yb6mh80571.png?width=1920&format=png&auto=webp&s=84d46cb250cbcf3a7c0a0feb2657596117444b00)",MachineLearning
ny4twy,1623497893.0,[R] DeepMind describes a possible solution to artificial general intelligence.,"Abstract:

> In this article we hypothesise that intelligence, and its associated abilities, can be understood as subserving the maximisation of reward. Accordingly, reward is enough to drive behaviour that exhibits abilities studied in natural and artificial intelligence, including knowledge, learning, perception, social intelligence, language, generalisation and imitation. This is in contrast to the view that specialised problem formulations are needed for each ability, based on other signals or objectives. Furthermore, we suggest that agents that learn through trial and error experience to maximise reward could learn behaviour that exhibits most if not all of these abilities, and therefore that powerful reinforcement learning agents could constitute a solution to artificial general intelligence.

Full text: https://www.sciencedirect.com/science/article/pii/S0004370221000862",MachineLearning
ny2vk4,1623490090.0,[D] Model that points to specific object in an image,"Hi,

I would like to train a model that takes as input an image & and the label of an object in text form (e.g., ""apple"") and outputs a point (x-y coordinates) that is at the center of the object in the image. This seems like a sufficiently simple idea that I'm hoping it already exists, but I'm not familiar with any paper proposing it. I know there is work on image captioning and object detection, but usually those are dealt with models that take just an image as input.

If the model outputs a bounding box rather than a point, this should still be fine since one can easily recover the point from the box. Bonus points if the model doesn't take a label as input but a sentence about the object (i.e., it takes an image of a car and the sentence ""this is a car because it has four tires"" and outputs a point on/bounding box around one of the tires).

Does anyone know of existing work similar to this?",MachineLearning
nxu6zw,1623457365.0,[N] Should we tell them that they're optimizing the wrong metric?,"Source: [https://www.infoq.com/news/2021/04/open-source-ai-storms/](https://www.infoq.com/news/2021/04/open-source-ai-storms/)

They are focusing on precision when they should be focusing on recall (which isn't that great) or F1-Beta.

""The team noted that for their use case, the worst outcome is a prediction of no damage for a storm that does indeed cause damage""

""The predictions are based on a [support-vector classifier](https://en.wikipedia.org/wiki/Support-vector_machine), which achieves 81% precision and 61% recall.""",MachineLearning
nxt04z,1623453593.0,[P] Read EEG in plain text,I'm trying to find a way to read raw EEG data in plain text but it's difficult. I thought of assigning words to EEG numbers. Like adding a full story tale to EEG by order then change words to numbers then train a model with EEG in one column and numbers that represent words in the second column. The EEG to train represents a story. The idea is to train it as a story then add new EEG and ML will create a new story by finding how EEG can be a story with the model that was trained previously. After training we use new EEG file and we generate the numbers that represent words then we change the numbers to words and it's expected to be a complete and readable story that makes sense to read,MachineLearning
nxslw9,1623452311.0,[D] Paper Explained - Efficient and Modular Implicit Differentiation (Full Video Analysis),"[https://youtu.be/8Oy7o3Yu-Xo](https://youtu.be/8Oy7o3Yu-Xo)

Many problems in Machine Learning involve loops of inner and outer optimization. Finding update steps for the outer loop is usually difficult, because of the.need to differentiate through the inner loop's procedure over multiple steps. Such loop unrolling is very limited and constrained to very few steps. Other papers have found solutions around unrolling in very specific, individual problems. This paper proposes a unified framework for implicit differentiation of inner optimization procedures without unrolling and provides implementations that integrate seamlessly into JAX.

&#x200B;

OUTLINE:

0:00 - Intro & Overview

2:05 - Automatic Differentiation of Inner Optimizations

4:30 - Example: Meta-Learning

7:45 - Unrolling Optimization

13:00 - Unified Framework Overview & Pseudocode

21:10 - Implicit Function Theorem

25:45 - More Technicalities

28:45 - Experiments

&#x200B;

ERRATA:

\- Dataset Distillation is done with respect to the training set, not the validation or test set.

&#x200B;

Paper: [https://arxiv.org/abs/2105.15183](https://arxiv.org/abs/2105.15183)",MachineLearning
nxpkg6,1623443744.0,[D]Suggestion for ML/Data Engineer-Related Projects in C++?,"I'm looking for a new job as an ML Engineer. I saw there're many job descriptions showing that they want the candidate to know Python/C++/Java. My current team builds production systems for ML models, and we ONLY use Python. I know some C++, and I have some small school-type projects (memory management, system usage monitor, concurrent programming) in C++, but I don't have any ML or MLOps-related projects in C++.

I saw there's a course on Linkedin for teaching you how to build a neural network from scratch in C++. If I put that on my resume, does it sounds fancy or strange? I mean, most people/companies use Pytorch or Tensorflow to build NN architecture models now, so I don't really see the point...

Anyway, I really want to know if I need to put a C++ project on my resume to make it competitive? If so, any suggestion for an MLOps or data engineering-related project in C++? Thank you!",MachineLearning
nxnci9,1623437592.0,[D] Wyze cam and Ring cam campfire discussion for computer vision purposes,"Basically, I'm doing a CV system with deep neural nets that is monitoring specific outdoor images of natural environment.

It would be nice to use the consumer-grade cams from Ring or Wyze.  These have cloud subscriptions and some under-100 dollar cams.  I have already acquired and paid for cloud and cam for both systems hoping one would work well for CV data capture.

I expect that an RDTP server on cam might help since I expect I then can write code for my own custom client and save any video stills that I find interesting.

In the past (2008) I made pre-machine-learning vision app with cheap PC webcams to automatically measure the speed of car traffic and it was semi-successful.  As you can guess, special cases began to overwhelm my rule-driven analysis code, and machine learning will work much much better, I expect. The current apps I am working on are not vehicle speed measurers.

My findings so far, for Wyze cams ""Outdoor"" and ""V3"" as of early 2021:

- Must click in the UI to manually download pre-motion-detected segments one at a time, even for paid cloud subscribers. This is a problem.

- No programmatic API, even for paid cloud subscribers. THis is a problem.

- For some not all cams they sell, there is an RDTP server firmware you can put on the cam, to replace the original firmware.  They call it ""beta"" release level not production level, with all that implies.

- RDTP would enable my code to read all video all the time, so it will not miss anything.

- The provided motion-detection too often misses my subjects that move, in my manual tests. I guess it's PIR driven, not AI driven in the provided motion-detection, and my subjects are not different enough in temperature than the background.  This means that their provided motion detection probably is more trouble than benefit.  I will have to do my own motion detection, which is fine really as I am confident I can do this myself.

- Wyze has a mode provided in the standard cam firmware, to do so-called time-lapse, which is basically taking a still photo at a chosen fixed frequency, like once per minute, during a defined time range, like 6 hours.  This might help me reduce the file sizes that need to be saved to the local SD memory card.  It would effectively be sampling instead of continuous-time recording.  Thus I would miss some interesting events, but on the other hand I will still get some interesting events.

- The wifi that is built-in makes them very easy to install in good locations for my projects.

As for the Ring cams:

- Slightly more expensive, slightly less useful and flexible.  Basically all of the same problems as Wyze cams.

- No RDTP that I could find (let me know if I overlooked)


TO summarize:

I might have to go back to PC web cams. At least I can do everything with the images.  It's not a closed proprietary cloud holding my data.

It would be a shame to go back to PC web cams, because the wifi in Ring and Wyze cams make them very easy to install in good locations for my projects.  Also these new cams have greatly improved resolution and color versus my old web cams from 10+ years ago.

- I feel like approaching these companies, to ask for API to be installed and published so scientists can use their cams.

- I feel like anyone who pays a subscription to their cloud, should ethically and morally be allowed by these companies to use the API without restriction to read (download) their own image data from the cloud.


In your own CV projects, what have you found that works for a cam system?

I expect a phone cams is another possibility, esp older phones that have no other uses and just sit around in a drawer.

Is there an app for RDTP serving on android phones?


Thanks for reading and sharing.",MachineLearning
nxn9q0,1623437376.0,[D] Epsilon Decay - Sporadic 'epsilon' jumping (reinforcement learning)," Hey all!

See the graphic below. I'm working on building my first Reinforcement Learning agent. I wrote a simple decay function with an initial epsilon of 100. The epsilon would decay by '1' every single episode. As you can see, I also set a minimum epsilon of 5.

My question is this: I implemented a 'sporadic' epsilon jump/increase, with a 15% chance of being hit. If the sporadic jump was indeed hit, it would randomly increase the epsilon value by 1-10, and then on the next episode, revert back to the previous epsilon and continue decreasing by 1, so on and so forth. I'm wondering if this would aid training in any way / if there is another name for doing this besides my current made-up terminology of 'sporadic epsilon increase'. Thanks in advance!

&#x200B;

https://preview.redd.it/yki5k069no471.png?width=480&format=png&auto=webp&s=96c46fd3256368062b36c3d491be7f3d22ad2827

Exploration / Exploitation Graph:

&#x200B;

https://preview.redd.it/9zr8gxqano471.png?width=480&format=png&auto=webp&s=70594eb7fd242de4dc57773208bba2e074c6d8a9",MachineLearning
nxn8jl,1623437286.0,[Discussion] How are you manage ML/AI projects?,"Is it possible to comfortably use Agile for it?

Or, maybe, you use some specific tools/processes? Can you describe it? (processes)",MachineLearning
nxn65x,1623437102.0,"[D] Can we begin to understand possible mathematical reasons as to why algorithms like ""xgboost"" and ""random forest"" win Kaggle Competitions, instead of neural networks?","Could there be any mathematical reasons behind why algorithms like random forest and xgboost are known to win Kaggle competitions (i.e. perform well for medium sized tabular datasets) compared to deep neural networks and linear regression models?

Heuristically, here are my general conclusions:

1) GLM (general linear models) perform best on smaller sized datasets, provided certain statistical assumptions are met.

2) boosting and bagging algorithms (e.g. random forest and xgboost) perform best on larger tabular datasets, and do not require many statistical assumptions.

3) deep neural networks perform best on very large datasets, preferably on non tabular datasets (e.g. tensors, pictures, audio, computer vision, text/nlp).

But can there be any mathematical reasons that try to explain these general conclusions (provided these conclusions are correct)?

For instance, suppose there is one response variable and one predictor variable, and when graphed together they look like a sine wave - it seems unlikely that a linear regression model could perform well. Perhaps this is because a linear model can only capture a linear trend? Perhaps it is too hard to understand the exact assumptions required for GLM models to work on real world data, or they are too prone to overfit on complex data?

The same way, is there any math that explains why alphaGO, self driving cars and Google's BERT NLP model are all based on neural networks - and not using random forest and xgboost? Is this because there is some mathematical property of random forest and xgboost which severely hinder their performance on very big and complicated datasets? Perhaps it can be shown theoretically that random forests require an exponentially large amount of trees to model complex data, which is just not computationally possible ... or would surely result in overfitting?

And the same way, is there any math that explains why deep neural networks aren't as successful as random forest and xgboost on medium sized tabluar datasets? Do deep neural networks simply require too much effort to select the right combinations of hyperparameters, and its just not worth it for medium sized datasets when random forests work well given significantly less effort? Are deep neural networks to prone to overfit medium datasets?

Of course, all of this comes to down to trial and error: if a certain model fits the training and test data well - then use that model. But just using mathematical logic and intuition, can we develop some general guidelines that tell us which conditions and types/size of data are favorable for specific algorithms? This could potentially save us a lot of time by directly trying better suited models for the task at hand (e.g. not even trying to use logistic regression for alphaGO).

So in the end: Beyond empirical results, could there be any mathematical reasons behind why random forest and xgboost are chosen in kaggle competitions compared to deep neural networks? And beyond empirical results, could there be any reasons why random forest and xgboost are not chosen for the ImageNet competition?

Thanks",MachineLearning
nxn1zj,1623436789.0,[D] Why don't conferences publish a review graph dataset for transparency?,"With recent allegations of rampant collusion in the ML conference industry, I wonder why literally no conferences make an anonymized reviewer-paper-author dataset public?

One of the prominent themes in ML is graph analytics. We can detect communities, we can predict links, we can detect anomalies, and measure hundreds of graph properties.

Why not publish an anonymized graph with review outcomes? We're supposed to be doing ML research, why don't we apply graph analytics to data generated by the most respected members of our community?

 It can be anonymized, fake nodes can be added, review scores can be bucketed to 0/1, etc. to prevent deanonymization.

Any obvious bad patterns of collusion like cliques and strongly coupled communities should be clearly visible in the data. Why has this never been attempted?

The current zero-transparency approach seems to be insufficient.",MachineLearning
nxlzja,1623433936.0,[D] Best package in Python to manually set up a neural network without layers purely for evaluation (without back-propagation training),"I have some decent experience using neural networks, and for everything else before this I have gotten away with just coding up the neural network directly or a script that creates a NN based on some inputs. I'm about to start working on something that steps up the complexity, so I feel like I should definitely leverage one of the big ML tools in Python to do the heavy lifting.

Everything I see online about Keras, Tensorflow, and Pytorch all involve creating layers of a NN and using those tools do to the training, which is not very helpful to me. I'm looking to get use out of a tool where I can specify which nodes are connected, the exact weight values, and just tell it to evaluate the network based on my inputs to get the output node values. I can't use any standard layer creation methods since there is no simple geometry for the connections between the nodes in the networks.

So I guess my question is: what Python ML tool makes doing this the easiest?

Bonus if the tool can handle time recurrent neural network evaluation in addition to just forward propagation.",MachineLearning
nxkuvn,1623431014.0,[D] What is actually the state of the art in text to speech?,"Tacotron2 was released over 3 years ago and to this day is still used as the de facto state-of-the-art baseline against which every modern paper compares their proposed method to.   And while it showed human parity MOS scores on very monotone and almost robotic internal Google dataset, it isn't able to achieve these levels of realism on more expressive, non-professionally recorded datasets.  So what is the actual state of the art on this front?  I'm assuming it's still not Tacotron2, because frankly, training Tacotron2 on LibriTTS has given terrible results for me.  And I'd also assume researchers use Tacotron2 as a baseline because it's easy to compare against, not because it's actually the best performing.  So, can any TTS researcher catch me up on the field -- what approach actually yields the most realistic speech on real world data?",MachineLearning
nxknop,1623430504.0,"[D] Offline Policy Evaluation: Run fewer, better A/B tests","Does anyone here use offline policy evaluation at their company? Very interested in learning about real use cases for it and how well it performs at predicting A/B test results.

[https://edoconti.medium.com/offline-policy-evaluation-run-fewer-better-a-b-tests-60ce8f93fa15](https://edoconti.medium.com/offline-policy-evaluation-run-fewer-better-a-b-tests-60ce8f93fa15)",MachineLearning
nxkmmm,1623430424.0,"[N] Wu Dao 2.0 - a new 1.75 trillion parameter multi-modal Mixture of Experts model from China's BAAI lab. With 10x the parameters of GPT-3, it reportedly achieves SOTA on a number of benchmarks across several domains","This is a link to the least politicized article I could find on the topic: [https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484](https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484)

China's Beijing Artificial Intelligence Lab released a statement this past week about their Wu-Dao 2.0 model. I haven't been able to find any demos or examples, but from the handful of articles I've seen it's apparently everything you'd expect from a model that size.",MachineLearning
nxkf2z,1623429870.0,[D] Have machine learning conferences become obsolete?,"With collusion rings, poor reviewership, and sparse if not empty poster sessions, what is the point of a conference? Especially an online one?

The main proponents that still support conferences seem to be the select few that run them and have their reputation staked into them. I have learned more, seen better feedback and had more networking opportunities from Twitter, Arxiv, Discord, Reddit, and other online networks.

So, what's the purpose of a conference these days? Extra lines on a CV, jobs, promotions, recruiting, $. Now it becomes pretty obvious why there are collusion rings, bad reviewers, low-effort, etc.

References and more reading:

* https://cacm.acm.org/magazines/2021/6/252840-collusion-rings-threaten-the-integrity-of-computer-science-research/fulltext#FNA
* https://jacobbuckman.com/2021-05-29-please-commit-more-blatant-academic-fraud/
* https://www.youtube.com/watch?v=bw1kiLMQFKU
* https://www.reddit.com/r/MachineLearning/comments/nxbcl9/d_collusion_rings_noncommittal_weak_rejects_and/",MachineLearning
nxjqvb,1623428136.0,[D] Preventing index collapse in VQ-VAE,"I keep experiencing index collapse wile trying to train a VQ-VAE on raw audio. More often than not the model just converges on picking one, or just a small subset of the codes. What are the ways to prevent this? I was thinking of using something like batch norm but my batch size was too small.",MachineLearning
nxjaae,1623426961.0,[D] Paper / study request: are most of ML/DS use-cases easy?,"We all know the data science pyramid of needs, where deep learning sits on top of classical / simple ML.   I've heard a lot that most of ML/DS use-cases are easy. Also, this fits my intuition. For example, I feel that the old resnet is the way to go in many computer vision tasks, not ViT or other SOTA / close to SOTA architectures. I've talked with other DS/ML consultants which think the same (they often plug in some Lasso/Ridge regression and they are done). Is there any data / arxiv paper / market study to back this up?

I know there is a problem with how we define ""easy"" and even with what we define as a project / use-case, but I expect to be a study regarding this

Anyway, do you think most of the  ML/DS use-cases are easy or not?",MachineLearning
nxikvw,1623425103.0,[R] Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL,"A research team from McGill University, Université de Montréal, DeepMind and Mila presents an end-to-end, model-based deep reinforcement learning (RL) agent that dynamically attends to relevant parts of its environments to facilitate out-of-distribution (OOD) and systematic generalization.

Here is a quick read: [Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL.](https://syncedreview.com/2021/06/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-39/)

The paper *A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning* is on [arXiv](https://arxiv.org/abs/2106.02097).",MachineLearning
nxfw8t,1623417825.0,[D] Paper explained - Decision Transformer: Reinforcement Learning via Sequence Modeling (DecisionTransformer) by Lili Chen et al.,"Transformers are everywhere, so why not add them to reinforcement learning (RL) as well? Yeah, that's right, the researchers at UC Berkley just did that. They approach RL as a sequence modeling problem and use an autoregressive transformer to predict the next optimal action given the previous states, actions, and rewards so that it maximizes some reward function. Perhaps surprisingly, this simple Decision Transformer approach achieves state-of-the-art performance on Atari, OpenAI Gym, Key-to-Door tasks.

Check out the [full paper digest](https://t.me/casual_gan/50) to learn about how offline RL can be turned into a sequence modeling problem, represent simulation trajectories for the Transformer to learn from, and, most importantly, apply Transformers to ace offline RL tasks!

Meanwhile, check out this paper poster presented by [Casual GAN Papers](https://t.me/casual_gan):

[Decision Transformer](https://preview.redd.it/jbwtg0031n471.png?width=759&format=png&auto=webp&s=010b79b8a7da054421dea9ef5394360443af4d1d)

\[[Full Explanation Post](https://t.me/casual_gan/50)\] \[[Arxiv](https://arxiv.org/pdf/2106.01345.pdf)\] \[[Project page](https://github.com/kzl/decision-transformer)\]

More recent popular computer vision paper breakdowns:

>[DALL-E](https://t.me/casual_gan/48)
[VQGAN](https://t.me/casual_gan/46)
[DINO](https://t.me/casual_gan/40)",MachineLearning
nxey6g,1623414936.0,[D] Why Normalization in initial layer of discriminator leads to unstable GANs?,"

According to the DCGAN [paper](https://arxiv.org/pdf/1511.06434.pdf):

"" Directly applying batchnorm to all layers however, resulted in sample oscillation and model instability. This was avoided by not applying batchnorm to the generator output layer and the discriminator input layer""

I have observed the same thing when I use other normalization layers like InstanceNorm or LayerNorm but not able to understand why that could be the case. Why is it that using a normalization layer in the initial layers of discriminator leads to unstable GAN training? I hope I can get an intuitive answer! Thanks!",MachineLearning
nxe2jm,1623412117.0,[D] ICCV Reviews are out,What did Reviewer 2 did do this time?,MachineLearning
nxd7jd,1623409131.0,[D] Dataset for directed graphs classification,"I want to evaluate some algorithms for the directed graph classification task. Therefore, I'm looking for directed graphs data sets (preferably without node or edge features) as benchmarks. Do you have any ideas for datasets that could fit?",MachineLearning
nxcbge,1623405653.0,[Discussion] XGBoost is the way.,"Came across this paper [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf) where the authors show XGBoost ( or an ensemble of XGBoost/NN) outperforms DNNs when it comes to traditional tabular data.

Would love to hear your views or professional anecdotes which may or may not agree with this.",MachineLearning
nxbcl9,1623401736.0,"[D] Collusion rings, noncommittal weak rejects and some paranoia","Hello everyone, I will start by saying that I am a fourth-year doctoral student in a small lab within a not-so-famous university, who, thus far sent about 10 papers to various ML/CV conferences and had peers in my lab who also sent bunch of papers which I had the opportunity to have a glance to the reviews they received. I know there are many people in this community who have more experience than I do, I am creating this post to have a discussion on the topic of academic reviewing process and collusion rings.

The topics of academic fraud and collusion rings recently gained traction with the blog post of Jacob Buckman \[1\] and the follow-up video of Yannic Kilcher ([u/ykilcher](https://www.reddit.com/user/ykilcher/)) \[2\] (many thanks to both researchers for talking about this topic).

\[1\] [https://jacobbuckman.com/2021-05-29-please-commit-more-blatant-academic-fraud/](https://jacobbuckman.com/2021-05-29-please-commit-more-blatant-academic-fraud/)

\[2\] [https://www.youtube.com/watch?v=bw1kiLMQFKU](https://www.youtube.com/watch?v=bw1kiLMQFKU)

&#x200B;

According to the professors in my lab, in recent years, they have seen a dramatic increase in the number of low-quality reviews with noncommittal weak rejects. These rejects often do not provide enough feedback to address in the rebuttal process and have conflicting outcomes compared to their reviews as well as other reviewer(s) who provide decent, well-written feedback.

Following up on the spirit of the aforementioned media, I wanted to share the experience I and fellow doctoral students in my lab had with the reviews.

&#x200B;

Two examples from the reviews from recent papers we submitted:

\--------------------------------------------------------

**Reviewer A:**

(Strengths of the submission): The investigation of this paper is valuable and interesting.

(Weaknesses of the submission): The article uses XYZ method, I don't think this method is useful for this type of analysis. The article is unstructured and hard to follow.

Outcome -> Weak reject

**Reviewer B:**

(Strengths of the submission): This work is interesting, which reveals the shortcomings of the methods used in ABC field.

(Weaknesses of the submission): In my opinion, contribution is maybe not enough. I suggest authors to use the methods in these papers \[paper1, paper2, paper3\].

\[paper1, paper2, paper3\] -> Three papers from the same university of which two of them were written by the same person and he is the author of the third paper.

Outcome -> Weak reject

\--------------------------------------------------------

Noncommittal weak rejects like these do not provide nearly enough feedback to make any improvement on the paper. But this kind of reviews ensures that the submission will be rejected, since the number of papers being submitted is increasing every year and ACs are under pressure to reject as many papers as easily as possible.

&#x200B;

I recently had a pleasure of having a conversation on this topic with another senior professor (who is also working on computer vision but another subfield). He said that I should try to get acquainted with researchers from a certain country and make sure to have a couple of them as co-author in my papers to improve my chances of acceptance. When I told him that the reviews are double blind and that having them as a co-author wouldn't matter, he confidently said that the double blind is just a facade.

&#x200B;

We are working in a niche field of computer vision with not many participants compared to other subfields. I am starting to have deranged thoughts, thinking that we are being somewhat unlucky with the reviewers and that our papers are being rejected by people who are part of a group that try to reject papers coming from outside their circle in a noncommittal way, so that these reviews do not raise any suspicion.

&#x200B;

I hear left and right that collusion rings are far more rampant than what people believe they are. Am I being paranoid? What is your experience with the reviews in recent years? Please, do share.",MachineLearning
nxba00,1623401424.0,[D] Generative Adversarial Network for tabular panel data,"I want to generate data using GAN, but my data is the panel, with time and unit dimensions.

Does it exist gans for this kind of tabular data?",MachineLearning
nxb3m1,1623400697.0,[R] A Neural Tangent Kernel Perspective of GANs,[https://arxiv.org/abs/2106.05566](https://arxiv.org/abs/2106.05566),MachineLearning
nx43y7,1623375178.0,[P] PaddleHub: An awesome and easy-to-use pre-trained models toolkit,"Hi, all,

I am glad to share that my team are working on an open source repository PaddleHub , which provides 300+ deep learning pre-trained models in practical. PaddleHub aims to provide developers with rich, high-quality, and directly usable pre-trained models.

&#x200B;

code：[https://github.com/PaddlePaddle/PaddleHub](https://github.com/PaddlePaddle/PaddleHub)

&#x200B;

**Features Set:**

* **Abundant Pre-trained Models**: 300+ pre-trained models cover the 5 major categories, including Image, Text, Audio, Video, and Industrial application. All of them are free for download and offline usage.
* **Quick Model Prediction**: model prediction can be realized through a few lines of scripts to quickly experience the model effect.
* **Model As Service**: one-line command to build deep learning model API service deployment capabilities.
* **Easy-to-use Transfer Learning**: few lines of codes to complete the transfer-learning task such as image classification and text classification based on high quality pre-trained models.
* **Cross-platform**: support Linux, Windows, MacOS and other operating systems.

&#x200B;

&#x200B;

[Some Visualization Demos](https://i.redd.it/c6wsje42ij471.gif)",MachineLearning
nx1b0e,1623366634.0,[D] Extrapolation vs Interpolation while using Statistical Models,"I have started to read more about the background of some of the popular statistical models used for predictive analytics, and I find some of this information 'troubling'. Although there is apparently no such thing as a ""universally best algorithm"" (i.e. there will be always some dataset where algorithm ""a"" performs better than algorithm ""b"", and vice versa), apparently some algorithms are inherently better at ""untangling"" complicated patterns within the data (the logic being, other algorithms are inherently incapable to capturing complex patterns, e.g. non-linear patterns) and as a result, this can impact their abilities to extrapolate and to interpolate.

&#x200B;

Here is an example I thought of: [https://imgur.com/a/4BIXMIe](https://imgur.com/a/4BIXMIe)

&#x200B;

Suppose you have a dataset with ""weight"" and ""height"" measurements of individuals, and whether they have a certain disease or not (this is a binary response variable, ""red"" no disease and ""green"" is disease). The goal of this problem is to predict whether a new individual will have the disease based only their height and weight measurements. However, little do you know, the majority of the data comes from children and only a few of the observations come from adults. As a result, most of the observations have ""low values of weight and low values of height"" (as typical in children) and only few of the observations have ""larger values of weight and larger values of height"" (as typical in adults). Thus, one could regions of the data with ""large weight and large height"" are ""underpopulated"". Naturally, one could expect that it might be more difficult to make accurate predictions for ""adults"", given that most of your data reflect information among children. But let's imagine that when we are working on this problem, we are not told which point corresponds to an adult or a child. We can just infer this information using logic, and only notice that ""large weight and large height"" are underrepresented in the data. We are only given 3 variables : height, weight and disease status.

&#x200B;

Now, the question is about choosing a statistical algorithm for this problem, given that one of the regions within the data is underpopulated.

&#x200B;

1) The first question I have : Suppose we want to make a prediction about whether a new adult (large height, large weight) has the disease or not - in the context of this problem, would this be considered as interpolation or extrapolation? And suppose we want to make a prediction about whether a new child (low weight, low height) has the disease or not - in the context of this problem, is this extrapolation or interpolation?

&#x200B;

Just using logic, based on the distribution of the available data, I would say that making a prediction for a new adult is relatively more of an extrapolation task; compared to making a prediction for a new child is more of a interpolation task. Is my logic correct?

&#x200B;

2) The second question I have is about preemptively understanding the limitations of certain algorithms when dealing with this kind of problem. I have read about some inherent problems of decision trees, such as : it can be theoretically shown that  A)  Decision Trees can not generalize to unseen data, B) Decision Trees require an exponentially large number of data points to maintain a certain level of accuracy, C) Decision Trees can only make Boolean splits in the data, further limiting their ability to make inferences beyond the data they have seen.

&#x200B;

On the other hand, algorithms such as neural networks do not require an exponentially large number of data points to maintain the same level of accuracy, and neural networks do not make Boolean splits within the data. When neural networks pass information from layer to layer, information becomes represented as a function of all variables within the data. Thus, instead of linear separations (characterized by Boolean splits), neural networks decision boundaries are able to be non-linear and capture a higher level of complexity within the data. But apparently the main advantage of non-Boolean splits, is that neural networks are able to extend the information and influence of their data to regions that are located further away. Apparently this theoretically gives neural networks to have better extrapolation abilities compared to decision trees.

&#x200B;

I tried to draw a sketch of this below: [https://imgur.com/a/kKIqpH9](https://imgur.com/a/kKIqpH9) (click the ""magnifying glass symbol"")

&#x200B;

Can someone please confirm my logic? Is this correct?

Thanks",MachineLearning
nx1asa,1623366616.0,"[P] PixLab Annotate - Online Image Annotation, Labeling and Segmentation Tool","Annotate is  A web based image annotation, labeling & segmentation tool for Machine Learning model training tasks and beyond.

https://annotate.pixlab.io/

###Features Set:

* Rectangle, Polygon, Zoom & Drag labeling tool.
* Consistent JSON output accepted by most Machine Learning frameworks.
* Optimized for instance segmentation (Mask R-CNN, etc).
* Client-side persistent storage - No data transfer involved.
* Persistent & easy label management (Create, Modify & Delete).
* Full screen display & Snapshot capture.",MachineLearning
nx0dsi,1623364052.0,[D] Why do second order methods work for ReLUs (which have 0 second derivative A.E.)?,"My question is a simple one: starting with the backprop chain rule, since the gradient of the relu is zero almost everywhere, how are there methods that are able to use second order methods with Relus?
> D^2 [Loss]/Dw^2 = D^2 [Loss]/Da^2 * D^2 [a]/Dy^2 * D^2 [y]/Dw^2 =0

Since
> D^2 [a]/Dy^2 = 0

Where y is the output of a matmul, w is the weights, and a(y) is the activation (Relu).",MachineLearning
nwxm6m,1623356890.0,[P] [R] Scaling AutoML-Driven Anomaly Detection With Luminaire,"Checkout this years Data+AI Summit talk on Scaling AutoML driven anomaly detection with Luminaire: https://databricks.com/session_na21/scaling-automl-driven-anomaly-detection-with-luminaire

Github repo: https://github.com/zillow/luminaire

Scientific Paper: https://arxiv.org/abs/2011.05047

Blog: https://medium.com/zillow-tech-hub/automatic-and-self-aware-anomaly-detection-at-zillow-using-luminaire-7addfdae4ca9",MachineLearning
nwwxba,1623355165.0,[D] Pricing of ML tools - are you paying this much?,"I'm looking at some of the tools available to help out with different verticals within ML. E.g. improving the workflow with logging ([W&B](https://wandb.ai/site/pricing), [Comet.ml](https://www.comet.ml/site/pricing/)). I've used them personally and they really are excellent. But if you're not using it privately or in a small startup, their list prices are around $200 USD / month / user. Their sales people keep saying that they're looking to solve more of the problems in ML but I'm completely uninterested in their other stuff. I've had friends in other companies go through their sales process only to be told in the end that they'd have to pay $250 USD / user / month. That seems crazy expensive, and makes a pretty big dent for our small but growing team that's yet to prove ourselves! I've seen the same thing for other products as well, e.g. data labelling. We'd have a very hard time using tools that charge per active user and month in this order of magnitude.

Are any of you in teams where you actually pay for this stuff, and if so, can you share how much you pay? Or do you use private accounts or similar?",MachineLearning
nwwnxd,1623354546.0,[R] Tabular Data: Deep Learning is Not All You Need,"Interesting Paper

A key element of AutoML systems is setting the types of models that will be used for each type of task. For classification and regression problems with tabular data, the use of tree ensemble models (like XGBoost) is usually recommended. However, several deep learning models for tabular data have recently been proposed, claiming to outperform XGBoost for some use-cases. In this paper, we explore whether these deep models should be a recommended option for tabular data, by rigorously comparing the new deep models to XGBoost on a variety of datasets. In addition to systematically comparing their accuracy, we consider the tuning and computation they require. Our study shows that XGBoost outperforms these deep models across the datasets, including datasets used in the papers that proposed the deep models. We also demonstrate that XGBoost requires much less tuning. On the positive side, we show that an ensemble of the deep models and XGBoost performs better on these datasets than XGBoost alone.

by  Ravid Shwartz-Ziv  and  Amitai Armon

&#x200B;

Linkt to Paper: [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf)",MachineLearning
nww4ir,1623353128.0,[D] Graph Neural Network fails at generalizing on unseen graph topologies,"Hi everyone!

&#x200B;

I'm using PytorchGeometric to train a graph convolutional network for regression over nodes problem (the graph models physical phenomena in the network of sensors). In the training dataset there graphs with different topologies (i.e. different edge\_index tensors), and each of which has input and label tensors, which consist of float values for each node in the graph.

The training curves look good, the loss curve is converging to a small value and there are no exploding nor vanishing gradients.

&#x200B;

There are 1000 different graph topologies in the training set and around 2000 training samples. So, when the trained model is tested on graphs whose topology occurs 2 or 3 times in the training set, the results are great, almost the same as the test sample labels for each node (the input values of nodes are different, only the topology is already seen). When the trained model is tested on graphs whose topology occurs one in the training set, the results are slightly worse.

But when the model is tested on the unseen (but similar) graph topology, the results are completely wrong.

Since the graph models physical phenomena in the network of sensors, I would expect that the GNN should be able to learn how sensor information impacts the neighboring variables, even for the unseen graphs.

I've tried going deeper into the graph and adding the convolutional layers.

&#x200B;

Did someone have a similar problem? Are there some GNN models that are better at generalizing on unseen graph topologies?

&#x200B;

Cheers!",MachineLearning
nwtwtn,1623347646.0,What are the pros and cons of a 1D versus 2D convolutional neural network in a Time series problem? [D],"I'm trying to understand from a theoretical point of view what are the pros and cons between a one-dimensional and a two-dimensional convolutional neural net for specifically for a data set of Time series features. Here we can think of things like your position over time, speed and distance and some measure of ground quality etc etc.

A 1D CNN is pretty common for time series problems and the intuition there is it's collecting a lot of localized representations of time steps by feature. Information between the features and time as well.

At first blush it would appear that 2D is better but I guess the con would be that it's potentially underweighting the localized time series within the feature versus across the feature?",MachineLearning
nwsyss,1623345273.0,[D] Regularizing a loss function,"While training a neural network, you find out that there are some examples that are hard for it to learn while some are easy to learn. How would you work on modifying the loss function so that the learned weights give more importance to the harder examples instead of giving all the importance to easier examples? Would L2 regularization be enough or is it possible to write a custom loss function for that particular dataset?",MachineLearning
nwqx5a,1623340150.0,[N] Facebook to launch NetHack competition at NeurIPS 2021 AI,"Facebook has been interested in NetHack for some time now: https://arxiv.org/abs/2006.13760

For a simpler explanation from Facebook: https://ai.facebook.com/blog/nethack-learning-environment-to-advance-deep-reinforcement-learning/

And now they're announced, ""This year as part of a NeurIPS 2021 competition, we are proud to launch the NetHack Challenge—the most accessible grand challenge for AI research—with our partner and co-organizer AIcrowd."" https://ai.facebook.com/blog/launching-the-nethack-challenge-at-neurips-2021/",MachineLearning
nwqnqx,1623339484.0,[R] IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design,"An IEEE team provides a comprehensive overview of the bottom-up and top-down design approaches toward neuromorphic intelligence, highlighting the different levels of granularity present in existing silicon implementations and assessing the benefits of the different circuit design styles in neural processing systems.

Here is a quick read: [IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design.](https://syncedreview.com/2021/06/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-38/)

The paper *Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence* is on [arXiv](https://arxiv.org/abs/2106.01288).",MachineLearning
nwqc8o,1623338689.0,[D] What is currently the best theoretical book about Deep Learning?,"I'm looking for the book about Deep Learning. Most of them (Deep Learning for Coders, Deep Learning with Python etc.) focus on practical approach, while I'd love to dig a little bit deeper into theory. One way is probably reading pivotal papers, but I still find it a bit intimidating. Therefore, I'd love to find a book with good, but more theoretical explanations. I heard good opinions about Deep Learning by Ian Goodfellow et al., but I wonder if it's not a bit outdated since the field is changing rapidly and the book already is 5 years old. How much will I miss while reading this one? Is there a better option currently?",MachineLearning
nwob3j,1623333494.0,[D] Who said AI Art has no soul? A summed up history of progress in the AI art world.,"&#x200B;

[Medium - AI Art](https://rednalabs.medium.com/the-real-state-of-the-art-how-artificial-intelligence-is-redefining-nfts-and-the-creation-of-ba25c33c8af0)

When i started experimenting with A.I. art back in 2018, the compute power was barely enough to generate blobs. It wasn't too different for the art stars of those days who produced fairly appalling aesthetics ([Edmond de Belamy](https://en.wikipedia.org/wiki/Edmond_de_Belamy) anyone?). The issue with this is that it stuck in the art commentators mind as gimmicky and far from the real thing, the art created by trained artists. But we had to start somewhere.

A lot of water has passed under the bridge since then and today it is difficult to tell the origin of an AI work of art. Was it created by a human, was it created by a machine?

Next step in this movement is the merging of A.I. | Art | Blockchain and the delivery of A.I. art as NFTs.

One day my real hope is that (a few) human artists will draw what the A.I. has helped them imagine, it is an amazing tool to enhance imagination.

The medium article illustrates those aspirations.",MachineLearning
nwlw64,1623326561.0,[D] Similarity of decision tree and bagging decision tree,"Most of peoples know the advantages of decision tree and bagging decision tree/ random forest.

1)But what is the advantages of decision tree that bagging decision tree/rf still retains after implementation?
2)What is the similarity in terms of characteristics between the bagging/rf and it base classifiers?",MachineLearning
nwkrj6,1623322821.0,"[R] Using machine learning to decipher the regulatory code of gene expression, a review","Excited to share that our review is out for those interested to learn more about the regulatory code of gene expression and how its modelled! [https://doi.org/10.3389/fmolb.2021.673363](https://doi.org/10.3389/fmolb.2021.673363)

We (i) review the latest developments that apply classical ML or deep learning to quantify molecular phenotypes and decode the *cis*\-regulatory grammar,

(ii) list published studies and results in tables,

(iii)  build from the ground up, first focusing on the initiating protein-DNA interactions, then specific coding and non-coding regions, and finally on advances that combine multiple parts of the gene and mRNA regulatory structures, achieving unprecedented performance, and

(iv) provide a quantitative view of gene expression regulation from nucleotide sequence by putting a number on the main processes in the central dogma of molecular biology.",MachineLearning
nwka1t,1623321014.0,[P] [D] Recognizing the brand of an advertisement based on advert video,"I am enrolled in a Deep Learning course for my Masters Degree and my semester project is to design a model that takes a video file (more appropriately, a pre-processed input data captured from a given video file) and outputs the brand in the advert in the video

For example, ideally, by feeding a video of a BMW commercial, the model outputs that the video was an advertisement for a BMW
Or feeding a video of Dove soap commercial, it predicts that the advert was a Dove soap advertisement.

The important thing is that this is not a classification problem. The model is expected to recognize what brand the advert was for even if it has never been trained on it, just like a human recognizes what the brand in an advert is even if he or she has never watched any advertisement of that brand before.

I am sort of blank as to what approach I could be using. Any help is appreciated!",MachineLearning
nwk7ae,1623320696.0,[D] finding good sources of data,"Hi

I am writing a university-level course on ML and need to find data for exercises. What are your favourite places to get data?

  of the datasets that are available to the public which are the lines that you think are the most interesting and why?",MachineLearning
nwjxpv,1623319633.0,[R] ProoD: Provably Robust Detection of Out-of-distribution Data (almost) for free,"https://arxiv.org/abs/2106.04260

Abstract:
When applying machine learning in safety-critical systems, a reliable assessment of the uncertainy of a classifier is required. However, deep neural networks are known to produce highly overconfident predictions on out-of-distribution (OOD) data and even if trained to be non-confident on OOD data one can still adversarially manipulate OOD data so that the classifer again assigns high confidence to the manipulated samples. In this paper we propose a novel method where from first principles we combine a certifiable OOD detector with a standard classifier into an OOD aware classifier. In this way we achieve the best of two worlds: certifiably adversarially robust OOD detection, even for OOD samples close to the in-distribution, without loss in prediction accuracy and close to state-of-the-art OOD detection performance for non-manipulated OOD data. Moreover, due to the particular construction our classifier provably avoids the asymptotic overconfidence problem of standard neural networks.

Code: https://github.com/AlexMeinke/Provable-OOD-Detection",MachineLearning
nwiyki,1623315553.0,[D] Deploy DL on ECS for multiple requests,"I am trying to run docker containers on ECS, the containers have DL models with flask. With 5-10 requests i am getting response within my acceptable timeframe.
But if there are 100s of requests aws i taking minutes to scale new instances and meanwhile those requests are being forwarded to the already running tasks. Due to this tasks are failing bcoz of memory error.
How do i scale ECS correctly so that every request is processed. Where to route requests untill new tasks are started ?",MachineLearning
nwhsrz,1623310536.0,[N] [R] Popup Online Conference : Machine Learning for Quantum,"This is quick post for whom it might be of interest. There will be an online conference about machine learning for quantum : [http://mlqx.quantumexcellence.org/](http://mlqx.quantumexcellence.org/) (July 5-9, 2021)


There will be talks from different experts from all around the worlds in the fields of quantum computing, machine learning, math, chemistry, etc...

There are 4 main topics for poster presentations :

* Machine Learning for chemistry and materials discovery
* Machine Learning for the development of quantum computers
* Machine Learning and quantum for industrial applications
* Quantum learning algorithms

&#x200B;

PS : Please remove this if it is against the rules, I thought some folks around here would be interested in registering, abstract submission is not mandatory, but it is welcome if you want to present your research.",MachineLearning
nwh6xp,1623307988.0,[D] Experience with Google's VertexAI?,"So I benchmarked an ML platform I created with some friends ([Nyckel.com](https://nyckel.com/)) against Googles ""Vertex AI"" (formerly known as Google AutoML). I was honestly expecting them to blow us out of the water but to my surprise, Google left the room and came back 5 hours later with an inferior model to what Nyckel returned in 60 seconds. Any ideas what they are doing during that time? My best guess is some sort of Network Architecture Search, but in that case I'd expect them to come back with a killer model. This particular test was training text sentiment classifier on a [public datasets](https://ai.stanford.edu/~amaas/data/sentiment/).

I also found other parts of their service excruciatingly slow: uploading and parsing a .csv file with 5000 lines seriously took them 5 minutes. Has anyone else had bad (or good?) experiences with Google's Vertex AI?

Here is a [blogpost](https://medium.com/nyckelai/automl-benchmark-nyckel-vs-google-vs-huggingface-1cc0649ef27d?source=friends_link&sk=d57724e5322ee24dccd46bbd0e927a29) I wrote that shares the results.",MachineLearning
nweokd,1623298244.0,Neural networks with memory [D] [R] [P],"Hi all,

I am a beginner in ML. I have previously used feedforward NN to for regression and it works great. I would like to know if there are neural networks that retain memory. For example, I trained NN using data 1 and obtained model 1. I have another set new data called data 2. Is it possible to use model 1 and train using data 2 and obtain new model 2 which remembers data 1 and data 2? In some sense to save time.
Currently I have been stacking together data 1 and 2 and training using feedforward NN. However, I get data in multiple batches and stacking the all the data for n batches would be really large and would be computationally expensive. Looking at alternative that train the NN on the go. Thanks a lot in advance.",MachineLearning
nwclj1,1623291338.0,[R] CoAtNet: Marrying Convolution and Attention for All Data Sizes,"https://arxiv.org/abs/2106.04803

Abstract:

Transformers have attracted increasing interests in computer vision, but they still fall behind state-of-the-art convolutional networks. In this work, we show that while Transformers tend to have larger model capacity, their generalization can be worse than convolutional networks due to the lack of the right inductive bias. To effectively combine the strengths from both architectures, we present CoAtNets(pronounced ""coat"" nets), a family of hybrid models built from two key insights:(1) depthwise Convolution and self-Attention can be naturally unified via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that our CoAtNets achieve state-of-the-art performance under different resource constraints across various datasets. For example, CoAtNet achieves 86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT data, outperforming prior arts of both convolutional networks and Transformers. Notably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet achieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images from JFT while using 23x less data.",MachineLearning
nwbrc2,1623288710.0,[D]Dataset for Spelling Correction,"What would be a good text dataset to train a Neural network for error detection task.

I am currently planning to use the texts from Blog Authorship Corpus. However, its from 2004 and have a fear it might be a bit outdated. Any other good recent datasets.

I am currently trying to avoid wikipedia dataset as it doesn't contain many first person samples.",MachineLearning
nwb7ed,1623286959.0,[D] Handwriting-Generator: Use Machine Learning to generate handwriting from example images in browser!,"[https://www.handwriting-generator.com/](https://www.handwriting-generator.com/)

I'm not the one who made this, but it's fascinating how well it works--my handwriting was imitated quite well. Anyone have a clue how it works (especially because it is offline handwriting analysis)? They also had some interesting animation and export options.

&#x200B;

&#x200B;",MachineLearning
nwart2,1623285619.0,[D] Is there accuracy drop when converting models from Pytorch to TF through ONNX?,I am curious if any accuracy drop happens when converting models to different framework using ONNX. What is it like from your experineces?,MachineLearning
nw9a3x,1623281022.0,[D] The 2021 Gradient Prize for Overviews and Op-Eds about AI,"TLDR: Submit an article to [The Gradient](https://thegradient.pub/) from now until September 1, 2021 for a chance to win a $500  prize. Full details [here](https://thegradient.pub/2021-gradient-prize/).

In case you don't know The Gradient is a digital magazine covering research and trends in AI and ML. We are a non-profit and volunteer-run effort run by researchers in the AI community (we basically don't make any money), but have recently received a grant that enabled this initiative. While it's not a huge prize fund, we hope it provides an incentive for anyone who has considered writing with us before.

Happy to answer any questions! But hopefully most should be addressed [here](https://thegradient.pub/2021-gradient-prize/).",MachineLearning
nw7jo2,1623275989.0,[Discussion] Correlated Outputs from Deep Learning Mutli-Output Regression,"I'm dealing with a problem at work right now that involves taking a non-linear signal generated from 5 continuous variables and training a Denoising Autoencoder to reconstruct the signal. Signals were generated by **randomly scanning over the vector space.** All variables are normalized between 0 and 1 and their histograms are flat across this space.

The main goal is to ensure that the latent representation of any signal is equal to the 5D vector that generated it. I enforce this constraint through a simple weighted sum of two MSE loss functions:

*loss = alpha \* mse(5D\_label, latent\_embedding) + (1 - alpha) \* mse(signal, reconstructed\_signal)*

I am able to obtain great reconstructed signals, but I find that I *always* obtain some type of correlation between the latent neurons (as seen in the correlation matrix attached). Furthermore, I find that the same feature always becomes mis-represented (Scatter plot attached shows each feature plotted against its embedding along with the R2 value in the legend)

Does anyone have any intuition as to why this would be occurring? I've even tried overfitting the model to absolute hell and I cannot for the life of me get close to perfect predictions. I've also tried using a simple (small) dense NN for this and still no luck. Any insight would be insanely appreciated!

https://preview.redd.it/kjjcysvpbb471.png?width=864&format=png&auto=webp&s=81f8a8529c16791662233be510b54901d0a46b49

https://preview.redd.it/9y3sqo5obb471.png?width=580&format=png&auto=webp&s=9653fa1b1dc48ea0b28af7a8ec7b5e05d51352b6",MachineLearning
nw623s,1623271980.0,[R] Cascaded Diffusion Models for High Fidelity Image Generation,"paper: [https://cascaded-diffusion.github.io/assets/cascaded\_diffusion.pdf](https://cascaded-diffusion.github.io/assets/cascaded_diffusion.pdf)

project page: [https://cascaded-diffusion.github.io/](https://cascaded-diffusion.github.io/)

twitter thread: https://twitter.com/hojonathanho/status/1402717929406275587?s=20",MachineLearning
nw2ajj,1623262091.0,[D] Temporal Network Graphs,"Has anyone ever worked with ""temporal network graphs"" before? Basically, these seem to be graphs in which :

A) new nodes can appear and old nodes can disappear as time progresses

B) edges between nodes can appear/disappear as time progresses

These seem to be newer methodologies. Has anyone tried to perform algorithms like community detection, node classification or edge prediction on temporal graphs?

I was trying to find more examples of this kind of stuff and all I was able to find was the Twitter github page (https://github.com/twitter-research/tgn) and this one general blog on temporal graphs with R:

https://programminghistorian.org/en/lessons/temporal-network-analysis-with-r

And

https://rstudio-pubs-static.s3.amazonaws.com/373665_283622728cdb4116af38768eea28473e.html

Can anyone please recommend anything else?

Thanks",MachineLearning
nvzib3,1623254896.0,[D] What Really Happened When Google Ousted Timnit Gebru,"[https://www.wired.com/story/google-timnit-gebru-ai-what-really-happened/](https://www.wired.com/story/google-timnit-gebru-ai-what-really-happened/)

I think this is a well-written article about the Timnit Gebru firing.",MachineLearning
nvxj88,1623249645.0,[R] Simulated Adversarial Testing of Face Recognition Models,[https://arxiv.org/abs/2106.04569](https://arxiv.org/abs/2106.04569),MachineLearning
nvw9xy,1623246230.0,"[D] What is ""breakthrough AI"" for self-driving cars?","I'm writing a story about Waabi, a self-driving car company that has just come out of stealth and raised \~$80M in funding. I'm trying to make sense of the technology they're using. Since it's proprietary, they didn't reveal much. The company claims to have a breakthrough approach to AI, which the [press release](https://www.globenewswire.com/news-release/2021/06/08/2243365/0/en/Waabi-launches-to-build-a-pathway-to-commercially-viable-scalable-autonomous-driving.html) describes as such \[emphasis mine\]:

*The company’s breakthrough, AI-first approach, developed by a team of world leading technologists, leverages* ***deep learning, probabilistic inference and complex optimization*** *to create software that is* ***end-to-end trainable, interpretable and capable of very complex reasoning****.*

And here's what the company's CEO told [*The Verge*](https://www.theverge.com/2021/6/8/22522824/waabi-raquel-urtasun-autonomous-vehicle-startup-stealth-funding):

*Urtasun and her team are also developing a new algorithm that will serve as the foundation for the “brain” of the self-driving car, which* ***helps with motion planning and predicting what other vehicles on the road will do so the AV can react accordingly****.* 

And this is what she told [TechCrunch](https://techcrunch.com/2021/06/08/ai-pioneer-raquel-urtasun-launches-self-driving-vehicle-startup-with-backing-from-khosla-uber-and-aurora/):

*Urtasun says she solved these lingering problems around deep nets by combining them with probabilistic inference and complex optimization, which she describes as a family of algorithms.* ***When combined, the developer can trace back the decision process of the AI system and incorporate prior knowledge so they don’t have to teach the AI system everything from scratch****.*

Now, I know that a lot of the stuff put into press releases and told to media by company execs is vague statements meant to do publicity. And there really isn't much more about the AI technology they're using elsewhere. But the company has raised an insane amount of money while the SDC industry is seeing a downturn, and their backers include Geoffrey Hinton, Fei-Fei Li, and Pieter Abbeel.

Does anyone here know what the combination of ""***deep learning, probabilistic inference and complex optimization""*** can do that previous ML systems used in SDCs can't?",MachineLearning
nvva7j,1623243384.0,[D] Is Beta-VAE regularization equivalent to using a Gaussian prior with variance smaller than 1?,"Hello everyone!

The Beta-VAE model offers a regularization over the -*𝛽*  KL(q(z|x)||p(z)) term of the ELBO in VAE formulation. Increasing this term forces some latent units to be distributed as unit Gaussians (given that p(z) is standard Gaussian). I wonder, is it possible to acquire the same regularization by only tuning the prior such as having a   Gaussian with smaller std such as 0.01?


edit: For the original VAE part, I corrected the distribution for the prior as standard Gaussian.",MachineLearning
nvsu3w,1623235661.0,[P] Help with an optimization algorithm for StyleGAN2 interpolation,"I would like to interpolate two images using StyleGAN2-ADA-PyTorch from NVLabs (https://github.com/NVlabs/stylegan2-ada-pytorch). For the sake of simplicity, it can be said that with two images of different persons I want to create a third image, depicting a third person, with a body from the first image, and a head from the second. I also have corresponding w-vectors for the two source images ready at hand.

    # G is a generative model in line with StyleGAN2, trained to output 512x512 images.
    # Latents shape is [1, 16, 512]
    G = G.eval().requires_grad_(False).to(device) # type: ignore
    num_ws = G.mapping.num_ws # 16
    w_dim = G.mapping.w_dim # 512

    # Segmentation network is used to extract important parts from images
    segmentation_dnn = segmentation_dnn.to(device)
    # Source images are represented as latent vectors. I use G to generate actual images:
    image_body = image_from_output(G.synthesis(w_body, noise_mode='const'))
    image_head = image_from_output(G.synthesis(w_head, noise_mode='const'))

    # Custom function is applied to source images to create masked images.
    # In masked images, only head or body is present (and the rest is filled with white)
    image_body_masked = apply_segmentation_mask(image_body, segmentation_dnn, select='body')
    image_head_masked = apply_segmentation_mask(image_head, segmentation_dnn, select='head')

In order to compare similarity of any two images, I use VGGLos:

    # VGG16 is used as a feature extractor to evaluate image similarity
    url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'
    with dnnlib.util.open_url(url) as f:
        vgg16 = torch.jit.load(f).eval().to(device)

    class VGGLoss(nn.Module):
        def __init__(self, device, vgg):
            super().__init__()

            for param in self.parameters():
                param.requires_grad = False

            self.vgg = vgg
            self.criterion = nn.L1Loss().to(device)

        def forward(self, source, target):
            loss = 0
            source_features = self.vgg(source, resize_images=False, return_lpips=True)
            target_features = self.vgg(target, resize_images=False, return_lpips=True)
            loss += self.criterion(source_features, target_features)

            return loss

    vgg_loss = VGGLoss(device, vgg=vgg16)

Now, I want to interpolate image_body and image_head, creating image_target. To do this, I need to find latent representation of image_target in the latent space of StyleGAN2 Crudely, I can optimize for a certain interpolation coefficient query_opt to partially include latents from image_body and image_head: w_target = w_body + (query_opt * (w_head - w_person))

    query_opt = torch.randn([1, num_ws, 1], dtype=torch.float32, device=device, requires_grad=True)
    optimizer = torch.optim.Adam(query_opt, betas=(0.9, 0.999), lr=initial_learning_rate)

    w_out = []
    for step in num_steps:
        # Learning rate schedule.
        t = step / num_steps
        lr_ramp = min(1.0, (1.0 - t) / lr_rampdown_length)
        lr_ramp = 0.5 - 0.5 * np.cos(lr_ramp * np.pi)
        lr_ramp = lr_ramp * min(1.0, t / lr_rampup_length)
        lr = initial_learning_rate * lr_ramp
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr

        # Synth image from w_target using query_opt.
        # This is an important step, and I think that my math is messed up here

        w_target = w_body + (query_opt * (w_head - w_person))
        image_target = image_from_output(G.synthesis(w_target, noise_mode='const'))
        image_target_body_masked = apply_segmentation_mask(image_target, segmentation_dnn, select='body')
        image_target_head_masked = apply_segmentation_mask(image_target, segmentation_dnn, select='head')
        loss = vgg_loss(image_body_masked, image_target_body_masked) + vgg_loss(image_head_masked, image_target_head_masked)

        # Step
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()
        logprint(f'step {step+1:>4d}/{num_steps}: loss {float(loss):<5.2f}')

        # Save current w_target
        w_out[step] = w_target.detach()

I can't figure out how to make my optimizer actually target query_opt in such a way that combined VGGLoss is actually optimized for. I must be missing something in my PyTorch code, or maybe even in the main interpolation formula.",MachineLearning
nvsej0,1623234009.0,[D] Has anyone tried combining self-supervised learning with active learning,"When talking to ML engineers using active learning we often heard that they had issues with the active learning queries selecting many similar examples. For example, a cat and dog classifier might have low confidence with the classification of small dogs such as Chihuahuas. Doing active learning at this stage only with model predictions might result in a query of many Chihuahuas, essentially oversampling this class. Since we were already working on self-supervised learning (see our [open-source repository lightly](https://github.com/lightly-ai/lightly)) we wanted to see whether features learned from recent self-supervised models could help.

We did some early tests and the results look quite promising. The model predictions can be used to find images where the model is uncertain the embeddings can be used to diversify the queried images.

We wrote two tutorials summarising this workflow:
- [Active learning using detectron2](https://www.lightly.ai/post/active-learning-using-detectron2)
- [Nvidia TLT active learning tutorial](https://www.lightly.ai/post/active-learning-with-nvidia-tlt)

We would love to hear your thoughts and whether anyone is working on something similar.",MachineLearning
nvs3sd,1623232865.0,[D] Key Computer Vision Trends in 2021,"Hi data scientists, I wrote an brief article based on a talk about key computer vision trends in 2021 given by Sayak Paul, who's an ML engineer.

What trends do you think are missed out? Let me know in the comments. Thank you!

Article: [https://medium.com/bitgrit-data-science-publication/5-computer-vision-trends-for-2021-96fd18d5596c](https://medium.com/bitgrit-data-science-publication/5-computer-vision-trends-for-2021-96fd18d5596c)",MachineLearning
nvrzn4,1623232422.0,[N] Improvement on model's inference from DeepSpeed team. [D] How is Jax compared?,"Great  work again from the DeepSpeed team on model optimisation, now not just during training but also inference step.

1. Multi-GPU inference with DeepSpeed for large-scale Transformer models
2. Compressed training with Progressive Layer Dropping: 2.5x faster training, no accuracy loss
3. 1-bit LAMB: 4.6x communication volume reduction and up to 2.8x end-to-end speedup

[https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/](https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/)

&#x200B;

I was wondering how much of all the DeepSpeed's gain in optimisation can be done automatically in Jax's \`pmap\` and \`xmap\`? Would a ""DeepSpeed for Jax"" project even make sense?",MachineLearning
nvr0v0,1623228436.0,[d] Inspecting Neural Networks with Canonical Correlation Analysis (CKA/SVCCA Video),"Canonical Correlation Analysis is one of the methods used to explore deep neural networks. Methods like CKA and SVCCA reveal to us insights into how a neural network processes its inputs. This is often done by using CKA and SVCCA as a similarity measure for different activation matrices. In this video, we look at a number of papers that compare different neural networks together. We also look at papers that compare the representations of the various layers of a neural network.

[https://www.youtube.com/watch?v=u7Dvb\_a1D-0](https://www.youtube.com/watch?v=u7Dvb_a1D-0)

&#x200B;

Papers covered:


SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability
[https://arxiv.org/pdf/1706.05806.pdf](https://arxiv.org/pdf/1706.05806.pdf)

Understanding Learning Dynamics Of Language Models with SVCCA
[https://arxiv.org/pdf/1811.00225.pdf](https://arxiv.org/pdf/1811.00225.pdf)

Insights on representational similarity in neural networks with canonical correlation
[https://arxiv.org/pdf/1806.05759.pdf](https://arxiv.org/pdf/1806.05759.pdf)

BERT is Not an Interlingua and the Bias of Tokenization
[https://www.aclweb.org/anthology/D19-6106.pdf](https://www.aclweb.org/anthology/D19-6106.pdf)

Similarity of Neural Network Representations Revisited
[http://proceedings.mlr.press/v97/kornblith19a/kornblith19a.pdf](http://proceedings.mlr.press/v97/kornblith19a/kornblith19a.pdf)

Similarity Analysis of Contextual Word Representation Models
[https://arxiv.org/pdf/2005.01172.pdf](https://arxiv.org/pdf/2005.01172.pdf)

Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth
[https://arxiv.org/pdf/2010.15327.pdf](https://arxiv.org/pdf/2010.15327.pdf)",MachineLearning
nvqdrv,1623225719.0,[Discussion] Does anyone have a use-case specific for the Airlines industry that can be used to learn ML,"Examples:

1. Dynamic Pricing for Airfare
2. Virtual Travel Assistant
3. Recommendation Engine for Travel Shopping
4. Disruption Management

What else can be a good use case? And where can we find training data?",MachineLearning
nvmzes,1623212184.0,[D] ACM SIGGRAPH on Discord / SIGGRAPH on Discord,"Hello all,

I'm trying to find the channels on Discord in which members of SIGGRAPH post topics, chat, collaborate, respond, and who's hosting.",MachineLearning
nvmiqq,1623210584.0,[D] A Mathematical Guide to Complex Variable Optimization,"In the field of AI, the adaptability of imaginary numbers is sometimes overlooked. When contrasted to their real-valued equivalents, the added domain information contained in these numbers can enable substantially richer representations.
I'm here to announce the release of the first of two reports featured on Weights and Biases, which delves deep into the math underpinning complex variable optimization and includes a regressive example in Tensorflow to demonstrate its utility. You can find it here:

https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM

The goal of this series is to encourage ML researchers and practitioners to indulge in complex numbers and representations in their research. Any feedback or suggestions are most welcome :)",MachineLearning
nvlgoe,1623207019.0,"[D] Intel said they don't plan on releasing their work on GTA V Enhancing Photorealism Enhancement as a mod, as it is research only. What efforts are currently being made (if any) to turn their research into a working mod? Can we get people started on this please?","[Video](https://www.youtube.com/watch?v=P1IcaBn3ej0&ab_channel=IntelISL)

[Side by side comparisons](https://intel-isl.github.io/PhotorealismEnhancement/)

[Paper](http://vladlen.info/papers/EPE.pdf)",MachineLearning
nvkowg,1623204458.0,"[P] GPT-J, 6B JAX-based Transformer LM","Ben and I have released GPT-J, 6B JAX-based Transformer LM!

\- Performs on par with 6.7B GPT-3

\- Performs better and decodes faster than GPT-Neo

\- repo + colab + free web demo

\- Trained on 400B tokens with TPU v3-256 for five weeks

\- GPT-J performs much closer to GPT-3 of similar size than GPT-Neo

https://preview.redd.it/e1yqex9it4471.png?width=908&format=png&auto=webp&s=a6411d57530d5f34e8524fd50fa3f1640421181a

tweet: [https://bit.ly/3isa84D](https://bit.ly/3isa84D)

article: [https://bit.ly/2TH8yl0](https://bit.ly/2TH8yl0)

repo: [https://bit.ly/3eszQ6C](https://bit.ly/3eszQ6C)

Colab: [https://bit.ly/3w0fB6n](https://bit.ly/3w0fB6n)

demo: [https://bit.ly/3psRCdM](https://bit.ly/3psRCdM)",MachineLearning
nvjsqs,1623201553.0,[D] Scaling Vision Transformers,"https://arxiv.org/abs/2106.04560

""wow much sota paper""
The title would suggest that the paper is just about training large vision transformers, but I think the main takeaways are the scaling characteristics---larger models do better, _especially_ with fewer examples.",MachineLearning
nvhyzy,1623195710.0,[R] NLP researchers' reaction wanted,"[This paper](https://arxiv.org/abs/2010.12438) claims that Eq. 2 approximates Eq. 1. Effectively, the concept of ""timestep"" in this autoregressive model / MDP is not defined based on the input sequence (as in most NLP models afaik), but rather an ad hoc decision.

My question:

1. Is this the first paper that has done this?
2. Is there any justification for it?

Thanks in advance for any pointers!",MachineLearning
nvhqu0,1623195056.0,[R] Graph embedding = mean of node embedding,[This paper](https://arxiv.org/abs/1803.08475) uses the mean of the embedded vector of the nodes as the embedded vector of the graph (Fig. 1). Is this the first graph neural network paper that has done this? Thanks in advance for any pointers.,MachineLearning
nvhm9d,1623194686.0,"[R] On the Robustness of Vision Transformers (Video, Paper and Code)"," On the Robustness of Vision Transformers to Adversarial Examples

TL;DR: An analysis of the transferability of adversarial examples between Vision Transformers and CNNs, and how this transferability can be leveraged for security.

Introductory Video: [https://youtu.be/pcYoymda49c](https://youtu.be/pcYoymda49c)

Paper Link: [https://arxiv.org/pdf/2104.02610.pdf](https://arxiv.org/pdf/2104.02610.pdf)

Github Code: [https://github.com/MetaMain/ViTRobust](https://github.com/MetaMain/ViTRobust)",MachineLearning
nvg6n8,1623190599.0,[D] what would be the best approach to use embeddings + extra features from a tabular dataset?,"I already know how to create embedding, however the other day I was thinking ""what happens if you have text in one feature but you also have other features that can help your model performance. How can you use your embeddings and extra features to create a new model?

For example, if you have 20k of vocabulary x 60 dimensionality embedding matrix. How can you add extra features to the model?

It could be in any framework, tensorflow, pytorch, etc",MachineLearning
nvffyb,1623188760.0,[D] Paper explаined - DALL-E: Zero-Shot Text-to-Image Generation,"Wouldn't it be amazing if you could simply type a text prompt describing the image in as much or as little detail as you want and a bunch of images fitting the description were generated on the fly? Well, thanks to the good folks at OpenAI it is possible! Introducing their DALL-E model that uses a discrete visual codebook obtained by training a discrete VAE, and a transformer to model the joint probability of text prompts and their corresponding images. And if that was not cool enough, they also make it possible to use an input image alongside a special text prompt as an additional condition to perform zero-shot image-to-image translation.

To learn how the authors managed to create an effective discrete visual codebook for text-to-image tasks, and how they cleverly applied an autoregressive transformer to generate high-resolution images from a combination of text and image tokens check out [the full explanation post](https://t.me/casual_gan/48)!

Meanwhile, check out some really awesome samples from the paper:

[DALL-E samples](https://preview.redd.it/vvekboe044471.png?width=1280&format=png&auto=webp&s=ff23dd61675d24082d4088da3e6c25cecf57f4c1)

\[[Full Explanation Post](https://t.me/casual_gan/48)\] \[[Arxiv](https://arxiv.org/abs/2102.12092)\] \[[Project page](https://github.com/openai/DALL-E)\]

More recent popular computer vision paper explanations:

>\[[CoModGAN](https://t.me/casual_gan/43)\]\[[VQGAN](https://t.me/casual_gan/46)\]\[[DINO](https://t.me/casual_gan/40)\]",MachineLearning
nvd9pj,1623183342.0,"[N] Hutter Prize Entry ""STARLIT"" Open For Comments","The judging committee has ruled [Artemiy Margaritov's STARLIT compressor](https://github.com/amargaritov/starlit) is a new prospective winner of The Hutter Prize!


As per [the award rules for The Hutter Prize For Lossless Compression of Human Knowledge](http://prize.hutter1.net/hrules.htm#award), this initiates the open comment period, prior to the final award:


​The prize is awarded as follows:

* Award = Z×(*L*\-*S*)/*L*, where
*S* = new record (size of comp9.exe+archive9.exe+opt or alternative above),
*L* = previous record for *S* [plus 5'000×(number of days that have passed since 1.1.2021)](http://prize.hutter1.net/hfaq.htm#ddisc),
*Z* = amount in prize fund ([500'000€](http://prize.hutter1.net/hfaq.htm#money))
Update: *L* := *S*, while [*Z* itself does not get reduced](http://prize.hutter1.net/hfaq.htm#money).
* Minimum award is 1% of *Z*.
* Contributions are dealt with in the order of their submission.
* The contribution is subject to public comments for a period of at least 30 days before the prize is awarded.",MachineLearning
nvcyof,1623182543.0,[D] Help on how to extract article text from Time Magazine Pages,"I've downloaded 90+ years of [Time Magazine](https://drive.google.com/drive/u/1/folders/1fFoFxY4i3YU-KNkz84_AG9Nftxr4Alnb) from [Time Vault](https://time.com/vault/). I'll put scraper code on my [GitHub](https://github.com/The-Gupta) soon.
I want to analyze the contents in all these years using Text Analytics or Natural Language Processing. First, I need a reliable and scalable way of Text Extraction from Page images. Any suggestions will be appreciated. Currently, I'm considering [OCR on Extracted Page Layout](https://github.com/Layout-Parser/layout-parser/blob/master/examples/Deep%20Layout%20Parsing.ipynb).",MachineLearning
nvcmww,1623181680.0,[D]Should I care about Statistical relational artificial intelligence?,"Hello!

I am a mathematician with a minor in CS and I find ML quite interesting so that I am choosing more of the ML courses. I could imagine working in that area(not research) and here is the thing:

There is a course on Statistical relational artifical intelligence which seems to cover the topics of a book with the same title. There is not so much about this topic in the internet so I doubt that it would be useful for me later. I don't know if this course covers topics mostly relevant to research and I am no expert so I wanted to ask you.",MachineLearning
nvauw5,1623176910.0,[D] Have we abandoned kernels?,"Hello everyone!

I have a question I was hoping that the community would be able to help me out with. My own research is almost completely about kernel functions. I did my PhD in pure mathematics, where I studied densely defined operators over a variety of classical kernel spaces and even made some of my own (hello! Polylogarithmic Hardy space!) After I graduated, I have been working in approximation theory and numerical analysis with engineers, and recently came back to operator theory through the study of Koopman operators and Dynamic Mode Decompositions.

Reading some textbooks by big guys in the field, I notice that Steve Brunton, for instance, makes almost no mention of kernels in his textbook, Data Driven Science and Engineering, and through my conversations with engineers over the years, there might be some nod to the Gaussian RBF, but then it's all about deep learning.

I have always been able to find new and interesting perspectives on kernel functions for learning theory, and a lot of these innovations are really just twists on ideas from 40 or 50 years ago (thanks to the great Wabha!). I feel that there is still a lot more life in that subject. However, as far as I can tell, most of my colleagues are of the opinion that kernels are something that were concocted to do some esoteric classification methods with SVMs and to perform inner products in feature spaces, and are otherwise unaware that kernel spaces were central to things like Shannon's theorem and many other classical topics.

Have we abandoned kernel functions for deep learning? Is there a good reason why people don't use kernels that I'm just missing? I'd be interested in hearing everyone's perspective.",MachineLearning
nv9mco,1623173577.0,[N] Bruno Maisonnier - CEO and Founder Another Brain- Previously Aldebaran Robotics,"We (IEEE Soft Robotics Podcast) are going to have Bruno Maisonnier  the founder, CEO of another brain  and previously founder of Aldebaran robotics acquired by SoftBank  Group. If you have any questions

&#x200B;

https://preview.redd.it/9zznnnpvu2471.png?width=1314&format=png&auto=webp&s=ee55c49b488a0af2b77890febae680427f0064e4",MachineLearning
nv7a4f,1623167587.0,[P] What are suitable Computer Vision projects that can be implemented in Office Environments,"I was brainstorming with a bunch of friends, we were wondering what are different use cases Computer Vision tasks in an office environment -
1) Social Distance maintenance through video analytics. Can also be used for monitoring cigarettes, alcohol, etc in cafeterias.

2) Facial Recognition application


What are some other useful applications of Computer Vision tasks in an office environment?


Looking forward to hearing from the community,",MachineLearning
nv5v93,1623164006.0,"[R] A theoretical reviewing video on ""AdamP: Slowing Down the Slowdown for momentum optimizers (ICLR 2021)""","This short ⏱ video ([https://youtu.be/bcLsnxkY36s](https://youtu.be/bcLsnxkY36s)) is a paper review on *""AdamP: Slowing Down the Slowdown for momentum optimizers""* presented at ICLR 2021 by Heo and Chun et al., NAVER AI Lab.

Paper: [https://openreview.net/forum?id=Iz3zU3M316D](https://openreview.net/forum?id=Iz3zU3M316D)
Code: [https://github.com/clovaai/AdamP](https://github.com/clovaai/AdamP)
Project page: [https://clovaai.github.io/AdamP/](https://clovaai.github.io/AdamP/)

The paper observed the growth of weight norm using the momentum-based optimizers can be problematic and proposed an excellent remedy, the optimizing step-projection onto the gradient-plane. In this review, focusing on the theoretical analysis, this video offers:

*  More explanations on scale invariance
* A proof of orthogonality of weight and its gradient
* Geometric interpretation on Lemma 2.1
* A proof using deductive reasoning for Lemma 2.2, while the paper uses mathematical induction
* Corrections to the proof of Corollary 2.3 due to the typos (Probably, they'll fix that in the next revision.)
* A more explanation on the step projection

Enjoy the paper reading! 🙂",MachineLearning
nv5lnw,1623163279.0,[R] What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights,"A research team from Google Brain conducts a comprehensive empirical study on more than fifty choices in a generic adversarial imitation learning framework and explores their impacts on large-scale (>500k trained agents) continuous-control tasks to provide practical insights and recommendations for designing novel and effective AIL algorithms.

Here is a quick read: [What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights.](https://syncedreview.com/2021/06/08/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-36/)

The paper *What Matters for Adversarial Imitation Learning?* is on [arXiv](https://arxiv.org/abs/2106.00672).",MachineLearning
nv5kn0,1623163204.0,[R] Behavioral Trees on AI agents for Soccer & other sports,"Hey there,

I have been looking into some AI algorithms and I've come across **Behavioral Trees (BT)** and I was captivated. I wanted to see some examples of BT being used in AI in games and such, but all I found was AI for an enemy player or some sort of PvE game.

I want to see how would a BT look like for a simple AI agent in a soccer game, or any others sports game in general. Would each agent have their own BT or would there be a central control system with a BT that tells each AI agent to what to do, like form formations etc.

In my search, I unfortunately have not seen or came across any good examples, and I wonder, if there is any? I'd be more than happy if you could provide an example or tell me where to look at. Or at least provide some sort of insight to what may it look like if there were a **BT driven AI sports game**. I am curious yet It sucks that all I got from my research are dead-ends and ""prediction algorithms for betting""",MachineLearning
nv3d0v,1623156831.0,[D] Best Cloud Dev Tool,"Hi all,

what is the best cloud development setup you've come across for industry dl research? (python,gcp,pytorch)

I'm talking about using a cloud sever as a work station for both development + training + eval.

Jupyter is great because connection problems don't stop the run. But it doesn't have modern tools like debugging, auto import ...etc

pycharm/vscode in remote dev - require connection to sustain through out training / dev session. But they have amazing tools that make jupyter look like childplay.

code-server - ultra buggy

anything else?
preferably paid off the shelf solution.",MachineLearning
nv1ox4,1623151170.0,[D] confusion matrix plot in few/single shot learning,In few shot learning(FSL) in every episodes they sample N classes(say 5) out of all available classes and then model predict its output classes. During model prediction stage all labels are reconverted to 0-4 for 5 way 1shot classification no matter what their actual value is.  I wanted to plot the confusion matrix but this is not possible as both actual label and predicted label are always in 0-4 range instead of actual labels. Is it possible to get model prediction in terms of actual label or any other pointer so that I can plot confusion matrix in FSL  experiments.,MachineLearning
nuysrd,1623136265.0,[R] RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition,"This paper is about MLP but does not intend to build pure-MLP models like MLP-Mixer, gMLP and ResMLP. The motivation is that FC has global capacity but lacks a local prior so we use convolutions to incorporate locality into FC.

It proposes **RepMLP**, an MLP-style building block, and uses convolutions to incorporate locality into FC layers to make them effective in extracting features in images. It significantly improves the performance of CNN like ResNet-50 by up to 2% **(78.03% top-1 acc ---> 80.07%)**. Like [RepVGG](https://arxiv.org/pdf/2101.03697.pdf)(CVPR 2021), [ACNet](https://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_ACNet_Strengthening_the_Kernel_Skeletons_for_Powerful_CNN_via_Asymmetric_ICCV_2019_paper.pdf) (ICCV 2019) and [Diverse Branch Block](https://arxiv.org/pdf/2103.13425.pdf) (CVPR 2021), it is also a member of the Structural Re-parameterization Universe as **the convolutions can be equivalently merged into the FC** via an elegant and platform-agnostic algorithm.

It turns out that FC is significantly faster than conv with a comparable number of parameters and has a stronger representational capacity.

It also suggests that **viewing convolution as a degraded FC** may bring more exciting discoveries.

paper: [https://arxiv.org/pdf/2105.01883.pdf](https://arxiv.org/pdf/2105.01883.pdf)

code: [https://github.com/DingXiaoH/RepMLP](https://github.com/DingXiaoH/RepMLP)

&#x200B;

In other words, the contribution can be summarized as follows.

Assume a model has two components.

A. Some conv layers. Seen from an FC perspective, each conv is equivalent to a sparse matrix with repeating parameters (Toeplitz matrix).

B. A regular FC.

We merged A into B and got an FC that is neither a regular FC nor a conv. It looked like semi-FC (global representational capacity) and semi-conv (locality). It showed  (A) better speed-accuracy trade-off than traditional conv and (B) significantly higher accuracy than a regular FC.

https://preview.redd.it/9i3fz5jvrz371.png?width=840&format=png&auto=webp&s=07b445cc260ccbc7aa6e8fbe87028d961909fabe",MachineLearning
nulhcw,1623094756.0,[D] Minimum requirements for loading gpt2-xl,"\[edited for clarifications\]

Hey! Quick question, First of all, sorry if this is not the right place for this question. I'm a beginner.

So I'm wondering which would be the minimum requirements for loading the [gpt2-xl](https://huggingface.co/gpt2-xl) (6 GB) PyTorch model, RAM is the key thing here I guess. Note that I am not talking about Fine-Tuning, but rather just load it.

I am using [this](https://github.com/graykode/gpt-2-Pytorch) repo to load the [large](https://huggingface.co/gpt2-large/tree/main) (3 GB) version via Google Colab and it works by changing a few parameters (Google Colab has 13 GB RAM). But when trying to load the xl in the RAM the python process is just directly killed.

For example, would this VPS configuration be enough?

**6 vCPU Cores**

**16 GB RAM**

**400 GB SSD**

**400 Mbit/s Port**

**thanks!!**",MachineLearning
nuhz42,1623086280.0,"[D] Looking for an ML website I saw a while ago, change a face based on sliders of facial properties","I saw a website maybe a year ago where there was a face made by a GAN and you could control what it looked like with a few sliders underneath the face, such as facial width, eye size, skin color etc. Does anyone have any examples of this?",MachineLearning
nugs5k,1623083344.0,[Discussion] Looking for a very particular data set.,"Hi! I'm kinda new to AI and don't know all of the best places to look for datasets, but from searching a bit I can't seem to find what I'm looking for....

Does anyone know of a data set that maps human descriptions to raw data? For instance, if I have a graph of vertical height which varies with time of a ball being tossed into the air, and it forms a parabola, a human might say ""the graph looks like a hump"" or ""the graph forms an arc,"" or even more specific, ""the graph peaks at \[x\] time."" In addition, if a human is asked the behavior of a graph at a particular point in time, they might say ""it's increasing"" or ""it's peaking"" or ""it's rapidly falling,"" depending on the context.

Any datasets relating to this sort of topic would be great, I can't really find any that come close, and frankly I don't know what to search for exactly. Thank you for reading.",MachineLearning
nufr33,1623080858.0,[R] Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems,"A research team from Google Research combines the benefits of implicit differentiation and autodiff and proposes a unified, efficient and modular approach for implicit differentiation of optimization problems.

Here is a quick read: [Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems.](https://syncedreview.com/2021/06/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-35/)

The paper *Efficient and Modular Implicit Differentiation* is on [arXiv](https://arxiv.org/abs/2105.15183).",MachineLearning
nufipo,1623080269.0,[P] PyTorch wrapper of Attention-Free Transformer (AFT) layer,"Hello folks,

Recently came across the paper titled, ""[An Attention-Free Transformer](https://arxiv.org/abs/2105.14103)"" by Zhai et al. from Apple, Inc..

Here's my PyTorch wrapper around the AFT-Full layer:

[https://github.com/rish-16/aft-pytorch](https://github.com/rish-16/aft-pytorch)

You can pip install it as well (more info in README). It's a plug and play module with existing Attention-based networks without major tweaks.

Any PRs/suggestions/amends appreciated :) The paper wasn't too clear for some implementation details so I had to essentially pull certain things out of thin air (and somehow it still works tbf).

Cheers!",MachineLearning
nuf0ms,1623079021.0,[D] Fine-Tune cause overfitting problem?,"\## Discuss

I am trying to use deep learning to predict continuous emotion evoked by movies.

Because my dataset has a similar task as the pre-trained model. So I only replace the FC layer in pre-trained model to make it suitable for my tasks. At the same time, I try to ensemble different pre-trained model to improve my accuracy. Before passing the features extracted by the different model to FC, I concatenate different features extracted by different models. This is the way how I fine-tune the pre-trained model. But it only performs well in the training dataset. I have already used dropout and L2- Regularization tricks in case of overfitting. It seems that overfitting still happens.

As I know, the reason why overfitting happens is that the network is so complicated for datasets, but my network only uses the pre-trained model(freeze all layers except for the last FC layer which is replaced by mine). I don’t really think that it is so complicated.

In conclusion, overfitting happens when I use the pre-trained model that is the last FC layer replaced by mine.What can I do to fix that?

\-----

Update: The overfitting problem happens in the first few epochs. Here is the graph of my loss.

https://preview.redd.it/kea0uw203y371.png?width=557&format=png&auto=webp&s=a663f1fc70c8b2049ecc7a9186dd14e626beb024",MachineLearning
nue1t6,1623076562.0,"[Project] Semantic text search in 42 lines of code. Searching ""a mourning man"" in the poems.","An example project made using [Jina](https://github.com/jina-ai/jina/)(AI search framework).

This is a short 42 line script to index \~800 poem verses from the huggingface \`poem\_sentiment\` dataset, and uses a transformer model to index them, and performs a \`KNN\` search using \`FAISS\` module.

The example output for the search phrase (**""a mourning man""**) looks like following

    [0]: sat mournfully guarding their corpses there,
    [1]: dearest, why should i mourn, whimper, and whine, i that have yet to live?
    [2]: taught by the sorrows that his age had known
    [3]: the love that lived through all the stormy past,

Notice, **many of the results don't even have the word ""mourn"" or ""man""** but they still are about ""a mourning man"" and thus appear in the results.

[Source Code](https://gist.github.com/tadejsv/32091353449c301c6506f42e70410809) on Github

What do you think about this? How can we make it even better and shorter?",MachineLearning
nucldz,1623072631.0,[D] Blog Post - Graphs at ICLR 2021,"ICLR 2021 has been over for 1 month.

I have put together a blog post where I summarize/discuss a number of graph/geometric DL papers from ICLR 2021, along with some personal reflections on the field. There are papers about spectral methods, graph attention, meshes/simulation, the bottleneck issue, and some more.

You can find it here: [https://danielepaliotta.com/blog/2021/graphs-iclr2021/](https://danielepaliotta.com/blog/2021/graphs-iclr2021/)

Of course, any feedback is appreciated!",MachineLearning
nubmwp,1623069894.0,[R] Silas: A High-Performance Machine Learning Foundation for Logical Reasoning and Verification,"Silas is a generic data mining and predictive analytics software toolkit built upon advanced machine learning, automated reasoning and artificial intelligence techniques. It deals with any type of structured data and performs tasks such as classification, regression, segmentation, anomaly detection, prediction, and more.

The below paper introduces Silas as a high-performance machine learning tool, which is built to provide a more transparent, dependable and efficient data analytics service. We discuss the machine learning aspects of Silas and demonstrate the advantage of Silas in its predictive and computational performance. We show that several customised algorithms in Silas yield better predictions in a significantly shorter time compared to the state-of-the-art. Another focus of Silas is on providing a formal foundation of decision trees to support logical analysis and verification of learned prediction models. We illustrate the potential capabilities of the fusion of machine learning and logical reasoning by showcasing applications in three directions: formal verification of the prediction model against user specifications, training correct-by-construction models, and explaining the decision-making of predictions.

[Journal Paper](https://www.sciencedirect.com/science/article/pii/S0957417421002475)

[Preprint PDF](https://zhehou.github.io/papers/Silas_and_comparison_paper_Expert_Systems_with_Applications.pdf)

[Educational Version Download](https://www.depintel.com/silas_download.html)

[Related Work](https://zhehou.github.io/papers/by-topic.html)",MachineLearning
nu8vyk,1623060860.0,[PROJECT] Unable to use emojis for masked language modelling using BERT?,"I am new to Hugging Face and masked language modelling (MLM), and I was wondering how to include emojis when doing such a task.

I have a dataset with tweets, with each tweet containing an emoji at the end - here is a sample of my data:

| ID |        Tweet |
| -------- | -------------- |
| 1    | Looking good today 😎         |
| 2   | Weather is so hot, lol ☀️          |
| 3  | I hate you!!! 🤬        |

At the moment, I have fully trained my masked language model using my dataset, but when I predict something, it does **NOT** output or predict the emojis. It just predicts words.

This is my desired input from using my dataset for MLM:

```
""You look great [MASK]""
```

This is my desired output from using my dataset for MLM:

```
[{'score': 0.26041436195373535,
  'sequence': 'You look great 😎""',
  'token': 72,
  'token_str': '.""'},
 {'score': 0.1813151091337204,
  'sequence': 'you look great 💯""',
  'token': 2901,
  'token_str': '!""'},
 {'score': 0.14516998827457428,
  'sequence': 'you look great 👌',
  'token': 328,
  'token_str': '!'},]
```

However, this is what I am actually getting from my output:

```
[{'score': 0.26041436195373535,
  'sequence': 'You look great?""',
  'token': 72,
  'token_str': '.""'},
 {'score': 0.1813151091337204,
  'sequence': 'You look great.""',
  'token': 2901,
  'token_str': '!""'},
 {'score': 0.14516998827457428,
  'sequence': 'You look great!',
  'token': 328,
  'token_str': '!'},]
```

I know it is possible to do this, but how do I do it? I am close, but not very.

Likewise, I have my model fully trained on my dataset, but it just does not seem to output emojis, even though I have included them in the training.

Does something need to be included to accept emoji? If so, what?

Thanks - I would really appreciate the help!",MachineLearning
nu8cs5,1623058669.0,[D] How do you handle cases when little relevant data is produced in Document related ML Systems in production?,"**For example,**

When extracting data from an unstructured document such as an order confirmation document, if only a few fields like date of order, and name  of the supplier are retrieved but details such as the amount and the items are not. **How is this handled?**

**What are the fallback mechanisms used?**",MachineLearning
nu5z18,1623048124.0,[D] What is the impact of r/MachineLearning on you as a Researcher/MLE/someone in the ML space?,"As the headline says. If you ask me personally, I learned more about nuances in ML from reading comments/discussions/topics on this subreddit than I did in my formal education.

Additionally Thank you r/MachineLearning and its Mods. This is a brilliant community from which I have learned so much.",MachineLearning
nu5kp3,1623046492.0,[D] Library for making splits,"A few times I've needed to split my data while attempting to keep various meta features of the data in particular proportion across the datasets.

For instance, if I am training an image classification model on images which I scraped from the web, I might want to attempt to keep roughly the same proportion of images scraped from instagram in the training/test/validation (so that if my total dataset is 30% instagram, each of my splits has \~30% instagram images). Conversely, I might want to ensure that all the images from a particular user on instagram ends up in one particular set (because the user might have some specific logo on their images or something that I don't want to accidentally learn and claim great performance discriminating against). Another example is in a multi-class classifier, I would want to ensure the number of examples of each class are represented roughly equally in each split.

The basic problem would be given a table where each row represents an example datapoint and each column represents a meta variable. I want a program that partitions the rows into three groups (presumably I can choose the percentage that goes into each partition) such that each column I specify to be split evenly is roughly distributed evenly in the partitions, and each column that I specify to be to be split exclusively has all rows with the same value for that column stay in exactly one split.

I've written some code to do this a few times, but I normally just roll a random split and then check if everything is within some tolerance. I'm sure there is a more optimal way to do this, but before I spend the time to figure this out on my own, I just wanted to know if something like this already exists.

Thanks!",MachineLearning
nu59cd,1623045280.0,"[D] Got ML role, but dislike ML, any advice?","
Hi all, before hand, I want to preface that I understand the field is very competitive and many people would be very glad to trade for my position. So I'm sorry if I look entitled.

I've recently been very fortunate to get a really high paying SWE role that is very relevant to ML (Have to read and implement ML algo and tune parameters). The amount of pay and level is what drives me to take this position.

However, I have been secretly developing a sense of dislike and despair toward learning ML related stuff, even though my resume clearly show that I only do ML stuff (undergrad courses, internship, and job exp). I mainly think that its a waste of my time in long run, and feel like the materials are too detached from systems level thinking.

I have realized that I couldn't care less about the next best paper in ML, or any new algorithm to tune model. What I trully care about in long run is mostly software systems, distributed system and devops. How long do you think I will last in ML field if I have no passion for it?
Or any advice from other who went through the same phase.",MachineLearning
ntyhzz,1623021808.0,[D] Paper Explained: VQGAN - Taming Transformers for High-Resolution Image Synthesis,"It is a lucrative idea to combine the effectiveness of the inductive bias of CNNs with the expressiveness of transformers, yet only recently such an approach was proven to be not only possible but extremely powerful as well. I am of course talking about ""Taming Transformers"" - a paper from 2020 that proposes a novel generator architecture where a CNN learns a context-rich vocabulary of discrete codes and a transformer learns to model their composition as high-resolution images in both conditional and unconditional generation settings.

To learn how the authors managed to create an effective codebook of perceptually rich discrete image components, and how they cleverly applied latent transformers to generate high-resolution images despite severe memory constraints check out [the full explanation post](https://t.me/casual_gan/46)!

Meanwhile, check out this paper poster provided by [Casual GAN Papers](https://t.me/casual_gan):

[Paper poster](https://preview.redd.it/xvsadvykbq371.png?width=2064&format=png&auto=webp&s=f2e1c3f74c704f4d69b3028dcf2ad0aac12f5b4e)

\[[Full Explanation Post](https://t.me/casual_gan/46)\] \[[Arxiv](https://arxiv.org/abs/2012.09841)\] \[[Project page](https://github.com/CompVis/taming-transformers)\]

More recent popular computer vision paper explanations:

>\[[CoModGAN](https://t.me/casual_gan/43)\]\[[GANCraft](https://t.me/casual_gan/41)\]\[[DINO](https://t.me/casual_gan/40)\]",MachineLearning
ntxz3b,1623020205.0,[P] Performance-oriented monitoring and bottleneck-detection,"In my [previous post ](https://www.reddit.com/r/MachineLearning/comments/nk3opi/d_r_bert_base_choosing_optimal_cloud/)I described a case how basic monitoring might help to save >10x on compute power for a specific NN model (BERT Base Uncased).

If you benchmark something, setting up a monitoring is trivial for one host, but  might be an ache if you have a k8s cluster. Also, there is no fun in setting this up every time, especially if you lack DevOps experience. And there is no point in manually parsing through the data and looking at graphs if you know exactly what you are looking for and what’s relevant for the performance/cost.

With my team we do that kind of cost/performance optimization service for our customers all the time, so we have built a set of simple tools for ourselves over time.

After some feedback from my first post, we’ve put together[ a public web app](https://bottleneck.rocketcompute.com/) with some of the tools we use, so others might use it too.

&#x200B;

https://preview.redd.it/5b1lw3gl4q371.png?width=1999&format=png&auto=webp&s=394932fd38019e871998b6541ed641639bd901bc

&#x200B;

https://preview.redd.it/ynslc6tr4q371.png?width=1839&format=png&auto=webp&s=f45f86f45a7b282856f47f1eeebc43787e63ae78

&#x200B;

https://preview.redd.it/tfykqmjt4q371.png?width=1839&format=png&auto=webp&s=02c28cdf2863650a89472a675d3ea833952ee65d

Basically, what it does - you can deploy well-tuned Telegraf-based monitoring with one command on any VM (AWS, GCP or on-prem), k8s cluster or bake it into an image and get basic visualization dashboards right away.

&#x200B;

https://preview.redd.it/hz3er5f05q371.png?width=1888&format=png&auto=webp&s=ed58e98645097f725a5b25916c8187866ecdd622

You also get an automated detection of some relevant bottlenecks and idle times on your infrastructure and can zoom in on them right away (including those I’ve mentioned in my previous post like one-thread preprocessing bottleneck, underutilized GPU, idle times, etc…).

&#x200B;

https://preview.redd.it/ho2euln55q371.png?width=1288&format=png&auto=webp&s=3dd0c1ac3ee9da908d1a15e0ac988b6b633d1258

&#x200B;

https://preview.redd.it/sn3uyb5a5q371.png?width=1264&format=png&auto=webp&s=97204b3af21923e90a3f9f7c05f066ba041af928

So if you have benchmarking routines similar to ours and just need something to quickly glance at metrics without a world of pain - here you go (if not, just stroll on,  you lucky bastard).

LMK if that’s useful or if you have any other ideas what might be.

PS If that catches any attention we are going to add an automated benchmarking (runs the same container on a set of instances and produces a nice summary report with runtime, price and metrics for each run).

PPS we just decided to publish it, so if anything is glitching - email me at egor@rocketcompute.com.",MachineLearning
ntv4v7,1623012211.0,[D] Are there ML PhD programs that also let you work in industry at the same time?,"I'm wondering which ML PhD programs let you build career capital while you study. I think there's a lot of valuable experience industry provides, while learning and exploring problems as one does is ML. Also a lot of the problems with a lot of impact are found through market research on users which you can only get in industry. Are there ML programs like this?",MachineLearning
ntu6lq,1623009605.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 114,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)|[Week 112](https://reddit.com/n8m6ds)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)|[Week 113](https://reddit.com/njfsc6)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)||

Most upvoted papers two weeks ago:

/u/DL_updates: [Intriguing Properties of Vision Transformers](https://arxiv.org/abs/2105.10497)

/u/au1206: [https://arxiv.org/abs/2105.01601](https://arxiv.org/abs/2105.01601)

Besides that, there are no rules, have fun.",MachineLearning
ntt4iv,1623006759.0,[D] Does anyone want to share their independent or hobbyist ML research setup?,"I recently moved from a scientist role to an engineering role, but I still have an itch for running academic experiments. I have a Windows 10 desktop with a Ryzen 3900x and a 1080 ti, but mostly use it for gaming.

I'm thinking the best research setup might be a dev box w/ cloud computing and a something like a local Linux terminal (instead of dualbooting). I want to minimize dev time and optimize for experiments without demolishing my wallet. Any tips?",MachineLearning
ntsxdv,1623006229.0,''[D]'' How do we use probability in data science and machine learning ?, I have been studying data science and machine learning from past few months from various online sources. I have built few projects also by using some github file as reference. But i failed to understand the explicit use of probabilitiy in it. Can anyone help me understand this with example or provide some good source to learn this? Thank you.,MachineLearning
ntrpnp,1623002925.0,[N] Call for papers: ICML 2021 Workshop on Distribution-Free Uncertainty Quantification,"**ICML 2021 Workshop: Distribution-Free Uncertainty Quantification**

This will be a virtual event (see website [here](https://sites.google.com/berkeley.edu/dfuq21)).

No reformatting of papers required, no page limit, rolling deadlines with 1wk casual review.

Workshop will be beginner-friendly, and all are encouraged to submit.

Speakers include Michael I. Jordan, Emmanuel Candes, Rina Barber, Vladimir Vovk, Leying Guan, Jing Lei, Larry Wasserman, and Kilian Q. Weinberger.

Submission deadline: up to **June 14** for spotlights and **July 1** for posters.

Topics include conformal prediction, risk-controlling sets, calibration, tolerance regions, and heuristic notions of uncertainty like Platt scaling.

[https://sites.google.com/berkeley.edu/dfuq21](https://sites.google.com/berkeley.edu/dfuq21)

Organized by myself, Stephen Bates, Aaditya Ramdas, Sharon Yixuan Li, and Ryan Tibshirani.",MachineLearning
ntqlm0,1622999808.0,[R] Text to image GANs text rendering not being interpreted,"Why, when working with text to image GANs e.g. CLIP and BigGAN, does  text from the prompt sometimes render in the image as text instead of  interpreting that text? Is the word not understood, is the prompt too  short or is there another reason?",MachineLearning
ntn1eg,1622989899.0,"[P] Just discovered a new 3Blue1Brown-styled, quality ML Youtube channel.","I'm reading Jax's documentation today and in there was a link to a [""quite accessible videos to get a deeper sense""](https://jax.readthedocs.io/en/latest/jax-101/04-advanced-autodiff.html) of Automatic Differentiation and it's actually very good ([What is Automatic Differentiation](https://www.youtube.com/watch?v=wG_nF1awSSY&t=6s)?)

https://preview.redd.it/9i2tiwv5nn371.png?width=1847&format=png&auto=webp&s=083e62f60b1cfe837c68661b900750f163734140

The video style is 3Blue1Brown-inspired, explains the topic from bottom up, very accessible though not shy away from maths.

I see that the channel is still relatively small but already got some great videos on Normalising Flow and Transformer. If you like those too please go there and subscribe to encourage the authors to create more high-quality contents.",MachineLearning
ntki7t,1622981930.0,[P] Paper Analysis: Negative Data Augmentation (ICLR 2021),"Here is my analysis of the paper ""Negative Data Augmentation"" published at ICLR 2021

[https://nicolabernini.github.io/PaperAnalysis\_ICLR2021\_NegativeDataAugmentation/](https://nicolabernini.github.io/PaperAnalysis_ICLR2021_NegativeDataAugmentation/)

&#x200B;

&#x200B;

https://preview.redd.it/oy67n04pnn371.png?width=1055&format=png&auto=webp&s=a3a1e98e508bcde34ad127b2f5d2fa4764d941f5",MachineLearning
ntk6ne,1622980778.0,[D]identifying products based on their weights,"I'm trying to develop a system that can classify a product based on its weight to double check if the operators are using the right setup on the balances we use in our production lines.

How is this? Where i work we measure the final product's wight to control the consumption of our raw material and quality control. The balance's operator set a certain product ID based on the production schedule and this product is measured and its weight is pointed on the system.

The problem is, the operator can input product A while we are manufacturing product B, and thus we will have a divergence between what is the expected weight and what is being measured.

I'm wondering if i can use some I.A to ""learn"" what product it is based on its weight to avoid this type of problem. The thing is my only input are the measured weights, but every product tend to be normally distributed.",MachineLearning
ntju5w,1622979459.0,"[D] For Linux users who develop ML/DL projects with Python, what IDE do you use? In particular, what are some advantages to use the popular PyCharm?","I use Sublime, and I feel good to use it.

My friend always persuades me into using PyCharm.

What are the adv. to use it?

Sync with remote server? Sublime has plugin to do it, or I can use sshfs to mount remote files.

Syntax autocomplete or auto-setting the conda env. Hmnn.. not appealing enough for me.

I never get familiar with PyCharm.

Anyone can give some *badass features* for it being the IDE for ML/DL projects?  :p",MachineLearning
ntjc9b,1622977553.0,[R] Not All Knowledge Is Created Equal (Selective Mutual Knowledge Distillation),"Not All Knowledge Is Created Equal

[https://arxiv.org/abs/2106.01489](https://arxiv.org/abs/2106.01489)

Mutual knowledge distillation (MKD) improves a model by distilling knowledge from another model. However, not all knowledge is certain and correct, especially under adverse conditions. For example, label noise usually leads to less reliable models due to the undesired memorisation \[1, 2\]. Wrong knowledge misleads the learning rather than helps. This problem can be handled by two aspects: (i) improving the reliability of a model where the knowledge is from (i.e., knowledge source's reliability); (ii) selecting reliable knowledge for distillation. In the literature, making a model more reliable is widely studied while selective MKD receives little attention. Therefore, we focus on studying selective MKD and highlight its importance in this work.

Concretely, a generic MKD framework, Confident knowledge selection followed by Mutual Distillation (CMD), is designed. The key component of CMD is a generic knowledge selection formulation, making the selection threshold either static (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special cases: zero knowledge and all knowledge, leading to a unified MKD framework. We empirically find CMD-P performs better than CMD-S. The main reason is that a model's knowledge upgrades and becomes confident as the training progresses.

Extensive experiments are present to demonstrate the effectiveness of CMD and thoroughly justify the design of CMD. For example, CMD-P obtains new state-of-the-art results in robustness against label noise.",MachineLearning
ntii8i,1622974093.0,[D] I think all vision researchers should be using event cameras in their research,"[Event camera](https://en.wikipedia.org/wiki/Event_camera).

The motivation of this post is based on driving the adoption and manufacturing of smaller, high quality, and cheaper event cameras which seem to offer much better data for high quality and high framerate applications. This post probably seems obvious to a lot of researchers as it's covered in abstracts, [survey papers](https://arxiv.org/abs/1904.08405), [blogs](https://medium.com/tangram-visions/event-cameras-where-are-they-now-293343754bfd), and talks (from 2014 onward) explaining event cameras and their benefits. The main benefits being getting intensity changes per-pixel and not having to consider under/overexposure nor motion blur in data augmentation pipelines. All of these benefits usually results in less computation required.

The first paper I'd point to is [""Event Based, Near Eye Gaze Tracking Beyond 10,000 Hz""](https://web.stanford.edu/~jnmartel/publication/angelopoulos-2020-event/). One of the hardware requirements of high quality VR/AR is eye tracking (over 250Hz) for foveated rendering. That paper creates what appears to be a perfect foundation for eye-tracking. It's not hard to imagine a miniaturized cellphone-scale event camera with maybe an ASIC tracking the eye at extremely high quality. As far as I'm aware it's not possible to get that quality with an IR camera and it would use a lot more energy processing the frame data.

[This page has recent projects including one on calibrating event cameras](http://rpg.ifi.uzh.ch/research_dvs.html). It also has a paper on [slowing down time](http://rpg.ifi.uzh.ch/TimeLens.html) which also has a lot of neat applications for [segmentation which others have looked into](https://www.prophesee.ai/2019/09/19/high-speed-counting-event-based-vision/). There's also a paper on there for [monocular depth estimation](http://rpg.ifi.uzh.ch/RAMNet.html) which seems like a perfect application for event cameras.

Another research area is super resolution algorithms. Granted most try to work on existing color video, but the ability to capture changing intensity values in theory offers much higher quality results for future event-based cameras. There's a number of [papers](https://arxiv.org/abs/1912.01196) on this topic. Reminds me of how our own human vision works with hyperacuity. (I'm fascinated with the concept of pointing a camera at something shaking it a bit and getting incredibly high resolution images).

I think one of the most important uses for event cameras is in the application of low powered [SLAM](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping). That UZH page above has a few SLAM projects and 3D reconstruction papers, but there are newer papers. The main idea though is event cameras can offer unparalleled sample rates and stability compared to standard camera-based approaches. They handle fast rapid motion much better as they don't have to deal with motion blur as mentioned. This has been discussed since probably before 2014, so it's well known, but limited by the availability of event cameras.

There's also applications like [optical flow](https://www.youtube.com/watch?v=8kTRJVQSer0). Also things like [tracking fiducial markers](https://arxiv.org/abs/2012.06516). Turns out tracking high contrast images with an event camera works really well. Seems like multiple people have applied it to YOLO type algorithms also which is impressive.

There's honestly so many vision applications though that could be researched or improved upon. Simply taking non-event camera research and applying event cameras seems to generally give better results. I was actually kind of surprised Google hasn't converted [mediapipe](https://google.github.io/mediapipe/) to use event cameras yet. Being able to do [pose detection](https://www.youtube.com/watch?v=4uJCVSu9Lf4) with rapid motion is huge.

I think photogrammetry might be the largest open area of research for such cameras. There's reconstruction papers and the super resolution stuff, but I don't think anyone has put it all together yet. In theory one should be able to scan objects with very high resolution with such a camera. (A moving camera at that since it wouldn't have the motion blur issues). I could see a company utilizing this approach out competing current company techniques.

VR/AR and Event Cameras:

Let me paint a picture of how I think VR/AR might work later. A VR headset would use 2 event cameras on the front left and right edges with overlap in their FOV. The headset would use these two cameras for SLAM tracking and high sample rate hand tracking. The headset would also have two event cameras for eye tracking. The controllers would have their own wide-angle event cameras on the top and bottom such that each would perform their own SLAM tracking independent of the headset. (The headset could still track the controllers for extra accuracy, but it wouldn't be necessary). In this setup the controllers essentially never lose tracking.

For full body tracking there's a few approaches. The controllers I described would have a huge FOV and could in theory do pose tracking, but it's possible to place the controllers such that they can't see the hips/legs. To remedy that one can imagine a small puck with a wide-angle event camera on each foot. With the ability to do pose tracking and SLAM and combined with pose tracking on the controllers they'd have only a few edge cases for pose reconstruction. (So 10 event cameras total for the whole system).

AR would have a similar 4 camera headset design for tracking and eye tracking. One of the issues with AR is that cameras can't track the user's hands fast enough to use them in the 240Hz+ rendering and get perfect hand occlusion. You want fingers to be in front of floating menus and realistically clip them. This involves calculating pixel perfect masks with near zero latency. There's basically always artifacts or a ghosting effect as the sensors aren't fast enough for AR where you're looking at your real hands. (ToF sensors might be fast enough later).

Conclusion:

I understand event cameras can be costly or time consuming to work with. There are simulators for them though which can make them approachable. (As far as I know they take in high framerate intensity renders from like Blender, Unreal, etc and output the intensity pixel change events).

With the advantages of event cameras I see them taking over a lot of use cases for conventional cameras. I could even see films being recorded with event cameras. Not sure how likely that is, but it seems powerful to be able to capture a whole HDR film with no motion blur for CGI editing purposes. (Would be able to extract all the markers in a scene with much higher quality).

I digress, but if someone could push a hardware company to produce a miniature event camera that would be amazing. I know Intel funds research that uses them, but I'm honestly surprised they haven't made their own to replace their T-265 SLAM device. That thing can't handle any sudden movement at all. A company that can produce an affordable small sensor could market it to VR/AR, motion capture, drones, robotics, and cellphones. An event camera on a cellphone would probably make so many things lower-powered like OCR. I digress again. This post culminated from watching a ton of event camera talks online and reading about the potential everyone sees in them.",MachineLearning
ntigf0,1622973888.0,Dataset of the Political Alignment of Subreddits [D],"Hi, as a part of a course on network science I'm currently taking, I'm doing a project where I want to analyze the political divide in the US, and how it carries into the digital landscape, in particular Reddit. I'd like to see the relationships between subreddits of differing political alignments.

I'd like to use [this dataset](https://snap.stanford.edu/data/soc-RedditHyperlinks.html) (which includes 6000 subreddits), which links subreddits where a user posted a link from one subreddit to another. My current issue is that I don't have any way to find out the political orientation of the subreddits, well, at least not in a matter which takes a reasonable amount of time.

Does anyone know of a dataset of subreddits that includes the political orientation of each?

Otherwise, if any of you thinks up an idea of how to perform my analysis without massively enriching the dataset (perhaps by only using a handful of political subreddits), I'd very like to hear what you have to say.",MachineLearning
nthjgq,1622970013.0,[D] How to reduce latency of DL models,I have a challenging task that I have to reduce latency of my deep learning model for faster inference. I would like to do it without having accuracy loss if possible. Can I get any advice on how to do it? I already have the weight models.,MachineLearning
ntbusg,1622947760.0,[R] Adversarial Reprogramming of Neural Cellular Automata,"Link: [https://distill.pub/selforg/2021/adversarial/](https://distill.pub/selforg/2021/adversarial/)

Authors: Randazzo, E., Mordvintsev, A., Niklasson, E., & Levin, M.

Opening Paragraphs:

In a complex system, whether biological, technological, or social, how can we discover signaling events that will alter system-level behavior in desired ways? Even when the rules governing the individual components of these complex systems are known, the inverse problem - going from desired behaviour to system design - is at the heart of many barriers for the advance of biomedicine, robotics, and other fields of importance to society.

Biology, specifically, is transitioning from a focus on mechanism (what is required for the system to work) to a focus on information (what algorithm is sufficient to implement adaptive behavior). Advances in machine learning represent an exciting and largely untapped source of inspiration and tooling to assist the biological sciences. [Growing Neural Cellular Automata](https://distill.pub/2020/growing-ca/) and [Self-classifying MNIST Digits](https://distill.pub/2020/selforg/mnist/) introduced the Neural Cellular Automata (Neural CA) model and demonstrated how tasks requiring self-organisation, such as pattern growth and self-classification of digits, can be trained in an end-to-end, differentiable fashion. The resulting models were robust to various kinds of perturbations: the growing CA expressed regenerative capabilities when damaged; the MNIST CA were responsive to changes in the underlying digits, triggering reclassification whenever necessary. These computational frameworks represent quantitative models with which to understand important biological phenomena, such as scaling of single cell behavior rules into reliable organ-level anatomies. The latter is a kind of anatomical homeostasis, achieved by feedback loops that must recognize deviations from a correct target morphology and progressively reduce anatomical error.

In this work, we *train adversaries* whose goal is to reprogram CA into doing something other than what they were trained to do. In order to understand what kinds of lower-level signals alter system-level behavior of our CA, it is important to understand how these CA are constructed and where local versus global information resides.",MachineLearning
nt3eva,1622921439.0,[P] Synthetic Data for Agriculture - an example with Houdini and Arabidopsis,"[https://cjgo.github.io/2021-06-05-Syn-Arabidopsis/](https://cjgo.github.io/2021-06-05-Syn-Arabidopsis/)

&#x200B;

I haven't seen too many examples of synthetic data in Ag... particularly with Houdini. Which I've found extremely difficult to learn but very rewarding.",MachineLearning
nta7gu,1622942077.0,[D] Does anyone know of coreference resolution tools where you can specify the entity?,"Hi. Let me elaborate on the title. I'm currently working on paragraph-level data and want to perform coreference resolution. I've tried working with spaCy's [NeuralCoref](https://github.com/huggingface/neuralcoref), and although it works great it receives a string as input and returns all entities and mentions it deems appropriate. Rather than that I'm looking for something where you can specify the entity and the model will return all such instances for that particular entity.

Does anyone know if something like that exists? Thanks.",MachineLearning
nt94u2,1622938490.0,"[D] Has anyone heard of ""zaslavsk's theorem of hyperplanes""?","Has anyone heard of Zaslavsky's theorem on hyperplane arrangement? Supposedly it says that there are only a finite number of ways that hyperplanes can be arranged? Does anyone know why this is important? Apparently it has implications to decision boundaries of machine learning classifiers?

Thanks",MachineLearning
nt86ef,1622935362.0,[R] Does anybody know good research papers or resources about identifying drivers behaviors?,"Hi, everyone! I'm starting my master's thesis in AI and I need to find information related to identification of driving behavior patterns, spatial-temporal data processing and determination of mobility patterns based on driving places, types of roads, places of interest, etc.

Could you please provide me with information?

Thanks in advance.",MachineLearning
nt77x5,1622932393.0,[D] Need help understanding the usage of rolling window sequence in a research paper,"I'm currently trying to implement this paper [https://www.catalyzex.com/paper/arxiv:2101.02908](https://www.catalyzex.com/paper/arxiv:2101.02908)

in the paper, they calculate subsequences of the original time series data using a rolling window method. See the image below:

&#x200B;

https://preview.redd.it/z8h7vhajxi371.png?width=595&format=png&auto=webp&s=a54be8ae0312df1f1a2c23b976297970135864a3

But what I don't understand is that how do you calculate the rolling window sequence at time step k=0, when there are no values behind it? Do you just pad the sequence with values of zero or the mean? Or think of it as negative indexing (to me that sounds a little stupid)?",MachineLearning
nt63aq,1622929082.0,[D] Video - The basics of spatio-temporal graph neural networks,"I'm a PhD student studying machine learning and applications in transportation systems and autonomous systems (think RL and robotics). While there are several ""GCN made easy"" videos out there on Youtube, I feel like these videos often miss the forest for the trees (especially since GCN is just 1 algorithm that was developed in 2016...) and videos often don't cover the broader historical context of how GNNs were developed and don't cover how different variations of these models allow them to model new types of systems.

This is the third video in a series I'm making about graphs, graph neural networks, and the application areas where they have the potential to make big impacts. Please let me know what you think of the video and if you learned anything new from it!

https://youtu.be/RRMU8kJH60Q",MachineLearning
nt2lie,1622919141.0,[D] What are the best resources to crack M L system design interviews?,"Hi,

For those who are brushing on their skillset for applied research roles, how do you learn more about ML system design?.

I have seen many resources about algorithms questions, and how to cover theoretical ML questions, but for ML engineers and for applied research positions, there is more emphasis on ""ML System Design interviews"".

There are some resources that I used before, such the following

[https://github.com/EthicalML/awesome-production-machine-learning](https://github.com/EthicalML/awesome-production-machine-learning)

[https://github.com/kelvins/awesome-mlops](https://github.com/kelvins/awesome-mlops)

I think that the field is relatively new and some of these resources are still not known. Please feel free to recommend some of the things that you found rewarding in your journey as an experienced ML engineer or applied researcher.",MachineLearning
nt118e,1622914767.0,[D] Paper Explained - Decision Transformer: Reinforcement Learning via Sequence Modeling (Full Video Analysis),"[https://youtu.be/-buULmf7dec](https://youtu.be/-buULmf7dec)

Proper credit assignment over long timespans is a fundamental problem in reinforcement learning. Even methods designed to combat this problem, such as TD-learning, quickly reach their limits when rewards are sparse or noisy. This paper reframes offline reinforcement learning as a pure sequence modeling problem, with the actions being sampled conditioned on the given history and desired future rewards. This allows the authors to use recent advances in sequence modeling using Transformers and achieve competitive results in Offline RL benchmarks.

&#x200B;

OUTLINE:

0:00 - Intro & Overview

4:15 - Offline Reinforcement Learning

10:10 - Transformers in RL

14:25 - Value Functions and Temporal Difference Learning

20:25 - Sequence Modeling and Reward-to-go

27:20 - Why this is ideal for offline RL

31:30 - The context length problem

34:35 - Toy example: Shortest path from random walks

41:00 - Discount factors

45:50 - Experimental Results

49:25 - Do you need to know the best possible reward?

52:15 - Key-to-door toy experiment

56:00 - Comments & Conclusion

&#x200B;

Paper: [https://arxiv.org/abs/2106.01345](https://arxiv.org/abs/2106.01345)

Website: [https://sites.google.com/berkeley.edu/decision-transformer](https://sites.google.com/berkeley.edu/decision-transformer)

Code: [https://github.com/kzl/decision-transformer](https://github.com/kzl/decision-transformer)",MachineLearning
nt0qio,1622913929.0,[D] bootstrap your own latent - why does it work?,"So this discussion is for people who read/know about the paper BYOL, if not you can watch an explantation here:[https://youtu.be/YPfUiOMYOEE](https://youtu.be/YPfUiOMYOEE)

So after reading the paper and watched some videos, there are stuff that are still unclear to me:

1. An inuition for BYOL was shown, when the authors showed they can use a random freezed network which will never change (not by sgd and not by moving average), and they trained an online network to match the representation of the random network the same way they do in BYOL. The represntation created by this got accuracy of 18% in linear evalution on imagenet, much better than random. I don't get why this would work. If the freezed network would recieve the un-augmented image and the online network would recieve an augmented image, I can see why it would work, because the online network will learn each image has one ""anchor"" in the latent space, and each augmented image would have to get the same latent represntation, and that would make the online network to ignore the augmentation and give it some semantic knowledge. But because the random network can recieve augmented images, each image in the dataset will have ""multiple anchors"", and it seems like the online network will just have to learn noise.
2. Why do they need to use the ""predictor"" head in the online network? What is it's purpose?  Couldn't the projection head just have the same role? Why can't the networks be symmetric?",MachineLearning
nt0cdg,1622912810.0,[D] Any good sci-fi books up to date with ML/AI?,"Slightly off topic for the sub, but I think it's still relevant.

Many of us have read a lot of sci-fi in our youth, inspiring us to think beyond what was possible back then. Things like the Internet, brain uploads, self-replicating machines, sentient AI and similar ideas were all seeded in the minds of geeks and scientists decades before they were technically achievable.

Have there been any great sci-fi books around AI published in the last 10-20 years? I'm looking to expand the realm of imaginability for my children, just like my imagination was expanded by ingesting hundreds of books written in 60s-90s.

All recommendations welcome!",MachineLearning
nszb6v,1622909944.0,[R] Research on activity tracker for dogs,"Hello guys, I'm developing an activity tracking app for pets. I'm looking for a dataset of accelerometer values of dog's activities, But I couldn't found one. If anyone having a dataset or know something please let me know. Thanks",MachineLearning
nsvf2m,1622898615.0,[D]Need help with Normalizing Flow 🙇‍♀️,"I'm reading a Normalizing Flow survey Normalizing Flows: An Introduction and Review of Current Methods https://arxiv.org/pdf/1908.09257.pdf And get confused with Section 3.4.2 regarding autoregressive flows MAF and IAF.

The conclusion is absolutely correct, i.e. MAF supports fast density estimation and IAF supports fast sampling. However, it seems to me that the remaining equations, descriptions and figures are all opposite? (I suppose x is the base distribution and y is the target distribution?)

I agree with this blog post, Eric Jang Blog: Normalizing Flows Tutorial, Part 2: Modern Normalizing Flows https://blog.evjang.com/2018/01/nf2.html. But the blog post and the survey paper seem contradictory?

Anyone familiar with Normalizing Flow pleas ping me 🙏Thanks 😉",MachineLearning
nstd3w,1622891200.0,[D] Red flags that indicate that an elderly ML researcher has a hopelessly outdated mindset,"Say, you're considering a distinguished-but-elderly AI / ML researcher as your future doctoral advisor.

You've checked their twitter, and decided against it, because they wrote an opinion about AI / ML that is so outdated, there is no hope that their advise on your long-term research directions will be of any use.

What opinion would be such red flag for you?",MachineLearning
nsq3ai,1622877314.0,[P] H5Records : Store large datasets in one single files with index access,"Recently I tried using TF-Record in Pytorch, however a lot of heavily used features by Pytorch such as data length, index level access isn't available.

Although the storage and performance is great, I really wanted something like TF-Record with build in compression support and the ability to scale well for Pytorch. Some projects do use HDF5 as an alternative to TFRecords (BigGAN Pytorch), however defining the data type isn't particularly user friendly. So I written this abstraction layer to ease the use of HDF5 as a dataset for Pytorch.

So far I have tested it on datasets of size around 200G+ without any major issue. I hope this would be useful for the community when dealing with extreme large datasets.

[Github link](https://github.com/theblackcat102/H5Record)

Edit: repost due to inappropriate tag",MachineLearning
nsplt4,1622875199.0,"[R] CMU Researchers Propose RATT (Randomly Assign, Train and Track), A Method for Guaranteeing AI Model Generalization","**The Approximately Correct Machine Intelligence (ACMI) Lab at Carnegie Mellon University** (CMU) has published a paper on **Randomly Assign, Train, and Track (RATT)**. RATT is an algorithm that uses noisy training data to put an upper bound on a deep-learning model’s actual error risk. Model developers can use **RATT to see how well a model generalizes to new input data**.

The researchers demonstrate mathematical proofs of RATT’s guarantees and conduct experiments on various datasets for computer vision (CV) and natural language processing (NLP) models in their publication. **When a trained model gets a high error rate on randomly labeled (or noisy) data but a low error rate on clean data, the model is assumed to have a low error rate on new data.**

Full Summary: [https://www.marktechpost.com/2021/06/04/cmu-researchers-propose-ratt-randomly-assign-train-and-track-a-method-for-guaranteeing-ai-model-generalization/](https://www.marktechpost.com/2021/06/04/cmu-researchers-propose-ratt-randomly-assign-train-and-track-a-method-for-guaranteeing-ai-model-generalization/)

Paper: https://arxiv.org/pdf/2105.00303.pdf",MachineLearning
nspkdq,1622875028.0,[D] Choosing best parameters from an optimization,"Hey Forum. I wanted to get some help and potentially collaborate/hire someone to help me find / come up with a solution to the below problem and the correct methodology on how to go about it. Here is the background:

&#x200B;

The use case is algorithmic trading. To make a simple example, I use indicators to trade forex/stocks / etc. I perform backtests on data (over 10 to 15 years) and my goal is to determine the best performing indicator input parameter combination. I do my backtesting using a process called ""walk forward analysis/walk forward optimization"" [https://en.wikipedia.org/wiki/Walk\_forward\_optimization](https://en.wikipedia.org/wiki/Walk_forward_optimization) . The goal is to determine how robust the trading algo is (the system) when it runs on ""out of sample data"". The goal is to select the best performing parameters (indicator parameters like stochastic, if that's what you are using), and carry that forward and use those input parameters on your out-of-sample data. so here is what a in sample results look like

&#x200B;

param1	param1	    CAGR/AvgDD

27	         140		10.661

27	        160		       10.236

29	         145	      9.633

31		 150	      12.927

33	        155	               3.952

35	       140	              3.214

37	        145	              5.977

&#x200B;

CAGR/AVgDD is my performance metric. It can be anything really, Profit, or profit factor, etc. Basically, parameters 1, 2, X are inputs to the system. During an in-sample optimization run, for each input parameter that I want to optimize, i pick a start, end and a step. So if there are 3 parameters and each has a start value of 1, the end value of 4, and a step of 1, then you have 4\*4\*4 combinations/passes and each pass will generate a performance metric value. My in-sample runs have a statistically significant amount of data. For example, a run over 4 years (in-sample period) will have at least 5000 to 10000 trades) for each pass/parameter combination.

&#x200B;

So here is the problem that I want to solve. How do I know which single ""pass"" / ""parameter combination"" to select to run on my out-of-sample data set? How do I choose the best-performing input parameter combination? I know it won't always be the one with the highest performance metric value. For example, my highest value can be 10, and the one right below it can be 4.3. Clearly here 10 is an outlier.

what algo or method should be used?

some people have said KNN. Is that true?

can this be done with more than just 2 parameter inputs? what if I am optimizing 3 or 4? is there a downside to optimizing 3, 4, 5, etc different parameters

&#x200B;

I'm also looking for someone to help automate this for me. Looking for someone in math/data science background to help me with this.",MachineLearning
nsiql5,1622850359.0,[D] feasibility of training model,"
What’s the feasibility of training a model to view a video of a person’s head / upper body (as if you were on a zoom call) and be able to estimate the person’s heart rate and/or respiratory rate?

I work in data science so have a decent idea of ML/AI techniques but don’t have a good intuition about what’s hard or feasible in a setting like this.

Any insights are much appreciated.",MachineLearning
nshlhw,1622846741.0,"[P] Dynamic image editing using CLIP and L-grammars, and the implications for HCI.","Hi everyone!

&#x200B;

I am a storytelling researcher at Georgia Tech who has a large interest in computational creativity. I also work at EleutherAI, directing the multimodal grounding subgroup as well as the (less official) computational creativity horde.

&#x200B;

We (EleutherAI) have spent the last few months working on an image editor based off of CLIP that allows you to specify/edit/and most importantly execute natural language substitution rules for editing images. For these purposes we've custom tailored a VQGAN 16k on Wikiart that we feels compliments this style of image editing fairly well.

&#x200B;

This method drastically differs from competitors like LatentRevision in that the masking component is automatic and it differs from StlyeCLIP in that we can perform all editing zero shot, we do not need to train a special model to perform edits. We also use a very different optimization technique thats based off of weighted spherical geodesic distances.

&#x200B;

This is the first stage of a larger computational creativity effort, where not only intend to see how these methods apply to image generation but to text as well. Can we specify ""reviews"" of stories in the form of L-grammars that when executed allow us to constrain and ground a story? Can we use CLIP as a discriminator of stories in a way that makes sense for collaborative writing? More on this project in the coming months ;)

&#x200B;

Here is the colab notebook:

[https://colab.research.google.com/drive/17AqhaKLZmmUA27aNSc6fJYMR9uypeIci?usp=sharing](https://colab.research.google.com/drive/17AqhaKLZmmUA27aNSc6fJYMR9uypeIci?usp=sharing)

&#x200B;

If you just want the wikiart model:

[http://eaidata.bmk.sh/data/Wikiart\_16384/](http://eaidata.bmk.sh/data/Wikiart_16384/)

&#x200B;

Paper and parallel blog post on [https://eleuther.ai](https://eleuther.ai) coming within the next month or so.

&#x200B;

Happy to answer questions!

&#x200B;

If you just want to see how the method performs, here is an example of editing the face of my advisor:

[https://twitter.com/lcastricato/status/1400635291887603716?s=20](https://twitter.com/lcastricato/status/1400635291887603716?s=20)


And here is an example of sequential editing:

[https://twitter.com/lcastricato/status/1394436280239501316?s=20](https://twitter.com/lcastricato/status/1394436280239501316?s=20)",MachineLearning
nsh6uu,1622845481.0,[R] CVPR 2021-Progressive Self Label Correction (ProSelfLC) for Training Robust Deep Neural Networks,"[https://arxiv.org/abs/2005.03788](https://arxiv.org/abs/2005.03788)

[https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021](https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021)

[https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021/issues/2](https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021/issues/2)

**Keywords**: entropy minimisation, maximum entropy, confidence penalty, self knowledge distillation, label correction, label noise, semi-supervised learning, output regularisation

&#x200B;

ProSelfLC is the first method to trust self knowledge progressively and adaptively. ProSelfLC redirects and promotes entropy minimisation, which is in marked contrast to recent practices of confidence penalty \[42, 33, 6\]",MachineLearning
nseiwd,1622838090.0,[D] Accidentally kept the author of previous code in my NeurIPS supplementary material. Will I get rejected for non-anonymous submission?,"Sorry if this thread might sound silly. I just submitted my supplementary material, and in the last minutes, I realized that I had kept the name of the author of some previous ML paper and code, as I used it again for my own submission. The name appears at almost every file from this specific part of the code. I clearly referenced to this paper and its authors, and said that I used their code (besides my own). Thereby that name also appears in my references.

Will I get rejected for non-anonymous submission? Any (former) NeurIPS reviewer having faced this situation or anyone having made the same mistake as me?",MachineLearning
nsbnh8,1622830535.0,[P] Alzheimer's detection and prediction of conversions from mild cognitive impairment using deep learning.,"Hi guys thought you may find this interesting. This was my university dissertation and I thought someone from here may want to build on this for their university project or just check it out. It was coded in Pytorch and it is a multi modal model which takes in both MRI images and clinical information.

What the model does is predict conversions from mild cognitive impairment to Alzheimer's diseases within 3 years for a given subject.

[https://github.com/McSpooder/camull\_net](https://github.com/McSpooder/camull_net)",MachineLearning
nsagsr,1622827374.0,[D] Searching for paper for regression loss variant,"I have used in my code a certain ""mix"" of L1 and L2 loss function like this

l2 / (1 + exp (kappa\*(c - l1)))

with l1=l1 loss, and l2=l2 loss computed over a batch.

I know that I have this from a paper (in the paper they chose specific kappa and c, I think i modified them)-- but I cannot find it anymore. I think it was to penalize higher difference, but be more benevolent to smaller differences.

Does anyone know where this comes from?

Thanks in advance!",MachineLearning
ns8i75,1622822335.0,[D] Suitable Machine learning techniques/ algorithm for anti money laundering,"Can someone suggest recent algos designed for AML fields or material to start learning more?
I have sample dummy data with different banking attributes, how can I get started?",MachineLearning
ns58kj,1622813609.0,[R] Help on hardware for Pose Estimation,"I don't know much about tech so would be very valuable if you could help. I'm in early planning for a golf AI app at the driving range (using 3D pose estimation).

I'm trying to understand the price of the hardware set up for around a golf bay. I've come to the conclusion that I would need; cameras (probably 2 webcams), a NUC, wiring, and a wifi booster. Would this setup be correct? Any information would be much appreciated

I will be happy to pay someone if they could give me helpful information",MachineLearning
ns4yn1,1622812806.0,ResNet50 Implementation for Face Detection [P],Does anyone know any good repositories that have implemented ResNet for Face Detection or face recognition? I want to implement this on my own dataset.,MachineLearning
ns49da,1622810650.0,[D] Differences between Multi-View and Multi-Modal Learning,"Greetings to the community!

I'm currently reading and studying about Multi-Modal Learning. By reading papers on a specific multimodal problem, I came across a Multi-View model.

As I have so far understood and if I'm not mistaken, the scope of Multi-View Learning is to train a model on all views but test it by using a subset of these views. That's not the case for Multi-Modal learning, where the model needs all modalities during inference time.

So is that it? What's the actual difference between views and modalities? Are Multi-View and Multi-Modal models comparable, or do they solve a different problem?",MachineLearning
ns3crk,1622807842.0,[D] Is one RTX 3090 enough for computer vision tasks?,"Hi, I'm a PhD student in an Eastern European university. My department currently is considering building a deep learning workstation to do research. Unfortunately, our budget is limited, and due to the high GPU prices, we can only afford one computer. We also do not consider professional GPUs due to the budget limitations.

We are making a decision now whether to install one or two RTX 3090 GPUs. I understand that the more VRAM the workstation has the better, but I also think that adding two heavy, hot and power hungry GPUs will introduce engineering difficulties, such as cooling and ventilation issues, power supply issues, more expensive UPS setups etc. It is also more expensive of course.

I am going to work with latest state of the art object detection models, YOLO variants, RetinaNet variants etc. Will one RTX 3090 with 24 GB VRAM will be enough to comfortably train these models? If yes, how future proof one RTX 3090 is? Is it worth to pay more and face technical difficulties described above to obtain more VRAM? And how about other areas of computer research that my colleagues might work at, like image classification, segmentation etc?

I don't have enough experience to answer these questions, so advice is greatly appreciated!",MachineLearning
ns2ne8,1622805335.0,[D] What do we know about brain neurons and why can't we recreate one?,"With access to so many advanced physical measuring techniques, why can't we measure exactly how a real neuron behaves, create a computer function to do the same and let it learn?

I imagine one could measure what kind of input causes what kind of output. It's mostly electrical and chemical signals? What is the closest mathematical description of what we know about a brain neuron?

Which part is missing that we cannot measure to create a learning algorithm?

Do we know if the brain sends any kind of signal backwards?",MachineLearning
ns2ene,1622804441.0,[D] Can machines learn covariance ?,"This question came up when I was reading generative model paper : such as VAE.

I've figured out (as far as I know) that probabilistic models does not learn off - diagonal covariance matrix. Instead, they tend to learn only mean and ""variance"".

I assume this is because of the reparameterization trick, or some other practical reasons. It is quite odd that not many papers directly consider about this issue, and this is the reason why I uploaded this post.

So here is my question:

1)  Is there any reason why probabilistic models tend to avoid covariance terms? I want to  know both theoretical and practical reasons

2) Is there any papers/ or models that learns covariance terms? Plus, is it *useful(practical)*?",MachineLearning
ns27ek,1622803689.0,[P] Train Model 3x as large with Dynamic Tensor Rematerialization,"In Deep Learning you can trade space for compute by recomputing activation in backpropagation phase, known as gradient checkpointing. Classical gradient checkpointing algorithm is great but they dont work for eager execution. Dynamic Tensor Rematerialization(DTR) is a gradient checkpointing algorithm that work with eager execution, and is implemented at Megenine, a deep learning framework. Read [this blogpost](https://github.com/MegEngine/MegEngine/wiki/Reduce-GPU-memory-usage-by-Dynamic-Tensor-Rematerialization) to learn more!",MachineLearning
ns1kj4,1622801246.0,"[Project] Text classification for item matching, best setup?","Hi  there, I am building a text classification model to match the name and  description of a customer's item (e.g. name: ""suction press nip"",  category: ""paper machine parts"") to a list of 10k basic items (name:  ""steel, unalloyed"", category: ""metals""). I have some initial matched  data to test and I will get more and more, hopefully.

I've build a sentiment analysis program in the past, this is a good example of what I used: [https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) (Spacy, Scikitlearn).

This  current problem is more complex though, it's 1 to 10k+ match and not  binary (or max 5, 6 values), the string for the item is short and  absolutely at the discretion of the source (client item log).

Which reads/tutorials/examples would you suggest to take a look at? (in Python please)",MachineLearning
ns1hwc,1622800957.0,[P] What ensemble techniques should i use?,"Hey guys!

My project is based on ensemble learning. I have used 4 pre-trained models to obtain my predictions and they are stored in 4 separate CSV files.

I am doing some research on different ensemble techniques but the ones that I have seen so far: use raw data, train and test models, get predictions and apply ensemble methods altogether.


I already have my predictions, so I am trying to look for ensemble methods that simply take in predictions and don't carry out the training and testing models bit.


P.S. I am quite new to coding and ML.

Thanks in advance,

H.",MachineLearning
ns1ag1,1622800152.0,[D] Can someone suggest an open/free face recognition dataset ?,I'm looking for a facial recognition dataset which is free/public to use for research purpose. I need a dataset which includes a relatively high number of images per identity (>200 images per identity) for at least \~30 identities with labels. Do you know any?,MachineLearning
ns0lb9,1622797366.0,[D] Gary Marcus and Luis Lamb -- discussion of AGI and Neurosymbolic methods,"[https://youtu.be/nhUt6mKCPf8](https://youtu.be/nhUt6mKCPf8)

Pod: https://anchor.fm/machinelearningstreettalk/episodes/54-Gary-Marcus-and-Luis-Lamb---Neurosymbolic-models-e125495

Professor Gary Marcus is a scientist, best-selling author, and entrepreneur. He is Founder and CEO of Robust.AI, and was Founder and CEO of Geometric Intelligence, a machine learning company acquired by Uber in 2016. Gary said in his recent next decade paper that — without us, or other creatures like us, the world would continue to exist, but it would not be described, distilled, or understood.  Human lives are filled with abstraction and causal description. This is so powerful. Francois Chollet the other week said that intelligence is literally sensitivity to abstract analogies, and that is all there is to it. It's almost as if one of the most important features of intelligence is to be able to abstract knowledge, this drives the generalisation which will allow you to mine previous experience to make sense of many future novel situations.

Also joining us today is Professor Luis Lamb — Secretary of Innovation for Science and Technology of the State of Rio Grande do Sul, Brazil. His Research Interests are Machine Learning and Reasoning, Neuro-Symbolic Computing, Logic in Computation and Artificial Intelligence, Cognitive and Neural Computation and also AI Ethics and Social Computing. Luis released his new paper Neurosymbolic AI: the third wave at the end of last year. It beautifully articulated the key ingredients needed in the next generation of AI systems, integrating type 1 and type 2 approaches to AI and it summarises all the of the achievements of the last 20 years of research.   We cover a lot of ground in today's show. Explaining the limitations of deep learning, Rich Sutton's the bitter lesson and ""reward is enough"", and the semantic foundation which is required for us to build robust AI.",MachineLearning
nry4ap,1622787024.0,[D] Stanford AI/ML course,"I’m considering the Stanford professional certificate in ML/AI (based on the graduate program) but worried it might be too theoretical.

Not completely new to ML (eg did Andrew Ng’s Coursera course before, read Aurelien Geron’s book) but looking to improve (and mostly become better / more efficient in python coding with sklearn and tensorflow).

Any experiences to share? How does it stack up to other programmes out there (eg MIT/Oxford)?

https://online.stanford.edu/programs/artificial-intelligence-professional-program",MachineLearning
nrxx35,1622786199.0,[D] What should be the data driven chatbot architecture using NLP2SQL?," Given a table, I am able to convert natural language questions into appropriate SQL query with transformers.

The architecture of a chatbot should be:

1. Natural language question to SQL query translation using transformers (this part is completed)
2. Fed SQL query to SQL engine and collect response (this part is completed)
3. Convert SQL engine response to Natural Language Response

How can I accomplish the last part? What kind of architecture or model should I use?",MachineLearning
nrxt4t,1622785751.0,[Research] What are recommended frameworks/libraries for live image segmentation?,"Basically the title. Which libraries/frameworks that offer object detection/instance segmentation (TensorFlow 3D, Mask RCNN, OpenCSV, etc.) are recommended? And is it live through the camera feed? (as in, not just a static image but live?)",MachineLearning
nrx8vn,1622783647.0,[P] Collaboration for ML Research Project,"I'm a data scientist at Nalagenetics, a Biotech startup in Indonesia, and we are looking for a corresponding author with expertise in ML to guide us for a high-impact and value project for healthcare workers in Indonesia. Please DM me if you would like to learn more and collaborate with us.",MachineLearning
nrvqgp,1622778093.0,[R] [IJCAI 2020] Flow-based Intrinsic Curiosity Module,"FICM is a flow-based intrinsic curiosity module to encourage a DRL agent to explore the environment. The rapidly changing parta or moving pattern between agent’s consecutive observations can be interpreted as an important indicator of information when exploring an environment. FICM evaluates novelty and generates an intrinsic reward based on the motion features extracted from two consecutive observations.

Advanced detail please visit: [https://reurl.cc/GmmNnD](https://reurl.cc/GmmNnD)

Paper Download: [https://reurl.cc/YOO33O](https://reurl.cc/YOO33O)

Github Link: [https://reurl.cc/bXXmmd](https://reurl.cc/bXXmmd)

Presentation Link: [https://reurl.cc/7rrVb9](https://reurl.cc/7rrVb9)

ELSA Lab is a research laboratory focusing on Deep Reinforcement Learning, Intelligent Robotics, and Computer Vision. Please visit our website: [https://elsalab.ai/](https://elsalab.ai/)

\#ArtificialIntelligence #ReinforcementLearning #MachineLearning #ComputerVision",MachineLearning
nrrv9o,1622765309.0,[D] Comment on this Binary Image Classifier Architecture - Pairs of Images as Input,"I'm looking for some feedback on an architecture that I'm experimenting with.  It seems to be performing well but I really want to make sure what I'm doing is fair.

My problem is a simple binary classifier.   I have 80k labled images.  They are often subtly different, think foggy or blurry images.  Because of that, traditional 4-6 layer Conv2D networks perform no better than random chance.  I've tried dozens and dozens of variations on that theme but it never even showed a hint of training, even with augmentation.  Traditional transfer learning didn't work because these images really don't share the feature space of VGG16 and other existing models.

Besides being challenging images, I also have a class balance problem. I have 30% of class A and 70% of class B.  In short, I don't have enough images to train from scratch, Class A is the important class, and it's ""expensive"" to get more images.

Here's my new approach, I take pairs of images.  In my use case I only care ""is Class A present?""   I noticed that if I concatenate two images and treat that as one training image, then my possible inputs are AA, AB, BA, BB.  Then notice that corresponds to probabilities of (0.3\*0.3), (0.3\*0.7), (0.7\*0.3), (0.7, 0.7).  If I combine those into ""Class A is present in either image"" and ""Only Class B"" my outputs are suddenly balanced at 0.51 vs 0.49 and also I am now drawing randomly from a pool of 80k \* 80k images, 6.4B images.

All of my original candidate models immediately went from coin flip (garbage) to an AUC of 0.85+ consistently on fairly generated holdout data that the model had never seen.

I have to defend this. (""Does the defense's case hold water?"" if you are a fan of My Cousin Vinny)  Is my approach valid?",MachineLearning
nromuk,1622756062.0,[R] Trajectory Transformer,[https://trajectory-transformer.github.io/](https://trajectory-transformer.github.io/),MachineLearning
nrohy9,1622755700.0,Plotting a decision tree where each node is a figure [D],"Does anyone know how I can plot a binary tree where each node is a figure (eg, seaborn graph) *in python*? I know dtreeviz can do something similar, but I’d like to specify what each image will be. Thank you in advance",MachineLearning
nrnxo6,1622754174.0,[D] Is it legal to create images with an open-source NN implementation and sell them?,"I want to use the recently published VQGAN+CLIP implementation of transformers to generate images based on a text description, and then sell those images in any way I can, maybe through a website. I would use very specific seeds and text, so these images would be almost impossible for anybody to replicate with the same network. Is this legal? As I understand, [VQGAN](https://github.com/CompVis/taming-transformers) and [CLIP](https://github.com/openai/CLIP) are both open-source.

Thank you",MachineLearning
nrm3rx,1622749465.0,[N] Deepfakes talk by Kaggle Grand Master Yauhen Babakin (b.e.s.),"https://preview.redd.it/39quevlnt3371.png?width=1969&format=png&auto=webp&s=d5c215f44c5568f8d08d31ada4d2a56336e6831d

Next **June 14 at 19:00 UTC+2** will be our next **online event**.

&#x200B;

Yauhen Babakin, Kaggle Grandmaster, will talk about Deepfakes.

&#x200B;

The talk will be in English, and English transcription subtitles will be available.

&#x200B;

And at the end of the event will be our Kahoot Quiz.

&#x200B;

Free event. Limited places. Sign up here: [bit.ly/eKDMSpain1](https://bit.ly/eKDMSpain1)",MachineLearning
nrktma,1622746199.0,[D] CV model compression for real-time inference on low powered computers,"Hi, I'm planning a research project for my university that will focus on compressing a SOTA CV model using quantization, pruning, knowledge distillation etc to allow for it to run on lower powered computers like a RPi and such.

I have a few queries:
- How does one effectively structure an ML research project of the aforementioned nature?
- Are there any resources for what I'm trying to do (except TinyML)?
- What is the possibility of achieving my goal if the model takes continuous video input? What challenges might I face and how can I best mitigate them?

TIA!",MachineLearning
nri3p5,1622739137.0,[D] Does anyone use Orange in their ML workflow?,"Orange seems to be default included in Anaconda and I've always wondered how useful it it. I've gone through a couple tutorials on how to use it, but i cant really find a use for it in my own work.

&#x200B;

has anyone here actually used it before, and if so do you find it useful and do you use it regularly?

what tasks does it work well to streamline?

and finally, once you've completed your analysis/testing on a ML design, what do you typically do after that for full implementation? (whats your process?)

&#x200B;

i feel like it may actually be a really cool tool if i can just pend enough time to actually learn it fully, but am not sure if its really worth committing too as i haven't really heard anyone use it, and the online resources are very limited.",MachineLearning
nrgyoa,1622736149.0,"[R] Anti-Koopmanism and ""Koopmanism is Wrong""","Hello everyone!

Over the past couple of years, I have been working on problems surrounding Dynamic Mode Decomposition. This is an intersection between time-series analysis, machine learning, and mathematical operator theory.  I want to present a paper that my colleagues and I just posted to arXiv, and also some fun YouTube videos that go over the contents.

The theoretical understanding of researchers of this topic are really all over the place. Some of the work rests soundly in ergodic theory, but then gets misconstrued when transported to other contexts.

Truly, like all data science, this topic requires samples, and a more appropriate theoretical underpinning is in sampling theory (akin to Hardy, Shannon, and Nyquist's work).

This paper is my group's take on the theoretical underpinnings of Koopman analysis, and we demonstrate where lots of people go wrong with a bunch of counter examples. We conclude the paper with a cogent numerical routine while avoiding the shortcomings of other approaches.

Our algorithm is very simple compared to what's out there, and we never touch a feature vector. This is really the best way to go about the problem. We just posted this manuscript to arXiv and it is based on a lecture I presented here: ""Koopmanism is Wrong"" [https://youtu.be/qJAIDQjM3K4](https://youtu.be/qJAIDQjM3K4)

The arXiv publication can be found here:

[https://arxiv.org/abs/2106.00106](https://arxiv.org/abs/2106.00106)

I have a series of YouTube videos on this topic, and they are a lot of fun.

""The Parable of Koopman Modes"" [https://youtu.be/uPj\_m5K8oLM](https://youtu.be/uPj_m5K8oLM)

The DMD Algorithm: DMD, QuasiPeriodicity and Juggling  [https://youtu.be/BoIQvGoCAmA](https://youtu.be/BoIQvGoCAmA)",MachineLearning
nrfzhk,1622733577.0,[R] UCSD Researchers Develop An Artificial Neuron Device That Could Reduce Energy Use and Size of Neural Network Hardware,"Researchers at the University of California San Diego developed a novel artificial neuron device, with the help of which training neural networks to perform tasks like image recognition or self-driving car navigation could require less computer power and hardware. The gadget uses 100 to 1000 times less energy and space than current CMOS-based technology to perform neural network computations. The work has been published in a paper in Nature Nanotechnology.

The basic idea behind Neural networks is that each layer’s output is fed as the input to the next layer. And to generate those inputs, a non-linear activation function is required. However, because this function entails transmitting data back and forth between two different units – the memory and an external processor – it necessitates a significant amount of computational power and circuitry.

Paper Summary: [https://www.marktechpost.com/2021/06/03/ucsd-researchers-develop-an-artificial-neuron-device-that-could-reduce-energy-use-and-size-of-neural-network-hardware/](https://www.marktechpost.com/2021/06/03/ucsd-researchers-develop-an-artificial-neuron-device-that-could-reduce-energy-use-and-size-of-neural-network-hardware/)

Paper: https://www.nature.com/articles/s41565-021-00874-8",MachineLearning
nredlk,1622729300.0,[P] Using ML to identify a particular object in a large collection of GSV image data?,"Last month, a six year old boy was fatally shot in a road rage incident on his way to kindergarten. The police have released an image of [the killer's vehicle](https://www.aiden-reward.com/) but thus far there have been no arrests. Because the crime took place around 8 AM, there's a good chance the killer lives or works somewhere near the crime scene.

According to this 2020 [research paper](https://dspace.cvut.cz/bitstream/handle/10467/86098/F3-DP-2020-Burde-Varun-Final_report.pdf?sequence=-1&isAllowed=y) (pdf), it should be feasible to use the Google Streetview API for Python to bulk download GSV images within a specified area (in this case, Orange County, California), then automate the process of searching for this vehicle. Our search is aided by the fact that this particular model of Volkswagen is relatively uncommon.

&#x200B;

>\[The author's combination of GSV data and CNN w/ TensorFlow computational backing\] can result in an application that can be used to find different objects located in space. **A neural network could be trained to find a particular object and find it in the area.** Further, it can be trained to detect an anomaly in the vast data set, which is quite dull and tedious work for a human.

GSV data [isn't free](https://developers.google.com/maps/documentation/streetview/usage-and-billing) (roughly $6-7 USD per 1000 images) but with a **$450,000 reward for tips leading to an arrest** and the potential of putting a child's killer behind bars, could this be an interesting project for someone in the ML community? Is it even technically feasible?",MachineLearning
nrd1rh,1622725522.0,[D]Large memory layer,"Hi,

Nowdays, huge pretrained model computes trillions of weight to absort the large dataset.

Ideally such task should be carried by a huge memory layer while keeping the computation part small:

Ideally, the memory layer should met the following definitions:

1: scalable. The memory can be giga bytes while the training cost remains almost constant.

2: Key-Value: it is a layer that take a key vector and reture a value vector.

3: differentialable: can be trained by SGD along with other network components.

4:sparsity or locality: combined with 1 to achived (quasi-)constant update time

Current softmax/attention type network does not met 1,4 thus is not scalable at all. Some other sparse one seems undifferntialble/ad hoc.

My question is: is there some lastest paper on this diretion that I missed? And is my definition of ideal memory layer make sense? If the definition is OK, let's invent it!",MachineLearning
nr7lc9,1622705390.0,[D]Is ML really data preparation most of the time?,"I thought that the main task of a ML Engineer is to construct the ML Algorithm/Model and to optimize it but I am not longer sure if that‘s actually the case.

I have read a comment somewhere which goes something like this:

„Actually there are no ML Engineers, all of these hired people are gonna do data preparation like 95% of their time because setting up the ML Model is actually trivial. So in most cases you are just a data engineer…“

Is he right?

PS: I remembered a comment which somehow fits this discussion:

„People won‘t pay you to type model.fit(…)“

It‘s not the first time I read comments like this…",MachineLearning
nr7jc4,1622705165.0,[D] What is the smallest dataset you styleGAN2 trained?,I hear somebody on twitter tried successfully to train a 300 sample dataset  GAN. Is it even feasible training with stylegan2 (pytorch) under 1k image dataset?,MachineLearning
nr562c,1622695741.0,[R] STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech,"New publication from Interspeech 2021! We introduced STYLER which is non-autoregressive based style modeling TTS model.

paper: [https://arxiv.org/abs/2103.09474](https://arxiv.org/abs/2103.09474)

demo: [https://keonlee9420.github.io/STYLER-Demo/](https://keonlee9420.github.io/STYLER-Demo/)

code: [https://github.com/keonlee9420/STYLER](https://github.com/keonlee9420/STYLER)",MachineLearning
nr3nz8,1622690430.0,[D] Should I create a label of group of many small adjacent objects in object detection?,"I'm working on object detection models and my dataset sometimes has a lot of small objects (stay far from the seen) (overlapping and nearby) which is really annoying in annotating (it's too small and hard to draw bounding boxes for each of them separately).

So should I create one more (or more) class and name it ""group\_of\_small\_A"" beside ""A"" ? Because I think if I make a few BB and forget those little, it's gonna make evaluation down but if I overdraw BB which also not good (low resolution and it becomes worse after resize before input to the model).

Context: I'm using one-stage DNN detection model.",MachineLearning
nr2lxc,1622686831.0,[D] Heuristics for initializing GP length scale hyperparameters?,"I have been training a sparse Gaussian process using the matern-5/2 kernel and I am having trouble getting the objective function to converge, and I think it has to do with my initialization of length scale hyperparameters.

I am not training on actual function observations, but instead on summations of several function observations and derivatives of the function—due to the particular application.

Currently, I am initializing each length scales as the std. dev. over all training data inputs for the corresponding feature, but it doesn’t seem to be working well. Does anyone know of other heuristics?",MachineLearning
nr2235,1622685021.0,[D] Balancing doesn't seem to work with neural network regressors,"I am currently training a neural network regressor on a highly unbalanced dataset. The huge majority (\~95%) of samples are labeled 0.0 or close to 0.0, whereas other samples are continuously labelled between 0.0 and 1.0.

I train a deep neural network in two different settings.

First, I select a certain threshold, build a binary classifier, train it with BCE and evaluate it on the f1-score. In this setting, unsurprisingly, I find that balancing (though oversampling) highly improves my f1-score.

Second, I use the same architecture but train it as a regressor with MSE. And in this setting, I find that whatever I do to balance my dataset or my training procedure (In particular I tried oversampling and LDS loss-reweighting from ""Delving into Deep Unbalanced Regression - ICML 2021""), my results are always much worse than when using no balancing at all. This is true in terms of MSE loss and also in terms of f1-score (using the aforementionned threshold).

Is this surprising to you? Would you have some insight about why this happens, please?

Thanks :)",MachineLearning
nqykna,1622673990.0,[R] Consistency Regularization for Variational Auto-Encoders,[https://arxiv.org/abs/2105.14859](https://arxiv.org/abs/2105.14859),MachineLearning
nquj8n,1622663230.0,[P] Convect - Instant Serverless Deployment of ML models,"I’ve recently launched Convect ([https://convect.ml](https://convect.ml)) and would love for folks to try it out.

Convect deploys machine learning (ML) models to instantly callable, serverless API endpoints. Using Convect, Jupyter notebook users can deploy trained models from their notebooks and share them with the world in seconds. No web development or infrastructure experience is needed. Convect simplifies the process by being more opinionated than other model deployment workflows.

To give Convect a try, visit [https://app.convect.ml](https://app.convect.ml). You can also try out models without signing into an account on the demo page ([https://app.convect.ml/#/demo](https://app.convect.ml/#/demo)). I would love your feedback.

Some background/context:

Deploying ML models to be used in production entails a different set of skills than training models in a sandbox environment and can get pretty complicated depending on what you’re trying to do. For many data scientists, this “sandbox” environment is a Jupyter notebook. One common approach to “deploying to production” that I’ve seen is turning a model trained with scikit-learn in a notebook into an API endpoint.

From my experience, there are a few ways to deploy a model to an API endpoint  and all of them involve a nontrivial level of effort and time. Examples of some of the steps in the process include pickling a model and uploading it to cloud storage, Dockerizing a model’s prediction code and environment, deploying a Flask app, or getting set up with an ML framework (e.g. MLFlow) or platform (e.g. SageMaker) so you can use the deployment feature in their SDK.

While complex workflows make sense for deploying complex models, I haven’t seen any dead simple deployment solutions for simple models, and that’s what I am working on building with Convect. In this case, simplicity comes at the cost of flexibility, i.e. you give up the ability to customize your infrastructure and runtime environment in exchange for a simple, one-click workflow. My hypothesis is that this tradeoff is worth it in many situations, and I’m curious to see what people are enabled to build when this aspect of the ML workflow is drastically simplified.

Under the hood, Convect creates two artifacts by serializing 1) the model prediction code and 2) all the variables that are in scope in the Python session at deployment time. I’ve made this part of the deployment code public here: [https://github.com/convect-ml/convect/](https://github.com/convect-ml/convect/). These artifacts are then loaded and executed in an AWS Lambda function upon invocation by an API Gateway endpoint.

I’ve talked with 50+ data scientists at small to medium size companies (2-300 employees) and many have identified deployment as a pain point in their workflows. I’ve also spoken with a few data scientists who have indicated that this would help save time on their after-work/weekend side projects.

I’d love for people to try out Convect and to hear about how you use it or how I can improve it to make it useful. I’ve also put together a gallery of examples for training and deploying models to make it easy to quickly get started ([https://convect.readme.io/docs](https://convect.readme.io/docs)) and provided example endpoints that you can use query or even build ML-powered apps on top of ([https://app.convect.ml/#/demo](https://app.convect.ml/#/demo)). Find out more at [https://convect.ml](https://convect.ml). Thanks for having a look!",MachineLearning
nqvuin,1622666629.0,[R] NLP Machine Learning with low RAM,"Hello,

I am trying to do sentiment analysis on a large dataset of news headlines. However, every tutorial I find involves two RAM consuming tasks

\- getting a list of every word in the dataset

\- creating a sparse matrix

&#x200B;

Is there any way to perform this kind of NLP without a sparse matrix? A dataset of tens of thousands of rows becomes near impossible without a machine that costs tens of thousands.


Even with batching, you still need to first have a list of every word in the dataset to create your bag of words. This alone is enough to cause out-of-memory errors on a good laptop (with even 32GB of ram).

&#x200B;

Is there any way to perform sentiment analysis without these constraints?",MachineLearning
nqv24c,1622664566.0,[D] Filling in large number of Bib entries in survey paper.,"Hello! I have been working on a survey paper that now has 170+ bibliography entries which so far have been just stubs (paper title, online link, etc.). Now that the paper is close to the finishing line, I am curious how can I avoid having to fill in all the bibtex fields that journals require. I am just completely sandwiched with other work.

Is there some automated way to just get the right fields filled in? Or should I try to get some paid help through others who are willing to help me with this?",MachineLearning
nqta5t,1622660098.0,[D] Searching a paper: Agent navigates a grid world with text queries of symbols and colors,"Hey guys,

&#x200B;

so some months ago I stumbled upon an interesting paper / blog post I simply cannot find anymore. It has two parts. The first part is about a part of an AI system that generates increasingly harder grid worlds (pictures of the grid worlds were black and white) for another AI to navigate through. The second part was about ""communicating"" what the agent should do / the reward with text queries. For example go and stand next to the blue triangle above the red square.

I know this is a very vage description but maybe anyone here knows the paper I'm talking about :D",MachineLearning
nqt9ip,1622660053.0,[D] Confusion about PyTorch loss functions and discussions/workarounds,"Say that for a single example, my target is a probability distribution over 3 classes, e.g.,

    soft_target = [0.2, 0.7, 0.1]

Let's call these kind of targets ""soft"" targets. I want to minimize the cross entropy of predictions relative to soft targets. Mathematically, this problem is equivalent to minimizing the KL-divergence of predictions relative to soft targets.

PyTorch's [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) unfortunately doesn't support soft targets. So I thought the simple work-around would be to use PyTorch's [KLDivLoss](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html) instead.

I started looking up how PyTorch users would do this task, just to make sure I'm thinking straight. There's a lot of discussion about training with soft targets in the context of label smoothing: see [this github issue](https://github.com/pytorch/pytorch/issues/7455) and [this SO thread](https://stackoverflow.com/questions/55681502/label-smoothing-in-pytorch). There, few people suggest using KLDivLoss for some reason.

One reason is spotted in the github issue: there's a [comment](https://github.com/pytorch/pytorch/issues/7455#issuecomment-718020534) saying that we can't just naively input the same x into CrossEntropyLoss and KLDivLoss. I think people may have been misled by the switch in notation. The line

    KL(x, y) = - sum_k {y[k] * x[k] - y[k] * log(y[k])

should be corrected to

    KL(x, y) = - sum_k {y[k]*log-prob(x[k]) - y[k]*log(y[k])

assuming x is a still a vector of unnormalized scores, not probabilities. After making this correction, I derived the expected result:

    # note that LS(x, y) is defined as the cross entropy of x relative to y, which was smoothed
    KL(x, y) = LS(x, y) - entropy(y).

I'm not sure why that math was useful, as it's easy and numerically stable to add a log-softmax to the final layer in order to use KLDivLoss.

So why are there [all](https://stackoverflow.com/a/66773267) of [these](https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/5) semi-complicated [workarounds](https://snorkel.readthedocs.io/en/master/packages/_autosummary/classification/snorkel.classification.cross_entropy_with_probs.html)? Why isn't everyone just using KLDivLoss for their soft targets? What's so impractical about the -entropy term? In the special case of label smoothing, isn't it much simpler and more abstract to just smooth labels as a preprocessing step, and then train with KLDivLoss?

There's one [comment on cross validated (see the motivation part)](https://stats.stackexchange.com/q/476170) that implies some practical challenge with KLDivLoss, probably about numerical instability. But it doesn't directly say what the problem is. So I'm very confused about why the simple solution of using KLDivLoss doesn't seem to be popular in PyTorch.",MachineLearning
nqhzun,1622626912.0,[P] SimpleT5 : Train T5 models in just 3 lines of code,"simpleT5 is built on top of PyTorch-lightning⚡️ and Transformers🤗 that lets you quickly train/fine-tune your T5 models on custom dataset (pandas dataframe)

🌟GitHub: https://github.com/Shivanandroy/simpleT5

🌟Medium: https://bit.ly/2SJjn5v

🌟Colab Notebook: https://cutt.ly/1nj0MzS",MachineLearning
nqrmpc,1622655923.0,Introducing Sklearn-genetic-opt: Hyperparameters tuning using evolutionary algorithms [project],"I recently released a new open-source python library that makes it easy to fine tune scikit-learn models hyperparameters using evolutionary algorithms.

The package is called Sklearn-genetic-opt and provides several optimization algorithms, build in plots to understand the results, custom callbacks to control the iterations and more.

Check the [documentation](https://sklearn-genetic-opt.readthedocs.io/en/stable/) to get started

If you want to know more the details or contribute, you can check the [Github repository](https://github.com/rodrigo-arenas/Sklearn-genetic-opt)

Install the package runing:

`pip install sklearn-genetic-opt`

I hope this can be useful to the general community and that the package keep growing to bring new features, any feedback is very welcome, still a lot of work to do!",MachineLearning
nqqle6,1622653249.0,[R] Decision Transformer: Reinforcement Learning via Sequence Modeling,"**Paper:** [https://kzl.github.io/assets/decision\_transformer.pdf](https://kzl.github.io/assets/decision_transformer.pdf)

**Website:** [https://sites.google.com/berkeley.edu/decision-transformer](https://sites.google.com/berkeley.edu/decision-transformer)

**GitHub:** [https://github.com/kzl/decision-transformer](https://github.com/kzl/decision-transformer)

Transformers is all you need?",MachineLearning
nqqheh,1622652979.0,[P] train-CLIP: A PyTorch Lightning Framework Dedicated to the Training and Reproduction of Clip,"In order to replicate and further build from OpenAI's CLIP, we’ve been working to create a scalable and easy to use library to train CLIP from scratch:

https://github.com/Zasder3/train-CLIP

As of right now we are working to expand the library to incorporate a recent paper on data-efficient training for CLIP (https://arxiv.org/abs/2104.08945) and further performance boosts. If you’re interested in contributing feel free to send a PR!",MachineLearning
nqnibq,1622645310.0,[D] What's missing in the ML bias debate,"Hey guys, I've noticed that debates about bias in ML / data rarely every consider whether ML should be used for a given decision in the first place. I think it is important to ask a number of questions to determine if ML should (not could) be used to solve a given problem, e.g.:

1. **Can humans handle the decision making equally well at reasonable cost levels?**
2. **Does the decision have a significant impact on a human life?**
3. **Does the benefit of this AI use case outweigh the risks?**

What do you think of these questions? Are they off track? Should more questions be asked?

I've written more about the reasoning behind the questions and give a few examples of use cases where ML, imo, should not have been used in this article:

[https://towardsdatascience.com/whats-missing-in-the-ai-bias-debate-a5d654809a3c](https://towardsdatascience.com/whats-missing-in-the-ai-bias-debate-a5d654809a3c)",MachineLearning
nqn7jg,1622644514.0,[Project] DVC Studio – Git-Based ML Experiments Management,"Hey everyone, our team is working on open-source tools for data scientists: [https://dvc.org](https://dvc.org) and [https://cml.dev](https://cml.dev). These two products help ML teams track ML experiments and run training in the cloud using Git & GitOps approach.

Today we are launching DVC Studio ([https://studio.iterative.ai/](https://studio.iterative.ai/)) - User Interface for DVC and CML. It is an ML experiment tracking and cloud training platform but build with Git and GitOps and DevOps principles in mind.

1. Visualizing dashboard of ML experiments

2. Graphs for your ML training

3. Manages connections to your clouds - data is not stored in Git, but cloud storages :)

4. Modify hyperparameters in UI & run ML experiments in clouds or Kubernetes

All of this through Git, GitOps paradigm and with connection to GitLab, GitHub and BitBucket.


An intro video: [https://www.youtube.com/watch?v=hKf4twg832g](https://www.youtube.com/watch?v=hKf4twg832g)

How it's connected to Git: [https://www.youtube.com/watch?v=5xM5az78Lrg](https://www.youtube.com/watch?v=5xM5az78Lrg)


Looking forward to your feedback!",MachineLearning
nqmw70,1622643644.0,[P] [D]How to get TensorFlow model to run on Jetson Nano?,"Hello -

I am relatively new to ML/AL (went through Andrew Ng's course a few years ago), and I find myself in a bit of a battle in getting a TensorFlow model to work on the Jetson Nano:

I built a model (for ANPR) using TensorFlow and EasyOCR. Over the past week or so, getting TensorFlow to install on the Jetson Nano has been next to impossible. Tons of issues with it (some are documented) and overall I found one person that was able to get it running well which took over 50hrs to install on the Jetson Nano.

This said, there has to be a better way to get a TensorFlow model to run on a Jetson Nano. Possibly I should try to convert and use with ONNX?",MachineLearning
nqlgge,1622639459.0,[D] Goto approach for incorporating global knowledge for semantic segmentation?,"I'm  working on a segmentation project for volumetric images. The data is  too large to be fed into the model (3D Unet) as a whole, so instead, I have been  cutting out subregions. This is of course very limiting, since  information outside of the cutout is lost.

What  are methods to incorporate global information in such a task? Is Google  deeplab's approach using dilation and spatial pooling the way to go or  has something new come up? Thanks!",MachineLearning
nqjos1,1622633507.0,[R] Cybersecurity data science: an overview from a machine learning perspective,"""In a computing context, cybersecurity is undergoing massive shifts in technology and its operations in recent days, and data science is driving the change. Extracting security incident patterns or insights from cybersecurity data and building a corresponding data-driven model, is the key to make a security system automated and intelligent.""

&#x200B;

 By Iqbal H. Sarker, A. S. M. Kayes, Shahriar Badsha, Hamed Alqahtani, Paul Watters & Alex Ng

&#x200B;

Paper: [https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00318-5](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00318-5)",MachineLearning
nqi7zt,1622627867.0,"[N] Sergey Levine: ""Is Reinforcement Learning Sufficient For Designing Generic And Adaptable Robots?""","Hello Guys,

I enjoyed this conversation with Sergy Levine, I want to share with people who maybe interested in we spoke about whether Reinforcement Learning Sufficient For Designing Generic And Adaptable Robots?,  Generalization In Reinforcement Learning VS Supervised Learning, I hope you find this conversation useful.",MachineLearning
nqh1n8,1622622864.0,[D] About the NeurIPS (2021) Author Survey,"NeurIPS is in a really interesting mood this year.  First we had the checklist.  Now we have this author survey:
> All authors are asked to estimate the probability that each of their papers will be accepted in the NeurIPS 2021 review process.  Authors who submitted more than one paper will additionally be asked a second question: to rank their papers in terms of their own perception of the papers' scientific contributions to the NeurIPS community.

According to the survey invite, ""[the] purpose of this survey is to evaluate how well authors' expectations and perceptions of the review process agree with reviewing outcomes.""  I suppose it's interesting to get an idea of authors' confidence in their work, but it feels ... weird.  I also question what sort of genuine insight they can get from it.

As for me, I got stuck in a dark fantasy of reading the rejection email along with an attachment of my acceptance estimate just to twist the knife a bit.  Now, I am extremely confident in the work that I submitted.  But I am much less confident in its chances as it goes through the increasingly random process of peer review.  So I had to be realistic when I filled out my estimate, which showed it being little better than a coin flip to get in.

How are you handling it?",MachineLearning
nqgdqn,1622620095.0,[project] RPG: Learning Recursive Point Cloud Generation,"Want to have a lightweight and efficient point cloud generator with many additional features for free?  Check out our recent work **RPG: Learning Recursive Point Cloud Generation** !

Our RPG starts from a single point and gets expanded recursively to produce the high-resolution point cloud via a sequence of point expansion stages (similar to the idea of ""太極生兩儀兩儀生四象四象生八卦""), where you can not only perform the interpolation between point clouds easily but also unsupervisedly obtain the hierarchical semantic segmentation of a single point cloud or across many!

Project page: https://odie2630463.github.io/rpg-page/

Paper: https://arxiv.org/abs/2105.14322",MachineLearning
nqflsp,1622616857.0,[R]RepVGG: Making VGG-style ConvNets Great Again,"UPDATE: our recent RepVGG model reaches around 83.5% top-1 acc on ImageNet. Not included in the paper but released on GitHub.

Do you still remember what happiness ConvNets (convolutional neural networks) brought to you seven years ago, when you could improve the performance by simply stacking several more conv layers?

&#x200B;

Our recent work RepVGG is a super simple VGG-like architecture. The body has nothing but a stack of 3x3 conv and ReLU. It has a favorable speed-accuracy trade-off compared to other state-of-the-art models. On ImageNet, it achieves over 80% top-1 accuracy! Such good performance is realized by a structural RE-Parameterization so that it is named RepVGG.

&#x200B;

RepVGG uses no NAS, no attention, no novel activation functions, and even no branches! How could a model with nothing but a stack of 3x3 conv and ReLU achieve SOTA performance?

&#x200B;

&#x200B;

https://preview.redd.it/oglxnj00ws271.png?width=567&format=png&auto=webp&s=3d5a179fb176af8ec07a57a34d5cda33d8126db7

https://preview.redd.it/9smbikw1vs271.png?width=558&format=png&auto=webp&s=7b033d870e76cdc45bb43f9c009a17205d84a722

Paper: [https://arxiv.org/abs/2101.03697](https://arxiv.org/abs/2101.03697)

Pretrained models and code（PyTorch）：[https://github.com/DingXiaoH/RepVGG](https://github.com/DingXiaoH/RepVGG). Got 1.7K stars and pretty much positive feedback!

## How simple can it be?

After reading the paper, you may finish writing the code and start training in one hour. You will see the results the next day if you use eight 1080Ti GPUs. If you don’t have time for reading the paper (or even this blog), just read the first 100 lines of the following code, and everything will be crystal clear. [https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py](https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py)

## What is VGG-like?

When we are talking about VGG-like, we mean

1. The model shall have no branches. We usually use “plain” or “feed-forward” to describe such a topology.
2. The model shall use only 3x3 conv.
3. The model shall use only ReLU as the activation function.

The basic architecture is simple: over 20 3x3 conv layers are stacked up and split into five stages, and the first conv of every stage down-samples with stride=2.

The specifications (depth and width) are simple: an instance RepVGG-A has \[1, 2, 4, 14, 1\] layers for its five stages; RepVGG-B has \[1, 4, 6, 16, 1\]; the widths are \[64, 128, 256, 512\] scaled by multipliers like 1.5, 2, 2.5. The depth and width are casually set without careful tuning.

The training settings are simple: we trained for 120 epochs on ImageNet without tricks. You can even train it with a PyTorch-official-example-style script ([https://github.com/DingXiaoH/RepVGG/blob/main/train.py](https://github.com/DingXiaoH/RepVGG/blob/main/train.py)).

So why do we want such a super simple model, and how can it achieve SOTA performance?

## Why do we want VGG-like model?

Except for our pursuit for simplicity, a VGG-like super simple model has at least five advantages in practice (the paper has more details).

1. 3x3 conv is very efficient. On GPU, the **computational density** (theoretical FLOPs/time usage) may achieve **four times** as that of 1x1 or 5x5 conv.
2. Single-path architecture is very efficient because it has a **high degree of parallelism**. With the same FLOPs, a few big operators are much faster than many small operators.
3. Single-path architecture is **memory-economical**. For example, the shortcut of ResNet increases 1X memory footprint.
4. Single-path architecture is flexible because we can easily change the width of every layer (e.g., via channel pruning).
5. The body of RepVGG has only one type of operator: 3x3conv-ReLU. When designing a specialized inference chip, given the chip size or power consumption, the fewer types of operator we require, the more computing units we can integrate onto the chip. So that we can integrate an enormous number of 3x3conv-ReLU units to make the inference extremely efficient. Don’t forget that single-path architecture also allows us to use fewer memory units.

## Structural Re-parameterization makes VGG great again

The primary shortcoming of VGG is, of course, the poor performance. These years, a lot of research interests have been shifted from VGG to the numerous multi-branch architectures (ResNet, Inception, DenseNet, NAS-generated models, etc.), and it has been recognized that multi-branch models are usually more powerful than VGG-like ones. For example, a prior work stated that an explanation to the good performance of ResNet is that its shortcuts produce an implicit ensemble of numerous sub-models (because the total number of paths doubles at each branch). Obviously, a VGG-like model has no such advantage.

A multi-branch architecture is beneficial to training, but we want the deployed model to be single-path. So we propose to **decouple the training-time multi-branch and inference-time single-path architecture**.

We are used to using ConvNets like this:

1. Train a model
2. Deploy that model

But here we propose a new methodology:

1. Train a multi-branch model
2. **Equivalently transform** the multi-branch model into a single-path model
3. Deploy the single-path model

In this way, we can take advantage of the multi-branch training (high performance) and single-path inference (fast and memory-economical).

Apparently, the key is how to construct such a multi-branch model and the corresponding transformation.

Our implementation adds a parallel 1x1 conv and an identity branch (if the input and output dimensions match) for each 3x3 conv to form a RepVGG block. This design borrows the idea of ResNet, but the difference is that ResNet adds a branch every two or three layers, but we add two branches for every 3x3 layer.

&#x200B;

https://preview.redd.it/45fritq7vs271.png?width=259&format=png&auto=webp&s=4db6e4316a34340ca285c392954335276d1253de

After training, we do the equivalent transformation to get the model for deployment. This transformation is quite simple because a 1x1 conv is a special (with many zero values) 3x3 conv, and an identity mapping is a special (the kernel is an identity matrix) 1x1 conv! By the linearity (more precisely, additivity) of convolution, we can merge the three branches of a RepVGG block into a single 3x3 conv.

The following figure describes the transformation. In this example, we have 2 input channels and output channels, so that the parameters of the 3x3 conv are four 3x3 matrices, the parameters of the 1x1 conv form a 2x2 matrix. Note that the three branches all have BN (batch normalization), and the parameters include the accumulated mean, standard deviation, and the learned scaling factor and bias. BN does not hinder our transformation because a conv and its following inference-time BN can be equivalently converted into a conv with bias (we usually refer to this as “BN fusion”). The paper and code contains some details. Just a few lines of code!

&#x200B;

https://preview.redd.it/3cwurmb9vs271.png?width=300&format=png&auto=webp&s=44910ff5701f4302102fe45844cf6d14ac29c783

After “BN fusion” of the three branches (note that identity can be viewed as a “conv” and the parameters form a 2x2 identity matrix), we use 0 to pad the 1x1 kernel into 3x3. At last, we simply add up the three kernels and three biases. In this way, every transformed RepVGG Block has the same outputs as before, so that the trained model can be equivalently transformed into a single-path model with only 3x3 conv.

&#x200B;

https://preview.redd.it/sbhuuy5avs271.png?width=257&format=png&auto=webp&s=4f837cbef4cbd6abce485e32c9768e42da9b6c00

Here we can see what “structural re-parameterization” means. The training-time structure is coupled with a set of parameters, and the inference-time structure is coupled with another set. By equivalently transforming the parameters of the former into the latter, we can equivalently transform the structure of the former into the latter.

## Experimental results

On 1080Ti, RepVGG models have a favorable speed-accuracy trade-off. With the same training settings. The speed (examples/second) of RepVGG models are 183% of ResNet-50, 201% of ResNet-101, 259% of EfficientNet and 131% of RegNet. Note that compared to EfficientNet and RegNet, RepVGG used no NAS nor heavy iterative manual design.

https://preview.redd.it/crtj04icvs271.png?width=226&format=png&auto=webp&s=0ff836e309f9d907556d14d0a941127432655ea3

It is also shown that it may be inappropriate to measure the speed of different architectures with the theoretical FLOPs. For example, RepVGG-B2 has 10X FLOPs as EfficientNet-B3 but runs 2X as fast on 1080Ti, so that the former has 20X computational density as the latter.

Semantic segmentation experiments on Cityscapes show that RepVGG models deliver 1% \~ 1.7% higher mIoU than ResNets with higher speed or run 62% faster with 0.37% higher mIoU.

https://preview.redd.it/zrdh2n3cvs271.png?width=239&format=png&auto=webp&s=725c94f66def83d1dbff81509ad6824bc56d25db

A set of ablation studies and comparisons have shown that structural re-parameterization is the key to the good performance of RepVGG. The paper has more details.

## FAQs

Please refer to the GitHub repo for the details and explanations.

1. Is the inference-time model’s output the same as the training-time model? Yes.
2. How to quantize a RepVGG model? Post-training quantization or quantization-aware-training are both okay.

How to finetune a pretrained RepVGG model on other tasks? Finetune the training-time model and do the transformation at the end.

## Reference

\[1\] Andreas Veit, Michael J Wilber, and Serge Belongie. Residual networks behave like ensembles of relatively shallow networks. In Advances in neural information processing systems, pages 550–558, 2016. 2, 4, 8",MachineLearning
nqeuhy,1622613773.0,"[D] Thoughts on augmenting transformers, knowledge graphs with each other?","This is something I've thought about for a while, transformers are really powerful, and the larger models produce semi-coherent responses to most questions, as long as the question is somewhat straightforward:

> ""Who was the main hero of the lightsaber movie?""

""Luke Skywalker""

But once you add more degrees of reference and abstraction, you see answers like this:

> ""Who was the master of the main antagonist of the lightsaber movie?""

""The master"" (intended: Palpatine)

or we've all seen questions like this:
> ""What happens if you leave milk out of a fridge for too long?""

""Milk is typically inside of a fridge""

While transformers do high dimensional anaysis of these queries, it would be great if you could quantize them, and find the nearest vertices/entities on a knowledge graph. Then try to get the knowledge graph and transformer to learn from each other. The knowledge graph behaves kind of like a discriminator in a GAN.

Has anyone done any work like this or thought of this? Poke some holes into my idea. Basically, I want to quantize some of the high dimensional aspects of text into a knowledge graph, to a transformer, and back, maybe repeat a few times. The benefit a knowledge graph brings is that it's interpretable, can hold ""truth"", and can be used to easily traverse the domain surrounding a transformer query.

I have a few ideas for how I would implement this, but I don't want to go down a rabbit hole if this is a dumb idea and or already tried and failed.",MachineLearning
nqee2u,1622611980.0,[D] Thoughts or opinions on serverless model deployment?,"I've been working on building a serverless ML deployment platform for a few months now and I eventually realized that there's actually a lot of similar platforms out there. But for some reason there's still a lot of divide in the MLOps community between using a serverless solution and using a dedicated server for model hosting. Any ideas why this is the case? Is there anything that would make these serverless solutions more enticing?

[View Poll](https://www.reddit.com/poll/nqee2u)",MachineLearning
nqdyer,1622610375.0,[D] Are there any conferences/journals where reviewers evaluate focused on new applications/areas of research rather than (mostly vain) architectural/algorithmic improvements (that usually don't translate to anything except the extremely specific task they were designed for)?,"I would like to write papers where the focus is on applying existing techniques to new domains/tasks and why the task is important or how different methods perform in this task, rather than having to justify why my method is novel or performs some improvement using a new module/loss function to appear novel to the reviewers? Is this even a possibility?",MachineLearning
nqdg6u,1622608572.0,[D] Training tips on diffusion models (DiffSinger) for a TTS?,"Hi all,

I'm currently playing with [DiffSinger](https://arxiv.org/abs/2105.02446), which is a TTS system extended by diffusion models. For the naive version, It consists of encoders (for embedding text and pitch information) and a denoiser where the encoders' output is used to condition the denoiser. Everything is similar to [DiffWave](https://arxiv.org/pdf/2009.09761.pdf) including denoiser's structure and prediction but the neural net to predict epsilon would be changed to \`epsilon(noisy\_spectrogram, encoder\_outputs, diffusion\_step)\` compared to DiffWave's \`epsilon(noisy\_audio, upsampled\_spectrogram, diffusion\_step)\`.

While I'm successfully training encoders, I got an issue during training denoiser. I used LJSpeech. Here is what I did:

1. First of all, as a preliminary experiment, I try to check all modules to work well by setting denoiser as \`epsilon(noisy\_spectrogram, clean\_spectrogram, diffusion\_step)\` to predict the \`noisy\_spectrogram\`.
2. After the model converges, I went back to the denoiser of \`epsilon(noisy\_spectrogram, encoder\_outputs, diffusion\_step)\` to predict clean\_spectrogram. I detached the encoders\_output from the auto\_grad when the input (to prevent from updating) to the denoiser to fix the conditioner for model convergence. The model was broken when I didn't detach (allow the encoder to be updated during denoiser training).
3. I found that when the range of the conditioner (encoder\_outputs) values is smaller, then the model shows better evidence of successful training.

Bellows are the results I've got so far. The upper one is the sampled (synthesized) mel-spectrogram, and the lower one is the ground truth (on each image).

1. I can see the model converge during the primary experiment:

&#x200B;

https://preview.redd.it/l3nb27ib7s271.png?width=1970&format=png&auto=webp&s=a024b9e4ddb86b5034a512b34828de8e23eec72e

2. When the encoder's output directly input to the denoiser (value range: -9.xxx to 6.xxx):

&#x200B;

https://preview.redd.it/3i0r36ic7s271.png?width=1138&format=png&auto=webp&s=ffa583a0040b110fccc967f5236b6f9d9ebc9031

3. When the encoder's output is multiplied by 0.01 to shrink the range:

&#x200B;

https://preview.redd.it/2p63z0wd7s271.png?width=1368&format=png&auto=webp&s=ce1f2a51bb5c1df08aa6aa9135f911d42fb730c9

For case 2., It shows any clues on training. On contrary, the case 3. shows 'some' levels of training but it is not what we expected. I double-checked the inference part (reverse part), but it is exactly the same as that of 1. and diffwave.

So I just want to know if you have any idea on the successful conditions of the input conditioner of the denoiser. Why does the model show such an unsatisfying result above? Do I miss something to process the conditioner?

I will appreciate all suggestions or sharing of your experience.

Thanks in advance.",MachineLearning
nq7w2f,1622590731.0,"[D] Depth In Tree Based Algorithms vs Neural Networks (""On the Expressive Power of Deep Architectures"" , 2007, Bengio and Delalleau)","I am reading this paper over here ""On the Expressive Power of Deep Architectures"" (2007, Bengio and Delalleau, http://www.iro.umontreal.ca/~lisa/bib/pub_subject/finance/pointeurs/ALT2011.pdf).

In this paper, they make a statement : ""
One of the characteristics that has spurred much interest and research in
recent years is depth of the architecture. In the case of a multi-layer neural
network, depth corresponds to the number of (hidden and output) layers. A
fixed-kernel Support Vector Machine is considered to have depth 2 (Bengio and
LeCun, 2007a) and boosted decision trees to have depth 3 (Bengio et al., 2010).""

If I understand this correctly, a neural network is said to have the same ""depth"" as the number of layers (e.g. a n-layered decision tree will have a depth of ""n""), whereas boosted decision trees are said to have a fixed depth of 3 - no matter how splits the boosted decision tree is said to have.

Does anyone know why this is? Why does a really deep boosted decision tree still only have a depth of 3?

Thanks",MachineLearning
nq7hen,1622589495.0,[D] ICML 2021 Accepted Papers List,"[https://icml.cc/Conferences/2021/AcceptedPapersInitial](https://icml.cc/Conferences/2021/AcceptedPapersInitial)

So many papers by Google!",MachineLearning
nq5b25,1622583378.0,"[D] The ""Institut Lumière"" tries to delete from YouTube the AI enhanced video ""Arrival of a Train at La Ciotat"" made by AI enthusiast Denis Shiryaev","You all have seen this video - it has gone viral around a year ago. Video is already blocked.

Around March-April 2021 ""Lumier Institute"" send a pre-trial claim to delete AI-enhanced version of the video from YouTube. They didn't like that it is different from the original - 60ps and stuff (like, duh, that's the whole point in AI-enhanced videos) + copyrights violation.

A couple of days ago Denis wrote that IL decided to sue him for real this time, and not strike in YouTube. They requested a formal answer in 7 days if the video will be deleted or not.

As Denis says, he has no time, neither money to fight with the lawsuit right now. So he decided to block the video on YouTube.

I was writing about that situation [here](https://irregularadel.substack.com/p/i-will-sue-your-neural-network-institut), and then just now Denis shared his own explanation [here](https://www.youtube.com/channel/UCD8J_xbbBuGobmw_N5ga3MA/community?lb=Ugx12JVrya1kEsgBxLN4AaABCQ). So I decided to post both.

[Denis runs from the train.](https://preview.redd.it/otmuo4v83q271.png?width=1000&format=png&auto=webp&s=26eb28f6ae842b7854f0794285d7ef222e04d68c)

I think that smells super bad. Looks like we will have more and more strange legal cases with AI solutions... What do you guys think about all of that?",MachineLearning
nq4es7,1622581027.0,[D] Unreal Engine Trick with VQGAN + CLIP,">When you generate images with VQGAN + CLIP, the image quality dramatically improves if you add ""unreal engine"" to your prompt.

More context on this Twitter thread: https://twitter.com/arankomatsuzaki/status/1399471244760649729?s=20

This is so cool and funny. The network as a byproduct learned *upsampling* based on language conditioning. LOL. I may be wrong about my stated implication but the results I am seeing are quite fascinating.",MachineLearning
nq2s21,1622576864.0,[D] What's the best ML method to predict weekday performance?,I have historical win/loss data per weekday (from a game). My goal is to find a correlation between gaming performance and a certain weekday (or the weekends). How can I best extrapolate the win/loss ratio i.e. what is the best statistical method to use to predict future weekday performance?,MachineLearning
nq2cg3,1622575760.0,[P] Looking to hire,"Hey guys, I am looking for a team of FTE of AI, and CV specialists that can help automate our process. We are in the fashion space and need to segment clothing from photos, as well as fill avatar bodies with classical computer vision algorithms. Shoot me a message if you or someone you know may be interested.",MachineLearning
nq19h0,1622572998.0,Convolutional neural network for cell images [D],"Hi! I'm not sure if this is the right subreddit for this, but I wanted some advice on using a convolutional neural network. I'm doing a project where I want to detect and count cells in clusters within an image, and was wondering the best way to do it in terms of frameworks or libraries. Are there any examples online that do something similar? Thanks for any advice!",MachineLearning
nq0zo3,1622572321.0,[D] How can C4.5 algorithm split numerical attributr,"How can c4.5 algorithm split numerical attributes? I had encountered one journal paper where the c4.5 decision tree has same attribute with different ranges multiple of time in same rules.

For example: IF age>60 and wealth=poverty and age=>75 then sick
Can somebody explain?",MachineLearning
npzqks,1622569223.0,"[R] Chinese AI lab challenges Google, OpenAI with a model of 1.75 trillion parameters","Link here: https://en.pingwest.com/a/8693

TL;DR The Beijing Academy of Artificial Intelligence, styled as BAAI and known in Chinese as 北京智源人工智能研究院, launched the latest version of Wudao 悟道, a pre-trained deep learning model that the lab dubbed as “China’s first,” and “the world’s largest ever,” with a whopping 1.75 trillion parameters.

And the corresponding twitter thread: https://twitter.com/DavidSHolz/status/1399775371323580417

What's interesting here is BAAI is funded in part by the China’s Ministry of Science and Technology, which is China's equivalent of the NSF. The equivalent of this in the US would be for the NSF allocating billions of dollars a year *only to train models*.",MachineLearning
nptvkk,1622553553.0,"[Project] PaddleOCR: Awesome multilingual OCR toolkits（practical ultra lightweight OCR system, support 80+ languages recognition, provide data annotation and synthesis tools, support training and deployment among server, mobile, embedded and IoT devices）","Hi all,

Technical article,  [https://arxiv.org/abs/2009.09941](https://arxiv.org/abs/2009.09941)

code：[https://github.com/PaddlePaddle/PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)

I am glad to share that my team are working on an open source repository PaddleOCR , which provides an easy-to-use ultra lightweight OCR system in practical. Comparing to the other open-source OCR repos, the performance of PaddleOCR is much more accurate but also the cost inference time is much shorter. Furthermore, the performance is comparable to commercial API solution in some scenarios.

[the visualizations of the general ppocr model](https://preview.redd.it/bhve4ujpdr271.jpg?width=1400&format=pjpg&auto=webp&s=8afd1d2a4483ffe4d683078fa4c9223d42ad3886)

[the visualizations of the general ppocr model](https://preview.redd.it/7srt7rfjdr271.jpg?width=3360&format=pjpg&auto=webp&s=50cadea0d43aa3a73ea24610c3a575273e0ce415)

At present, the stargazers of PadleOCR have exceeded 12K and increase continuously. We hope that more people can benefit from the project.

Thank you and looking forward.

PaddleOCR R&D Team.",MachineLearning
npy08z,1622564885.0,[D] Hypothesizing the Ideal Conditions for Neural Networks vs Random Forests,"Is it possible to speculate what are the ideal conditions required for a neural network to perform well compared to a random forest?

For instance, when dealing with image recognition tasks, we know that Convolution Neural Networks are generally favorable, seeing as how the ""convolution operation"" is very effective at ""understanding images"" (e.g. recognizing edges).

Now suppose we look at a standard ""binary classification task"". Suppose we have a smaller sized dataset (e.g. 15 columns, 5000 rows).

In general terms, we know that a neural network works by approximating small regions of the target function with a collection of ""mini functions"". This is done by calculating a set of weights : in the future, data is passed through this network of weights, and these weights are used to calculate the probability that a new observation belongs to a certain class is calculated. In theory, we could repeatedly pass similar points through the neural network and monitor how the probability of belonging to a certain class incrementally changes.

A random forest is quite different. Look at the decision tree for a second - the decision tree works by randomly making binary partitions in the data. A binary partition is made for a predictor variable, such that this partition tries its best to cleanly separate the classes of the response variable. When a suitable partition is made for the first predictor variable, we move on to the second variable, then the third variable, etc. So in the end, if we imagine our data as a ""big box"", we create these ""mini boxes"" (i.e. terminal nodes) within the ""big box"" : each of these ""mini boxes"" has an ""address"" (i.e. the different partitions, e.g. if var1>5 and var2<10 then ""mini box 1""). Each of these mini boxes is associated with a response label.

The random forest improves the decision tree by bootstrap aggregation: thousands of randomized and smaller decision trees are combined together for improved predictive power and less overfitting. All the trees in the forest are used to collectively decide which ""mini box"" a new observation should be placed in.

My question: based on this very general understanding on how both these algorithms work - can we try to hypothesize what kind of datasets are more suited for neural networks vs random forests? For example, in the random forest algorithm, by using the gini index criteria, it is relatively straightforward to make ""mini boxes"" for categorial predictor variables. However, a neural network would have to one-hot-encode these categorical predictor variables and as a result, deal with more variables (curse of dimensionality) and as well, these one-hot-encoded variables are likely to contain a greater level of sparsity. Furthermore, it might be easier to make general ""mini boxes"" in sparse data compared to using gradient descent with missing values?

I know this is all speculation (and the ""no free lunch theorems"" say that no machine learning algorithm is universally best) - but could we try to speculate and say that certain machine learning algorithms might be better suited for certain types of datasets? Just as Convolution Neural Networks are better for image recognition and LSTM Networks are better at handling sequential data - could we argue that bagging and boosting algorithms (e.g. random forest, gradient boosting) might have an easier time at handling smaller datasets with mixed categorical-continuous variables?

I would be interested in hearing some opinions and thoughts on this.

Thanks",MachineLearning
npxtrk,1622564429.0,[R] How would you simulate online learning in keras,"I would like to train a classification network per sample after being pre-trained on an early part of the dataset. How would you go about this in python tensorflow/keras code?

I'm currently calling the fit() method in a for loop using SGD optimizer at a 0.001 learning rate. I've heard that Adam might reset in some way when the fit() method is called, while SGD is somewhat ""static"".",MachineLearning
npxdjv,1622563270.0,[D] Predictions in survival models with time-varying covariates,"I'm having trouble with making predictions for survival models with time-varying covariates. When using the R flexsurvreg function I can fit parametric models (Weibull, lognormal, exponential, etc) to my data which is in the long format in order to incorporate time-varying covariates (I have intervals with start and stop times every time a time dependent covariate changes value). When training my model with this fit, there's no problem, because I think it is able to know the ID of every row of data (what I mean is, for example, if a certain observation has 3 rows with intervals from [0,1], [1,2], [2,3], it knows that they refer to a single observation) . However, when I try to use the predict() function in order to predict the time-to-event of a new observation which has N intervals of covariates values, it gives me N predictions instead of one prediction. Therefore, it assumes that each of the N rows is a new case instead of assuming that it is only a single case with multiple rows. How can I make a prediction for an observation with multiple rows of time dependent covariates?

TLDR: Having trained a parametric survival model with time-varying covariates, how can I make a prediction of time-to-event of new data with time-varying covariates in R using the predict() function?",MachineLearning
npwvn5,1622561973.0,[R] Georgia Tech & Microsoft Reveal ‘Super Tickets’ in Pretrained Language Models: Improving Model Compression and Generalization,"A research team from Georgia Tech, Microsoft Research and Microsoft Azure AI studies the collections of ""lottery tickets"" in extremely over-parametrized models, revealing the generalization performance pattern of winning tickets and proving the existence of ""super tickets.""

Here is a quick read: [Georgia Tech & Microsoft Reveal ‘Super Tickets’ in Pretrained Language Models: Improving Model Compression and Generalization.](https://syncedreview.com/2021/06/01/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-31/)

The paper *Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization* is on [arXiv](https://arxiv.org/abs/2105.12002?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+arxiv%2FQSXk+%28ExcitingAds%21+cs+updates+on+arXiv.org%29).",MachineLearning
npwmft,1622561315.0,[D] Have you used implicit layers in your research or personal projects?,"I work with physics-based time series models, and not only did the neural ODE paper blow my mind, but it really changed the course of my research. The training is currently slow on these methodologies and they’re fairly specialized, which perhaps explains the lack of mainstream appeal so far, but in my opinion neural ODEs and similar methods will come to dominate machine learning research in the physical sciences

Anyone been working on implicit methods for deep learning problems? Thoughts on their future prospects?

Here is the 2018 paper, in case you are interested:
https://arxiv.org/abs/1806.07366",MachineLearning
npwafu,1622560425.0,[P] Albumentations 1.0 is released (a Python library for image augmentation),"Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data.

&#x200B;

[Examples of new augmentations in Albumentations 1.0](https://preview.redd.it/rzmea4ef1o271.jpg?width=1431&format=pjpg&auto=webp&s=86e2b47ef5b112b14cbed120292ea5c569b64e9c)

# Release highlights:

Albumentations no longer uses the [imgaug](https://github.com/aleju/imgaug) library by default. All previous imgaug augmentations in the library are reimplemented in Albumentations with the same API (but you can still install Albumentations with imgaug if you need the old augmentations).

New augmentations:

* [SafeRotate](https://albumentations.ai/docs/api_reference/augmentations/geometric/rotate/#albumentations.augmentations.geometric.rotate.SafeRotate). Safely Rotate Images Without Cropping.
* [SomeOf](https://albumentations.ai/docs/api_reference/core/composition/#albumentations.core.composition.SomeOf) transform that applies N augmentations from a list. Generalizing of [OneOf](https://albumentations.ai/docs/api_reference/core/composition/#albumentations.core.composition.OneOf).
* [RandomToneCurve](https://albumentations.ai/docs/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomToneCurve). See a [notebook](https://nbviewer.jupyter.org/github/aaroswings/RandomToneCurveTests/blob/main/RandomToneCurveTests.ipynb) for examples of this augmentation.

Other changes: bug fixes, improved serialization that is fully backward compatible, ""ToTensor"" is fully removed in favor of ""ToTensorV2"", logic in setup.py that detects existing installations of OpenCV now also looks for ""opencv-contrib-python"" and ""opencv-contrib-python-headless"".

# More info about the library

To install Albumentations from PyPI run `pip install -U albumentations`

Full release notes: [https://github.com/albumentations-team/albumentations/releases/tag/1.0.0](https://github.com/albumentations-team/albumentations/releases/tag/1.0.0)

Documentation is available at [https://albumentations.ai/docs/](https://albumentations.ai/docs/)

Try the online demo at [https://albumentations-demo.herokuapp.com/](https://albumentations-demo.herokuapp.com/)",MachineLearning
npw5l7,1622560062.0,[N] Synthetic Data Engineering Platform Open for Beta,"**Rendered.ai is looking for synthetic data engineers and computer vision engineers to beta test our Synthetic Data Engineering Infrastructure.** The Rendered.ai engine has demonstrated improved outcomes for computer vision algorithm performance through the use of synthetic data as measured by AP scores through rapid creation and modification of synthetic worlds. Our platform is for synthetic data engineers and computer vision engineers to create, modify, and experiment with synthetic data and is available as a selected beta. Drop us a note at [www.rendered.ai](http://www.rendered.ai/)",MachineLearning
npvjus,1622558408.0,[P] help in collecting a dataset for building a neural network,"hi, I'm a junior developer, and I'm creating a machine learning project.

So please fill out the form below,you will really help me in the development.

\*\*\*The data is completely anonymous and depersonalized so no need to worry about it\*\*\*

It will take you no more than 5-7 minutes

Please distribute this form so that I can finish my project faster

[https://forms.gle/tGmr6fQeD3eucY5YA](https://forms.gle/tGmr6fQeD3eucY5YA)",MachineLearning
npv3t0,1622557157.0,[D] What is the appropriate reward function for maximizing the distance travelled with a limited amount of resources?,"If my agent is like a drone trying to go the farthest with a limited amount of battery, are there readings/paper or reward function that suits this?

I only saw a reward of maximum possible distance minus the distance travelled.

Are there any ways to engineer this reward function?",MachineLearning
npu5h3,1622554388.0,[R] Acceptability of AI in healthcare,"We are still recruiting participants with a knowledge or interest of machine learning for our study exploring the acceptability of artificial intelligence in healthcare. The survey should only take around 5-10 minutes to complete and is being conducted at the University of Liverpool. Please let me know if you have any questions before participating (contact details on link).
https://livpsych.eu.qualtrics.com/jfe/form/SV\_eCCHeVzRvR78goC",MachineLearning
nptpem,1622553039.0,"[D] If you finetune GPT-3, are you cheating?","In its annual Build Conference, Microsoft announced its first GPT-3-powered application, a code generator for the Power Fx data query language.

According to [the Microsoft Blog](https://blogs.microsoft.com/ai/from-conversation-to-code-microsoft-introduces-its-first-product-features-powered-by-gpt-3/), “For instance, the new AI-powered features will allow an employee building an e-commerce app to describe a programming goal using conversational language like ‘find products where the name starts with “kids.”’ **A fine-tuned GPT-3 model** \[emphasis mine\] then offers choices for transforming the command into a Microsoft Power Fx formula, the open source programming language of the Power Platform.”

The question is, wasn't GPT-3 supposed to be an all-purpose language model that can perform multiple tasks without being finetuned? From the [GPT-3 paper's](https://arxiv.org/abs/2005.14165) abstract: “Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art finetuning approaches.”

There isn't much detail on what Microsoft means by ""fine-tuned GPT-3 model,"" but a few scenarios come to mind:

1- GPT-3 can't perform code generation on par with models that have been specially trained for this purpose. Its performance is not stable enough to release it as a product.

2- The vanilla GPT-3 can perform quality code generation, but it is computationally expensive, wastes too much resources, and can't turn in profits. A smaller, optimized version of the model can perform the same tasks at a lower cost.

This led me to the following questions:

1- Can the fine-tuned GPT-3 model perform other language-related tasks (text generation, question answering, etc.)?

2- If not, do you really need GPT-3 for this in the first place? I mean, there are several other Transformer-based architectures that can perform specialized tasks.

3- And finally, if you finetune GPT-3, are you cheating in the sense that you're defying the original goal of the model?

On a separate note, I think Microsoft's GPT-3 generator raises a few other important issues:

1- In its raw form, is GPT-3 a scientific achievement or a product ready for commercialization? (again, from the Microsoft blog: “This discovery of GPT-3’s vast capabilities exploded the boundaries of what’s possible in natural language learning, said Eric Boyd, Microsoft corporate vice president for Azure AI. But **there were still open questions about whether such a large and complex model could be deployed cost-effectively at scale to meet real-world business needs** \[emphasis mine\].”)

2- Does it even make sense to build products on top of the GPT-3 API given that Microsoft has an exclusive license to the technology, hosts the model, and can basically do whatever you do with the language model faster, better, and at lower cost?

I'm interested to know what the community thinks about this. You can find my full analysis here:

[https://bdtechtalks.com/2021/05/31/microsoft-gpt-3-and-the-future-of-openai/](https://bdtechtalks.com/2021/05/31/microsoft-gpt-3-and-the-future-of-openai/)",MachineLearning
npdtca,1622496410.0,"[D] A Theoretical Review on ""Rethinking Attention with Performers (ICLR 2021 Oral)""","I make some time to make a theoretical review on an interesting work from Choromanski et al. (2021) with the title of “[rethinking attention with performers](https://openreview.net/forum?id=Ua6zuk0WRH),” which is presented as an oral paper in ICLR 2021. I assume that you have skimmed the paper, to focus on their theoretical analyses. I hope it helps your reading!

**Part 1:** [https://youtu.be/prP2fCUNRdE](https://youtu.be/prP2fCUNRdE?fbclid=IwAR1wmQzzJepBrkT2o9WUs5566vwJkZ1-RB-0K9vecoV-_EUx1RizW3Nse3M)

* Preliminaries on attention mechanism
* Generalized kernelizable attention
* Work-through of the proofs of Lemma 1 and 2.

**Part 2:** [https://youtu.be/I6Skr4Khhqk](https://l.facebook.com/l.php?u=https%3A%2F%2Fyoutu.be%2FI6Skr4Khhqk%3Ffbclid%3DIwAR2q_a3Q2Sy82wkG9qYKt5EKtPNwVQIOVDUXTIRaeBwHci8NrSMVEcVNGU4&h=AT0xcirDAr_8UK9oWWVBLwU2fPeR0ttdzg91ieXj3nisa_W4at9jlXn5NmpibUWr5IuY2qvLarrnLehZE26GRGcA49xp7SMEpaS6fAbyPi_FUvQjB0kMuFL8Zj16pFQ0WEMPniM&__tn__=-UK-R&c[0]=AT2YhEEmk1ttWx8WyENwHNCkkky2QiZX9Oq0fIh3H673Cln5sq_tRx_65MotZEGcrlNhic81PBw33rZvbYWB8ooPX5AxNk9Mu-1nVA7hjH550wjtIhcHbsoCxRXYIACDAH1GmH5B0YAVHb_9G9eiQ2hsTQTL5knWkjb2EgN75GIee51d4gdjpD_7gy1NFqYkE8tPm6gCgCeMiSv1Jg)

* Theorem 2 states that if we choose orthogonal random samplings instead of Gaussian random samples, the mean squared error is improved with a specific margin.
* Lemma 4 gives the inequality for a tail probability using Legendre transformation.
* Theorem 5 states the orthogonality provides smaller tails, where we use a trick with canonical basis vectors to prove this.
* Lemma 5 gives an insight into “beautiful things” with Gaussian distribution.
* Lemma 6 shows the upper bound on the analysis of chi distributions.",MachineLearning
npt9fe,1622551877.0,[N] AWS Announces Redshift ML To Allow Users To Train Machine Learning Models With SQL,"Amazon has announced the general availability of [Redshift ML](https://aws.amazon.com/redshift/features/redshift-ml/), enabling customers to utilize SQL to query and combine structured and semi-structured data across various data warehouses, operational databases, and data lakes. Redshift ML can deploy, train, and create machine learning models directly from an Amazon Redshift instance.

Previously, AWS customers who wanted to process data from Amazon Redshift to train an AI model were required to export the data to an Amazon Simple Storage Service (Amazon S3) bucket. Then they can configure and start training. The process needed many different skills and more than one person to complete, thereby raising the barrier to entry for enterprises aiming to forecast revenue, predict customer churn, detect anomalies, etc

Full Article: [https://www.marktechpost.com/2021/06/01/aws-announces-redshift-ml-to-allow-users-to-train-machine-learning-models-with-sql/](https://www.marktechpost.com/2021/06/01/aws-announces-redshift-ml-to-allow-users-to-train-machine-learning-models-with-sql/?_ga=2.90407449.2041055336.1622397040-488125022.1618729090)

AWS Source: [https://aws.amazon.com/redshift/features/redshift-ml/](https://aws.amazon.com/redshift/features/redshift-ml/)",MachineLearning
npsbsx,1622548796.0,Introducing Hyperlib: Simple Deep learning in Hyperbolic space [project],"We have just released a new open-source python library that makes it easy to create the next generation of neural networks in the Hyperbolic space (as opposed to Euclidean). We're calling it [Hyperlib](https://github.com/nalexai/hyperlib).

The Hyperbolic space is different from the Euclidean space - It has more capacity which means it can fit a wider range of data. Hyperbolic geometry is particularly suited to data that has an underlying hierarchical structure. There’s also a growing amount of research documenting the benefits of modelling the brain using Hyperbolic over Euclidean geometry.

We found that existing Hyperbolic implementations were less ready to be applied to real-world problems. Hyperlib solves that, abstracting away all of the complicated maths and making Hyperbolic networks as easy as a pip install. We hope it will inspire more research into the real-world benefits of non-Euclidean deep learning.

You can install Hyperlib using:

`pip install hyperlib`",MachineLearning
npqw6b,1622543593.0,[D] Life expectancy of a 1080Ti (buying decision: used 1080Ti or RTX 2060)?,"It goes without saying that GPU prices are insane right now, but sometimes we still have to spend. I'm setting up a machine to train CNN and LSTM models in keras and need to buy a GPU, but budget constraints limit me to about $600, and I'm a bit torn between getting a new RTX 2060 or a used GTX 1080Ti.

Speed-wise I don't think there's any question that the 1080 is the better choice, but aside from being more energetically expensive I am also worried about how much more life I am able to get out of a used card, physically. I'd imagine that a large number of 1080Ti's in the used market may have come from cryptominers who decide to retire these cards for whatever reason, and while capacitors and fans can last a while are used miner cards going to be a significant problem in a machine that will inevitably also power the cards nearly 24 hours a day 7 days a week? I guess I can avoid the issue of getting a secondhand miner card by only looking for private sellers and going by their words instead of going through big-box stores, but then I lose the safety net of being able to return the card if it's a clunker (although honestly it's not like I'd be able to tell if a card is going to die suddenly within a week, right?)

That and the aspect of not having tensor cores make me worry about how future proof the 1080Ti will be.

Well, what would you do? I guess buying a used RTX 2060 is an option but retailers are slowly restocking their shelves and new 2060s can go for less than used ones.",MachineLearning
npnye9,1622530977.0,[R] Drop Clause boosts Tsetlin Machine accuracy up to +4% and training speed up to 4x,"&#x200B;

[CIFAR-10 Interpretability with and without Drop Clause](https://preview.redd.it/oa8g4rngpl271.png?width=1492&format=png&auto=webp&s=de971d56a36776fedae5c521cb9ec0bac6bc195f)

Tsetlin Machine (TM) with drop clause ignores a random selection of the clauses, the key learning elements of a TM, in each epoch (inspired by dropout).  To explore the effects clause dropping has on accuracy, training time, and interpretability, we conduct experiments on IMDb, SST-2, MNIST and CIFAR-10. By visualizing the TM model, we uncover that drop clause patterns seem more robust, providing pixel-level interpretability for images and word-level interpretability for natural language. Open challenges: Improved Booleanization techniques for color images and self-supervised learning of interpretable TM-based language models. [https://arxiv.org/abs/2105.14506](https://arxiv.org/abs/2105.14506)",MachineLearning
nplhy3,1622521076.0,"[R] Reward Is Enough (David Silver, Richard Sutton)","This is a text-based post only because the paper is behind a paywall and so the Yannic Kilcher video may be more useful to those who don't have access.

Paper:
https://www.sciencedirect.com/science/article/abs/pii/S0004370221000862

Video:
https://youtu.be/dmH1ZpcROMk",MachineLearning
nphjk9,1622507734.0,[D] Are ML phd programs toxic?,"I've heard grad schools can be really toxic but it also varies by field. I am an incoming freshman in computer science and I am interested in studying ML in grad school after I graduate. But I've come across these two posts and it seems the ML phd programs can be really toxic.

&#x200B;

[https://www.reddit.com/r/MachineLearning/comments/n7qrz5/d\_why\_has\_machine\_learning\_become\_such\_a\_toxic/](https://www.reddit.com/r/MachineLearning/comments/n7qrz5/d_why_has_machine_learning_become_such_a_toxic/)

&#x200B;

[https://www.reddit.com/r/MachineLearning/comments/bwwmh9/d\_doing\_a\_phd\_is\_not\_worth\_it\_unless\_exception/](https://www.reddit.com/r/MachineLearning/comments/bwwmh9/d_doing_a_phd_is_not_worth_it_unless_exception/)

&#x200B;

Are ML phd programs really that toxic? I've seen many people advising me to stay away from grad school but at the same time there are a lot of people who claim that phd degree is a bare minimum for research scientists and one needs to have at least a masters degree to be a ML engineer. For those people who pursued grad school in ML, do you think it was worth it? Also, was the environment toxic?",MachineLearning
npfp5c,1622501966.0,[D] How does it sound if paperswithcode also supports you to implement the paper's code in GUI?,"Assuming that they also have a service for you to execute the paper's code in GUI (without coding), you only need to upload your dataset and run the code just by clicking.

What I am feeling is, there are many papers I would like to implement, but it definitely takes time to code it and check its reproducibility. So I usually end up picking one or two papers to implement for time. I am thinking it would be nice if I can also run the code more easily somehow.

Is there anyone who feels the same about this?",MachineLearning
np82ib,1622480509.0,[P] New Parallel Computing Framework,"Hi. I'm in the early release stage for my new python workflow/dataflow compute framework that makes writing parallel python processes simple and transparent. It has CPU/GPU scheduling, containers, hardware parallelism, concurrency, extensible, localized or distributed, etc. very lightweight. Have a look, comment or contribute!

[https://github.com/radiantone/entangle](https://github.com/radiantone/entangle)

With Entangle you can run simple, hardware parallelized code with conditional logic that looks like this. There are some AI/ML examples as well.

```python
result = add(
            add(
                num(6),
                two() if False else one()
            ),
            subtract(
                five(),
                two()
            )
)
print(result())
```",MachineLearning
np828l,1622480489.0,[N] Reinforcement Learning on Real Robots - NeurIPS 2021 Challenge on Robotics in the Cloud Benchmark,"Are you tired of RL in simulation with unrealistic behaviors or intrigued by the sim2real problem? Then participate in the Real Robot Challenge II [https://real-robot-challenge.com/en](https://real-robot-challenge.com/en) hosted as an official NeurIPS 2021 competition. 

&#x200B;

[We have multiple of these platforms hosted similar to a cluster in Tübingen. Extensive baselines and starting packages are provided. Win prizes by participating and solving tasks in the real-world. ](https://preview.redd.it/u5won2bqlh271.jpg?width=1200&format=pjpg&auto=webp&s=279e05daa9b1670f341ee4d6ae1e76683ec2b7b5)

We have multiple of these platforms and you can submit your algorithm similar to a cluster. Tasks range from lifting a cube, orienting it in air to manipulating multiple of them into new 2D shapes.

The goal of this challenge is to design machines that generalize across different settings in the real-world.

For this we are hosting multiple robotic platforms at the Max Planck Institute for Intelligent Systems. Participants  submit their code as they would for a cluster, and it will then be executed automatically on our platforms. This will allow teams to gather hundreds of hours of real robot data with minimal effort.

You can participate in different rounds ranging from relatively simple to extremely hard, from pushing one cube to manipulating multiple ones at the same time.  Extensive baselines and tutorials for example from last year are provided [https://arxiv.org/abs/2105.02087](https://arxiv.org/abs/2105.02087) and for more information we refer to our twitter account [https://twitter.com/robo\_challenge](https://twitter.com/robo_challenge) and our homepage [https://real-robot-challenge.com/](https://real-robot-challenge.com/)

You can likewise win prizes.

Organized by members from MILA, MPI for Intelligent Systems, NYU, Facebook & Deepmind",MachineLearning
np7qdn,1622479592.0,[D] Help with multi-class segmentation Images,"Hi guys I need some help with how to transform my images to create a multi-class segmentation using a U-Net.

My question is regarding the target images, they are 1D with three colors: 0, to background, 128 to my first class and 255 for my second class. When I'm calling the images they get transformed: mask\[mask == 128\] = 1, mask\[mask == 255\] = 2.

I'm using 3 out\_channels for the last part of the U-net and I'm using Cross-Entropy as my loss function. Is this correct? Because I'm feeling that I might need to one hot encode my target masks",MachineLearning
np6w14,1622477265.0,[D] What is considered samples in Tensorflow object detection API?,"In image classification, it is obvious that images are considered as samples but what is considered as samples in Tensorflow object detection API? Are the samples images or the individual objects in the images?

if an image contains 10 objects, should I consider 10 objects as training samples or just a single image?

I need to know this to effectively set batch size and steps for training.",MachineLearning
np6usk,1622477167.0,[P] It Is Now Possible To Generate a Model Audit Report with Shapash,"Many publications say that a trustworthy AI need to be auditable and that companies should build a strong governance on these topics.

**With the new version of** [**Shapash**](https://github.com/MAIF/shapash) **that is now available, you can document each model you release into production.** Within a few lines of code, you can include in an HTML report all the information about your model (and its associated performance), the data it uses, its learning strategy, … this report is designed to be easily shared with a Data Protection Officer, an internal audit department, a risk control department, a compliance department, or anyone who wants to understand his work.

It’s like a “snapshot at the moment” with all the information related to the training of your model and to the upstream steps (data prep, scoping,…).

**Do you need this feature for your models in production?**

**What kind of information would you put in your report?**

For more details :   [MAIF/shapash: 🔅 Shapash makes Machine Learning models transparent and understandable by everyone (github.com)](https://github.com/MAIF/shapash)",MachineLearning
np6mr8,1622476590.0,"[R] NYU, Facebook & CIFAR Present ‘True Few-Shot Learning’ for Language Models Whose Few-Shot Ability They Say Is Overestimated","A research team from New York University, Facebook AI, and a CIFAR Fellow in Learning in Machines & Brains raise doubts regarding large-scale pretrained language models’ few-shot learning abilities. The researchers re-evaluate such abilities with held-out examples unavailable, which they propose constitutes “true few-shot learning.”

Here is a quick read: [NYU, Facebook & CIFAR Present ‘True Few-Shot Learning’ for Language Models Whose Few-Shot Ability They Say Is Overestimated.](https://syncedreview.com/2021/05/31/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-30/)

The paper *True Few-Shot Learning with Language Models* is on [arXiv](https://arxiv.org/abs/2105.11447).",MachineLearning
np6eph,1622475994.0,[D] Supporting the ML Reproducibility Challenge,"Hey, r/ML! I'm one of the creators of [DAGsHub](https://dagshub.com). As some of you might know, an [ML Reproducibility Challenge](https://paperswithcode.com/rc2020) is happening now, organized by Papers with Code, with some of the leading ML conferences.

If you haven't heard about it or didn't consider joining, I think that it provides an awesome opportunity for several reasons:

* It's a chance to work on SOTA research, with a clearly defined goal – I personally took part in the last round of the challenge and it was a lot of fun and very challenging (I learned a lot from the other participants).
* You can create a cool project for your portfolio.
* You'll be helping to advance the field by making sure that the results are replicable.

I care a lot about ML reproducibility, and making machine learning projects easily reproducible is one reason we started DAGsHub in the first place.

We've decided to support the challenge by providing participants ***$500*** per paper reproduced, to help cover compute costs and incentivizing participation, and providing our platform and support from our team and community for the challenge.

This is not a challenge we started, and other organizations are supporting it, but we thought this might encourage more people to participate and think that everyone would benefit.

You can read the full guidelines here: [https://dagshub.com/pages/reproducibility-challenge](https://dagshub.com/pages/reproducibility-challenge)

Would love to answer any questions you might have, or if you have other ideas on how to incentivize reproducibility further.",MachineLearning
np656d,1622475270.0,[D] Can a re-implementation of StyleGAN2 be released with MIT license?,"I have seen the amazing work of *lucidrains* implementing an easy-to-use version of StyleGAN2: [https://github.com/lucidrains/stylegan2-pytorch/](https://github.com/lucidrains/stylegan2-pytorch/).

However, I am puzzled seeing that the license is MIT (which includes commercial use), while the original algorithm from NVIDIA has a very restrictive license that explicitly states it ""*may be used or intended for use non-commercially*"".

Does anyone know if this actually possible or we shouldn't trust that MIT license statement?",MachineLearning
np51lr,1622472361.0,[R] Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging,"&#x200B;

https://preview.redd.it/clpe5fuqxg271.png?width=1476&format=png&auto=webp&s=e86a7880ab32be73da5ce19f74ec3a3e35f7c88c

paper: [http://yaksoy.github.io/papers/CVPR21-HighResDepth.pdf](http://yaksoy.github.io/papers/CVPR21-HighResDepth.pdf)

project page: [http://yaksoy.github.io/highresdepth/](http://yaksoy.github.io/highresdepth/)",MachineLearning
np4ql9,1622471514.0,[Research] Looking for an article or paper similar to Data Augmentation by Pairing Samples for Images Classification,"Hello everyone,

I remember an article from more than a year ago which trained a neural network on a single or a handful of images.
The main idea (I am basing this on MNIST as I remember it from the article) was to build new pictures that were made up of the original training images. One training image for example was 30% ""three"" and 70% ""five"". By using this method you would be able to learn MNIST with 5 images or less if you include more classes in a single training image.


I think this [https://arxiv.org/pdf/1801.02929.pdf](https://arxiv.org/pdf/1801.02929.pdf) is doing pretty much what I am looking for just not for MNIST.


If anyone can point me in the right direction that would be great!",MachineLearning
np4jyd,1622470995.0,[P] OpenChat Video : Opensource chatting framework for generative models,"[https://youtu.be/uN-OBI0n0JE](https://youtu.be/uN-OBI0n0JE)

&#x200B;

* OpenChat is python opensource chatting framework for generative neural models.
* currently OpenChat supports BlenderBot and DialoGPT, and we plan to extend models
* If you use OpenChat, You can talk with AI with **only one line of code** : OpenChat(model=""blenderbot"", size=""large"")
* You can build your own environment, not just terminal or web demo application.
* You can install easily \`pip install openchat\` and detailed information can be found here. ([https://github.com/hyunwoongko/openchat](https://github.com/hyunwoongko/openchat))",MachineLearning
np3lqo,1622468271.0,[D] Paper Explained - Reward Is Enough (Full Video Analysis),"[https://youtu.be/dmH1ZpcROMk](https://youtu.be/dmH1ZpcROMk)

What's the most promising path to creating Artificial General Intelligence (AGI)? This paper makes the bold claim that a learning agent maximizing its reward in a sufficiently complex environment will necessarily develop intelligence as a by-product, and that Reward Maximization is the best way to move the creation of AGI forward. The paper is a mix of philosophy, engineering, and futurism, and raises many points of discussion.

&#x200B;

OUTLINE:

0:00 - Intro & Outline

4:10 - Reward Maximization

10:10 - The Reward-is-Enough Hypothesis

13:15 - Abilities associated with intelligence

16:40 - My Criticism

26:15 - Reward Maximization through Reinforcement Learning

31:30 - Discussion, Conclusion & My Comments

&#x200B;

Paper: [https://www.sciencedirect.com/science/article/pii/S0004370221000862](https://www.sciencedirect.com/science/article/pii/S0004370221000862)",MachineLearning
np2q2r,1622465583.0,[N] Google’s Multitask Unified Model (MUM) Transforms How Google AI Understands Complex Queries,"Google launches a Multitask Unified Model (MUM) that offers expert-like answers to user’s questions with fewer queries to complex tasks. With google search, one can get answers to what they are looking for. However, one needs to type out many questions and perform many searches to get the desired results. Most of us generally require multiple steps (eight search queries on average) to tackle a task with Google. Present search engines are not advanced enough to respond with expert-like answers. 

Article: [https://www.marktechpost.com/2021/05/31/googles-multitask-unified-model-mum-transforms-how-google-ai-understands-complex-queries/](https://www.marktechpost.com/2021/05/31/googles-multitask-unified-model-mum-transforms-how-google-ai-understands-complex-queries/?_ga=2.156869048.2041055336.1622397040-488125022.1618729090)

Google blog: [https://blog.google/products/search/introducing-mum/](https://blog.google/products/search/introducing-mum/)",MachineLearning
np2muc,1622465296.0,[D] kmeans on t-SNE?,"In regards to the recent ""academica fraud"" thread, am I right think that doing a kmeans or similar distance based clustering on t-SNE (or similar embedding) is utter BS?

Because I just read a paper that did that claiming new insight into the domain of the data. Or what am I missing?",MachineLearning
np0zsv,1622459728.0,[D] Randomized image augmentation during training?,"TL;DR: Is it a good idea to apply random augmentation during training (= every image is only seen once) instead of training multiple epochs on the same fixed training set of images randomly augmented beforehand?

So I'm training an OCR classifier to recognize Chinese characters of a specific font in a specific newspaper. I have a very similar font as a .ttf file but very little labeled data (1000 manually cropped characters from the newspaper which I'm using as a validation set). So I generated a png image of about 4000 glyphs (the ones I want the OCR classifier to be able to recognize) from the font file and applied different randomized augmentation to it: random translation, different intensities of random noise, random patches of increased brightness and morphological opening/closing after random noise application. In all combinations I get 36 augmented images from every original glyph image = a fixed synthetic training set of 36x4000 images.

Training GoogleNet on this yields about 20% accuracy when evaluating on the ""real-life"" validation set (not good but it's a start), with the training error going down to almost 0. So I was wondering if, since the augmentation methods are all based on randomness, it might make sense to not have the model overfit on a fixed selection of them, but instead take the original 4000 glyph pngs as a training set and apply a randomly chosen combination of the augmentation methods described above as I load the image. If I'm not mistaken, it will make it more of an online learning approach. It makes a lot of sense to me but I can't find any papers on this. With image augmentation being so wide-spread and much talked-about, why does everybody do it beforehand and train on a fixed data set, trying to combat overfitting afterwards, instead of serving any of an almost infinite number of combinations of different randomized augmentation methods during training, improving generalization and avoiding overfitting? Is it for reproduciblility?",MachineLearning
np0th5,1622459095.0,[D] What does LSTM (compared to FC) do for SAC and TD3 Policy Gradient Methods and when to use them?,"I came across an implementation for continuous actions where SAC uses (1) Fully-Connected Layers, and (2) LSTM. This is the same for TD3.

Here is the example: [https://github.com/quantumiracle/Popular-RL-Algorithms](https://github.com/quantumiracle/Popular-RL-Algorithms)

My questions are:

(a) what advantage does LSTM give for policy gradient methods such as SAC and TD3?

(b) when should you use them?


I am currently training an agent to control its attitude given external physics simulation as forces. I am not sure whether to try and use LSTM for it or no.",MachineLearning
noz8i2,1622452925.0,[P] Prediction Logger for Model Serving,"We’ve recently launched [https://github.com/graphsignal/graphsignal](https://github.com/graphsignal/graphsignal), a prediction logging and monitoring library for model serving applications, i.e. long running servers, but also periodic batch jobs. It will automatically compute statistics for prediction time windows or batches and send them, along with input and output data samples and outliers, to our cloud (works with free account).

One of the goals is to make root cause analysis possible in case of issues with data or model by associating issue related prediction input and output data instances with data metrics and errors. I’m pretty sure many of you are aware of data-related issues in production, which are really hard to troubleshoot without prediction samples and context.

[Graphsignal](https://graphsignal.ai/) visualizes and automatically monitors multiple data metrics for each feature/class for data schema validity and consistency, anomalies, sudden input and output data drift and more.

Here is a [2-minute screencast](https://www.youtube.com/watch?v=g_wNa9A8gr4).

I hope some of you, who deploy/maintain models in production find it useful. I’ll be happy for any feedback.",MachineLearning
nowg24,1622441695.0,[Discussion] Unsupervised vs Supervised learning,"I was recently exposed to unsupervised and supervised learning and from my understanding, the main difference between the two would be whether labelled datasets provided.

However, during the implementation of the code, the models used are largely similar such as the Resnet or Osnet models.

I would like to ask how the code mainly differs for these 2 methods or does it only differ for the input provided. Thanks!",MachineLearning
nov5r7,1622438642.0,[D] Project ideas based on Machine Learning,Hi Radditors Please suggest some Project ideas based on Machine Learning (ML).?,MachineLearning
notwbx,1622435743.0,"[D] ""Deep"" Learning vs ""Wide"" Learning","Today, my friend was telling me about something called the ""universal approximation theorem"", which apparently contains the mathematical foundation behind neural networks work. After watching a lot of youtube videos on this topic, I think I have some understanding on this topic.

Supposedly, a 2 layer neural network can approximate any function - and the error of this approximation is proportional to the number of neurons within the neural network : the more neurons there are, the better the approximation will be. The only problem with this is, that a 2 layer neural network will likely require a very large number of neurons to produce a decent quality approximation - apparently so many neurons, that the computations will become very inefficient. Conceptually, you can imagine a 2 layer neural network as being very ""wide"" looking.

Supposedly, the solution to the above problem is to create neural networks that are ""deep"" instead of ""wide"". So instead of a 2 layer neural network with a very large number of neurons, it's said that a neural network with fewer neurons and more layers is more computationally effective - and these ""deep"" neural networks also have the ""universal approximation"" property.

The question I have: If ""wide"" neural networks require a very large number of neurons to adequately approximate a function, why don't ""deep"" neural networks require a very large number of layers to approximate a function (at a similar level of accuracy)?

What explains this mismatch between the ""number of layer"" and ""number of neurons"" equivalence? Suppose a ""wide"" neural network with a Relu activation function, 2 layers and 1000 neurons is able to approximate some function with an error of 0.05 - clearly, we believe that a ""deep"" neural network (also with a Relu activation function) with 1000 layers with each layer having 2 neurons, is not necessary. Instead, we believe that the number of layers does not need to be so deep.

What explains this mismatch? Why are ""deep"" neural networks typically able to maintain a relatively low number of neurons and layers, compared to ""wide"" neural networks where only the number of layers can be kept small ?",MachineLearning
noop0z,1622422150.0,[D] Papers on disentanglement that study limit/failures of disentanglement?,"Hi,

For some time ago, I read a paper that discussed how some generative model (maybe beta-VAE? VAE-GAN?) can't fully disentangle independent sources of variations in observed data.

&#x200B;

I vaguely remember that it showed how a kind of variations (e.g. hair color in a face dataset)  was spread through multiple dimensions, and how either adversarial loss or additional constraints on the latent space was not a constraint strong enough to achieve full disentanglement.

&#x200B;

Does anyone know papers that study this kind of failed-to-disentangle problems?  I've been trying to recall the paper, but it hasn't come back yet..! Nevertheless, I'd love to know more about works along this line.  Thank you for sharing in advance!",MachineLearning
nolm4q,1622411755.0,[P] Latest TensorFlow 2.5.0 optimized wheels with CUDA 11.3 for Python3.9,"I  built some wheels for the new Tensorflow 2.5.0 with CUDA 11 and cuDNN 8  in case anyone finds them useful. This includes SSE4.X,AVX2,FMA  instructions: I usually build these for skylake march or other  architectures on request (depending on my availability).

[https://github.com/davidenunes/tensorflow-wheels](https://github.com/davidenunes/tensorflow-wheels)

Why is this useful? For when you install the official binaries and see a warning like this:
`Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2`

in case anyone finding these useful, contribute to my coffee addiction ☕ and support these builds and related projects here: [https://github.com/sponsors/davidenunes](https://github.com/sponsors/davidenunes) or [https://ko-fi.com/davidenunes](https://ko-fi.com/davidenunes)

or just say hi [@davidelnunes](https://twitter.com/davidelnunes) on Twitter.",MachineLearning
noby1e,1622383718.0,[D] Discussion about no-code AI development platform,"What do you think of no-code AI model development service like Darwin AI and Crowd AI?

Those services make the users build the AI models only in GUI. Some people would say they prefer to write codes on their own, so they can know how the models are built, but some people would like the no-code service, valuing its convenience more than code customizability. What is your opinion on those services?",MachineLearning
noad89,1622378382.0,"[D] How does anyone get any work done on Cloud? [Vertex AI, etc.]","Looking at the Vertex AI stuff has my back up again.

Sorry, not sorry, to all the ""MLOps"" workers, but for years I've never
understood how fast iteration happens on Cloud, what with waiting for machines
to ""spin up,"" latency accessing ""s3"" buckets, Docker craziness, and the
general ""from 10,000 feet"" view of code and data.  It's like trying to perform
surgery wearing mittens.  Really, how does one get any work done if you can't
even grep a logfile?",MachineLearning
no9q18,1622376024.0,"[R] 99.2% wrong, but my maths AI brainchild is definitely learning - My AI brainchild","Hi..I was inspired by the kind and useful feedback from this group on my first post about using deep learning to mimic how young children learn to add. Here is my second post. Thoughts and feedback would be very much appreciated again ...

[https://mrshrekblogs.com/my-ai-brainchild/99-2-wrong-but-my-maths-ai-brainchild-is-definitely-learning/](https://mrshrekblogs.com/my-ai-brainchild/99-2-wrong-but-my-maths-ai-brainchild-is-definitely-learning/)

&#x200B;

https://preview.redd.it/jveauznbz8271.jpg?width=1200&format=pjpg&auto=webp&s=b044fc5eff9514073dd188c190ba5b9ba6ae9d47",MachineLearning
no9f4v,1622374877.0,[D] Reinforcement learning for inverse kinematics,"I am trying to explore this area for my research.

Need help with understanding problems/shortfall with current implementations. Also, has anyone used the learned model on the actual robot? what were your learnings?",MachineLearning
no91s0,1622373404.0,[D] Is there any way to use multiple google colab accounts' gpu for distributed training?,"I wanna train the RoBERTa language model for Nepali language  from scratch. But neither I have money to get GCP with powerful gpus nor my college has a powerful computer. Therefore I was thinking is there any way to get collective power of multiple google colab machines....

Any help or suggestion is appreciated....",MachineLearning
no8jh3,1622371254.0,[D] ELI5 explanation of Meijer G-functions,"Hi,

I am trying to understand following paper by Michaela van der Schaar about symbolic meta-models: [https://paperswithcode.com/paper/demystifying-black-box-models-with-symbolic#code](https://paperswithcode.com/paper/demystifying-black-box-models-with-symbolic#code) although I am struggling with understanding Meijer G-functions. Can anyone try to write eli5 explanation for them? Thank you in advance.",MachineLearning
no5q8j,1622358894.0,[P] - Potential Logistic Regression Closed Form Solution,"Hey r/ML,

Need a bit of feedback here, so please give it to me if you can! Recently I was thinking about how linear regression does have a closed-form solution but logistic regression doesn't. I've come up with a pretty lazy idea that sort of does give logistic regression an alternative to an iterative GD-derived training process, and I would like to share it to get any suggestions on what to do with it.

You simply formulate the logistic regression problem as linear regression. All you do is take the labels and turn them to -100 (or any small negative number guaranteed to be 0 when plugged into a sigmoid activation) if a given label is 0 and +100 if a label is 1. You feed this into a linear regression solver (where you can just use the normal equation), and then when needing to predict simply pass in your data to the linear regression model and if its output/prediction is closer to 100 than -100 it's 1 and if its closer to -100 than 100 it's 0. This has lead to small 2% decreases in (validation) accuracy, but using a closed-form solution does mean it will run faster.

Not sure what to do this, need a bit of help here. Thank you so much!",MachineLearning
no5k5o,1622358152.0,What is the architecture of the quick96 DeepFake Model? [D],What is the architecture of the quick96 DeepFake Model?,MachineLearning
no4w6y,1622355193.0,[D] Pose estimation,"Can anyone provide me some good beginner resources for pose estimation?
I need some resources where I can learn from scratch.
Thanks in advance.",MachineLearning
no3r7m,1622350312.0,[D] JAX learning resources?,"I have been hearing a lot of great stuff about jax lately. And, from what i understand, google's not gonna give up on this project anytime soon. So i wanted to have a look at it. But, unfortunately i could not find many learning resources for jax, found a couple of blog posts here and there and that's it. So can someone kind enough drop a couple of links to learning resources down in the comments?",MachineLearning
nnz7mp,1622332346.0,[D] Contrastive loss on sequences,"I'm working on labeling a sequence of speech embeddings with a speaker. These speakers aren't known, so usually a unsupervised clustering approach is taken.

My hunch is that I can incorporate some temporal information across the speech embeddings by passing the input embeddings through an LSTM, and then doing the clustering on the hidden states.

To enforce that embeddings from the speakers are close, I've thought of simply encouraging the cosine distance of hidden states for the same speakers to be 1, and for different speakers to be -1. Something along the lines of:

    X = speech embeddings          # shape (N, D1)
    Y = labels                     # shape (N, 1)
    H = LSTM(X)                    # shape (N, D2)

    H = normalize(H, dim=1)        # normalize for cosine
    sim = H @ H.T                  # pair-wise cosine distance in (-1, 1)
    sim = 0.5 * (sim + 1)          # cosine distance in (0, 1)
    target = (Y == Y.T).           # boolean if (i, j) same speaker
    loss = CE(similarity, target)

I have very little experience with this kind of (supervised) contrastive learning, so this was just the a simplistic initial approach I thought of.

When looking at some papers (e.g. SimCLR), it seems that the losses are designed for a source image, an augmented positive, and some negative examples, which seems amenable to a similar simplistic approach. What's the reason why the below loss is so much better?

https://preview.redd.it/3tkzw11zc5271.png?width=870&format=png&auto=webp&s=ebd3dc8c227721d5429d6abbabe5d65c9968b113",MachineLearning
nnxx0s,1622327746.0,[R] E2ETag: An End-to-End Trainable Method for Generating and Detecting Fiducial Markers,"Presentation: [https://www.youtube.com/watch?v=hcGg6SFsLJg](https://www.youtube.com/watch?v=hcGg6SFsLJg)

This work was accepted to BMVC2020.

Link to our paper: [https://www.bmvc2020-conference.com/assets/papers/0890.pdf](https://www.bmvc2020-conference.com/assets/papers/0890.pdf)

E2ETag proposes an end-to-end trainable method for designing, detecting, and enabling fiducial markers with deep learning.  Our method is made possible by introducing back-propagatable marker augmentation and superimposition into training.  The detector used was a modified DeepLabV3+ encoder which predicts marker's localization, projective pose, and class.  The images used for superimposition training were from the ImageNet dataset.  Results demonstrate that our method outperforms existing fiducial markers in ideal conditions and especially in the presence of motion blur, contrast fluctuations, noise, and off-axis viewing angles.",MachineLearning
nnuyzs,1622317915.0,Simple & Fast GAN Training [D],"I'm working on a theoretical project right now which I believe has interesting applications for generative modeling. I've successfully tested the modification suggested by my theory using the implementation of WGAN-GP [here](https://github.com/eriklindernoren/PyTorch-GAN) on MNIST data, but I'm having trouble to get any GAN working on a more complex dataset (I'm a theorist, architecture choices and hyperparameter tweaking scare me :) ). Does anyone have any pointers to a GAN implementation (WGAN-ish preferred for theoretical reasons, but not necessary) which is relatively easy to train on a more interesting dataset (like some low res faces or cats). For some reason (completely unrelated to the NeurIPS supplement deadline), I'd prefer something which can train in less than a day (though faster is even better).",MachineLearning
nns9vh,1622309580.0,[P] Introducing Skim : Platform to help skim through papers in this fast moving research world,"YouTube Video: https://youtu.be/i6cpBQezPSA

After seeing arxiv-sanity down for more than half of the time whenever I visited and going though lot of tweets, I decided to create a better platform which not only solves the problem like arxiv-sanity, but gives lot more features which allows ML folks to stay on it - for almost everything.

Skim aims to be Spotify of the ML world but here, papers are your tracks, racks are your playlist of papers.
We got search, you can follow/unfollow users and conferences, like/unlike racks and papers.

Currently we're planning to bring conferences' related data like deadlines, visualisations of acceptance rate, statistics, a list of papers maintained year wise for that conference in a rack.
More features like images of papers' pages to skim through, finding similar papers, recommending papers, notifications are in our roadmap.

This platform is built in just 2 months and at very early stage of beta. We are open for all sorts of feedback!

Website:
https://skim.vercel.app",MachineLearning
nnro30,1622307713.0,[D] Can I use group normalization on variable sized inputs?,"I am working on a project which involves processing raw audio.  I basically have a few dilated 1D conv networks I am using to build an auto-encoder.  The issue I am hitting is the memory on my gpu which is forcing me to use small batch sizes.  My model currently does not work well without batch normalization.  I would like to try using either group or instance normalization.  The problem I see with these is that they depend on the length of the inputs.  Right now I am training on audio samples of length 2\*\*14 (sampled at 22050 hz.)  However, in practice I will be applying this network to much longer sequences than it was trained on.  I think this would cause the group/instance normalization to be much less noisy than in training which could alter the results.  Any thoughts?  Maybe I could come up with a way to apply group norm in chunks over the time axis.",MachineLearning
nnqrol,1622305039.0,"[D] Dangers of ""parametric"" models","After doing a lot of thinking, I think I am starting to better understand some of the basic concepts behind parametric models vs non-parametric models.

Historically, it was thought that parametric (statistical) models with too many parameters (e.g. regression coefficients, neural networks with too many weights) were said to be prone to overfit training data and generalize poorly to unseen data. Thus, lots of emphasis was placed on methods like regularization : how to simplify parametric models with too many parameters. This includes approaches like L1 regularization (pushes some parameters heavily towards 0), L2 regularization (generally pushes all parameters towards 0) and drop out (randomly cancelling some of the weights within the neural network).

Apparently, these problems contributed to the popularity of non-parametric models. Non-parametric models, e.g. kernel based models such as SVM (support vector machines) and Gaussian Processes (e.g. gaussian process regression) - these models do not have parameters per say. For instance, gaussian process regression directly estimates the response variable by (repeated simulation) using conditional expectation formulas. If you look at the estimation formula used in gaussian process regression, there are no beta coefficients (unlike standard regression). Somehow, this absence of model parameters are desirable for statistical modelling, seeing as this somehow mitigates potential overfitting and poor generalization.

All this is supposedly implied in the famous bias-variance tradeoff: simple models are said to be stable but are too simple to sufficiently capture complexity within the data, complex models are able to capture complexity within the data but are said to be unstable (poorly generalize). Machine Learning is apparently about trying to make these complex models more stable and generalize better.

Here is my question: what initially lead researchers to believe parametric models with too many parameters are prone to overfit? Is there some mathematical formula that showed some relationship between the number of regression coefficients and error or variance? Or some formula showing the relationship between the number of weights in a neural network and the error or variance?

Or was this all empircally observed? I am curious to see the initial justifications and math formulas that first started to warn researchers about the ""dangers"" of having models with too many parameters?

Note: I am aware that models with too many parameters aren't necessarily ""doomed"" to generalize poorly. Apparently models like ""gpt-3"" (famous natural language model developped by ai researchers) are said to have ""millions of parameters"" (neural network weights) and perform incredibly well in the real world. However, I am more interested in the general idea and mathematical justification relating to ""potential poor model performance linked to overparametrized models"".

Why were overparametrized models said to be more prone to overfitting? Is this really why non-parametric models became popular, because the absence of parameters made them more flexible and less prone to overfit? Is this all empirical, or is there math behind it?

Thanks",MachineLearning
nnpwi3,1622302458.0,[D] Garments Crease/Wrinkles/Dirt Removal using Computer Vision?,"Hi Reddit,

I've been looking for some AI/Computer Vision based automated way to remove crease, wrinkles, folds, dirt from clothes in fashion images captured for ecommerce.

I did try to search for GAN based methods or Image inpainting based methods but couldn't find anything reliable. I am looking for some way to retouch the image in a way that the wrinkles/folds/crease/dirt on the clothes could be removed.

I could find few websites which are doing the similar work which I require to attain programmatically but I couldn't find exactly where in computer vision to look for.

Sample Solution:

https://imageedit.ai/

https://retouch4.me/cleanbackdrop

https://studiodrop.com/retouching/


Could anyone provide me any pointers/help what and where I can look?

Any help is highly appreciated. Thanks.",MachineLearning
nnpqxd,1622301983.0,[D] Is a PhD in ML worth it if one doesn't plan on becoming researcher/professor?," I'm finishing a 5-year diploma (MSc equivalent) in applied math (focusing on CS and ML). I'm currently working on my thesis and my advisor straight up suggested for me to continue with a PhD in ML.

I've read various opinions online. Some say a PhD will only give you precious knowledge on the topic to continue your career as a researcher/professor and it's not worth it if you plan on working in the industry. Others say it's a powerful asset for future jobs and will skyrocket your salary.

I see myself most likely working as software engineer, data scientist or ML engineer rather than researcher or professor.

Given that, do you think a PhD is something worth doing in my case?",MachineLearning
nnpgck,1622301103.0,"[D] Has anyone ever used the ""drwhy"" package in R for ""explainable ai""?","https://github.com/ModelOriented/DrWhy

Has anyone ever used this package in R before for trying to ""explain blackbox machine learning models""?  This package (""drwhy"") seems like a comprehensive collection of different algorithms (e.g. lime, shap) meant for explaining blackbox models (e.g. neural networks).

Has anyone ever used this package before? How have your experiences been? Did it prove to be useful? Were the results reliable?",MachineLearning
nnp7vl,1622300399.0,[D] Has anyone transitioned into computational neuroscience from ML research?,"I'm thinking about doing a phd in computational neuroscience after previously researching in machine learning. I enjoyed building models in ML but realized I enjoyed thinking about how humans think more.

Has anyone gone down this path? What are some good subfields to apply my quantitative skills to (not necessarily training nets).

What are some good labs to work in? I'm open to travelling internationally.

What's the fastest way to get a lay-of-the-land?

DM me if you're a current comp neuro student and you'd like to knowledge share. I can provide lay-of-the-land for ML.",MachineLearning
nnp1vy,1622299886.0,[D] Paper explained: Endless Loops: Detecting and Animating Periodic Patterns in Still Images.,"[The animation is generated from a single still image](https://reddit.com/link/nnp1vy/video/1y35wimuo2271/player)

Have you ever taken a still photo and later realized how cool it would have been to take a video instead? The authors of the ""Endless Loops"" paper got you covered. They propose a novel method that creates seamless animated loops from single images. The algorithm is able to detect periodic structures in the input images that it uses to predict a motion field for the region, and finally smoothly warps the image to produce a continuous animation loop. Read the [full explanation](https://t.me/casual_gan/44) in the Casual GAN Papers blog to find out about detecting repetitions in images, predicting the motion field and generating seamless animation loops from flow vectors!

\[[Full Explanation Post](https://t.me/casual_gan/44)\] \[[Arxiv](https://storage.googleapis.com/ltx-public-images/Endless_Loops__Detecting_and_animating_periodic_patterns_in_still_images.pdf)\] \[[Project page](https://pub.res.lightricks.com/endless-loops/)\]

More recent popular computer vision paper explanations:

>\[[CoModGAN](https://t.me/casual_gan/43)\]\[[GANCraft](https://t.me/casual_gan/41)\]\[[DINO](https://t.me/casual_gan/40)\]",MachineLearning
nnolpp,1622298506.0,[News][Research] High-Resolution Photorealistic Image Translation in Real-Time,"Apply any style to your 4K image in real-time using this new machine learning-based approach!

The paper is **High-Resolution Photorealistic Image Translation in Real-Time: A Laplacian Pyramid Translation Network** by Liang, Jie and Zeng, Hui and Zhang, Lei, (2021), [https://export.arxiv.org/pdf/2105.09188.pdf](https://export.arxiv.org/pdf/2105.09188.pdf)

They use high and low-frequency versions of the image to optimize the computation time and resources needed. It can run a 4K image in less than a tenth of a second with a single regular GPU.

**Code publicly available**: [https://github.com/csjliang/LPTN](https://github.com/csjliang/LPTN)

Short read: [https://www.louisbouchard.ai/4k-image-translation-in-real-time/](https://www.louisbouchard.ai/4k-image-translation-in-real-time/)

Video Demo: [https://youtu.be/X7WzlAyUGPo](https://youtu.be/X7WzlAyUGPo)",MachineLearning
nnoij2,1622298251.0,[D] - Dataset management - What is the best tool for a team to collaborate over an Image/Audio dataset?,"Our team is doing several audio and image detection projects and we have not found a great tool for the whole team \[of varying levels of technical expertiese\] to collaborate in. So far, we have ended up going with Dropbox, because it's easy enough for our collection team to view and review images & audio, but also has a robust API to plug into our pipeline. Seems like some options would be Scale / Roboflow / V7 Labs...? Thanks!",MachineLearning
nnnrqb,1622295854.0,[P] StyleGAN2 implementation with side-by-side notes,"Implemented StyleGAN2 model and training loop from paper ""Analyzing and Improving the Image Quality of StyleGAN"".

Code with annotations: [https://nn.labml.ai/gan/stylegan/index.html](https://nn.labml.ai/gan/stylegan/index.html)

This is a minimalistic implementation with only 425 lines of code and lots of documentations and diagrams explaining the model.

* [Github](https://github.com/lab-ml/annotated_deep_learning_paper_implementations/tree/master/labml_nn/gan/stylegan)
* [Paper on arXiv](https://arxiv.org/abs/1912.04958)",MachineLearning
nnjkf9,1622279610.0,The encoder of this deepfake model makes the input larger instead of making it small [D],"[This](https://github.com/llSourcell/deepfakes/blob/master/plugins/Model_Original.py) and [this](https://github.com/deepfakes/faceswap/blob/master/plugins/train/model/original.py) Deepfake model recieves an input of shape: (64, 64, 3) or 12288 values, and the encoder outputs of shape (8, 8, 512) or  32768 values.. The size of the output is larger than the size of the input! But, the job of an encoder is to compress the input but this encoder made the input larger instead of making it smaller.. And, the deepfake still works..... Why does it still works?",MachineLearning
nnjduf,1622278804.0,[D] Any suggestions for regression task in deep learning?,"## background

I am studying how to use video data to predict temporal regression value. Firstly, I tried using some backbone with pretrained parameters. Here is a part of my code.

    class Mynet\_LSTM(nn.Module):
     def \_\_init\_\_(self, model, num\_classes):
     super().\_\_init\_\_()
     self.featureModel = nn.Sequential(\*list(model.children())\[:-1\])
     self.linear = nn.Sequential(nn.LayerNorm(2048), nn.Linear(2048, 256))
     self.rnn = nn.LSTM(256, 128, 2, bidirectional=True, dropout=0.3)
     self.classifier = nn.Sequential(nn.LayerNorm(256), nn.Linear(256, num\_classes))
    ​
     for m in self.modules():
     if isinstance(m, nn.Linear):
     n = m.in\_features
     y = 1.0 / np.sqrt(n)
     m.weight.data.uniform\_(-y, y)
     m.bias.data.fill\_(0)
    ​
     def forward(self, x):
     b, c, t, h, w = x.shape
     x = einops.rearrange(x, 'b c t h w -> (b t) c h w', b=b, t=t)
     x = self.featureModel(x).squeeze()  # -> (b t), 2048
     x = self.linear(x)  # -> (b t), 256
     x = einops.rearrange(x, '(b t) d -> b t d', b=b, t=t)
     x, \_ = self.rnn(x)
     x = einops.rearrange(x, 'b t d -> (b t) d', b=b, t=t)
     x = self.classifier(x)
     x = einops.rearrange(x, '(b t) d -> b t d', b=b, t=t)
     return x
    ​
    \# this is an example how to use my Net
    model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101\_32x8d\_wsl')
    mymodel = Mynet\_LSTM(model, 2)
    frame\_for\_example = torch.rand(2, 3, 16, 400, 400) # b, c, t, h, w

The result are not good as I expected as shown in the picture below. In the training time, it worked so efficiently, but then the performing became worse during the validating time. After few days of debugging, I found out that this is because no matter what the input data is, my network will always show the output as “the last given ground\_truth”. By the way, I am using nn.MSELoss() as my criterion.

&#x200B;

In the case of using CCC as my criterion, the metrics for my tasks should commonly be CCC as well. My results are shown below; even keep training for more than 5-6 epoch, the results are still the same.

##

## question

I would like to know why this strange result happened? And is there any suggestion for me to train the regression network?

Thanks

\--Joanna",MachineLearning
nnivo6,1622276607.0,[D] Why is batch norm becoming so unpopular,I read a few papers recently that stress that the architecture is batch-norm free and know that there are recent advancements by DeepMind and with the Vision Transformers that do not need it. WHY is it so advantageous NOT to have batch norm? The only thing I think I read is that calibration of NN output gets better when not using batch norm.,MachineLearning
nnew1m,1622260335.0,Dataset big enough to train RL agents to accurately identify gunmen with malicious intent [D],"How do I find dataset big enough to train RL agents to accurately identify gunmen with malicious intent and not law abiding citizens. What are my sources other than free internet with information on cartels, ISIS and Boko Haram",MachineLearning
nnenxh,1622259482.0,"[R] Continuous Instrument, Continuous Treatment - Is there an ML causal model to help with this?","

Hey, thanks for reading it, and even more for any help.

I work with historical data: percentage of slave population in my country's counties and its relation to homicide rates nowadays. As when my interest variable was collected, many counties didn't exist yet, there are many many zeros in this predictor.

I am using inequality (gini index) as endogenous treatment and slavery as the instrument: both are numeric. I would like to employ a causal approach to get the indirect effect of slavery: inequality is visible and present, different from historical data.

Is there an ML method that can handle instrument and endogenous as continuous/numeric variables? My advisor asked me to use data science and not only classic econometrics so we can have a kind of 'robustness check' with the test group and in the face of so many zeros.

(if you have an R solution, it would be better, but if there's no other way, God help me with Python)

Thanks again!",MachineLearning
nnbx3b,1622249500.0,[D] Efficient net as a feature extractor in Computer vision,"Most of the feature extractor use Resnet as backbone for feature extraction.  Is there any implementation available with the efficient net as a feature extractor?

Any reason it's not popular considering its give better or similar accuracy with less computation power.",MachineLearning
nn9q8s,1622241971.0,"[P] ArXiv-Miner: A toolkit for scraping, parsing, and searching ArXiv Research Papers","Since the past year, I have been working on research projects around scientific literature mining. A by-product of the research projects was a small search engine named [Sci-Genie](https://sci-genie.com/).

Today I am open sourcing the core library that runs Sci-Genie. ArXiv-Miner is a python library that helps scrape, parse, and mine research from **LaTeX source** on ArXiv. The library also supports Elasticsearch on the storage layer and provides hooks to quickly search indexed research records.

Github Repo: [https://github.com/valayDave/arxiv-miner](https://github.com/valayDave/arxiv-miner)

Documentation: [https://arxiv-miner.turing-bot.com/#/](https://arxiv-miner.turing-bot.com/#/)

Please note, this doesn't parse PDF and but I am very happy to have contributors to help make it better. I hope this helps anyone working in the field.",MachineLearning
nn9bkm,1622240699.0,[R] Recommended: Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges," by Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova, and Chudi Zhong


10 technical challenge areas:


(1) Optimizing sparse logical models such as decision trees;
(2) Optimization of scoring systems;
(3) Placing constraints into generalized additive models to encourage sparsity and better interpretability;
(4) Modern case-based reasoning, including neural networks and matching for causal inference;
(5) Complete supervised disentanglement of neural networks;
(6) Complete or even partial unsupervised disentanglement of neural networks;
(7) Dimensionality reduction for data visualization;
(8) Machine learning models that can incorporate physics and other generative or causal constraints;
(9) Characterization of the “Rashomon set” of good models; and
(10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.

Paper: [https://arxiv.org/abs/2103.11251](https://arxiv.org/abs/2103.11251)",MachineLearning
nn9160,1622239841.0,"[N] Anthropic is the new AI research outfit from OpenAI’s Dario Amodei, and it has $124M to burn","[TechCrunch article](https://techcrunch.com/2021/05/28/anthropic-is-the-new-ai-research-outfit-from-openais-dario-amodei-and-it-has-124m-to-burn/)

[Company announcement](https://www.anthropic.com/news/announcement)

From About page:
""Anthropic is an AI safety and research company that’s working to build  reliable, interpretable, and steerable AI systems. Large, general  systems of today can have significant benefits, but can also be  unpredictable, unreliable, and opaque: our goal is to make progress on  these issues.  For now, we’re primarily focused on research towards  these goals; down the road, we foresee many opportunities for our work  to create value commercially and for public benefit.

Our research  interests span multiple areas including natural language, human  feedback, scaling laws, reinforcement learning, code generation, and  interpretability. The easiest way to understand our research directions  is to read some of our team’s previous work, such as: [GPT-3](https://arxiv.org/abs/2005.14165), [Circuit-Based Interpretability](https://distill.pub/2020/circuits/), [Multimodal Neurons](https://distill.pub/2021/multimodal-neurons/), [Scaling Laws](https://arxiv.org/abs/2010.14701), [AI & Compute](https://openai.com/blog/ai-and-compute/), [Concrete Problems in AI Safety](https://arxiv.org/pdf/1606.06565.pdf), and [Learning from Human Preferences](https://arxiv.org/abs/1706.03741).""

Thoughts? OpenAI may have been divisive with some of their PR in the past, but they definitely do have/had some great minds working on policy and safety (many of whom seem to be going to this), so personally I find it cool.",MachineLearning
nn1sxa,1622219811.0,[D] Prediction using time-varying covariates in Survival Analysis,"Hi guys! I'm having trouble with making predictions using time-varying covariates. I already prepared a dataset with the appropriate format in order to include time-varying covariates (for each event or censored observation, I have several intervals with the start and stop time and the values of the time-varying covariates in those intervals). But my issue is: when I'm at a certain time t, and I have the values of the time-varying covariates up until that moment t, how can I estimate the remaining time-to-event? Because obviously I don't know the values of the covariates after moment t... Even if wanted to assume that the most recent values are the ones that will stand after moment t, I don't know the stop time of the last interval (the one that starts at time t and finishes at the time of the event) because obviously I don't know the time of event that I'm trying to predict. So how can I make this prediction of the remaing life at time t, and how is it done in R? Also, is it possible to do this with Cox PH model or with parametric models?",MachineLearning
nn1snv,1622219792.0,[D] GraphDF (Graph Deep Factors for Forecasting) implementation anywhere?,"Hi all,

I came across the GraphDF[ paper](https://arxiv.org/abs/2010.07373) a while ago (it's dated Oct 2020), seemed interesting, and I've been checking periodically for an implementation. A couple projects/libraries I work with have already requested it too.

Does any of you know about it?

Thanks in advance!",MachineLearning
nn13l6,1622217846.0,[R] AndroidEnv: A Reinforcement Learning Platform for Android,"[https://deepmind.com/research/publications/androidenv](https://deepmind.com/research/publications/androidenv)
[https://arxiv.org/abs/2105.13231](https://arxiv.org/abs/2105.13231)
This is similar to what OpenAI Universe aspired to be.",MachineLearning
nmzrjv,1622214153.0,[P] I need help generating GST reference wav file in this colab," Hi

I am trying to clone voice and I found [this colab](https://colab.research.google.com/drive/1JX29gDcsPHx5HlbwNkpHnPQkhhrSvrji?usp=sharing) but its giving me a hard time due to the absence of reference Global Style token wav file of my voice.

I have seen section 4 of this [gst-tacotron](https://github.com/syang1993/gst-tacotron) but it doesn't have pretrained weights to use the eval.py

Can anyone please help me generate a good GST reference wav file or help with voice cloning in general?",MachineLearning
nmxefj,1622207079.0,[D] Architecture Search in practice - what's your go-to?,"There's been tons of papers on NAS, but in my experience most suffer from being either a) very slow, b) not easily applied to existing code, or c) focused on one application (mostly image recognition). Also, there's a big difference between looking good in a paper and being a useful and versatile library.

If you're using a particular library, I would love to hear your experience, the good and the bad. (Pytorch-based ones in particular)",MachineLearning
nmxd09,1622206950.0,[D] What is binarization in the context of NLP and fairseq library?,"I find the developers in fairseq library recommending the binarization of text before inference or training, however I looked over the internet and I didn't find a clear explanation of what binarization is.",MachineLearning
nmwvi6,1622205279.0,[D] Graph embeddings of Wikidata items,"I'm trying to use PyTorch BigGraph pre-trained embeddings of Wikidata items for disambiguation.  The problem is that the results I am getting by using dot (or cosine) similarity are not great. For example, the similarity between the Python programming language and the snake with the same name is greater than between Python and Django.  Does anybody know if there is a Wikidata embedding that results in better similarities?

&#x200B;

|Wiki Item 1|Wiki Item 2|dot|cosine|
|:-|:-|:-|:-|
|Q28865 (Python language)|Q271218 (Python snake)|17.625|0.64013671875|
|Q28865 (Python language)|Q10811 (Reptiles)|8.21875|0.300048828125|
|Q28865 (Python language)|Q2407 (C++)|25.296875|0.919921875|
|Q28865 (Python language)|Q842014 (Django Python)|11.34375|0.409912109375|
|Q271218 (Python snake)|Q10811 (Reptiles)|11.25|0.409912109375|
|Q271218 (Python snake)|Q2407 (C++)|12.5390625|0.4599609375|
|Q271218 (Python snake)|Q842014 (Django Python)|6.05859375|0.219970703125|
|Q10811 (Reptils)|Q2407 (C++)|4.76171875|0.1700439453125|
|Q10811 (Reptils)|Q842014 (Django Python)|\-0.60009765625|\-0.0200042724609375|
|Q2407 (C++)|Q842014 (Django Python)|11.53125|0.419921875|",MachineLearning
nmwl6n,1622204258.0,[P] Semantic similarity between programming languages and math terminology,"I've wondered how good neural nets can get at predicting semantic similarity at a more abstract level between different topics. For example, finding context between math terminology like 'vector' and 'matrix' and programming terminology like 'list/array' and '2d array'. Also, finding context between common data types, functions, concepts between different languages and frameworks/libraries. Ideally, I'd want a binary output that takes two strings as input to compare.

Question is what would be the approach to a problem like this, would it need carefully labelled data ('translating' the terminology between the two topics) or is a self-supervised method at all possible? I've only recently got into data so I could be way off here on what is possible and what is not.",MachineLearning
nmuywe,1622198351.0,[P] Pseudo-Labeling on MNIST dataset,"I couldn't find any good resources/code examples on Pseudo labeling on MNIST dataset, so ended up experimenting and figuring it out on my own. This is the results of my experiments

[https://github.com/consequencesunintended/Pseudo-Labelling](https://github.com/consequencesunintended/Pseudo-Labelling)",MachineLearning
nmu4y6,1622194920.0,[Discussion][Research] Fault Detection and Diagnosis for telemetry data in near real time,"I'm concerned about an industrial IoT scenario where the various telemetry data(temperature,humidity and etc) of machinery will be logged and sent near real time to analytics layer which will then process on detecting any fault that can happen in near future.

Here I'm worried about that do we need to implement ML model to predict the future telemetry data values first and then based on the predicted values do we have to pass that values to a FDD (Fault Detection and Diagnosis) model to prevent any fault that can happen in future( within the predicted time period)",MachineLearning
nmtyu8,1622194188.0,Datascience vs Automation RPA future prospects [D],"Hi Everyone,

I started my professional journey only a few months back. I was put into the Automation team, which is totally out of my area of expertise as I have had no background in computer engineering. I majored in Economics with a minor in computer science, and have always felt that I would be more suitable for a datascience related role. But being this early in my career, I have heard sayings like ""You shouldn't fixate yourself on one field this early"", so I am super confused on how to proceed.

Should ask my manager for a switch to another team, as this will result in severing whatever relationship I have built with my manager (which I might regret later). Or should I keep at it and see where this takes me. I guess it boils down to:

1. Is it recommended to work in a field that I see no future in yet, but does broaden my skill set?
2. Will it put me at a disadvantage if I dont get direct exposure to datascience projects, if I do want to pursue datascience in future?
3. How are the future prospects of Automation/RPA in comparison with data science?

Sorry for the long winded question, this has been troubling me for quite some time, so please mind if its comes out a little vague. Any type of guidance is hugely appreciated.

Thank You!",MachineLearning
nmt2bu,1622190086.0,[D] Will JAX be the next big thing?,I would like to know of you if you think that JAX will disrupt Pytorch in the future as the new „Tensorflow“?,MachineLearning
nmsg5e,1622187325.0,[D] [R] Any reviews about DARTS ?,"Hello !

I'm working on autoML, and have been discovering some of its fields over the last two months. I've learnt some stuffs about NAS and HPO, and techniques to perform them such as Bayesian optimization (mostly for HPO, but applicable for NAS), or evolution based NAS, or more simple grid/random search.

But I've learnt about another techniques which I find interesting : gradient-based NAS. The first article that I know which deals with it is DARTS, which tackles the problem of NAS by introducing a differentiable model.

DARTS : [https://arxiv.org/abs/1806.09055](https://arxiv.org/abs/1806.09055)

There are also some derivatives of DARTS, such as :

pDARTS : [https://arxiv.org/abs/1912.10952](https://arxiv.org/abs/1912.10952)

DARTS+ : [https://arxiv.org/abs/1909.06035](https://arxiv.org/abs/1909.06035)

SNAS : [https://arxiv.org/abs/1812.09926](https://arxiv.org/abs/1812.09926)

&#x200B;

What do you think about it guys, for those who know about gradient-based NAS ?

Some people think this is b\*llshit, but I don't see why...

By the way, I don't find any more recent alternative (from 2020 to 2021), if you guys find any of them, I would glad to hear about it !

Thanks for your answers !",MachineLearning
nmr2wd,1622181382.0,[D] Question about Dropout variants,"Hello,

So dropout is very binary in nature: neurons are either dropped or kept.

But is there a variant that scales down some incoming neurons by a factor and allows the other nneurons to pass through unaffected?

I've tried to find something like that couldn't find anything.

Any help / papers appreciated.

Thanks!",MachineLearning
nmq6cs,1622177812.0,[D] Can a cycle-gan work with data imbalance?,I wanted to know if anyone has tried training a cycleGAN where target distribution has 10 times the number of samples than source distribution. Does it work in practice?,MachineLearning
nmpkmq,1622175597.0,[D]Collusion Rings in CS publications,"https://cacm.acm.org/magazines/2021/6/252840-collusion-rings-threaten-the-integrity-of-computer-science-research/fulltext#FNA
This issue is huge. What do you think about it and how to cope with it?",MachineLearning
nmlji1,1622161482.0,[D] PaddlePaddle vs. Pytorch,"Does anyone have experience learning PaddlePaddle after learning PyTorch here? If so, what did you think of it? Is it an easy language to code in for someone who is used to building DNN's from layers? Does it have any functionality that you appreciate that PyTorch doesn't, or vice versa, any functionality that you want that PyTorch provides but PaddlePaddle doesn't? I've been thinking of learning another DL framework, and trying to decide whether to look into jax or PaddlePaddle. Thanks!",MachineLearning
nmh9ip,1622148562.0,[D] Augmenting A/B tests with offline policy evaluation,"I recently read about a technique in statistics/ML called ""offline policy evaluation"".

The idea is that you can evaluate how new policies will perform by using historical data generated under a previous policy. For example, rather than testing a new fraud policy in an A/B test, you can use historical logs to determine if the new policy will outperform the existing one. This seems like it could be a great step before A/B testing new policies.

I whipped up some [example code](https://github.com/banditml/offline-policy-evaluation) to test out what would be considered the ""hello world"" of offline policy evaluation if anyone is curious.

My question to you is -- have any of you have tried this or do any of your currently use OPE at your companies?",MachineLearning
nm2ysh,1622104695.0,[R] From Motor Control to Team Play in Simulated Humanoid Football (DeepMind),"A 20-authors paper from DeepMind where they show that they can train humanoid agents to play 2 vs 2 soccer.

The video is pretty impressive: [youtu.be/KHMwq9pv7mg](https://t.co/pebXTv7f7T?amp=1)",MachineLearning
nmac79,1622130319.0,[R] Cornell & NTT’s Physical Neural Networks: a “Radical Alternative for Implementing Deep Neural Networks” That Enables Arbitrary Physical Systems Training,"A team from Cornell University and NTT Research proposes Physical Neural Networks (PNNs), a universal framework that leverages a backpropagation algorithm to train arbitrary, real physical systems to execute deep neural networks.

Here is a quick read: [Cornell & NTT’s Physical Neural Networks: a “Radical Alternative for Implementing Deep Neural Networks” That Enables Arbitrary Physical Systems Training.](https://syncedreview.com/2021/05/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-28/)

The paper *Deep Physical Neural Networks Enabled by a Backpropagation Algorithm for Arbitrary Physical Systems* is on [arXiv](https://arxiv.org/abs/2104.13386).",MachineLearning
nm9xq2,1622129194.0,[N] This AI startup is putting a fleet of airplanes in the sky without human pilots,"Original article [here](https://thenextweb.com/news/ai-startup-merlin-labs-autonomous-flight-ai). There is no information on what AI models or algorithms were used. I can't find any AI/ML job openings at their career site - only software engineers and .. Flight Controls Lead. I wonder if it is similar to Boston Dynamics in their limited use of AI and focusing on complex physics models instead?

The [showcase video](https://www.youtube.com/watch?v=-gwHRVI-MSM) looks impressive.

If you like this piece of news, you can find more [here](https://thereshape.co/). ",MachineLearning
nm95ur,1622127062.0,[P] Modifying open-sourced matrix multiplication kernel,"I've spent the past few months optimizing my matrix multiplication CUDA kernel, and finally got near cuBLAS performance on Tesla T4. In the past few weeks I've been trying to fuse all kinds of operations into the matmul kernel, such as reductions, topk search, masked\_fill, and the results are looking pretty good. All of the fused kernels are much faster than the seperated versions while using much less memory.

[Runtime of fused MinBMM vs. torch.bmm + torch.min](https://raw.githubusercontent.com/DeMoriarty/custom_matmul_kernels/main/imgs/min_bmm_A%5B1%2CN%2C64%5D%20B%5B1%2C64%2CN%5D.png)

edit: unit of time in this plot should be seconds, not milliseconds

[Runtime of fused TopkBMM vs. torch.bmm + torch.topk](https://raw.githubusercontent.com/DeMoriarty/custom_matmul_kernels/main/imgs/topk_bmm_A%5B1%2CN%2C64%5D%20B%5B1%2C64%2C1024%5D_semilogx.png)

[Runtime of fused MBMM vs. torch.bmm + torch.masked\_fill](https://raw.githubusercontent.com/DeMoriarty/custom_matmul_kernels/main/imgs/mbmm_A%5B128%2CX%2C64%5D%20B%5B128%2C64%2CX%5D.png)

I also wrote a [blog post](https://demoriarty.github.io/BMM-1/) about the motivation, applications and some implementation details of these kernels. The source code can be found in [this repo](https://github.com/DeMoriarty/custom_matmul_kernels).",MachineLearning
nm7x4o,1622123486.0,[R] Transformer encoder and temporal sequence encoding,Is there any way of including temporal data instead of positional data as the input for a transformer encoder?,MachineLearning
nm7ow2,1622122807.0,[R] Video explaining Self DIstillation with NO Labels (DINO) paper from Facebook AI,"In our series of videos explaining AI papers concisely, we explaing the paper, ""Emerging Properties in Self-Supervised Vision Transformers"" from Facebook AI this week. Hope its useful: [https://youtu.be/yDXdIR7XUxI](https://youtu.be/yDXdIR7XUxI)",MachineLearning
nm7ezc,1622121968.0,[D] Equivalence between traditional state space models and recurrent neural networks,"Can anyone recommend a source that explains the relationship between recurrent neural networks and state space models? I often see recurrent neural networks being explained just in terms of ""neural network"" vocabulary. Can anyone recommend a website/book/video in which the ""hidden state"" aspect of recurrent neural networks are discussed?

Thanks",MachineLearning
nm5nys,1622116212.0,[D] How did you implement papers with models that required a lot of GPUs to train?,"I'm self-learning ML and trying to implement the papers [listed here](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap) but I don't have access to hundreds of free GPUs like those corpos do.

Edit: I have RTX 2060",MachineLearning
nm546y,1622114121.0,Deep learning frameworks inference speed compariosn [D],"Hi everyone,
I'm currently working as a DS in a small company. We're dealing mainly in web search and recommendation areas.
We want to start utilizing DL for ranking and CTR calculations, and we're debating on which DL framework would suit us best.

The most important thing for us is fast inference. We tried googling for benchmarks comparison but we found inconclusive results (everyone agrees that the low level APIs have the potential to be faster, but between them every comparison favours different framework).
Other things that we care about include training time, development time, debugging complexity and flexibility in building the model. While these things are important, inference time is a necessary condition for our product.

Does anyone have experience with the different frameworks and can help us understand which direction we should go?

Thanks a lot in advance!",MachineLearning
nm4d55,1622111057.0,[Project] Building detection model," I am given a task to develop a building detection model based on satellite images. I've been given coordinates of buildings. There is not many API services available for getting images based on coordinates - I am using [this one](https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/export?bbox=-2.003750722959434E7,-1.997186888040859E7,2.003750722959434E7,1.9971868880408563E7), which does not have high resolution so you can't send request for each building. So I have to build a bounding box around multiple nearby buildings and send a request based on it. I've used k-means to cluster nearby buildings and got 165 clusters which I put a bounding box around it. Then wrote a parser and got images for those bounding boxes.

Now I have to build the model, however I have my suspicions that the model won't perform great because of low quality reference data. Each image contains multiple buildings, roads and etc. So I am not sure what can I do. Should I proceed cleaning this dataset(masking, interpolation and etc) or it doesn't worth the effort?

Most images look like [this](https://imgur.com/a/hvRo7Li). I have nearly 100 of them, but I can increase size of dataset by requesting more building coordinates. Any advice would help.",MachineLearning
nlztk6,1622090966.0,How does Google's 'showing results for' work? [D], If I search 'I love to eate my food' on Google then Google will 'show results for' I love to eat my food.... How does this algorithm work?,MachineLearning
nlz8hh,1622088648.0,[D] Thoughts and comments of on Concrete Autoencoder,"I have been doing some experiments with concrete autoencoder, which uses gumbel-softmax distribution in one of its encoder layer to select a subset of features. What I found was, this was not robust at all, giving me different subset of features at different runs. The paper is here - [https://arxiv.org/abs/1901.09346](https://arxiv.org/abs/1901.09346)

I also have another question about existence of a SOTA in deep learning based feature selection methods. Please do suggest.",MachineLearning
nlvxro,1622076630.0,[P] I Trained a Model to Generate Video Game Pages,"These past two months I've been working on a project I've called [THIS GAME DOES NOT EXIST](https://thisgamedoesnotexist.jsonchin.com). I've always wanted to try building something with generative A.I. so this project scratched that itch for me.

Here's a video with a few of my favourites read by voice actors: [https://www.youtube.com/watch?v=\_mTWMLhpJoA](https://www.youtube.com/watch?v=_mTWMLhpJoA)

&#x200B;

>THIS GAME DOES NOT EXIST is an experiment in generative artificial intelligence. This site contains 130 video game pages that were generated using an implementation of OpenAI's [Generative Pre-trained Transformer 2 (GPT-2)](https://openai.com/blog/better-language-models/) to generate text and a simple implementation of generative adversarial networks (GAN) to generate header images and ""screenshots"".
>
>To generate the names, descriptions, publishers, and developers of the games I finetuned the [HuggingFace](https://huggingface.co/transformers/index.html) implementation of GPT-2. I used the [Steam Store Games (Clean dataset)](https://www.kaggle.com/nikdavis/steam-store-games) from Kaggle with slight modifications and preprocessing.Here is what one training sample looks like:
>
>*<|game|><|name|>Half-Life<|developer|>Valve <|publisher|>Valve<|description|>Named Game of the Year by over 50 publications, Valve's debut title blends action and adventure with award-winning technology to create a frighteningly realistic world where players must think to survive. Also includes an exciting multiplayer mode that allows you to play against friends and enemies around the world.<|endoftext|>*
>
>The model uses the tokens (e.g. <|game|> and <|description|>) to prompt each class of data while keeping context during the entire generation.
>
>Image generation was done by training a custom GAN very similar to the architecture seen in the PyTorch [DCGAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) which was built to generate faces. I created two models for this site: one for generating the header images and one for generating multiple screenshots for each game.To assemble the dataset I wrote a script that downloads the images from the URLs in the [Steam Store Games (Clean dataset)](https://www.kaggle.com/nikdavis/steam-store-games) dataset. Due to my lack of resources and time to put into this project, the image generation is less than ideal. You may notice though, that the header image model will generate artifacts in images that look like the titles of games, and the screenshot image model with generate what looks like levels of a 2D platformer.",MachineLearning
nlvsg1,1622076109.0,[D] Advertisements in this sub,"A while back there were a couple of posts ([Post 1](https://www.reddit.com/r/MachineLearning/comments/mv452o/d_new_tag_for_self_promotion_content/), [Post 2](https://www.reddit.com/r/MachineLearning/comments/j1s3yw/d_recent_increase_in_self_promotion_content/)) on the increase of self-promoting blogs and youtubers on the sub. I won't beat a dead horse and repeat what they've said.


But more so than self-promoting blogs and youtube channels, what concerns me is the increasing number of self-promoting *products* on this sub. There are posts trying to convince people to use a product from their startup. Here are some examples just from today's feed:


[Example 1](https://www.reddit.com/r/MachineLearning/comments/nlluep/p_automl_for_unsupervised_learning/)
[Example 2](https://www.reddit.com/r/MachineLearning/comments/nlgnq4/p_seldon_core_180_released/)
[Example 3](https://www.reddit.com/r/MachineLearning/comments/nlhi7k/p_play_with_models_ml_ones/)
[Example 4](https://www.reddit.com/r/MachineLearning/comments/nlg070/d_version_control_with_dvc_highlevel_usage/)
[Example 5](https://www.reddit.com/r/MachineLearning/comments/nka4kf/n_dataprep_v03_has_been_released/)


I am not sure I like the idea of a research-oriented sub being overrun by promotion of products, even if they are related to ML. Rule 5 prevents non-arxiv link posts on weekdays, but in my opinion this should be expanded to include text posts which are only promoting a startup or their product.


Thoughts?",MachineLearning
nlnrag,1622053299.0,[D] Online machine learning (or how to automatically update your model in production),"I'm trying to find resources to learn more about online machine learning.

The idea is beautiful and powerful: your model in production trains itself with new latest data to react to changes faster. However the classic ways to build the MLOps infrastructure and algorithms' maths won't do the job here, so I'm eager to learn more:

* I've found [this post](https://huyenchip.com/2020/12/27/real-time-machine-learning.html) by Standford's ML lecturer Chip Huyen to be a great introduction to the concept of Online Learning.
* I've found [River](https://github.com/online-ml/river) to be a promising python library for online learning.

Apart from that, I don't know many resources out there, could anyone help?

I'm **especially interested in finding a ""Titanic"" equivalent** (a simple problem to get going). The way I see it, I would need a problem from where **both historic and real-time** data can get imported. I would train my beta model with historic data and then I'd use real time data to both track the performance and keep evolving the models. So, the classic benchmark databases won't do the trick here (there's historic data of the Titanic but luckily not real time feed of it).

I was thinking in:

1. Trading (both historic and real-time data available)
2. Bike sharing (both historic and real-time data available through APIs for certain cities)

Any further ideas?",MachineLearning
nlnl7i,1622052866.0,[D] Unsupervised learning with audio data,"I had a (probably crazy) idea for a project and I was wondering if you all think it would be in any way possible. I'm interested in analyzing sounds made by different types of animals (for example bird songs or the croaking sounds made by different species of frog) and looking for relationships between the sound and other factors like habitat or taxonomic classification. If I could obtain digital recordings, would it be possible to feed the data into a clustering algorithm in such a way that it could identify and compare important characteristics? My fear is that most algorithms would prioritize extraneous details related to the quality of the recording or the type of compression over potentially meaningful factors like pitch, timbre, and pattern.

A Google search uncovered a few possibly related articles:

[This one](https://link.springer.com/article/10.1186/s13636-017-0123-3) proposes a k-medioids approach but seems to focus on computer engineered sound waves rather than real life recordings.

[This one](https://hal.archives-ouvertes.fr/hal-01491270/file/LEBEL_ACfACuLlD-v01_paper.pdf) uses a hierarchical algorithm and has a lot of good discussion on data cleansing and extracting ""Low-level descriptors"" to use as potential model features, however the focus is on classifying music which is obviously a much richer feature space than what I'm considering.

I have very limited knowledge in this area and would have to do a lot more research on data prep, feature creation, model selection, and so on but just wanted to ask if this is completely insane before I go too far down this rabbit hole.",MachineLearning
nlnk41,1622052784.0,[D] BERT + metadata,"New to BERT and wondering if there are ways to incorporate additional information (like, for example, font size of words) in BERT models? Would appreciate pointers!",MachineLearning
nlmlbg,1622050294.0,[N] OpenAI announces OpenAI Startup Fund investing $100 million into AI startups,"https://openai.com/fund/
https://techcrunch.com/2021/05/26/openais-100m-startup-fund-will-make-big-early-bets-with-microsoft-as-partner/

It does not appear to be explicitly GPT-3 related (any type of AI is accepted), but hints very heavily toward favoring applications using it.",MachineLearning
nlmdg4,1622049728.0,[D] What should be the next AlphaGo/AlphaFold moment in AI?,What milestone does AI research need to tackle next that would be similar in scope to what DeepMind did with AlphaGo or AlphaFold?,MachineLearning
nllvkz,1622048445.0,[D] Predicting the class of an event or its probability in N days after,"I have a dataset with time series and for some of them (test sample) dates are known (maybe from zero to several pieces per time series), which we will call target events, the occurrence of which I want to predict.

Also, for each rserie, several heuristics have been calculated that catch some kind of local change in the serie (different types of drops in the serie level) and fix in themselves whether a change has occurred on such and such a date or not.

I want to take advantage of these heuristics and so, to learn how to predict the occurrence of targeted events.

 Three metrics are of interest: forecast accuracy, forecast completeness (recall), and forecast of interval between heuristics date and target event (for example, that a target event will occur n days after a set of heuristics is triggered).

 For each date, I can calculate how many target events will occur on the test sample after each of the heuristics is triggered for n days.  By this calculation, I want to evaluate the usefulness of each of the heuristics.

  But there are several questions:

- How to relate the triggering of the heuristic on date n with the desired event, and for example, not with the next one?  This is necessary to assess that the accuracy of the heuristics.

- is it possible to somehow generalize the triggering of heuristics to predict the occurrence of a target event exactly after the calculated number of days?

- maybe there is some way to predict the class of the event in n days (whether it will be target or not) or the probability that it will be target.  This is necessary in order to ultimately generalize the triggering of heuristics and additional known time series features.",MachineLearning
nlkvl1,1622045921.0,"[D] ML Engineers, do you find that you make yourself redundant?","Was having a conversation with a friend the other day - there's a bit of a principal/agent problem going on with ML engineering (as well as other fields I'm sure). If you do a perfect job as an ML engineer you make yourself 100% redundant (or as close to as possible). But if you are redundant you become replaceable. If I build an ML pipeline that detects performance drift, automatically retrains, has error handling, keeps costs low etc, and provide perfect documentation, there's no need for my involvement unless something goes completely off the rails. If on the other hand I build  a broken mess that no one else dare touch because no one can wrap their head around all the criss-crossed band aid fixes, then I'm literally irreplaceable.

I guess it depends a lot on your company & culture. The company I work for has a few ML projects that come in here and there, and I'm finding myself worrying that I'll wrap them up way quicker than they come in. The better job I do, the more idle I look which is weird. Anyone else have similar experiences?  Seems ML engineers are in need of a steady stream of new problems to solve, vs data scientists who can be working on the same problem for years  (e.g. incrementally optimizing a profit yielding model).",MachineLearning
nlj3jw,1622041259.0,[D] Are Pre-trained Convolutions Better than Pre-trained Transformers? – Paper Explained,"Paper reference: Dehghani et al. (2021). ""Are Pre-trained Convolutions Better than Pre-trained Transformers?""  [https://arxiv.org/abs/2105.03322](https://arxiv.org/abs/2105.03322)

Reading this paper (with wrong expectations?) made Ms. Coffee Bean wonder what it takes for a transformer(-like) architecture to be named ""transformer"". When does it become something else, e.g. a CNN? Let's discuss!

[https://youtu.be/xchDU2VMR4M](https://youtu.be/xchDU2VMR4M)

Outline:

* 00:00 Are you tired of transformers?
* 01:12 What makes transformers so good?
* 05:13 CNN vs. Transformers
* 09:53 What makes a transformer a transformer? -- Discussion",MachineLearning
nlhi7k,1622036985.0,[P] Play with models (ML ones),"I know it’s thrilling to find a cool ML model online. But it’s almost always a hassle to deploy it. At Neuro, we’re trying to make ML development easier. So today we’re launching a new product, which we call the ‘Model Hub’. It’s a library of popular open source models like GPT-Neo and Detectron2, where you can learn about them, experiment with different inputs, and see how to use them in just a few lines of code (all from our API). In that way, it’s like HuggingFace for everything. I hope you find it useful! [https://hub.getneuro.ai](https://hub.getneuro.ai/)

The website is still young, but we’re planning to add more models every week. So if you have any suggestions, or if you’d like to see a particular model then just send me a PM here and I’ll try to get it added for you.

Deploying models can be pretty painful at the moment if you do it yourself, which is why we built the Neuro API: so that ML engineers can focus on the fun parts and leave the hassle to us. If you believe in our mission – to accelerate ML development – and want to help, we’re hiring: [https://getneuro.ai/jobs](https://getneuro.ai/jobs)

https://i.redd.it/oyobc91cyg171.gif",MachineLearning
nlgnq4,1622034614.0,[P] Seldon Core 1.8.0 Released,"[Seldon Core](https://github.com/SeldonIO/seldon-core)  [1.8.0](https://github.com/SeldonIO/seldon-core/releases/tag/v1.8.0) has been released.

Seldon Core is an open source library for cloud native machine learning deployment.

This release contains an integration to our new [Tempo data science library](https://github.com/SeldonIO/tempo), updates to support the latest [Alibi-Detect](https://github.com/SeldonIO/alibi-detect) release for outlier and drift detection, as well an example for [GPT-2 Inference on Triton](https://github.com/nadinet/seldon-core/blob/gpt2_notebook_example/examples/triton_gpt2/README.ipynb).",MachineLearning
nl6taw,1621998046.0,[D]Which machine learning model can achieve this effect？,"This is a residual-based anomaly detection model in the field of Internet of Things. The red line is the true value of the sensor, the blue line is the predicted value of the model, and the yellow line represents the residual. According to a certain residual threshold, it is determined whether an abnormality occurs. This graph is just one of multiple sensor data.

What I am puzzled about is the predictive component, which has two typical characteristics:

(1) Perfect prediction within the range of training data

(2) The predicted value does not exceed the range of the training data

I think that multiple inputs are used as labels at the same time in this model in the training phase. I tried MultioutputRegressor(DecisionTree()).fit(X, X) using sklearn framwork, but the fit is not smooth enough.

Which model or method can achieve this effect?

&#x200B;

https://preview.redd.it/wr3yz6hdrd171.jpg?width=1022&format=pjpg&auto=webp&s=b5c0ec8042721fcea5d55a7e293e86a4a969e60e",MachineLearning
nl5kou,1621993921.0,[D] Nice paper on compositionality based on attention-based architectures solving Math problems,"Nice paper on compositionality in human cognition based on NN attention-based architecture solving Math problems (PDF): «[Compositional Processing Emerges in Neural Networks Solving Math Problem](https://arxiv.org/pdf/2105.08961.pdf)s» by a M$, UC Davis and Johns Hopkins research group. They  look for corresponding sub-expression from math questions in different parts of attention-based network architectures (poorly named transformers) . They found some ability to compose the meanings of math symbols according to their structural  relationships.",MachineLearning
nl5c8l,1621993126.0,"[N] Outstanding Performance of Nvidia A100 on HPL, HPL-AI, HPCG Benchmarks",[https://www.pugetsystems.com/labs/hpc/Outstanding-Performance-of-NVIDIA-A100-PCIe-on-HPL-HPL-AI-HPCG-Benchmarks-2149/](https://www.pugetsystems.com/labs/hpc/Outstanding-Performance-of-NVIDIA-A100-PCIe-on-HPL-HPL-AI-HPCG-Benchmarks-2149/),MachineLearning
nl58at,1621992761.0,"[N] 65% of execs can’t explain how their AI models make decisions, survey finds","From this VentureBeat article:

https://venturebeat.com/2021/05/25/65-of-execs-cant-explain-how-their-ai-models-make-decisions-survey-finds/

>	In fact, only a fifth of respondents (20%) to the Corinium and FICO survey actively monitor their models in production for fairness and ethics, while just one in three (33%) have a model validation team to assess newly developed models.

How should companies responsibly assess deployed ML systems? What metrics make sense for evaluating bias and assuring regulatory compliance in these systems once they are in the wild?

EDIT: That’s what I get for using the article’s clickbait title… no one read past the title. What about the other aspects of the survey?",MachineLearning
nl50b8,1621992006.0,"[D] Which is more valuable for grad study, research experience or software engineer internship?"," Hi, I'm a third-year undergrad. I am planning to do grad study in AI/ML right after graduating. My college has a lot of co-ops (internship) opportunities. Let's say I got an internship offer from a big company for doing some SW development stuff or data science stuff, and the other offer from a non-popular research centre for doing some ML research. Which one do you think is a more valuable asset for applying to graduate schools?

Side question: maybe the best opportunity is doing research or ML dev in big companies in this case?",MachineLearning
nl44x7,1621989145.0,[D] Looking for tips on training language models on large datasets,"I'm phd student currently working with a small research group that doesn't have deep experience with my research area. I have set of experiments I want to run on BERT-like models where the training data won't fit into memory and will require preprocessing. Most of the work I've done in the past, it was possible to do the preprocessing up front and load the entire dataset and run multiple training epochs.

Are there any resources (e.g. blogs posts or guides) on tools and best practices for training language models on large datasets. My definition of large here is like 20 million or so sentences. Currently debating if I'll frame the task as a masked word (MLM) prediction task ( which is expensive) or discriminator task  (like Electra) which may be more efficient to train with my resource limitations but is completely new to me.

I'm trying to figure out how to store the data (is a database necessary or should I write multiple text files that can be lazy loaded). How do I monitor the model training (should I checkpoint every 1000 steps?). The experiments would be run on a GCP instance with a couple of T4s and I'm working with pytorch-lightning to handle some of the more complicated aspects of the training loop as a starting point.  Any advice or pointer to resources would be greatly appreciated.",MachineLearning
nl0h5u,1621977984.0,[Discussion] Risk Mitigation Techniques for Online Learning,"I am designing a backend service in which there is an online machine learning component. It's implemented as either as reinforcement learning or a genetic algorithm, not sure yet which. It's impossible to train offline for various domain-specific reasons, we have to pick some naive/heuristic solution as a starting point and train online.

I am exploring the idea of ""risk mitigation"", that is, ways to control the total damage that bad policies can inflict. We have to run the actions generated by bad policies to identify them as bad, so it's impossible to screen them a priori. There are two concepts I am trying to work in:

1. Restricting the amount of damage available to unknown policies: suppose we're training an ad recommendation engine. Then if a policy is unknown, only let it recommend ads to a small group of people.
2. Check similarity: if we have a set of policies we trust to not be harmful, ensure that new policies that are learned or that evolve are somewhat similar to those. Once we trust the new policies, add them to the pool of trusted policies.

Curious if anyone has run into this problem in online learning or knows about a paper or something that would point us in the right direction. Would love to hear opinions about my ideas as well :)",MachineLearning
nkwplt,1621967666.0,[D] Paper explained - Large Scale Image Completion via Co-Modulated Generative Adversarial Networks,"Large Scale Image Completion via Co-Modulated Generative Adversarial Networks (ICLR 2021 Spotlight)

Is it true that all existing methods fail to inpaint large-scale missing regions? The authors of CoModGAN claim that it is impossible to complete an object that is missing a large part unless the model is able to generate a completely new object of that kind, and propose a novel GAN architecture that bridges the gap between image-conditional and unconditional generators, which enables it to generate very convincing complete images from inputs with large portions masked out.

Continue reading about co-modulation and paired/unpaired inception discriminative score in [the full paper explanation in the casual GANs channel](https://t.me/casual_gan/43).

[Samples from the model](https://preview.redd.it/y4x692ql8b171.png?width=1548&format=png&auto=webp&s=a3d5a2481b62090511fa847a2b6f576aac000e97)

\[[Full Explanation Post](https://t.me/casual_gan/43)\] \[[Arxiv](https://openreview.net/pdf?id=sSjqmfsk95O)\] \[[Code](https://github.com/zsyzzsoft/co-mod-gan)\]
More recent popular computer vision paper explanations:
\[[GANCraft](https://t.me/casual_gan/41)\]
\[[DINO](https://t.me/casual_gan/40)\]
\[[MLP-mixer](https://t.me/casual_gan/35)\]",MachineLearning
nkvvax,1621965446.0,[D] Can an SVM give you feature importance?,"I thought tree based models like RFs and boosts are the only modern classifier that gives some sort of feature importance. But I found a guide online taking the coefficients of features resulting from an SVM as feature importances, is this valid ?",MachineLearning
nkse4b,1621956418.0,[R] Yoshua Bengio Team’s Recurrent Independent Mechanisms Endow RL Agents With Out-of-Distribution Adaptation and Generalization Abilities,"A research team from the University of Montreal and Max Planck Institute for Intelligent Systems constructs a reinforcement learning agent whose knowledge and reward function can be reused across tasks, along with an attention mechanism that dynamically selects unchangeable knowledge pieces to enable out-of-distribution adaptation and generalization.

Here is a quick read: [Yoshua Bengio Team’s Recurrent Independent Mechanisms Endow RL Agents With Out-of-Distribution Adaptation and Generalization Abilities.](https://syncedreview.com/2021/05/25/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-26/)

The paper *Fast and Slow Learning of Recurrent Independent Mechanisms* is on [arXiv](https://arxiv.org/abs/2105.08710).",MachineLearning
nkpg2j,1621948359.0,[N] Sergey Levine-Audience Questions- Soft Robotics Podcast,"&#x200B;

Hello,

We are going to have Sergey Levine on the podcast, if you have any questions, you can send them here: [https://docs.google.com/forms/d/e/1FAIpQLScOBGZ169ydQ13Akg\_BC3I1wWGjJJVlYiDRrwcoOEDs\_k\_Guw/viewform?vc=0&c=0&w=1&flr=0](https://docs.google.com/forms/d/e/1FAIpQLScOBGZ169ydQ13Akg_BC3I1wWGjJJVlYiDRrwcoOEDs_k_Guw/viewform?vc=0&c=0&w=1&flr=0)

&#x200B;

https://preview.redd.it/ac76z4jen9171.png?width=2586&format=png&auto=webp&s=9cdd684a795dbb9c5d1395610febd4e52f1df100",MachineLearning
nko4bw,1621944330.0,[N] Machine Learning Security Evasion Competition 2021 Calls for Researchers and Practitioners,"[MLSEC21 announced](https://cujo.com/machine-learning-security-evasion-competition-2021-calls-for-researchers-and-practitioners/) it will have a Defender track for machine learning malware detection models like [last year](https://cujo.com/machine-learning-security-evasion-competition-2020-results-and-behind-the-scenes/). Participants will be able to submit their models June 15–July 23, 2021, and their submissions will subsequently be attacked by participants of the Attacker challenge.

Registration opens Jun 15 at [https://mlsec.io](https://mlsec.io)

Last year, Erwin Quiring, Lukas Pirch, Michael Reimsbach, Daniel Arp, and Konrad Rieck from the Technische Universitat Braunschweig, Germany won the Defender Challenge with this model: [https://arxiv.org/pdf/2010.09569.pdf](https://arxiv.org/pdf/2010.09569.pdf)

The event is organized by Hyrum Anderson, Principal Architect and Ram Shankar Siva Kumar, Data Cowboy in Azure Trustworthy Machine Learning at **Microsoft**, Zoltan Balazs, Head of Vulnerability Research Lab at **CUJO AI**, Carsten Willems, CEO at **VMRay**, and Chris Pickard, CEO at **MRG Effitas**.",MachineLearning
nknf06,1621941938.0,Identifying bias/poor performance in machine learning models [D],"Let’s say you developed a machine learning model to predict whether or not someone will need food stamps this month, and we want to see when/where our model performs poorly. For instance, we might make poor predictions for people from low income populations, and we want to identify that. How can we systematically and automatically identify where our model is performing poorly? Can anyone point me to some papers? Thank you!",MachineLearning
nkkbie,1621929596.0,[D] On the evaluation of deep learning models in case of highly im-balanced data and small test dataset,"Hello, I am currently working on a project regarding the classification of images, in particular chest x-ray images. Unfortunately, the train dataset is highly im-balanced (1/6 of class ""positive"" and 5/6 of class ""negative""), while the test dataset is very small but balanced (1/2 of both class ""positive"" and ""negative"").

I am trying using some relevant deep learning models for classification such as VGGs, ResNets and DenseNets. In order to mitigate the train dataset im-balance issue, weighted binary cross entropy is used as the loss function (where the weights are inversely proportional to class sizes). Moreover, scaling and translating data augmentation techniques are used as well. Evaluation metrics include precision, recall and F1 scores.

For simpler networks, in testing phase I obtained very good results on the test set. However, the results on the non-augmented train dataset (i.e. resubstitution metrics) are much worse. The main question is: *since the model performs better on the test set, is this a sign of under-fitting ? Or is this due to the fact that I included data augmentation when training the data ?*

Second, for more complex networks (with a lot more of parameters, e.g. VGGs), the evaluation metrics on the test dataset are much similar to the evaluation metrics on the non-augmented train dataset. However, generally performing worse than simpler models on test data. So, the other question is: *how should I fairly compare these models since the ones that perform very  well on test data perform a lot worse on train data (and viceversa) ?*

Thanks in advance.",MachineLearning
nkhe89,1621918029.0,[D][P] Working Memory Hackathon,"Hi all.

I wanted to share an announcement about an upcoming hackathon you all may be interested in. Along with the [Whole Brain Architecture Initiative](https://wba-initiative.org/en/about/) in Japan, we're ([Cerenaut](https://cerenaut.ai/)) hosting a Working Memory Hackathon, with a Delayed Match to Sample challenge and an agent that possesses Active Vision (low resolution periphery, high resolution fovea that actively moves around the scene). We supply a basic architecture and implementation, which is based on [PBWM](https://en.wikipedia.org/wiki/Prefrontal_cortex_basal_ganglia_working_memory).

There are cash prizes up to 100,000 JPY. There will be an orientation event early June.

[Hackathon Call for Participation](https://wba-initiative.org/en/18626/)",MachineLearning
nkgkip,1621915136.0,[D] Multimodal Deep Learning - Practical Project,"Hi  Guys, I have been reading into Multimodal Deep Learning and came across several blogs which explain it from a bird's eye perspective without diving into implementation details. Also, I browsed through the following research papers:

1. ""Multimodal Deep Learning"" by Jiquan Ngiam et al.
2. ""Multimodal Deep Learning for Activity and Context Recognition"" by Valentin Radu et al. -> Promising
3. ""Multimodal deep learning models for early detection of Alzheimer’s disease stage"" by Janani Venugopalan et al.
4. ""Improved Multimodal Deep Learning with Variation of Information"" by Kihyuk Sohn et al.

I am interested to implement a personal project where the problem statement is a need for fire  detection. This is usually handled by Computer Vision Object Detection models - YOLO, Faster R-CNN, etc. However, I was thinking about using  Multimodal DL for this to take inputs from heat/thermal sensor, etc.  apart from video feeds.

Can you provide me any practical blog/tutorial which shows implementation/codes?

Thanks!",MachineLearning
nkfarw,1621910912.0,"[D] Do successful models defy the ""bias-variance tradeoff""?","In statistics, we are always warned about the ""bias-variance tradeoff"": simple statistical models are reliable, but are generally unable to sufficiently capture the complexity within the data (i.e. high bias, low variance) ; complex statistical models are able to capture complexity within the data, but are generally not as reliable when generalizing to new data (i.e. high variance, low bias).

This leads me to my questions:

1) Are successful statistical models able to defy the ""bias-variance tradeoff""? As a simple example, consider the famous ""iris dataset"". Kaggle competitions have shown us that statistical models can be made that perform well on both the training data as well as the test data. Are these statistical models defying the ""bias-variance tradeoff""? Now, let's imagine a far more complicated problem and dataset - but suppose that we are still able to create a statistical model that performs well on both the training data as well as the test data : are we again defying the ""bias-variance tradeoff""?

2) I have seen proofs that show how the MSE (mean squared error) can be decomposed into a ""bias term"" and a ""variance term"". Thus, for a given statistical model : for a fixed value of this model's MSE, if the variance is high then the bias must be low in order to compensate (and vice versa).

My question relates to the following : when people discuss the variance in the ""bias-variance tradeoff"", they are generally interested in the variance of a statistical model's performance when dealing with unseen data. Since this unseen data might not even exist at the moment, how is the ""bias-variance tradeoff"" able to make claims about unseen data? Is the ""bias-variance tradeoff"" a general idea with some theoretical foundations? Or is it mainly empirical?

3) Finally, how does the ""bias-variance tradeoff"" apply to real world models such as the ""self driving car"" , ""alpha go"" and computers playing tetris? Or in the case of reinforcement learning models, the ""bias-variance tradeoff"" does not apply the same way it does in supervised learning models?

Thanks",MachineLearning
nkd53z,1621904162.0,"[R] Parametric Spectral Filters for Fast Converging, Scalable Neural Networks","This is my first primary author publication.  I'd appreciate any feedback, suggestions, or thoughts!

&#x200B;

Paper: [https://lukewood.dev/pdf/spectral-conv.pdf](https://lukewood.dev/pdf/spectral-conv.pdf)

IEEE Xplore: [https://ieeexplore.ieee.org/document/9414587](https://ieeexplore.ieee.org/document/9414587)

Implementation: [https://github.com/LukeWood/spectral-neural-nets](https://github.com/LukeWood/spectral-neural-nets)",MachineLearning
nka4kf,1621895123.0,[N] DataPrep V0.3 has been released!,"[DataPrep](https://dataprep.ai/) is the easiest way to prepare data (for ML) in Python. We’re an open-source data preparation library, and we just dropped a very big, very exciting release.

All 3 of DataPrep’s current components have received some notable updates to make DataPrep closer than ever to a full-fledged, off-the-shelf data preparation solution. Here’s a rundown of some changes:

[EDA](https://www.youtube.com/watch?v=RCZ8c8o6HH0&t=8s)**:**

* Added plot\_diff(): Compare dataframes
* plot() now supports geographical heatmaps
* Customize plots by changing display parameters

[Clean](https://www.youtube.com/watch?v=EHArIpp-DDw&t=7s)**:**

* Added clean\_duplication: Creates an interface for users to select how to cluster detected duplicate values
* Added clean\_address(): Clean US addresses
* Added clean\_headers(): Clean column headers
* Added clean\_date(): Clean dates
* Added clean\_df(): Clean a dataframe

[Connector](https://www.youtube.com/watch?v=kZCi0b4cu1c)**:**

* Added support for more APIs - we now support over 30 APIs on Connector
* The Connector team is currently working on expanding Connector with the addition of [ConnectorX](https://github.com/sfu-db/connector-x)

These updates allow users to use DataPrep for all their data preparation needs. We are very excited to be taking this step forward and becoming closer to an end-to-end data preparation tool.

&#x200B;

Release Blog: [https://towardsdatascience.com/dataprep-v0-3-0-has-been-released-be49b1be0e72](https://towardsdatascience.com/dataprep-v0-3-0-has-been-released-be49b1be0e72)

GitHub: [https://github.com/sfu-db/dataprep](https://github.com/sfu-db/dataprep)

PyPI: [https://pypi.org/project/dataprep/](https://pypi.org/project/dataprep/)",MachineLearning
nk56i1,1621882149.0,[D] How to do project planning for research heavy projects (in the private sector)?,"Assume you are being tasked coming up with a project plan, e.g. creating Jira epics, for an application built around machine learning. How do you come up with ETAs? This is already guess work for traditional software engineering, but how do you handle this when the machine learning part will require prototypes and some research (\*) before you can even start speccing out the subtasks for its implementation?

I do have a PhD, I know how to plan and carry out a research agenda, but their time estimates are always fuzzy when looking more than 1-2 months ahead. You might also have to adjust directions and shuffle priorities. I have found repeatedly that my non-technical supervisors just don't understand. It is not like front end, where you can just compile a list of buttons/features to add.

(\*) not research-research, more like investigating different methods proposed in the scientific literature",MachineLearning
nk3opi,1621878240.0,[D] [R] BERT Base. Choosing optimal cloud infrastructure and environment setup (long read),"Quite often I optimize DL models (aiming to get the cheapest placement within a certain model performance range), find optimal instances and tuning the environment for training and inference, etc.

After multiple such optimizations, I’ve put together a quick framework, a guide that I can refer to when I need it. Some approaches I came up with and results I got seem quite odd and counterintuitive, so ideally I’d like to start a discussion with those dealing with model performance optimization - does my approach make sense, is the benchmarking the only way or am I missing something?

If TLDR, main points:

* Rules of thumb in choosing the instance type/shape did not work for me - when I try and guess cost or runtime based on GPU generation I always land on the wrong side of a **4-5x** variability. In some cases not so obvious options might provide decent performance (P4) and costs (P100).
* What works for me is optimizing for GPU utilization as a proxy for cost/performance optimal placement (duh!)
* To achieve that I have to deal with different bottlenecks in the system outside of GPU, the biggest culprit being preprocessing on CPU and following data streaming to GPU (so, benchmarking with rudimentary monitoring is a must)
* Batch size optimisation can give as much as **4-5x** in performance
* Worker number optimisation (vCPU count, basically)got me another **2-3x**
* (!wtf) Driver/CUDA versions might influence performance much greater than expected (**10x!!?**)
* Benchmarking is a pain in the ass as I typically run at least **100** benchmarks to gather a comprehensive picture

Below you could find a breakdown of those points above.

**Approach**

To illustrate my points I decided to go with the most popular NLP model (BERT base uncased according to [huggingface](https://huggingface.co/)), because 1. this domain looks more suitable for a generalized approach for optimization, 2. dataset and preprocessing are very similar across different models.

It took me around 110 benchmark launches to gather the data below, so I put together a small repo ([Github link](https://github.com/BykovEgor/ml-benchmarks)) using PyTorch to run inference on a small mock dataset, and run it on all GPU instances available for me on GCP (Tesla K80, Tesla P4, Tesla P100, Tesla V100, Tesla T4). This simple script can perform text input encoding, the numbers of preprocessing workers and the batch size are input parameters, it also can find the maximum possible batch size (with linear bruteforce) that saturates the GPU. On top of that I backed it into 4 different containers to run it with different versions of CUDA.

I played with the batch size and the number of processes used by dataloader to preprocess the data. The goal was to maximize GPU utilization and find the optimal batch size / # of processes to get the best price/performance for each type of GPU and then compare how much they would cost me per job.

After that, I chose the best performing GPU and ran additional benchmarks for different NVIDIA driver and CUDA versions to try to catch some optimizations there. I used this approach ([link](https://rocketcompute-com.medium.com/yet-another-guide-on-how-to-install-nvidia-drivers-on-linux-fd72c6cc38f6)) to install different drivers.

**Test results and observations**

To get the baseline I passed text to the model sentence by sentence (it appeared that the number of processes does not change the picture much). Below is the summary of bench runtime and cost for the baseline

&#x200B;

https://preview.redd.it/pug2plhyu3171.png?width=3000&format=png&auto=webp&s=fea61b1ff093574318935436b6f9cbd94a70833e

X axis legend as follow: {GPU}\_{batch size}x{# of workers}\_{# of vCPU}, where:

* GPU - accelerator family (k80, t4, p100, etc.)
* batch\_size - number of sentences I am pushing to GPU and passing to the model simultaneously
* \# of workers - ""num\_workers"" parameter of the DataProcessor, i.e. number of processes to perform data loading and pre-processing
* \# of vCPU - number of virtual core present in VM. GCP allows varying number of virtual cores for GPU instances (from 1 up to 8 for K80, 12 for V100 , 16 for P100, 24 for P4, T4 ).

Then I began increasing batch size and the number of data loader workers to maximize GPU utilization. To illustrate the approach below are 3 graphs of GPU utilization for P100.

Instance with 4 vCPU cores, 4 workers, and maximum possible batch size. Obviously underutilized.

&#x200B;

[P100 \(4 vCPU + 4 workers\)](https://preview.redd.it/q03ty0cuu3171.png?width=887&format=png&auto=webp&s=e23cc74dc46038cd0fd2d4a26660c730233add09)

Then I increased the number of vCores and workers to 8, keeping the maximum possible batch size. Utilization jumps to 66% but still far from maximum.

&#x200B;

[P100 \(8 vCPU + 8 workers\)](https://preview.redd.it/guv747nsu3171.png?width=883&format=png&auto=webp&s=15c2fabe428e6ff26d5eeed8d7b478b63f76104c)

A further increase to 12 vCore and 12 workers finally did the job pushing utilization to 94%

[P100 \(12 vCPU + 12 workers\)](https://preview.redd.it/pxrtt4equ3171.png?width=887&format=png&auto=webp&s=36ca51baeaf1d2b2b384de41f9eaa81c54004acf)

After playing with vCPU / workers counts I got the following charts.

**K80** maxed out its utilization at 2 workers (I didn't go below 4 vCPU but in this particular case lowering the number of vCPU can bring additional savings).

https://preview.redd.it/3k63tytou3171.png?width=3000&format=png&auto=webp&s=d5eacff67987a66cc83d08ed2c5c39888facb765

It took 8 workers and 8 vCores to fully utilize **P4**. Note p4\_63x4\_4, p4\_63x4\_6 and p4\_63x6\_8 launches, it is a clear indicator that there is no much sense to have more workers than you have vCore in this particular case.

https://preview.redd.it/xf6hx21ou3171.png?width=3000&format=png&auto=webp&s=53e7e4bd955c94a5c3913c05e4d018143e808f98

The same for **T4** 8 workers is enough to saturate this GPU.

https://preview.redd.it/q2uvtm1nu3171.png?width=3000&format=png&auto=webp&s=456697fd293e9ee37cf17c361df51931b3f6773c

The following two cases are the most interesting. In both of them, I had to go to 12 vCPU (the maximum number of vCores GCP allows to assign to a single GPU VM). Another remarkable thing is that both these GPUs showed an order of magnitude runtime improvement between the “one-by-one” approach and maximum possible parallelization of data pre-processing.

**P100** showed the maximum utilization (as you can see on a chart above) at 12 workers. Worth noting p100\_146x6\_4 and p100\_146x4\_4, it looks like overcommitting vCores might backfire.

&#x200B;

https://preview.redd.it/5hyan4dmu3171.png?width=3000&format=png&auto=webp&s=e21e1f6077ed0496652c4af62c6710cb2ab10911

**V100** was utilized only on 59% under 12 workers. Potentially it can be pushed further with a  multi-GPU set-up where more than 12 vCPU per GPU can be added to the VM or if the data set is fully preprocessed before inference.

&#x200B;

https://preview.redd.it/6ghmm7zlu3171.png?width=3000&format=png&auto=webp&s=96a08bd01b280e75a2a581a383e2cc964ce1a65f

Below is the summary of cost / runtime for different combinations of vCPU count / GPU.

&#x200B;

https://preview.redd.it/wy703dtku3171.png?width=3000&format=png&auto=webp&s=5821fb9db6b6c344720ec9be5446ea7a6a9210cd

**T4** is a clear winner in terms of price per volume of processed data. Interesting to note that P4 appears to be a clear forerunner in terms of processed data per dollar.

After that I varied PyTorch for different CUDA libs, version 1.7.1 can go with:

* CUDA 9.2
* CUDA 10.1
* CUDA 10.2
* CUDA 11.0

I tried all of these versions against the following drivers:

* 460.32.03
* 455.32.00
* 450.102.04
* 440.118.02
* 418.181.07
* 410.129
* 384.183 ( was not able to install it on Ubuntu 16.04 with the above-mentioned GPUs)

Below is the summary of all runs I gathered. All of them were for optimal T4 setup, i.e. maximum possible batch size, 8 workers on 8 vCPUs.

&#x200B;

[Runtime \(sec, Y\) vs Nvidia Driver version \(X\)](https://preview.redd.it/c0b4vnsju3171.png?width=1800&format=png&auto=webp&s=79b088c2f548a1a18781f3aa2a9f6204ed97a5c2)

I struggle to explain the order of magnitude difference for certain combinations of driver / CUDA. I have not seen this discrepancy of performance for drivers before (although I did such analysis for different networks before with typically up to 15% variability). I ran benchmarks for all outliers 3 times and the results were consistent (crosses on the graph can indicate the amount of variance across different launches).

So, there is at least an order of magnitude cost improvement available with rudimentary benchmarking/monitoring. But the driver/CUDA combination’s effect on the performance puzzles me to say the least. Has anyone seen something like that and what might cause that?

Hope that might be useful.",MachineLearning
nk3b87,1621877225.0,[D] Cost-effective solution to deploy Transformers model,"I'm working on building a SaaS application which utilizes a Transformers model for inference. I was wondering what is the most cost-effective way to deploy this model on the GPU? Obviously, I could pay for an AWS EC2 instance that has a GPU, but the per-hourly costs and the fact that the service would be running 24/7 is daunting. I was hoping for an AWS-Lambda type solution but for the GPU. This probably doesn't exist but just wanted to get ya'll opinion before going the EC2 route.",MachineLearning
nk30t8,1621876468.0,[D] How has AI Contributed to Dealing with the COVID-19 Pandemic?,"After months of drafting and editing, we at The Gradient are happy to share a new article we are proud of - [How has AI Contributed to Dealing with the COVID-19 Pandemic?](https://thegradient.pub/how-has-ai-contributed-to-dealing-with-the-covid-19-pandemic/)

This piece reviews where AI research efforts have been realized as practical solutions, i.e. being used by corporations, governments, or individuals. Practical in this case refers to being used in the field,  be it on an individual or collective level.

Five general categories are used to distinguish the different contributions:

1. Clinical applications
2. Epidemiological applications
3. Applications for biochemistry
4. Providing information
5. Safety assessment

The TLDR is that the author believes the pandemic has strongly benefited from all the work that has been done on AI and that a future pandemic shall strongly benefit from AI, and will do so even more widely and more extensively.

Feedback on anything we missed is welcome! This is a large topic to address, so it may make sense to public a supplementary piece, we'll see.",MachineLearning
nk2t63,1621875882.0,[D] Using Two Optimisers for Large Model with two parts? Need Advice,"Hello there,

I have a very large model (\~51M params) that comprises of two sections, one non-differentiable and the other differentiable. I tried training the whole thing using GD (like Adam, SGD, etc.) but the results were very subpar.

I have tried using derivative-free optimisation algorithms like genetic algos but the results were even more abysmal. I am aware of CMA-ES, ARS, PGPE, and other blackbox optimisers but they only work on smaller models with <10K params (and that's stretching it too lol). Similarly, Simuated Annealing and Hill Climbing also failed.

My new idea is to use two optimisers: one gradient-based and the other gradient-free. During each epoch, I hope to tune the parameters separately while using the loss at the end as the only feedback signal. I want to optimise both subsections in a disconnected fashion without entangling their parameters together. That way, both modules can be trained while being oblivious to the other's performance, ideally forcing them to become better and not rely on the other to improve the network as a whole.

Would like some advice on how I can go about this and if there are any alternatives I should consider.

I'm open to all options. Appreciate any help :D

Thanks!",MachineLearning
nk2s3y,1621875813.0,[D] Regarding training BERT from scratch,"Hi everyone,

This might seem to be a trivial question, but any advice is appreciated.

While  training BERT from scratch makes sense, why do we not use pretrained  embedding as an initialization point for the model (instead of training  it from scratch). I can understand why they didn't do it in first paper,  since they were trying to understand model effectiveness but doesn't it  make sense now to see if these initialisations can do better (given we  have multiple variants)? I might be skipping one or more papers here,  feel free to correct me. Secondly,  if they don't work, do we have an  intuition for it?

If somebody has tried this and if it didn't work, do we have an intuition for this?

Is  there a study for the inherent structure between the matrices that can  tell about the similarity or difference in the matrices at different  layers?",MachineLearning
nk0bpp,1621869431.0,[D] Why Intel's DL-based photorealistic enhancement tech is not ready for prime-time gaming,"Last week, Intel unveiled a DL system that enhances GTA V's graphics to photorealistic level. Several media outlets have suggested that the technology has turned GTA V to ""a photorealisitc game.""

While impressive, Intel's image-enhancement system is not ready for prime-time gaming. Here are three key reasons:

* **Memory**: The model requires more than a gigabyte of VRAM for inference. While this amount of memory is available on most gaming computers, we must also consider that games gobble up most of the resources of the GPU at runtime. Basically, to free up memory for photorealistic render, the users will have to make some kind of sacrifice, such as playing at a lower resolution.
* **Sequential processing**: Neural nets rely on non-linear computations. So while you can use a GPU to process several inputs in parallel, each input must go through the entire sequence of layers. Intel's model contains at least 100 layers of computation, which is nearly impossible to run at playable framerates with current graphics cards. The researchers tried it on RTX 3090, which has no shortage of VRAM, and they still got 2 frames per second. They have suggested some optimizations to integrate the model into the game engine. This could give it a speed boost, but not enough to get anywhere near playable framerates.
* **Development and training costs:** The researchers needed thousands of well-annotated images of urban settings to train the model. Lucky for them, the Cityscapes team had already done this for them. But if a game takes place in a setting that doesn't have an open-source dataset, then it will be up to the game devs to curate or generate and annotate their own dataset of images, which can come with huge costs. Also, most gaming companies don't have ML talent to develop, tune, and train models.

Read the full analysis here. Happy to hear thoughts on/corrections to the take:

[https://bdtechtalks.com/2021/05/24/intel-ai-photorealistic-enhancement/](https://bdtechtalks.com/2021/05/24/intel-ai-photorealistic-enhancement/)",MachineLearning
njyzct,1621865773.0,[D] I'm new and scrappy. What tips do you have for better logging and documentation when training or hyperparameter training?,"Hi,

I'm relatively new to the field. I'm self-taught (like most) and have a pretty scrappy approach to logging and documenting. I want to have a more organised approach.

I'm looking for tips, resources, or a discussion on what methods are available to be more systematic with the way I document my ML training and hyperparameter optimisation.

For example, when training a model for a specific project, do you save each hyperparameter configuration and output in a .json? Or should I use a .txt? Is one of these formats more suitable for hundreds of separate fittings?

How do you save your learning curves? Also a .json file?

Is there any reason to save each model you train?

Thanks in advance!

Edit: I use sklearn mostly. Is there a universally accepted way to log or is it package dependent? ",MachineLearning
njxvc3,1621862584.0,How to geo-cluster houses in a real-estate dataset? [D],"I have a fairly large portfolio of houses (think thousands) that I want to cluster based on - proximity to neighboring houses and some house types (fuel source, detached / apartment ...).

The goal is to create clusters based on the distance to other houses and the types (e.g., cluster of 5 houses max. 50 meters from each other which are all on the same fuel source and are detached). Luckily, in my dataset it is most likely that houses next to each other will also be of the same type.

Do you have any tips on algorithms / approaches for this job? I am proficient in Python / R.

Thank you.",MachineLearning
njx0df,1621859947.0,[D] Paper Explained - Expire-Span: Not All Memories are Created Equal: Learning to Forget by Expiring (Full Video Analysis),"[https://youtu.be/2PYLNHqxd5A](https://youtu.be/2PYLNHqxd5A)

Facebook AI (FAIR) researchers present Expire-Span, a variant of Transformer XL that dynamically assigns expiration dates to previously encountered signals. Because of this, Expire-Span can handle sequences of many thousand tokens, while keeping the memory and compute requirements at a manageable level. It severely matches or outperforms baseline systems, while consuming much less resources. We discuss its architecture, advantages, and shortcomings.

&#x200B;

OUTLINE:

0:00 - Intro & Overview

2:30 - Remembering the past in sequence models

5:45 - Learning to expire past memories

8:30 - Difference to local attention

10:00 - Architecture overview

13:45 - Comparison to Transformer XL

18:50 - Predicting expiration masks

32:30 - Experimental Results

40:00 - Conclusion & Comments

&#x200B;

Paper: [https://arxiv.org/abs/2105.06548](https://arxiv.org/abs/2105.06548)

Code: [https://github.com/facebookresearch/transformer-sequential](https://github.com/facebookresearch/transformer-sequential)",MachineLearning
njufdn,1621850789.0,[N] Open source Best Practices for Ethical and Responsible Machine Learning,"The Foundation for Best Practices in Machine Learning released the first versions of their organisation and technical Best Practices.

The Best Practices are free and open source!

The Best Practices are designed to be easily accessible to anyone working on or interested in machine learning. They can be used as:
- A way to get started with implementing ethical and responsible machine learning in products;
- A common language between data scientists, engineers, managers and governance & compliance professionals;
- A repository for your responsible machine learning questions;
- A point of reference for your machine learning audits, policies, governance and regulations.

They are also open source and they are looking for contributors through their wiki portal: https://wiki.fbpml.org/wiki/Main_Page

Find the Best Practices on their website: https://www.fbpml.org/home

Or find them on LinkedIn: https://www.linkedin.com/company/the-foundation-for-best-practices-in-machine-learning",MachineLearning
njtz1m,1621848945.0,[R] Differential Privacy,"I have recently decided to look into this topic and it seems pretty amazing. The basic idea is to anonymize the dataset and add random noise to the database queries outputs. The anonymization includes generalizing the dataset with each attribute's specific taxonomy tree.  I think, decision tree can come in handy with its information gain at each level, I can find a best split and produce the tree from there.

The problem is I unable to produce such taxonomy. The numeric attributes such as 40, 45, 47 will be generalized in a range like \[40-50\]. I don't how to produce such ranges and also, I don't know how to find a way to merge into the dataset as after replacing the values with the generalized one, I will be left with strings of the ranges .

Also, I can't find any way to produce a taxonomy for string attributes like jobs such as engineer, teacher, etc. If anyone knows the way around feel free to help.",MachineLearning
njsjig,1621842936.0,[D] What are the active fields of research in Bayesian ML?,"I have only a vague idea that Variational Autoencoders are quite mature already and there is a lot happening about making Variational Inference usable for larger datasets.

Can you give me some more detailed and broader view of the topic? Thanks a lot :)",MachineLearning
njr0vr,1621836395.0,[R] Machine Learning Baseline Model,"Assume you work for an apparel retailer as a data scientist and your task is to send out 100,000 advertising mail pieces to past customers about a new line of fall apparel. You have access to a database of information about past customers, including what they have purchased and their demographic information (Ramakrishnan 2018). What model should you build first?

A baseline!

In this article, we will discuss what a baseline is and where it fits in our data analysis projects. We will see that there are two different types of baselines, one which refers to a simple model, and another which refers to the best model from previous works. A baseline guides our selection of more complex models and provides insights into the task at hand. Nonetheless, such a useful tool is not easy to handle. A literature review (Lin 2019; Mignan 2019; Rendle et al. 2019; Yang et al. 2019) shows that many researchers tend to compare their novel models against weak baselines which poses a problem in the current research sphere as it leads to optimistic, but false results. A discussion on such contemporary issues and open-ended questions is also provided at the end, followed by suggestions aimed at the community.

https://blog.ml.cmu.edu/2020/08/31/3-baselines/",MachineLearning
njiy2c,1621808730.0,[D] Is it financially viable to do a PhD in the UK as a Canadian/international?,"Looking at Oxford, Cambridge, UCL websites the tuition for international PhD is 20-30k pounds per year whereas domestic fees are only 5-8k.

Are international students able to break even on the tuition from scholarships and teaching assistantship? Should I even bother applying if I don't want to get a $100k loan to do a PhD?",MachineLearning
njhtei,1621805420.0,[R] An overview of some available Fairness Frameworks & Packages,"I've created an overview with some available fairness toolkits. I hope it can be helpful for one or the other.

Content:

1. The LinkedIn Fairness Toolkit (LiFT)

2. Fairlearn: Fairness in machine learning mitigation algorithms

3. AI Fairness 360

4. Algofairness

5. FairSight: Visual Analytics for Fairness in Decision Making

6. GD-IQ: Spellcheck for Bias (code not available)

7. Aequitas: Bias and Fairness Audit Toolkit

8. CERTIFAI: A Common Framework to Provide Explanations and Analyse the Fairness and Robustness of Black-box Models

9. ML-fairness-gym: Google’s implementation based on OpenAI’s Gym

10. scikit-fairness

11. Mitigating Gender Bias In Captioning System

Link:  [An overview of some available Fairness Frameworks & Packages](https://murat-durmus.medium.com/an-overview-of-some-available-fairness-frameworks-packages-ff22fde9d2f4)",MachineLearning
njfsc6,1621800005.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 113,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)|[Week 112](https://reddit.com/n8m6ds)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)||

Most upvoted papers two weeks ago:

/u/HateRedditCantQuitit: [Autodidax: JAX core from scratch](https://jax.readthedocs.io/en/latest/autodidax.html)

Besides that, there are no rules, have fun.",MachineLearning
njfb7s,1621798661.0,"[D] Efficient Learning, what direction is best to invest ?","How should someone approach the problem of efficient learning ?

There is many ideas and they all seem legit (GANs to generate more data, weakly supervised learning, self supervised learning, fine tuning and others), what should someone choose if no time is there for testing and evaluating all of them ?",MachineLearning
njf8ba,1621798437.0,[D] Time-varying covariates in survival analysis,"I'm doing survival analysis in order to predict the time-to-failure of machines and some of my covariates are from sensors (pressure, vibration, etc.). Up until now I've been building parametric models using a survival dataset in which I only have a single value for each sensorization covariate, which is the value at the time of failure or at the time of maintenance in the case of censored cases (i. e. I've been treating these covariates as if they were a constant value throughout the whole period of observation). However, I just came to the conclusion that this would not work well in real life. Is there a way of estimating parametric survival models with time-varying covariates? If so, how can I do it in R? Any help is appreciated because I have to finish my dissertation soon and I'm running out of time. Thank you in advance! ;)",MachineLearning
njevld,1621797450.0,[D] Practicality of a Machine Learning classifier for driver vigilance?,Through computer vision and machine learning. Is it possible to build a neural network that can classify if the driver is engaged/focused or vice versa? What are some potential challenges and what kind of data would be needed/best for training this model? Let me know what you guys think.,MachineLearning
njbv6z,1621789104.0,[D] Should I use locality-sensitive hashing or MD5 to check if two datasets are the same?,"I need to compare if two datasets (of type audio, text, image, etc.) are the same or not. Should I use locality sensitive hashing or split the dataset into smaller chunks and hash using MD5/SHA-1.

I'm leaning towards the second step. Locality sensitive hashing is more about finding similar items but I only need to check if two datasets are exactly the same or not. Both run on O(n) time complexity so I don't think speed will be a difference.",MachineLearning
njbjfb,1621788151.0,[D] Is there a point to having layers with just a linear activation?,"I know in some contexts you can use a linear layer with no activation to increase or decrease the size of a vector.  However, I have been looking at wavenet implementations and I noticed that they apply a linear layer with no activation function before adding to the residual bus.  The size of the output convolutions appears to be the same as that of the dilated convolutions so the linear layer is not needed to resize the outputs and they could be directly added to the bus.  Is there really any point to doing this?  The 1x1 conv on top eventually has a ReLU applied to it.  However, the bottom one is simply added to the resnet bus, and goes on to the next layer of dilated convolutions.   Could I just remove the bottom 1x1 conv or is there a good reason for having it?

                   |-> [gate]   -|        |-> 1x1 conv -> skip output
                   |             |-> (*) -|
            input -|-> [filter] -|        |-> 1x1 conv -|
                   |                                    |-> (+) -> dense output
                   |------------------------------------|

If you look at the following code I got from ([https://github.com/imdatsolak/wavenet/blob/master/mlwavenet.py](https://github.com/imdatsolak/wavenet/blob/master/mlwavenet.py)).  Notice that res\_x and skip\_x have no activation.  Also it appears it has the same number of filters as tanh\_out and sigm\_out.  Why are these filters needed?

&#x200B;

        def _build_model_residual_block(self, x, i, s):
            original_x = x
            # TODO: initalization, regularization?
            tanh_out = CausalDilatedConv1D(self.filters, 2, atrous_rate=2 ** i, border_mode='valid', causal=True, bias=self.use_bias, name='dilated_conv_%d_tanh_s%d' % (2 ** i, s), activation='tanh', W_regularizer=l2(self.res_l2))(x)
            sigm_out = CausalDilatedConv1D(self.filters, 2, atrous_rate=2 ** i, border_mode='valid', causal=True, bias=self.use_bias, name='dilated_conv_%d_sigm_s%d' % (2 ** i, s), activation='sigmoid', W_regularizer=l2(self.res_l2))(x)
            x = layers.Multiply()([tanh_out, sigm_out])

            res_x = layers.Conv1D(self.filters, 1, padding='same', use_bias=self.use_bias, kernel_regularizer=l2(self.res_l2))(x)
            skip_x = layers.Conv1D(self.filters, 1, padding='same', use_bias=self.use_bias, kernel_regularizer=l2(self.res_l2))(x)
            res_x = layers.Add()([original_x, res_x])
            return res_x, skip_x


&#x200B;",MachineLearning
njajvr,1621785286.0,[D] Are there parallels between patch-based image models and biological vision systems?,"Recently, we have seen patch-based image models perform very well on image recognition tasks. First, we saw this using attention-based models like ViT, and more recently in work like MLP-Mixer.

In a way, this seems (very) loosely similar to how our own brains (and indeed the brains of many other species) process visual information. Namely, there is a high acuity structure in the eye (fovea centralis) which saccades from place to place. The brain then processes this stream of saccades (along with lower acuity peripheral vision) to construct a 3D model of the world. That is to say, the brain looks to be stitching together visual patches using some (presumably not fully understood) mechanism.

Perhaps this comparison has been made in either the papers eluded to above or elsewhere in the literature. If so, I've sadly missed it.

I would be interested to hear if anyone thinks there is something to this comparison, or not :).",MachineLearning
nja3mx,1621783957.0,[P] GPT-2 - Annotated Paper + Paper Summary,"The GPT-2 model was a major breakthrough in the path of creating a general multitask NLP system that was totally unsupervised. It demonstrated that given a large training corpus and a large model size, the language model was capable of learning the knowledge required for solving these tasks. It was not perfect, however, and performed poorly on some tasks as well.

I went through the paper and have written an informative summary of the paper.  The paper was quite easy to follow and the experimentation section had interesting observations. Check out the links below and happy reading!

Paper Summary -  [Language Models are Unsupervised Multitask Learners](https://shreyansh26.github.io/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf)",MachineLearning
nj9tyu,1621783161.0,[P] ResNet-18 magnitude based pruning,"ResNet-18 global, unstrctured, magnitude based and iterative pruning with CIFAR-10 dataset. The pruning goes on till 99.08% sparsity.

This is based on the research papers:

1. ""Learning both Weights and Connections for Efficient Neural Networks"" by Song Han et al.
2. ""Deep Compression: by Song Han et al.
3. ""The Lottery Ticket Hypothesis"" by Frankle et al.
4. ""What is the State of Neural Network Pruning?"" by Blalock et al.

Original and unpruned model has  val\_accuracy = 88.990% . Original model size = 42.7 MB, zipped model size = 40 MB.

Pruned model with sparsity = 99.063% has  val\_accuracy = 91.260%. Pruned, trained and zipped model size = 3.5 MB. This results into a compression ratio = 11.43%.

You can refer to the code [here](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet18_Global_Magnitude_Custom_Pruning.ipynb).

*NOTE:* Post pruning PyTorch doesn't cast tensors to sparse format. Therefore, the tensors are of the same dimensions as before but with 0s in it to denote pruned connections.

Thoughts?",MachineLearning
nj9rgq,1621782945.0,"[N] LinkedIn Open-Sources ‘Greykite’, A Time Series Forecasting Library","LinkedIn recently opened-sourced [Greykite](https://engineering.linkedin.com/blog/2021/greykite--a-flexible--intuitive--and-fast-forecasting-library), a Python library originally built for LinkedIn’s forecasting needs. Greykite’s main algorithm is Silverkite, which delivers automated forecasting, which LinkedIn uses for resource planning, performance management, optimization, and ecosystem insight.

While using predictive models to estimate consumer behavior, data drift has proven to be a great challenge during the pandemic in 2020. In such a situation, predicting future expectations is challenging as well as necessarily helpful to any business. Automation, which allows for repeatability, can increase accuracy and can be used by algorithms to make decisions further down the line. According to LinkedIn, Silverkite has improved revenue forecasts for ‘1-day ahead’ and ‘7-day ahead’ and Weekly Active User forecasts for 2-week ahead.

Full Summary: [https://www.marktechpost.com/2021/05/23/linkedin-open-sources-greykite-a-time-series-forecasting-library/](https://www.marktechpost.com/2021/05/23/linkedin-open-sources-greykite-a-time-series-forecasting-library/?_ga=2.74959442.1924646600.1621739878-488125022.1618729090)

GitHub: [https://github.com/linkedin/greykite](https://github.com/linkedin/greykite)

PyPI: [https://pypi.org/project/greykite/](https://pypi.org/project/greykite/)

Paper: http://arxiv.org/abs/2105.01098",MachineLearning
nj6ui3,1621773162.0,[R] Over-fitting in Iterative Pruning,"In global, unstructured and iterative pruning algorithms such as:

1. ""Learning both Weights and Connections for Efficient Neural Networks"" by Han et al.
2. ""Deep Compression"" by Han et al.
3. ""The Lottery Ticket Hypothesis"" by Frankle et al.

except ""The Lottery Ticket Hypothesis"" where the weights are rewind-ed to their original values and resulting sub-network is trained from scratch thereby needed more time/epoch.

Since the usual algorithm is:

Take a trained neural network and repeat steps 1 and 2:

1. prune globally smallest magnitude p% of weights
2. re-train/fine-tune pruned neural network to recover from pruning

Usually, the number of pruning rounds needed to go from original and unpruned network (sparsity = 0%) to 99% sparsity requires 25-34 rounds depending on the exact architecture and number of trainable parameters.

In my experiments I have observed that during this repeated *prune and repeat* algorithm, the resulting pruned neural networks start to overfit to the training dataset, which is to be expected. Apart from using techniques such as regularization, dropout, data augmentation, learning rate scheduler, etc. are there any other techniques to prevent this overfit?

I assume that such a resulting pruned sub-network when used for real world tasks might not perform as expected due to the overfitting induced due to the *iterative* process. Correct me if I am wrong.

You can refer to my previous experiments [here](https://github.com/arjun-majumdar/Neural_Network_Pruning) and [here](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2).

Thanks!",MachineLearning
nj5oj9,1621768413.0,[D] Using CMA-ES to train model on dataset (supervised),"Hello folks,

I'm looking a way to train a rather large model (50M params) that's not gradient-descent-friendly during training (all gradient based methods are failing horribly with a shabby increase in accuracy). I'm looking to use CMA-ES to optimise the params in the model. I've read up on the basics of implementing it but want a second opinion.

I came across this post on StackExchange and found it useful for my problem. [https://datascience.stackexchange.com/questions/64007/covariance-matrix-adaptation-evolution-strategy-cma-es-implementation-with-ten](https://datascience.stackexchange.com/questions/64007/covariance-matrix-adaptation-evolution-strategy-cma-es-implementation-with-ten)

I've also been reading u/hardmaru 's Attention Agent paper from GECCO 2020 and [his article](https://blog.otoro.net/2017/10/29/visual-evolution-strategies/) and [Lillian Weng's article](https://lilianweng.github.io/lil-log/2019/09/05/evolution-strategies.html) on the various evolutionary optimisation algorithms.

For very very large models, I feel this blows up the total parameter count of N model copies (""children"") by a large extent. I'm training on a Colab TPU but can move to GCP TPU v3 if needed (I managed to snag a few from TFRC). I'm using PyTorch XLA as the framework.

Can I get some advice on how to go about this? Is there a better way of training my network? I'm aware of Hill Climing and Simulated Annealing but have heard CMA-ES outperforms them and is effective.

Any thoughts and possible directions welcome.

Thanks again!",MachineLearning
nj3icz,1621758990.0,[D] What left-field approaches to AI do you know of?,"Over the years, I've come across the occasional alternative approach to AI. Huge efforts creating comprehensive hardcoded domain knowledge, alternatives to neutral nets, etc, but I regret not bookmarking them so the above descriptions is all I remember. Do you guys know of interesting/quaint but serious efforts of doing things really differently? It would be nice to eventually get an overview of all the wierdness out there.

Edit: thanks everyone, interesting stuff so far. Does anyone know the two examples I was referring to? I'd love to find them again. One was a professor, that, as a alternative to gpt-like nlp, was handcrafting a huge database of concepts and how they related to eachother. I read about this.. 2-3 years ago and the effort was ongoing.  The other one was a machine learning alternative to neutral nets. I think it had a 3 letter acronym with an M and a C in it? It also had one lone professor/flagbearer. Can't remember much about it, but it didn't fit into anything I had heard of. I can't remember the general premise.. Not SVM on anything that common. It was.. mid 2000's tech.?",MachineLearning
niy8f1,1621737611.0,[D] We need a new reviewing system,"Nowadays there are two reviewing systems that coexist, and both are broken in their own way:

* **the formal conference/journal reviewing system.** It is broken because  (1) only a small fraction of papers gets accepted, so that the  conference/journal remains prestigious, but there are many more papers  that deserve to be published, (2) bad reviews are rarely read and debunked by the community, even when they are public, (3) the reviewing cycle is too slow.
* **the informal  social media reviewing system.** People post their opinions about new papers in the form of blog posts / tweets / reddit posts.  These reviews often lack the formalism, rigor and completeness of a real peer review (with some exceptions). And many papers that would deserve  the attention of reviewers are never reviewed.

What would be nice is a reviewing system that combines the best of both worlds:

* **reviews are posted directly on twitter and reddit**, where the community can read and discuss them.
* **reviews are moderated** to make sure they are formal (and not just baseless opinions or disrespectful rants).
* **anyone can write a review** (anonymously or not).
* **anyone can ask for a review** about any paper of interest (authors themselves or others).

This is what we are proposing to do at Flying Scholars.

What do you think?",MachineLearning
nivevu,1621727762.0,[D] Does code for relational networks related to physical system dynamics actually exist?,"I'm talking of course, about the paper [A simple neural network module for relational reasoning](https://arxiv.org/pdf/1706.01427.pdf). The paper itself does not have any corresponding code, through some folks seem to have implemented certain parts of it.

&#x200B;

The code I am looking for is related to their claim of being able to model physical dynamical systems. Are there any sources that have actually implemented this part? Thanks",MachineLearning
nit6vw,1621720787.0,[P] Implementation of KernelSHAP on NumPy,"I implemented KernelSHAP on NumPy. https://github.com/mburaksayici/ExplainableAI-Pure-Numpy/blob/main/KernelSHAP-Pure-Numpy.ipynb

I also recorded a video on details https://youtube.com/playlist?list=PLRRY18KNZTgVYJWXkby5V7sXuRyVaHt9p , I tried my best at least.",MachineLearning
niqcde,1621712401.0,[R] Help with understanding the Mathematics / Theory behind the UMAP paper.,"I posted this on the math subreddit but didn't get a lot of responses, so let me try here.

I am from a comp science Machine Learning background. I have taken some additional math classes including Real Analysis, Probability Theory (the measure theoretic one), some convex optimization courses and some statistics courses that would presumably help with my ML education.

But I was reading this paper: [UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction](https://arxiv.org/pdf/1802.03426.pdf) and I found it very hard to follow.

The authors recommend background texts on category theory, but they seem to be huge references to an entire field, and I am not even sure I have the required background for it.

So, if anyone is familiar with the paper/idea can they please recommend some introductory texts or at least enumerate the background areas that would help me understand the concepts discussed considering my background. Particularly the ""local fuzzy simplical sets"", ""spectral methods"",  ""probabilistic t-conorm"" etc.",MachineLearning
nip6gg,1621709049.0,[R] Strategies and Tactics for Regression on Imbalanced Data,"Hello everyone! Happy to share our new work on tackling regression problems on imbalanced data (this work was accepted at ICML 2021 as a Long oral presentation!).

Data imbalance is ubiquitous and inherent in the real world. Under the classic problem of data imbalance, this work explores a very practical but rarely studied problem: **imbalanced regression**. Most of the existing methods for dealing with imbalanced data are only for classification problems — that is, the target value is a discrete index of different categories; however, many practical tasks involve **continuous**, and sometimes even **infinite** target values. This work promotes the paradigm of the traditional imbalanced classification problems, and extends the data imbalance problem from **discrete** targets to **continuous** ones.

Such imbalanced problem in the continuous domain exists in both *linear* and *deep* models. It is even more serious in the deep model. Why is this? Because neural network predictions are often *over-confident*, and this data imbalance issue is severely magnified. So, in this work, we formally define and investigate Deep Imbalanced Regression (DIR) arising in real-world settings.

We develop two simple, effective, and interpretable algorithms for addressing DIR: *label distribution smoothing (LDS)* and *feature distribution smoothing (FDS)*, which exploit the ***similarity*** between nearby targets in both *label* and *feature* spaces. The proposed algorithms are easy to implement, and could serve as a good starting point for this new problem.

To support practical evaluation of imbalanced regression methods, we also curate large-scale DIR datasets for common real-world tasks in computer vision, natural language processing, and healthcare. They range from *single-value* prediction such as age, text similarity score, health condition score, to *dense-value* prediction such as depth. The new datasets could support practical evaluation, and facilitate future research on imbalanced regression. Check out the links below for more details:

* **Paper**: [https://arxiv.org/abs/2102.09554](https://arxiv.org/abs/2102.09554)
* **Code** (+ dataset + models): [https://github.com/YyzHarry/imbalanced-regression](https://github.com/YyzHarry/imbalanced-regression)
* **Blog post** (check out for in-depth details!): [TowardsDataScience](https://towardsdatascience.com/strategies-and-tactics-for-regression-on-imbalanced-data-61eeb0921fca)

&#x200B;

[Deep Imbalanced Regression \(DIR\) aims to learn from imbalanced data with continuous targets, tackle potential missing data for certain regions, and generalize to the entire target range.](https://i.redd.it/nmd0uinevp071.gif)

Let me know if you have any questions or comments!",MachineLearning
nim8w4,1621700701.0,[D] Make a model do binary classification on a user-specified class in a multi-class scenario?,"Title sounds confusing, but let me clarify. \*\*Each image can only contain 1 class.\*\* Let's say you have 3 classes (0, 1, 2), but you only want to see if class 0 is in an image

\`\`\`

model(\[image,0\]) -> outputs binary classification of class 0 with sigmoid + threshold.

\`\`\`

This is not the same as straight up the model outputting logits for all 3 classes and then softmax + argmax because then the model predicts either the most likely class even if the probability of the 2nd most likely class is high.

&#x200B;

I feel like that this has been done before, like using said \*\*inputted class as part of a loss function to limit the output to 1 class. What is the name of this procedure (if it has one) or are there any relevant papers that do something like this?\*\*

&#x200B;

Maybe I'm overthinking it idk. Thanks.",MachineLearning
nim25x,1621700176.0,[D] Researching with no affiliations to any Universities/Academic organizations?,"Naive High-Schooler here - I had a pretty solid idea (or so I think) of a particular experiment I want to do which involves an intersection of 2 fields (ML + Signal Processing). It hasn't been done before (surprisingly) and there isn't much research into that area.

I wanted to write a research paper on my idea, but obviously lack the skill and resources needed to experiment more with the idea.

I know universities and professors often secure research grants to fund their work, but I don't have any affiliations with any universities.

Is there any way I can still provide my idea, some of the solutions to the problems created using it and implementation/coding help to a professor/uni and get myself listed as a co-author of the paper?

Or can I go down some other path to help me publish the idea?

>NOTE: Even though I am publishing primarily for my C.V, I think my solution is highly novel and **might** benefit the industry. But It appears I am stuck without an actual professor :(",MachineLearning
nil73w,1621697712.0,[D] How much memory does Intel's GTA5 image-enhancer use for inference?,"Last week, Intel presented a neural network that enhances the graphics of Grand Theft Auto 5 to photorealistic level. The results are impressive (video [here](https://www.youtube.com/watch?v=P1IcaBn3ej0), paper [here](https://arxiv.org/abs/2105.04619)) and the researchers state that they were able to perform the transformation at ""interactive rate,"" which I assume is near real-time.

I'm trying to figure out how much memory/horsepower the model needs to perform the transformation in real-time. The question is, what size of a GPU you would need if this would become a real feature.

The paper provides information about the structure of the neural network but very little in terms of implementation details. Below is the key components of the model that are used during inference (there are more pieces to it, but those are used during training).

&#x200B;

https://preview.redd.it/fz20jfpfuo071.png?width=936&format=png&auto=webp&s=2b102649814548edab8bd3930c361a1a46bf3db4

I tried to figure out the numbers based on what information exists in the video and paper. The Image Enhancement Network is a modified version of HResNetV2 (paper [here](https://arxiv.org/abs/1908.07919)). On a 1024x2048 input the HResNetV2 uses 1.79GB of video memory on a size-1 batch.

&#x200B;

https://preview.redd.it/8m2unyezvo071.png?width=2600&format=png&auto=webp&s=f88f39cff397405005ac96119b9df1a38e45b883

Intel's model has made some modifications to HResNetV2, including the replacement of batch normalization layers with rendering-aware denormalization modules, which add more learned parameters to the model. So I suppose this makes a minimal addition to the model's size.

Also, the G-buffer encoder takes six different maps (normals, depth map, albedo, glossiness, atmosphere, segmentation), and encodes them into a 128-component feature vector. There are no details on how many convolution layers are used and I'm not sure what the input size is, so I don't know what the model size will be, but it is a lot smaller than the main image enhancer network.

&#x200B;

https://preview.redd.it/h0xwfk40xo071.png?width=1342&format=png&auto=webp&s=fc8ce4efc699cca58c24b529be6179fcd8c4514c

Here's an interesting quote from the paper: ""Inference with our approach in its current unoptimized implementation takes half a second on a Geforce RTX 3090 GPU. Since G-buffers that are used as input are produced natively on the GPU, our method could be integrated more deeply into game engines, increasing efficiency and possibly further advancing the level of realism.""

Given all we know about the image enhancer, how much do you estimate its memory consumption to be?

Also considering that GTA5, a game that was released in 2013, [can consume up to 3.5G of VRAM](https://www.reddit.com/r/nvidia/comments/405yy9/how_much_vram_does_gta_v_1080p_use/) in 1080 resolution, how realistic is it to see this kind of enhancement become available for gamers who don't have the highest-end graphics card?",MachineLearning
nijpfk,1621693405.0,[D] How to turn Minecraft maps into photorealistic 3d scenes explained!,"Did you ever want to quickly create a photorealistic 3d scene from scratch?

Well, now you can! The authors from NVidia in their paper ""**GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds**"" proposed a new neural rendering model trained with adversarial losses ...WITHOUT a paired dataset.

Yes, it only requires a 3D semantic block world as input, a pseudo ground truth image generated by a pretrained image synthesis model, and any real landscape photos to output a consistent photorealistic render of a 3D scene corresponding to the block world input. Check out the [full paper explanation on my channel](https://t.me/casual_gan/41)!

Here is an example of the model outputs:

[Looks like something out of a PS3 game but still very impressive](https://reddit.com/link/nijpfk/video/ydjbojhrko071/player)

\[[Full Explanation Post](https://t.me/casual_gan/41)\] \[[Arxiv](https://arxiv.org/pdf/2104.07659.pdf)\] \[[Project Page](https://nvlabs.github.io/GANcraft/)\]
More recent popular paper explanations:
\[[DINO](https://t.me/casual_gan/40)\]
\[[MLP-mixer](https://t.me/casual_gan/35)\]
\[[Vision Transformer (ViT)](https://t.me/casual_gan/33)\]",MachineLearning
niiwqa,1621690970.0,[P][SP] MLP-Mixer implementation in Flax + PyTorch [Video],"Hey there,

I made a video where I implement the MLP-Mixer in both Flax and PyTorch. Among other things, I try to discuss in what way it is similar to CNNs. Also, if you have never used Flax before the video contains a quick tutorial on the most important concepts.

&#x200B;

Original paper: [https://arxiv.org/pdf/2105.01601.pdf](https://arxiv.org/pdf/2105.01601.pdf)

My video: [https://youtu.be/HqytB2GUbHA](https://youtu.be/HqytB2GUbHA)",MachineLearning
nihwz7,1621687694.0,Clothing prediction based on weather [R] [P],"Hello all!

I  live in the UK, and I never know what to wear - the problem is more  complicated than ""what temperature is it"" (is it raining, is the sun  out, humidity, wind...)

I've  created a website where people can log how ""comfortable"" they are, and  what they've got on (and the site automatically records the current  weather conditions)

[https://weather-clothing.web.app/](https://weather-clothing.web.app/)

Hopefully, this will give me a good dataset which I can use to train some AI model, and start making predictions!

If you have any ideas, I'd appreciate the input!",MachineLearning
nig3h7,1621681011.0,[P] Find Trending Machine Learning Research Papers on Twitter,"We developed a website to find popular/trending research papers on Twitter.

**Link:** [https://papers.labml.ai/](https://papers.labml.ai/)

Features that I like to highlight here:

* Analyses the Twitter feed and shows popular/trending research papers daily, weekly and monthly basis.
* Shows tweets, retweets and likes count for each paper so that the user can filter out random papers.
* Shows, popular tweets that related to each research paper.

**We love to hear your feedback and suggestions**. Thank you all and I appreciate the support.",MachineLearning
niecie,1621673513.0,[R] Video Datasets,"Here is a list of existing video datasets for cv research [https://github.com/xiaobai1217/Awesome-Video-Datasets](https://github.com/xiaobai1217/Awesome-Video-Datasets)

&#x200B;

https://preview.redd.it/0qnslgsdym071.png?width=610&format=png&auto=webp&s=e3ad18975fe3ee7ea6dbfb8714a1f317bebf34de",MachineLearning
nid87e,1621668493.0,[R] Tsetlin machine framework attains F1 score of 0.901 on PolitiFact and 0.896 on GossipCop with interpretable AND-rules. New interpretable state-of-the-art?,"&#x200B;

[Tsetlin machine \(TM\) vs state-of-the-art techniques](https://preview.redd.it/681uclr9gm071.png?width=1128&format=png&auto=webp&s=a4cf6c11fa7dda282d950c7aa44cb1fadb55b19c)

The framework uses the conjunctive clauses of the Tsetlin machine to capture lexical and semantic properties of both true and fake news text. The resulting model decomposes straightforwardly into meaningful words and their negations, for increased interpretability. [https://arxiv.org/abs/2105.09114](https://arxiv.org/abs/2105.09114)",MachineLearning
nic6at,1621663833.0,[D] BERT experiment variance,"When training BERT-variants or probably even neural networks in general, the performance varies a lot depending on random initialization. The extent of this ofc depends alot on the architecture, size of dataset, training procedure etc, but in the end there will often be a significant variance, especially when comparing on benchmarks where you are like 1-2% better than the competition.

Now in academic papers I took it for granted, that the authors perform multiple runs with the same configuration and report mean and std. Recently I have seem many papers that don't do so, (or dont mention it) even from FAANG. One example is the recent FNET paper.

1. Do they actually perform multiple runs and just report the mean without mentioning it? If so, why not include the std as well?

2. If they dont perform multiple runs, how can one ""rely"" on the results? I mean I can ""prove"" my great innovation by just running experiments until I get a lucky initialization even if it is complete trash.

3. What are best practices for this? How many runs per configuration should one perform to be confident about the result? Is the std of the performance interesting as well?",MachineLearning
nia3hs,1621655480.0,[P] Rudimentary real-time 2D to 3D media conversion and playback in VR,"Hi everyone,
I'm a developer working on a project for converting 2D media to 3D meshes using Intel's MiDaS ([https://github.com/intel-isl/MiDaS](https://github.com/intel-isl/MiDaS)) model for playback in VR. Running custom on-edge DirectCompute based inference engine in Unity.
Initial results and early prototype available here:
[https://www.youtube.com/watch?v=5ce4M5YdavY](https://www.youtube.com/watch?v=5ce4M5YdavY)",MachineLearning
ni90r9,1621651510.0,[N] Facebook’s ‘Expire-Span’ Tool Enables Machine Learning Models to Forget Irrelevant Data (Paper and Code included),"Facebook has recently developed an AI tool that allows machine learning models to preserve certain information while forgetting the rest. It claims that the tool, [**Expire-Span**](https://arxiv.org/pdf/2105.06548.pdf), can predict information most relevant to a task at hand thereby, allowing AI systems to process data at larger scales. 

Conventionally, AI models memorize information without distinction, unlike humans. Therefore, creating the ability to decide whether to forget the information or not at the software level is challenging. Usually, state-of-the-art models struggle with large quantities of information like books or videos and incurring high computing costs. This can lead to many other problems such as catastrophic learning or catastrophic interference, a situation where AI systems fail to recall what they’ve learned from a training dataset. 

Source: [https://www.marktechpost.com/2021/05/21/facebooks-expire-span-tool-enables-machine-learning-models-to-forget-irrelevant-data/](https://www.marktechpost.com/2021/05/21/facebooks-expire-span-tool-enables-machine-learning-models-to-forget-irrelevant-data/?_ga=2.232088284.2144888320.1621650511-488125022.1618729090)

Codes: [https://github.com/facebookresearch/transformer-sequential](https://github.com/facebookresearch/transformer-sequential)

Paper: [https://arxiv.org/pdf/2105.06548.pdf](https://arxiv.org/pdf/2105.06548.pdf)",MachineLearning
ni8i04,1621649593.0,[D] Possible research topics in Time Series analysis using ML,Hello there! I'm a master's student and I have an opportunity to publish a paper this summer. My advisor wants me to propose some possible research project ideas to get started. I'm interested in time series analysis as there seem to be many job opportunities in this area. So can anyone here suggest me some interesting research ideas within this domain? I know anomaly detection is a pretty hot topic these days but I'd also love to hear more!,MachineLearning
ni4osx,1621636361.0,[N] Google Unit DeepMind Tried—and Failed—to Win AI Autonomy From Parent,">LONDON—Senior managers at Google artificial-intelligence unit DeepMind have been negotiating for years with the parent company for more autonomy, seeking an independent legal structure for the sensitive research they do.
>
>DeepMind told staff late last month that Google called off those talks, according to people familiar with the matter. The end of the long-running negotiations, which hasn’t previously been reported, is the latest example of how Google and other tech giants are trying to strengthen their control over the study and advancement of artificial intelligence.

Full text: [https://www.wsj.com/articles/google-unit-deepmind-triedand-failedto-win-ai-autonomy-from-parent-11621592951](https://www.wsj.com/articles/google-unit-deepmind-triedand-failedto-win-ai-autonomy-from-parent-11621592951)",MachineLearning
ni4dfd,1621635439.0,[D] What is it like being a PhD student in a big research group?," Hello,

I was wondering what it is like doing a PhD in a big research group (Such as Sergey Levine, Pieter Abbeel etc...). These groups have \*a lot\* of students, so do these students regularly meet with their advisor; does their advisor look and discuss at a low-level about their research progress? Or are they mainly collaborating with other students in the group, and benefiting from that.

I am just confused about what makes such students really prolific in terms of research output, and what kinds of resources make these students stand out.",MachineLearning
ni3vxn,1621634029.0,"[R] Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI","A comprehensive overview and introduction on XAI:

## Highlights

• We review concepts related to the explainability of AI methods (XAI).

• We comprehensive analyze the XAI literature organized in two taxonomies.

• We identify future research directions of the XAI field.

• We discuss potential implications of XAI and privacy in data fusion contexts.

• We identify Responsible AI as a concept promoting XAI and other AI principles in practical settings.

link to the paper:  [https://www.sciencedirect.com/science/article/pii/S1566253519308103](https://www.sciencedirect.com/science/article/pii/S1566253519308103)",MachineLearning
ni2xch,1621631246.0,"[D] how ""interpertable"" are regression models?","I was recently reading some articles on the importance of ""interpertability"" when dealing with ""blackbox"" models. ""Blackbox"" models like neural networks are said to have a very low level of interpertability, because they don't allow the analyst to understand why the model is making a certain predictions for an individual observation.

On the other hand, models like decision trees and regression models are said to have much higher levels of interpertability. In a general sense, I can understand why models like decision trees are interpretable, because they literally provide the analyst with a set of fixed rules that explain how to classify an individual observation.

If you look at a regression model,

e.g. salary = 5.3 * height  + 2 * weight  - 15.8 * age

A regression model can allow the analyst to understand how much each variable contributes to the prediction (e.g. in this example, age contributes more to the prediction by a factor of almost 8 times), and you can also find out how statistically significant each variable is (e.g. indivudal p-value of each regression coefficient).

Is this what is meant by the ""interpertability of a regression model""?

Thanks",MachineLearning
ni0t28,1621625486.0,[D] Paper Explained - FNet: Mixing Tokens with Fourier Transforms (Full Video Analysis),"[https://youtu.be/JJR3pBl78zw](https://youtu.be/JJR3pBl78zw)

Do we even need Attention? FNets completely drop the Attention mechanism in favor of a simple Fourier transform. They perform almost as well as Transformers, while drastically reducing parameter count, as well as compute and memory requirements. This highlights that a good token mixing heuristic could be as valuable as a learned attention matrix.

&#x200B;

OUTLINE:

0:00 - Intro & Overview

0:45 - Giving up on Attention

5:00 - FNet Architecture

9:00 - Going deeper into the Fourier Transform

11:20 - The Importance of Mixing

22:20 - Experimental Results

33:00 - Conclusions & Comments

&#x200B;

Paper: [https://arxiv.org/abs/2105.03824](https://arxiv.org/abs/2105.03824)

&#x200B;

ADDENDUM:

Of course, I completely forgot to discuss the connection between Fourier transforms and Convolutions, and that this might be interpreted as convolutions with very large kernels.",MachineLearning
nhwwfs,1621615215.0,[R] High-performance speech recognition with no supervision at all,"Paper: https://ai.facebook.com/research/publications/unsupervised-speech-recognition

Blog: https://ai.facebook.com/blog/wav2vec-unsupervised-speech-recognition-without-supervision

Claims to get good performance while just using audio, unaligned text and a GAN.

Pretty incredible.",MachineLearning
nhve9v,1621611320.0,[P] Multivariate forecasting with Facebook Prophet,"A small open source package for using fbprophet for multivariate forecasting.

Blog post:

[https://vonum.medium.com/forecasting-multiple-dependent-variables-with-facebook-prophet-61e12302d50b](https://vonum.medium.com/forecasting-multiple-dependent-variables-with-facebook-prophet-61e12302d50b)

Github repo:

[https://github.com/vonum/multi-prophet](https://github.com/vonum/multi-prophet)

&#x200B;

Let me know your thoughts, all feedback and PRs are welcomed.",MachineLearning
nhuuvq,1621609952.0,[R] Unsupervised ways of comparing the quality of clusters between feature sets?,I'm trying to compare the same clustering technique (k-means) on different feature sets of the same data. Are there any ways I can perform internal validation on this?,MachineLearning
nhtr1e,1621607043.0,[D] Does it make sense to generate sentences with Transofmrer's encoder?,Quite a few vision+language papers pretrain BERT-based model with image-text data  and finetune for image captioning task.  But there is no decoder  involved to generate sentences. Does that make sense? And what's the  main difference between using T's encoder  to do the sentence generation  and do it with a  T' decoder?,MachineLearning
nhte7y,1621606097.0,[D] How to stay relevant for work after 1 year of break in ML?,"Hello guys,


Unfortunately being a male, my country requires me to serve the military for the next 1 year. That means a year with minimal or zero exposure to any code or machine learning. I had a job as a Data Scientist after college for 1 year that I had to stop recently because of that. I know my career will have to take a big hit but there is no way around it unfortunately. I'm a bit worried now how easy it will be 1 year from now to get a decent job, having a 1 year+ ""gap"" on my resume plus the big influx of Data Scientists coming each year. My goal is to increase my odds of getting hired as soon as possible after I finish my serving.



Some good news are that for the next 2 months I'm relatively free to study technologies that will boost my CV before I join the military, and help me land a job faster once I finish. Furthermore I might have some afternoons free inside the military during the year, to learn stuff or keep my memory fresh for the interviews. Nothing that would require a laptop though, only books or a smartphone with internet.



I know predicting what will be hot in a year might not be that easy, (especially since big advancements in ML and DL happen within the span of a few months) but I wanna min-max all my lost time. So given my situation above, what would you recommend me to focus on for:

a) The next 2 months where I will have access to laptop and free time

b) The next 10 months where I will have access only to books/smarthphone and little to no time


AWS? GCP? Docker? Thanks in advance!",MachineLearning
nhtcl8,1621605969.0,Schizophrenia in LaMDA [D],"At the Google IO 2021 they showed an example conversation between a human and a paper airplane.

Human: What's it like being thrown through the air?

LaMDA: .... The wind blowing against YOU, and the trees flying past ....

The question was about it's feelings. Not mine. The answer should be like: ""The wind blowing against ME, ...."".

This kind of schizophrenia is very common in our days in texts and live conversations when people use YOU instead of ME when talking about their own experience. So AI have picked this up as a normal behavior.

Using YOU instead of ME is a hypnotic technique to convince a person to accept one's feelings as his own feelings.",MachineLearning
nhr3y8,1621599462.0,[D] Has anyone worked with Physics Informed Neural Networks (PINNs)?,"I'm trying to decide on my final year project and one of them is supposed to be on geometric deep learning utilizing PINNs. I've skimmed through the paper introducing this (https://www.sciencedirect.com/science/article/pii/S0021999118307125) and it all seems very theoretical. The project aims to improve upon an existing biomedical classification task using PINNs and I'm not sure about how practical that will be.

Could someone please enlighten me on this? It'd be much appreciated. Thanks!

Edit: The ""biomedical classification task"" happens to be trying to predict heat transfer, fluid flow and patient specific tissue properties, tumor sizes and location by feeding in thermograms, 3D scans as well as bioheat transfer + navier stokes equations. I'm not very good with phrasing my sentences so apologies for any confusion in advance.",MachineLearning
nhpuao,1621595120.0,[N] Earthquake Prediction AI Challenge,[https://dphi.tech/challenges/aeta-earthquake-prediction-ai-algorithm-competition-2021/70/overview/about](https://dphi.tech/challenges/aeta-earthquake-prediction-ai-algorithm-competition-2021/70/overview/about),MachineLearning
nhnjr3,1621585770.0,"[R] A Review of ""Neural Anisotropy Directions"" (2020) by Flying Scholars","**Paper:** ""Neural Anisotropy Directions"" (2020)
*by Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard*
[https://arxiv.org/abs/2006.09717](https://arxiv.org/abs/2006.09717)

**TL;DR:** It is often said that deep networks prefer simple solutions to complex ones. This study elegantly demonstrates that sometimes, deep nets prefer complex non-linear solutions to simple linear ones, depending on the inductive biases in their architecture. **Link to full review in the comments**",MachineLearning
nhkvum,1621574711.0,[D] looking for references on overparametrized models and overfitting,"Has anyone ever come across some papers that give mathematics explanations as to why non-regularized (i.e. overparametrized) models tend to overfit data? As far as I understand, this is only an empirical observation: overparametrized models have just been observed to often overfit data, we don't actually know if there are mathematical reasons as to why overparametrized models tend to overfit.

In any case, whether math based or empirical - can anyone recommend any references/ papers/sources that explain why overparametrized models overfit data?

Also : is there a mathematical intuition behind why lower order poynomials aren't very powerful, but higher order polynomials tend to overfit?

Can anyone recommend a source on this as well?

Thanks",MachineLearning
nhbvpa,1621545701.0,[P] A model theoretic view of storytelling and what it means for creative NLG evaluation,"Hi everyone!


I’m a storytelling researcher based out of Georgia tech (some of you probably can already guess my advisor lmao) and I’ve been working away at a formal theory of narratives from the perspective of category theory and model theory for the last bit.


Over the last six months or so I’ve written a few papers on objective measures of story coherence with grounding in information and model theory that might be of interest to people here who work tangential to NLU/NLG and evaluation.


The project is still in its infancy, we’re only three papers in so far and we make assumptions like the narrator being a perfect realization of the author’s intent as well as transmission of information between the narrator and reader being lossless- but those will soon be remedied.


I’ve shared prior approaches like this one here before, mostly based around TDA methods. But model theory provides a much more elegant way to discuss NLU/NLG evaluation methods.


The introduction post is here

https://louiscastricato.wordpress.com/2021/05/19/on-the-structure-between-narrators-and-readers/

Arxiv links:

https://arxiv.org/abs/2103.12872

https://arxiv.org/abs/2104.07472


It links to two of the three papers, the third is still in review but it should be up soon. The third is the evaluation methods applied to language models rather than artificially constructed datasets.

Willing to answer questions in the comments :)

Edit: I had a lot of fun answering questions. If you want to stay updated, I’ll be posting updates (and memes, my meme game is strong) on my Twitter https://twitter.com/lcastricato",MachineLearning
nh9p3p,1621540196.0,[R] Can an AI learn political theory?," Interesting paper: ""Can an AI learn political theory?""

by Stephen J. DeCanio


""Abstract Alan Turing’s 1950 paper, “Computing Machinery and Intelligence,” contains much more than its proposal of the “Turing Test.” Turing imagined the development of what we today call AI by a process akin to the education of a child. Thus, while Turing anticipated “machine learning,” his prescience brings to the foreground the yet unsolved problem of how humans might teach or shape AIs to behave in ways that align with moral standards. Part of the teaching process is likely to entail AIs’ absorbing lessons from human writings. Natural language processing tools are one of the ways computer systems extract knowledge from texts. An example is given of how one such technique, Latent Dirichlet Allocation, can draw out the most prominent themes from works of classical political theory

&#x200B;

link to the paper (springer):   [https://aiperspectives.springeropen.com/articles/10.1186/s42467-020-00007-2](https://aiperspectives.springeropen.com/articles/10.1186/s42467-020-00007-2)",MachineLearning
nh7hq3,1621534709.0,[R] Episodic Curiosity (ECO) with flat observations,"I'm trying to solve a simple 2D maze with [ECO](https://github.com/google-research/episodic-curiosity) by using PPO's MlpPolicy.The environment is simple: a mujoco maze with actions space of two float (from -1 to 1, x and y force) and continuous observation of 4 (x, y, v\_x, v\_y).

The algorithm cannot reach a good policy.

Has someone a suggestion or experience with this?",MachineLearning
nh7hpg,1621534709.0,[D] miscellaneous theorems used in machine learning,"I am trying to learn more about the background of machine learning and came across the following theorems:

1) the universal consistency theorem (i have heard of the universal aproximation theorem, but not of the universal consistency theorem)

2) the cover-heart theorem (i have heard of something called ""cover's effect"", which talks about how non-linearly sepperable patterns tend to become linearly sepperable when projected into higher dimensions ... is the cover-heart theorem related?)

3) stone's theorem (i have heard of something called the weistrass-stone theorem, which talks about how polynomials can be used to aproximate almost any function, is the weistrass-stone theorem related to this?)

Can someone please help me better understand these?

Thanks",MachineLearning
nh45yq,1621526858.0,[D] How is it possible that a researcher with an h-index of 80+ publishes bollocks?,"This is a genuine question. I am a Master's student and I was only starting with Machine Learning at the start of this academic year.

During my long project, I was trying to reproduce a paper from Affective Computing. I tried for at least 2 weeks but I couldn't get it to work.

Now, after several months, when I read that paper it is completely obvious to me that the numbers were either completely made up or they only got it because of random error. Very little detail is given in the paper -- as if they are actively trying to make the paper irreproducible.

In any case, bullshit papers like these are not uncommon so my project turned into a ""Debunking \[a particular application in Affective Computing\]"". But what is bogus for me is that many of these papers were published by scientists in Amazon, Facebook AI, etc. One of the authors of the paper mentioned above has 80+ h-index.

I understand that he wasn't the one coding it and he probably only had an advisory role + read the paper but even a 1-year Master's student (me) would have realized how bullshit the whole paper was.",MachineLearning
nh1tal,1621521212.0,[P] I created a page to compare cloud GPU providers,"I use cloud GPUs sometimes when I need a lot of GPUs for a short period of time, and found it quite tricky to compare prices and features across them.

So I just created this page which shows a summary of all the main ones I know about: [https://mlcontests.com/cloud-gpu](https://mlcontests.com/cloud-gpu).

It's a small add-on to a project I was already running which aggregates ML competitions from across multiple platforms.

Everything is open source - the file that drives it all is here: [https://github.com/mlcontests/mlcontests.github.io/blob/master/js/cloud\_gpu.json](https://github.com/mlcontests/mlcontests.github.io/blob/master/js/cloud_gpu.json).

If you spot any inaccuracies, feel free to send me PM/tweet ml\_contests/submit a pull request.

I'd love to hear your feedback/suggestions!",MachineLearning
nh19mp,1621519884.0,[D] Accumulated Local Effects,"I recently came across a newer technique called ""accumulated local effects"", that attempts to explain the effect of predictor variables on the response variable :

https://docs.seldon.io/projects/alibi/en/stable/methods/ALE.html

Has anyone tried using this method on real data? Did you find it useful? Any stories/anecdotes/experiences/comments/reviews you would be willing to share regaeding this method?",MachineLearning
nh06ym,1621517206.0,Highest resolution GAN available? [D],"Hi everyone. For a private film production / experiment am seeking for the highest quality/resolution image generation GAN available for public. I am searching for those that are trained on landscape and architectural datasets not those for human faces. Alternatively if there is a Hi res GAN that could be retrained it would also be appreciated.
 Generation consistency is also a big factor for me as plan to animate a lot of generated frames What providers are out there that can do this. My manual search has only pointed me to tech papers andl am an artist not a ml scientist :/

Thank you very much for your help!
<3",MachineLearning
ngz914,1621514747.0,[D] Weka + dl4j image iteration," I posted this in [r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning/) first, but didnt get any responses, so trying here

\---

I am hoping someone is familiar with image classification using the dl4j library in Weka, using the GUI

I can train and save my model just fine - but I am having trouble figuring out how to point the model to new data to classify.

My training.arff and newData.arff are in ""abc123.jpg, class"" format. For training the model I set the image iterator location to the folder with all of my training images. However, when I try to run the model on the newData.arff, it seems to want to look in the test folder for images, and I am failing to understand where I can set the filepath for the newData.arff

I'm positive that I am overlooking a simple setting, but frustration has set in, and any help would be greatly appreciated.",MachineLearning
ngz6yk,1621514591.0,[N] NIST Proposes Method for Evaluating User Trust in Artificial Intelligence Systems,"How do we humans decide whether or not to trust a machine’s recommendations? 

This is the question that a new draft publication from the National Institute of Standards and Technology (NIST) poses, with the goal of stimulating a discussion about how humans trust AI systems. The document, [*Artificial Intelligence and User Trust*](https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8332-draft.pdf) ([NISTIR 8332](https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8332-draft.pdf)), is open for public comment until July 30, 2021. 

Learn about the publication and broader NIST effort to help advance trustworthy AI systems: [https://www.nist.gov/news-events/news/2021/05/nist-proposes-method-evaluating-user-trust-artificial-intelligence-systems](https://www.nist.gov/news-events/news/2021/05/nist-proposes-method-evaluating-user-trust-artificial-intelligence-systems)",MachineLearning
ngwe8f,1621505770.0,[D] Could Machine Learning help to improve cheat detection on chess platforms?,"Hello everyone,

I have been wondering if it might be possible to create a neural network that helps with cheat detection on online chess platforms?

For example one trains a Neural Network with games played by humans and games played by engines. (There can be found enough training data on the net)

Then when the engine is given a new game it gives out an information like this:

White (%) - Black (%) while the % is the probability the AI thinks the side was played by an engine.

You think this could be become an effective way to detect cheaters in online chess?",MachineLearning
ngvuur,1621503837.0,[D] Any reason not to make T depend on H in a highway network?,"The typical formulation for a highway network is...

y = H(x) \* T(x) + (1 - T(x)) \* x

However what seems strange to me about this is that the transform gate has no knowledge of what it is gating.  Seems like it might make more sense to make the transform gate a function of H(x).

y = H(x) \* T(H(x)) + (1 - T(H(x))) \* x

I tried this yesterday on a large 1D conv network I had processing raw audio and it seemed to work.  Any reason this is not a good idea?  I'm just going off intuition but not sure if that is theoretically correct.",MachineLearning
ngvhh0,1621502463.0,[N] The Thesis Review Podcast with Tomas Mikolov - Statistical Language Models Based on Neural Networks,"The creator of word2vec describes his work on language modeling and recent projects about complexity and cellular automata in this episode of the Thesis Review Podcast. Tomas Mikolov recently left Facebook to move back to academia apparently.

Also an interesting discussion about persistence in research and the difficulty of working on non-mainstream ideas (e.g. RNN and Statistical LM in the 2000s).

Link to the podcast: [https://cs.nyu.edu/\~welleck/episode25.html](https://cs.nyu.edu/~welleck/episode25.html)",MachineLearning
nguvb2,1621500187.0,[R] Fast and Accurate Camera Scene Detection on Smartphones,"**Abstract.**  AI-powered automatic camera scene detection mode is nowadays available in nearly any modern smartphone, though the problem of accurate scene prediction has not yet been addressed by the research community. This paper for the first time carefully defines this problem and proposes a novel Camera Scene Detection Dataset (CamSDD) containing more than 11K manually crawled images belonging to 30 different scene categories. We propose an efficient and NPU-friendly CNN model for this task that demonstrates a top-3 accuracy of 99.5% on this dataset and achieves more than 200 FPS on the recent mobile SoCs. An additional in-the-wild evaluation of the obtained solution is performed to analyze its performance and limitation in the real-world scenarios. The dataset and pre-trained models used in this paper are available on the project website.

https://preview.redd.it/rh0tayhml8071.png?width=2365&format=png&auto=webp&s=71dd6439c8986b022ff3cfaeb29eeaec54760f61

arXiv paper:  [https://arxiv.org/pdf/2105.07869.pdf](https://arxiv.org/pdf/2105.07869.pdf)

Project website:  [https://people.ee.ethz.ch/\~ihnatova/camsdd.html](https://people.ee.ethz.ch/~ihnatova/camsdd.html)

\---------------------------------------------------------------------------------------------------------------------

[Mobile AI 2021](https://ai-benchmark.com/workshops/mai/2021/) Challenge on Quantized Camera Scene detection:  [paper](https://arxiv.org/pdf/2105.08819.pdf), [website](https://ai-benchmark.com/workshops/mai/2021/)",MachineLearning
ngudau,1621498156.0,[N] Interview with Privacy Guru Anne Cavoukian Today,"Hello MachineLearning! Today at 2PM EDT we'll be sitting down for a conversation with the inventor of Privacy by Design (part of the GDPR) and Former (3-term) Information & Privacy Commissioner of Ontario, [Ann Cavoukian, Ph.D.](https://www.linkedin.com/in/ACoAAAG6-i8BBtgDmfSY7TT75PWygfvym8nHfL8) Together with the CEO of Private AI, [Patricia Thaine, MSc](https://www.linkedin.com/in/ACoAAA3LkwYBU6-1loEQiidlsaTRN97yPyBKNo8), we'll discuss:

\- Why it matters to embed Privacy by Design into your workflows
\- How the most successful tech companies embrace privacy
\- What to expect from upcoming privacy legislation around the world

We'll be touching on these points from a Machine Learning perspective in particular.

If you're interested, please register here:

[https://app.livestorm.co/private-ai/talking-with-ann-cavoukian-privacy-by-design-inventor?type=detailed](https://app.livestorm.co/private-ai/talking-with-ann-cavoukian-privacy-by-design-inventor?type=detailed)",MachineLearning
ngt1rw,1621493085.0,"Data Validation and Model Testing Strategy on Training vs Serving Data ""[D]""","Problem at Hand:

Once you identify the model degration problem in the serving environement,

1. How can I evaluate new incoming data of serving environment to understand the following:

   1. Drift and skew in the training vs serving data
   2. Test models and decide the next steps

I believe the strategy would highly differ based on the domain,volume of data or the complexity of model.But are there any generic frameworks available that tries to addresses these issues?

Potential Solutions/Framework I could find

1. [Drifter ML](https://pypi.org/project/drifter-ml/)
2. [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started)",MachineLearning
ngpg7d,1621481063.0,[D]Why does functional causal model fail to identify causal sturcture in linear gaussian case?,"Hi there,

Recently I studied causal discovery with FCM(functional causal model), in [Review of Causal Discovery Methods Based on Graphical Models](https://www.frontiersin.org/articles/10.3389/fgene.2019.00524/full#B6), Sec. 4, it says ”It turned out that the former case is one of the atypical situations where the causal asymmetry does not leave a footprint in the observed data or their joint distribution“ I wonder if there are any proof about it?

Thanks a lot!",MachineLearning
ngpevp,1621480958.0,"[D] Running ML experiments on a dataset with 5000 samples and 500,000 categorical features","I'm using Python and have access to a solid computing cluster with solid GPU power. I am wondering how to do the following:

1. Load the dataset, which I assume has to be done in memory but could also be parallelized/distributed using something like Dask or Vaex?

2. Feature selection starting from the full 2M feature set, using recursive feature elimination and top X features from different feature ranking methods (e.g., F-test, Gini importance, SHAP). However, can these be done if the data are parallelized?",MachineLearning
ngo00k,1621476819.0,[D] ML to train on billions of csv file rows,What computer do you use to train ML on a two column two billion rows CSV file. I checked thinkmate servers but I thought I need an entire server room,MachineLearning
ngn6at,1621474436.0,"[N] Pornhub uses machine learning to re-colour 20 historic erotic films (1890 to 1940, even some by Thomas Eddison)","As a data scientist, got to say it was pretty interesting to read about the use of machine learning to ""train"" an AI with 100,000 nudey videos and images to help it know how to colour films that were never in colour in the first place.

Safe for work (non-Porhub) link -> https://itwire.com/business-it-news/data/pornhub-uses-ai-to-restore-century-old-erotic-films-to-titillating-technicolour.html",MachineLearning
ngmn11,1621472903.0,[Research] How I started in research and development in AI/ML,"My interest in the areas of AI/ML started when I was in the last years of university, there I started to become interested in topics such as Artificial Neural Networks, Signal Processing and Digital Systems. Thus, in addition to my undergraduate courses, I took courses in Control using Fuzzy Logic and Neural Networks, where I learned important fundamentals of these areas.

After finishing university, and concluding my English studies, I applied for a 6-month internship funded by UNESCO and the Government of Poland because there was an area that caught my attention: Computer Vision. I applied and had the opportunity to be accepted. A few months later, in October 2016, I traveled to Poland to start the internship, there I conducted a research project on Deep Learning for hand gesture recognition and trying to optimize computational resources by using Gabor filters. At the end of the project we were able to publish a scientific paper in a top Iberoamerican conference on Artificial Intelligence: the Iberoamerican Congress on Pattern Recognition (CIARP). That was my first scientific publication.

Returning to Peru, in 2017, I started to carry out projects on my own as an independent researcher and related to what I did in Poland. The results of these works were presented at national conferences such as INTERCON, which helped me to get more involved in research.

Later I looked for an opportunity at the Universidad Peruana Cayetano Heredia (UPCH), more precisely in the Laboratory of Bioinformatics and Molecular Biology, led by the outstanding scientist Dr. Mirko Zimic. I chose this laboratory because they were developing interesting projects in Artificial Intelligence and Medicine. Thanks to my interest and my previous work, I was able to get the opportunity to work in their lab. There I started to help in projects where Machine Learning techniques were applied to make a faster and low cost diagnosis for several diseases such as anemia, autism and tuberculosis.

In parallel to my work at UPCH, I was doing projects independently. Thus, I had the opportunity to have one of my papers accepted in the LXAI workshop @ ICML 2019, and also to win a travel grant from the ICML organizers for ICML 2019. In that conference I was able to observe more closely the advances and applications of Machine Learning and Deep Learning, which motivated me to get more involved in the research and development of these interesting areas, besides that, I was able to establish contact with the LatinX in AI community and meet several latin guys involved in AI/ML.

Subsequently, some of my projects that I developed independently were submitted and accepted at conferences such as INTERCON and SIMBig. In addition, I submitted papers developed at UPCH to workshops at NeurIPS 2019 and ICML 2020. Most of those papers were successfully accepted and exhibited. I also had the opportunity to win a travel grant from LXAI for NeurIPS 2019, which helped me a lot to learn about the state of the art of ML/AI and also to expand my network.

A few months later, I won a Fondecyt-Peru grant to do an internship in Italy, in the laboratory of Dr. Lamberto Ballan, at the University of Padua. The work consisted in developing an automatic segmentation algorithm for tuberculosis cords in order to have a faster diagnosis. This work was successfully developed and the results were accepted for an oral presentation at the ML for Global Health workshop at ICML 2020. After finishing this internship I was accepted and won a scholarship to the Pi School of AI, where we had lectures on AI and developed a project for a company, the project was related to automatic generation of text summaries using BERT models. This experience helped me to see the differences between developing research projects and developing projects in a company, both of which present great challenges.

Since I had already published in several local conferences and workshops of major ML/AI conferences, I applied and was accepted to review papers for ICML/NeurIPS/ICLR/CVPR workshops, and at the same time I was invited to review papers for local conferences. This helped me to strengthen my ability to critically analyze research articles. Then I had the opportunity to participate in important summer schools such as the Lisbon Machine Learning School (LxMLS) 2020 and the Cornell, Maryland, Max Planck Pre-doctoral School (CMMRS) 2020, where I learned a lot about AI/ML fundamentals and the state of the art. At the end of 2020, I was accepted and obtained a scholarship for the 'Program in Data Science & Global Skills' which is organized by Aporta and MIT. I am currently in the program, which lasts a year and a half. There we are learning more about the fundamentals along with hands-on labs on Statistics, Probability, Machine Learning and Deep Learning. As part of this program we will also develop a Data Science project with an NGO.

Now, in 2021, I am still involved in ML/AI projects at Cayetano Heredia University. I am also participating in a project for an OpenCV competition where we passed the first stage, and at the same time I am waiting to participate in summers schools that accepted me such as the Eastern European Machine Learning Summer School (EEML) 2021, the Nordic Probabilistic AI School (ProbAI) 2021, among others.

I hope what I have shared here can help you as a small reference on how to get involved in AI/ML research and development, you can visit my personal website www.dennishnf.com for more information.

### References

\[1\] [Universidad Nacional de Ingeniería (UNI)](https://en.wikipedia.org/wiki/National_University_of_Engineering).
\[2\] [Universidad Peruana Cayetano Heredia (UPCH)](https://en.wikipedia.org/wiki/Cayetano_Heredia_University).
\[3\] [UNESCO/Poland Co-Sponsored Fellowship Programme in Engineering](http://www.unesco.org/new/en/fellowships/programmes/unesco-poland-co-sponsored-fellowships-programme-engineering/).
\[4\] [LatinX in AI (LXAI)](https://www.latinxinai.org/).
\[5\] [Pi School of Artificial Intelligence](https://picampus-school.com/programme/school-of-ai/).
\[6\] [Advanced Program in Data Science & Global Skills](https://www.datascienceglobalskills.pe/).
\[7\] [International Conference on Machine Learning (ICML)](https://icml.cc/).
\[8\] [Conference on Neural Information Processing Systems (NeurIPS)](https://nips.cc/).
\[9\] [International Conference on Learning Representations (ICLR)](https://iclr.cc/).

### Original post

[https://dennishnf.com/posts/daily/2021-04\_how-i-started-in-research-development-in-ai-ml/page.html](https://dennishnf.com/posts/daily/2021-04_how-i-started-in-research-development-in-ai-ml/page.html)",MachineLearning
ngl8hw,1621468906.0,[D] Gradient Descent Algorithm vs. Normal Equation for regression fit with large n,"I'm currently working my way through Andrew Ng's beginner course on machine learning.

At one point he compares the pros and cons of using a Gradient Descent Algorithm to iterate and find the optimum parameters for a regression fit and using the Normal Equation to find the parameters analytically. He explains that the main drawback of using the Normal Equation is that for n>=10000 features the cost of computing the inverse matrix becomes prohibitive.


My background is in numerical analysis and computational math, whenever we're working with large matrices we avoid computing the inverse of a matrix unless it is absolutely necessary. For most systems a variant of LU decomposition is sufficient.


Professor Ng skipped over the derivation of the system he shows, so maybe the answer is in there, but my question is, does anyone in machine learning use an alternative to computing that inverse matrix (such as an LU decomp) that makes the Normal Equation viable for very large n problems?


The equation in question:

 *θ* = (*X\^(T)X*)\^(−1)*X\^(T)y*


where *θ* is the parameter we are trying to minimize, X is the matrix of features, and y is the vector of values we'd like to predict.


Thanks!",MachineLearning
ngkwyj,1621468027.0,[D] PyTorch to Desktop App Deployment,"I have trained a model through PyTorch and wish to bring it into production through a Windows desktop app for real-time inference. My current plan is to convert my PyTorch model to a TorchScript. Then in actual C++ inference, I'll then use LibTorch to call the TorchScript-formatted model.

My goal is to integrate this into a desktop app and run it in real-time on a stream of data. Also, I plan on only running on CPU, not GPU. Does anybody have any advice on how to best decrease latency and throughput? I really want to optimize efficiency, and I'm wondering if I'm missing anything... Is there any hardware (CPU) specific optimizations I could look?

Are there any benefits going to ONNX or even TensorFlow over PyTorch?

Thanks!",MachineLearning
ngk7w4,1621466099.0,[D] Does directly optimizing the soft F1 loss make sense ?,"Hello, I am currently training a NN on a binary classification task with an unbalanced dataset, and trying to get the best F1 score I found that some people optimize it directly :

https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d#:~:text=The%20problem%20of%20the%20F1,%2F1)%20to%20be%20measured.

I have tried this approach both with and without balancing through oversampling, and using the mean between positive and negative f1 scores as done in this article. What I found is that my model would very often get stuck in the regime where it always predicts 1 (and never 0 for some reason, although the point of using the mean between the positive and negative f1scores is supposed to avoid this issue as far as I understand).

So I wonder why this happens, and whether there is a grounded reason why people usually optimize binary cross entropy and not this ?",MachineLearning
ngjha8,1621464132.0,[D] How can I run real time pose recognition with out doing it on device?,I want to as close to real time as possible upload images from live camera from a weak device to an api/cloud and then immediately render the result. What can do this?,MachineLearning
ngi3xh,1621460683.0,[D] Survival Analysis - Prediction of Time-to-event in R,"I'm doing survival analysis in order to predict the time-to-failure of machines, but I have some doubts regarding the predictions. With the Cox Proportional Hazards model I can assess how the covariates influence the risk of failure, but how can I actually predict the time to failure of test data? I have a dataset of 100 machines and I want to use 80 for training and 20 for testing. The covariates are age and values from sensors like pressure and vibration. After applying the coxph function to the training dataset, how can I predict the time to failure of the test dataset based on the values of the covariates? Sorry if it's a dumb questiona but I can't find how to do it anywhere. Thank you in advance ;)",MachineLearning
nge6ht,1621451178.0,[D] Fortran and Neural Networks,"I just started to work in a company that do predictions for chemistry and they use Fortran.

My first comment was ""I didn't know that Fortran has NN implementation"" , and they answer that the algorithms was implemented from scratch.

They are consider to migrate to another language, but the head programmer believe in Fortran because ""it is used by scientists"" (physic and chemistry).

What do you think? Are they insane or I need to be open mind about this?",MachineLearning
ngc1ps,1621445896.0,[R] Blind Bipedal Stair Traversal via Sim-to-Real Reinforcement Learning,"[My lab](https://mime.oregonstate.edu/research/drl/) recently released a paper which was accepted to RSS 2021, wherein we use RL to train a recurrent neural network to ascend and descend stairs on the [Cassie](https://robots.ieee.org/robots/cassie/) robot without the use of any vision or perception, and then deploy it to the robot in the real-world to climb staircases. It's able to use proprioception alone to respond to large steps up and steps down without falling.

[Here is a link to the submission video](https://www.youtube.com/watch?v=MPhEmC6b6XU) with a few interesting clips of going up/down stairs, hills and over curbs.

[Here is a link to the arxiv preprint](https://arxiv.org/abs/2105.08328).

For the curious, [here is an uninterrupted five-minute video](https://www.youtube.com/watch?v=nuhHiKEtaZQ) of the policy climbing and descending a staircase as part of a reliability/robustness test:",MachineLearning
ngbslr,1621445273.0,[D] Customers purchase intent prediction,"Hi all,

I have recently begun my ML journey and although it has been challenging, its also enjoyable. Power BI has an ML functionality that i have decided to explore to predict customers purchasing intent. It would mean alot if you could spare a moment to see it here: [BIFI](https://bifi.online/) any feedback or tips is greatly appreciated 😀",MachineLearning
ngaxrn,1621443201.0,[P] Extracting Job Skills and Yrs of experience required from job offers...,"Assuming the preprocess is done (removing all html, css and js) to start analyzing a text, how can I extract the job skills and experiences needed from the offer? , e.g:

""5+ years of experience in managing personnel."" To return

""5+ years / management."" being ""Experience in yrs if any / skill to extract.""

I tried with NLTK, but got to the point where I can POS the whole text sentence by sentence, but I'm stuck here, I do not know how to determine the appropriate skill as there's not always the same grammar structure or they list the skills literally.

I'm thinking on using a token classification model from Huggingface Transformers trained with custom tags, but I am really new to all of this and would like to ask for opinions on my approach or some kind of guidance on how to achieve something like this.",MachineLearning
ng9za1,1621440845.0,[D] One-liners in ML!,Saw [this](https://www.reddit.com/r/math/comments/ng09u8/what_are_your_favorite_one_sentence_results_in/?utm_source=share&utm_medium=web2x&context=3) post on r/math and was wondering if y'all have some interesting one-line results/facts to share about anything machine learning ¯\\\_(ツ)\_/¯,MachineLearning
ng946a,1621438729.0,[D] Do(es) the target(s) need to distribute normally before training?,"I have built many classification models, now I am working on a continuous target that, like many other cases, is heavily skewed to the right (value from 0 and up that becomes less frequent as the value increases). I have read that it is necessary to first have a transformation to make the target distribute normally (and invert it upon predictions). I have also read that residuals have to distribute normally. Is this necessary? Does it also depend on which model you are using? (I have been playing with a random forest regressor). Thanks",MachineLearning
ng8l4e,1621437478.0,[R] Intelligent Graphic Design: Adobe’s Directional GAN Automates Image Content Generation for Marketing Campaigns,"A research team from Adobe proposes Directional GAN (DGAN), a novel and simple approach for generating high-resolution images conditioned on expected semantic attributes, greatly simplifying the image content generating process for marketing campaigns, websites and banners.

Here is a quick read: [Intelligent Graphic Design: Adobe’s Directional GAN Automates Image Content Generation for Marketing Campaigns.](https://syncedreview.com/2021/05/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-22/)

The paper *Directional GAN: A Novel Conditioning Strategy for Generative Networks* is on [arXiv](https://arxiv.org/abs/2105.05712).",MachineLearning
ng89ev,1621436711.0,[D] Why Transformers are taking over the Compute Vision world: Self-Supervised Vision Transformers with DINO explained in 7 minutes!,"Check out the [new post from Casual GAN Papers](https://t.me/casual_gan/39) that explains the main ideas from Self-Supervised Vision Transformers with DINO.

1 Minute summary:

>In this paper from Facebook AI Research the authors propose a novel pipeline to train a [ViT](https://t.me/casual_gan/33) model in a self-supervised setup. Perhaps the most interesting consequence of this setup is that the learned features are good enough to achieve 80.1% top-1 score on ImageNet. At the core of their pipeline is a pair of networks that learn to predict the outputs of one another. The trick is that while the student network is trained via gradient descent over the cross-entropy loss functions, the teacher network is updated with an exponentially moving average of the student network weights. Several tricks such as centering and sharpening are employed to combat mode collapse. As a fortunate side-effect the learned self-attention maps of the final layer automatically learns class-specific features leading to unsupervised object segmentations.

\[[Full Explanation Post](https://t.me/casual_gan/39)\] \[[Arxiv](https://arxiv.org/pdf/2104.14294v1.pdf)\] \[[Project Page](https://github.com/facebookresearch/dino)\]

[Self supervised video segmentation](https://reddit.com/link/ng89ev/video/d0h6awn8e3071/player)

More recent popular paper explanations:
\[[MLP-mixer](https://t.me/casual_gan/35)\]
\[[Vision Transformer (ViT)](https://t.me/casual_gan/33)\]",MachineLearning
ng86r9,1621436542.0,[D] inductive biases in machine learning,"Can someone please try to explain the concept and role of ""inductive biases"" in machine learning? Are inductive biases very basic and general assumptions  required for machine learning algorithms to work?

E.g. birds of the same flock fly together = unseen data can be predicted based on how similar it is compared to seen data?",MachineLearning
ng7q0s,1621435426.0,[P] - timm-vis: Visualizer for PyTorch image models,"There are so many cool visualization techniques for CNNs out there. But, the code implementations of these techniques in a lot of repositories/ libraries seems to be limited to very few models such as VGG or AlexNet. I'm sure all of us would love to visualize and understand our own models. So, I created  [timm-vis](https://github.com/novice03/timm-vis), a library using which you can visualize your image classification models with just a few function calls. So far, I've implemented filter and activation visualizations, maximally activated patches, saliency maps, synthetic image generation, adversarial attacks, feature inversion and deep dream. If you're interested in the project and want to try these methods out on your own models, I encourage you to go through details.ipynb in the repository. I'd love to hear your thoughts, feedback and suggestions.",MachineLearning
ng7ln8,1621435139.0,[N] Final deadline extension: Call for papers: KDD 2021 Workshop on Bayesian Causal Inference for Real-World Interactive Systems,"[https://bcirwis2021.github.io](https://bcirwis2021.github.io/)

August 14 - 15, 2021

&#x200B;

\---

Submission deadline (**extended**): May 27, 2021, anywhere on Earth

Format: 3 page extended abstract + references + appendices, ACM Proceeding Template

Submission website: [https://cmt3.research.microsoft.com/BCIRWIS2021](https://cmt3.research.microsoft.com/BCIRWIS2021)

\---

&#x200B;

Increasingly we use machine learning to build interactive systems that learn from past actions and the reward obtained. Theory suggests several possible approaches, such as contextual bandits, reinforcement learning, the do-calculus, or plain old Bayesian decision theory. What are the most theoretically appropriate and practical approaches to doing causal inference for interactive systems?

We are particularly interested in case studies of applying machine learning methods to interactive systems that *did* or *did* *not* use Bayesian or *likelihood* based methods, with a discussion about why this choice was made in terms of practical or theoretical arguments. We also welcome submissions in the following areas:

* Offline evaluation of recommender and interactive systems.
* Comparison of Bayesian, off-policy and other heuristic approaches for offline metrics.
* Probabilistic approaches applied to contextual bandits and reinforcement learning approaches.
* Probabilistic approaches to incrementality and attribution.
* Non-Bayesian approaches and trade-offs with Bayesian/Likelihood approaches.
* Bayesian methods in a production environment.

&#x200B;

Organizers

* Nicholas Chopin (ENSAE)
* Mike Gartrell (Criteo AI Lab)
* Dawen Liang (Netflix)
* Alberto Lumbreras (Criteo AI Lab)
* David Rohde (Criteo AI Lab)
* Yixin Wang (UC Berkeley)",MachineLearning
ng5fz9,1621429891.0,[P] Creating the handbook for visionAI in production,"For our projects, we were looking for a resource that summarizes the most important concepts for computer vision and focuses on the knowledge only, which is relevant for the practical implementation of the concepts. It shouldn't explain every theoretical deviation for a hyper-parameter but rather provide intuition on how to set it and what happens when you change it.

We didn't find what we're looking for, so we started to create it on our own. We spent hours reading through great blog posts, forums and just asking our senior ML engineers. I'm proud to share the first version of our wiki with you today. I hope for some of you it'll be as useful as it is for us.

We're just getting started with the wiki, so don't expect it's 100% complete yet. But we'll keep expanding it over the upcoming weeks, and if you'd like to contribute to this handbook for visionAI in production, please reach out to me! We're happy about anyone interested to help.

Also, if you spot any mistakes or have feedback, please also let us know!

Link: [wiki.hasty.ai](https://wiki.hasty.ai/)",MachineLearning
ng525u,1621428927.0,"[P] Using Google Cloud or Paperspace for U-Net image segmentation and Tensorflow, possible?","Hy all,

is it possible/feasible to train a TensorFlow U-Net model für image segmentation over cloud services like Google Cloud or Paperspace?

Currently, I am using my tower pc (even though I am not utilizing the GPU right now) to build a U-Net based image segmentation model. Following this tutorial:

[https://www.youtube.com/watch?v=XyX5HNuv-xE&t=674s](https://www.youtube.com/watch?v=XyX5HNuv-xE&t=674s)

I will move to another country in a few weeks and there I will only have access to my laptop. I worry that my Laptop might not be powerful enough, therefore I am looking for other solutions for training. Would Google Cloud or Paperspace be a solution?

In general, I am missing a feeling of what is a big/computational expensive model. If I would train with about 10.000 images with U-Net, would this be considered something big?

I appreciate all answers as well as links for sources where I can read up on those topics. Thanks a lot!",MachineLearning
ng4nbw,1621427819.0,[D] How to predict NLP Transformer model sizes?,"When I read about BERT-Base and BERT-Large, I read that BERT-Base will fit into 10-12GB gpus, but BERT-Large won't.

I tried multiplying the number of parameters (110 million and 330 million respectively) with 32 bits (presuming all parameters are FP32) but according to that the models take 0.4 GB and 1.2 GB respectively.

What am I doing wrong here? I assume there must be a way to actually to actually calculate this.",MachineLearning
ng3b9m,1621423842.0,[Discussion] Fixed sized input to variable sized output,"Hello everyone, this is a crosspost from /r/learnmachinelearning, but since I got no reply there I will try my luck here:

The input is a fixed size image. Let's say the image  contains k objects (say dogs)  that I would like to detect and in addition the relation of these objects to the other objects in the image (say, two dogs are in relation with each other if their respective leashes are held by the same person). Hence I would like to return a vector of size k\^2 (or matrix of size k x k), where k is the number of detected objects. Is there any architecture that can achieve such a thing?

Best regards and thank your for your time!",MachineLearning
ng2lp8,1621421669.0,[D] Generating discrete encodings for music.,"I posted about this a few weeks ago but since then I have made some progress and thought I might share and get some feedback.  The ultimate goal of my project is to generate discrete encodings that compress sound/music in the time domain.  Using these discrete encodings I would like to make another model to generate new music in the same way an RNN can be use to generate text.  Since these encodings are compressed in time the RNN can learn music longer sequences than if I used raw audio.

The training data I am using is about 30 hours of random music mashups I downloaded from youtube.  I resampled it to 22050 hz and converted it to mono channel.  The input for the network is the raw audio quantized to  256 values via mu-law encoding.

The network consists of three components...

\*\*Encoder:\*\*The job of the encoder is to compress the audio down 64x (I would like to go larger but so far this is the most I can do.)  I start by running the raw waveform through two strided convolutions to compress the time axis 64x, and then I run it through a highway like network of dilated convolutions.  I say highway like since I did change gate convolution to look at the value it is gating instead of the inputs.

    def create_encoder():
        input_audio = keras.Input((None,), dtype = 'int32')

        x = layers.Embedding(256, 16)(input_audio)

        x = layers.Conv1D(64, 8, strides = 8, use_bias = False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)

        x = layers.Conv1D(256, 8, strides = 8, use_bias = False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)

        x = layers.Conv1D(512, 3, padding = 'same', use_bias = False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)

        for d in [1, 2, 4, 8, 1, 2, 4, 8]:
            f = layers.Conv1D(512, 3, padding = 'same', dilation_rate = d, use_bias = False)(x)
            f = layers.BatchNormalization()(f)
            f = layers.LeakyReLU(0.01)(f)
            g = layers.Conv1D(512, 1, activation = 'sigmoid', bias_initializer = keras.initializers.Constant(-2))(f)
            x = g * f + (1 - g) * x

        x = layers.Conv1D(512, 3, padding = 'same', use_bias = False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)

        x = layers.Conv1D(8, 1)(x)

        return keras.Model(inputs = input_audio , outputs = x, name = 'encoder')

The output of this encoder is a vector of length 8 for each 64 chunk of input audio.  However, I wanted one discrete/integer value per 64 samples not 8.  This currently would only compress it 8x with a continuous encoding.  What I need is for each of those 8 floating number to represent bits in an 8 bit integer (I actually used 1 and -1 instead of 1 and 0.)  To do this I use the sign function as the activation.  This function is normally not differentiable, however, I have found that I can apply the sign function on the forward pass, but use the derivative of tanh on the backwards pass.

    @tf.custom_gradient
    def sign_with_gradients(x):
        def grad(dy):
            return dy * (1 - tf.square(tf.tanh(x)))
        return tf.where(x < 0.0, -1.0, 1.0), grad

I apply this activation in my custom training function between the encoder and the expander layer.  I also add some activity regularization to the outputs of the encoder before applying the sign function.  Not sure if this is necessary but I wanted to keep the value from getting too far from zero.

    e = encoder(r, training = training)
    reg_loss = 0.0001 * tf.reduce_mean(tf.square(e))
    e = model.sign_with_gradients(e)
    e = expander(e, training = training)

\*\*Expander:\*\*The purpose of the expander is to take the discrete encodings and expand it back out 64x to the size of the original audio.  The output of the expander is then used to condition the decoder to recreate the sound.  The architecture of the expander mostly mirrors that of the encoder.  I have debated whether it makes sense to make the expander a larger model than the encoder but most auto encoder architectures I have seen seem to be symmetric.

    def create_expander():
        input_data = keras.Input((None, 8))

        x = layers.Conv1D(512, 3, padding = 'same', use_bias = False)(input_data)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)

        for d in [1, 2, 4, 8, 1, 2, 4, 8]:
            f = layers.Conv1D(512, 3, padding = 'same', dilation_rate = d, use_bias = False)(x)
            f = layers.BatchNormalization()(f)
            f = layers.LeakyReLU(0.01)(f)
            g = layers.Conv1D(512, 1, activation = 'sigmoid', bias_initializer = keras.initializers.Constant(-2))(f)
            x = g * f + (1 - g) * x

        x = layers.Conv1D(512, 3, padding = 'same', use_bias = False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)

        x = upsample(x, 64)

        return keras.Model(inputs = input_data, outputs = x, name = 'expander')

\*\*Decoder:\*\*The decoder takes the output of the expander and the prior audio sample of the encoded sequence as inputs and tries to predict the next sample.  Currently I am using an RNN architecture but may try something like a wavenet.  I kept the decoder simple since I want it to use the input from the expander more than what it has learned from the prior sequence.  Currently I am having an issue with it inserting other sounds into the output on top of the original music.  Need to find a way to remove these artifacts.  I have found smaller models produce less of this.

    def create_rnn_decoder(stateful = False, batch_size = None):
        prior_audio_input = keras.Input((None,), batch_size = batch_size, dtype = 'int32')
        expander_input = keras.Input((None, 512), batch_size = batch_size)

        x = layers.Embedding(256, 16)(prior_audio_input)
        x = cat(x, expander_input)
        x = layers.GRU(512, stateful = stateful, return_sequences = True)(x)
        x = layers.Conv1D(512, 1, use_bias = False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(0.01)(x)
        x = layers.Conv1D(256, 1)(x)

        return keras.Model(inputs = (prior_audio_input, expander_input), outputs = x, name = 'decoder')

I have been training this on sequences of length 512 which are randomly sampled from the output of the expander which is currently 2\^14 in length.  I need to do this since I don't have the time or memory to train on the full length outputs.  Currently I am using sequences of length 2\^14 input to the encoder which compresses down to just 256 when run through the dilated convolutions.  If I made this much small enough that I don't need to sample, the dilated convolutions would be encountering padding on both sides in all cases which would not generalize well to when I use it on longer sequences.

I trained the network overnight and it seems to still be improving on the out of sample data so I will leave it running for now.  I did generate an output sample you can listen to.  The underlying song can be clearly heard.  I just need to figure out how to get rid of some of the annoying artifacts.  If you have any suggestions please let me know.

[https://www.dropbox.com/s/4ws1kdbzfbe50bm/out.wav?dl=0](https://www.dropbox.com/s/4ws1kdbzfbe50bm/out.wav?dl=0)

Previously I was using a gumbel softmax in a similar way to to how I used the hard value on the forwards pass but a soft value on the backwards pass.  I found this to be less than ideal since I prefer my encoder to be deterministic.  When I tried not applying gumbel noise the encoder would only ever activate a small portion of the nodes in the softmax.  In generating the audio in the link I checked the values it was using.  It used 237/256 possible combinations of bits.  Each of the 8 bits also got activated close enough to 50/50 that I am happy with it.

So please let me know what you think and if you have any suggestions.

&#x200B;

UPDATE:The validation data stopped improving around iteration 240,000.  This is the final output of the above clip.
[https://www.dropbox.com/s/w40cqkr3gk8cw3v/out2.wav?dl=0](https://www.dropbox.com/s/w40cqkr3gk8cw3v/out2.wav?dl=0)",MachineLearning
ng0qdk,1621415096.0,[Research] Vision Transformers are Robust Learners,"For some time now, Transformers have taken the vision world by storm. In this work, we question the robustness aspects of Vision Transformers. Specifically, we investigate the question:

*With the virtue of self-attention, can Vision Transformers provide improved robustness to common corruptions, perturbations, etc.? If so, why?*

We build on top of existing works & investigate the robustness aspects of ViT. Through a series of six systematically designed experiments, we present analyses that provide both quantitative & qualitative indications to explain why ViTs are indeed more robust learners.

* Paper: [https://arxiv.org/abs/2105.07581](https://arxiv.org/abs/2105.07581)
* Code: [https://git.io/J3VO0](https://git.io/J3VO0)",MachineLearning
ng0kdo,1621414493.0,[D] What happened to the Arxiv Insights Youtube channel?,"The Arxiv Insights Youtube channel was one of my favourite ones for Deep Learning, but he stopped posting videos over a year ago. Does anyone know what happened?",MachineLearning
nfzhky,1621410471.0,[D] Labelbox threatens to sue small open-source startup Diffgram,"Hi everyone,

Did some of you already read this article? What's your opinion on this?

[https://anthony-sarkis.medium.com/andreessen-horowitz-backed-firm-labelbox-appears-to-threaten-federal-court-to-pre-seed-upstart-7b938ef69229](https://anthony-sarkis.medium.com/andreessen-horowitz-backed-firm-labelbox-appears-to-threaten-federal-court-to-pre-seed-upstart-7b938ef69229)",MachineLearning
nfz7rn,1621409464.0,What is the science behind ArtBreeder?[D],"I recently encountered [artbreeder](https://www.artbreeder.com) website. I am wondering whether there is any description of how it works behind the scenes. I know what BigGAN and StyleGAN are and I read artbreeder uses them but these are the things I want to know more in detail:


1. how these gene knobs are created given the datasets? I understand you train the model on a big dataset of face images, then how do you create these gene knobs?
2. how do you merge two images with each other? Do you interpolate between their latent representation?

Thanks in advance!",MachineLearning
nfxkvl,1621403805.0,[D] (Paper Overview) VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning,"**Video**

[https://youtu.be/MzKDNmOJ67Q](https://youtu.be/MzKDNmOJ67Q)

**Paper**

[https://arxiv.org/abs/2105.04906](https://arxiv.org/abs/2105.04906)

**Abstract**

Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually. VICReg combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization, and achieves results on par with the state of the art on several downstream tasks. In addition, we show that incorporating our new variance term into other methods helps stabilize the training and leads to performance improvements.",MachineLearning
nfxita,1621403603.0,[R] Indian Vehicle Dataset," To use object detection and classification problem for Indian Vehicle dataset which contains robust data.

I'll keep updating the dataset as more images come through here: : [https://www.kaggle.com/kanan275/indian-vehicle-dataset](https://www.kaggle.com/kanan275/indian-vehicle-dataset)

The sample images are given here: [https://github.com/datacluster-labs/Datacluster-Datasets/](https://github.com/datacluster-labs/Datacluster-Datasets/)",MachineLearning
nfuqt3,1621394884.0,[D] Relation Between Number of Layers in Graph Neural Networks and L-hop Neighborhood," After working with GNNs for a short amount of time now, I have come across a little bit of confusion.

Some papers that I have read state something along the lines of: ""The number of layers (L) in a GNN determine the L-hop neighborhood of the computational graph of a certain node"".

I am very confused by this statement. Wouldn't the number of training iterations determine the neighborhood of a node? For example, after 3 iteration of training one layer of GNN, aren't we basically gathering information from the 3-hop neighborhood of each node?

Isn't the number of GNN layers irrelevant to the neighborhood of the node since information from further nodes can still be aggregated with a single GNN layer and enough training iterations?",MachineLearning
nfto81,1621391822.0,[D] Different Angle Estimate,"I was wondering if any work has ever been done on utilizing machine learning to generate different angles of a photo? E.g. if I take a photo of a dog from the front, it could ""generate"" different angle views.",MachineLearning
nfrw5z,1621386797.0,[D] ML basic technology,"I had this idea of creating low impact ML inventions that are like the most basic way to use ML in every day life. Eg: a ML door, a ML window, a ML chair etc

What do you guys think about this?",MachineLearning
nfqt83,1621383776.0,[P] How to use SVM to sort vehicle CAN bus data?,"I have seen several examples of Python scripts which make use of SVM to sort different types of data using the scikit learn library methods. I would like to know if there is a good way to incorporate a stream of CAN messages from a vehicle and use the SVM algorithm to detect CAN intrusion through malicious messages. I will most likely be tracking the types of message headers received and classifying attack messages and normal messages based on that, and I would also like to measure the degree of change in certain parts of the messages over time (to see if there are any sudden irregularities in the stream of input of seemingly normal messages that could indicate an attack). Does anyone know a good approach to implementing something like this? Most code examples I’ve seen either use attributes that are too simplistic or techniques that seem very cryptic to understand). I’m an electrical engineering undergrad, by the way, if that is any help.",MachineLearning
nfp5v4,1621379240.0,[D] Do you feel in control while working with ML ?,"Im finishing BSc in EE this year, and I have worked on a pretty standard deep learning project in uni doing semantic segmentation using a published model with a couple of tweaks and a new data set.

I generally love a subject that I can fully understand and make sense of, which made me really love math. What felt weird to me is how well the project worked, and how little I felt in control of it. Even while having a solid understanding of the math behind it, I did not actually know why in practice stuff work or didnt work, and it was more of a trial and error rather than a calculated path.

I know im not the first person to point it out.

I think ML is fascinating, and I'm not even close to understanding 1% of it, so i genuinly want to hear how it feels for people who dealt with it enough time and have the proper education.

How much do you feel in control when dealing with a model ? How well can you predict how things are gonna go ? Does it still feel like a black box to you ?",MachineLearning
nfneo3,1621374772.0,[D] How are Text-to-Speech Models Trained? Do they use the same data as Speech Recognition Models?,"I've been fascinated with this topic for a long time, but have yet to get a solid answer...

The best I've come across is [this paper](https://google.github.io/tacotron/publications/semisupervised/) on Google's Tacotron Text-to-Speech model, which says *""\[end-to-end text-to-speech models\] typically require a sizable set of high-quality <text, audio> pairs for training, which are expensive to collect""*

So I assume you can train Text-to-Speech models with the same labeled audio data you use to train speech recognition models...except, in this case, the *audio* is the label and the input is the *text.*

Am I right here? Is the data labeled in the same way?

Even so, I expect that what constitutes 'good data' is probably quite different when looking at Text-to-Speech vs. Speech-to-Text.

For speech recognition, I know it's beneficial for your audio data to have background noise, multiple speakers, and for your speakers to be talking in a conversational tone -- these are the kinds of conditions you want your speech recognition model to accurately perform under. So something like YouTube audio that's captioned or transcripted podcast audio would be ideal.

But is it fair to assume that the opposite is true for Text-to-Speech? Would you want your data to be clean, single-speaker, and delivered in a narrative tone like Audiobook data?

Would love to hear everyone's thoughts on this. And if anyone has sources where I can educate myself more on Text-to-Speech training, I'd love to see it!",MachineLearning
nfmzf1,1621373719.0,[P] ML to assign words to EEG numbers it didn't train on,"I have a CSV file made of two columns, one column is the EEG raw data (numbers) the other one is words I assigned to the EEG numbers. if a ML algorithm trains on this CSV file, can it assign words to EEG numbers even if the EEG numbers is a new number it didn't train on? if I add only the ""EEG column "" can it generate the ""words column"" based on how it trained previously?

it has to detect how words are assigned to numbers and assign words to numbers it didn't train about. how many words should the training file have on it?",MachineLearning
nfky63,1621368846.0,[N] GCP Vertex announcement,"https://techcrunch.com/2021/05/18/google-cloud-launches-vertex-a-new-managed-machine-learning-platform/

Anybody know what this is or use GCP’s AI services before?",MachineLearning
nfkueu,1621368595.0,[N] New models announced in Google I/O '2021,"LAMDA: Next generation conversational AI agent [https://9to5google.com/2021/05/18/google-lamda-natural-language/](https://9to5google.com/2021/05/18/google-lamda-natural-language/)

MUM: an encoder-decoder language model model that can understand images and is trained on 75 different non-English languages, trained on more conversational data to improve the search queries. [https://blog.google/products/search/introducing-mum/](https://blog.google/products/search/introducing-mum/)

(This is like T5, but more powerful, sounding more like a human and can do downstream tasks in non-English languages without the need to fine-tune, it can also understand images)

Opinions?",MachineLearning
nfj6a2,1621364692.0,[R] Details behind LaMDA the conversation technology mentioned at Google I/O 2021,"It is based heavily on the Meena Bot which came out back in January 2020. One must agree the demo was very very impressive.

Google AI Blog -  [Google AI Blog: Towards a Conversational Agent that Can Chat About…Anything (googleblog.com)](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html)

Paper -  [https://arxiv.org/abs/2001.09977](https://arxiv.org/abs/2001.09977)",MachineLearning
nfecr5,1621353448.0,[Discussion] Citizen science platforms for annotating images with bounding boxes,"I came across this platform [https://www.zooniverse.org/](https://www.zooniverse.org/) where one can upload images and volunteers can draw polygons or bounding boxes around an object of interest (in my case insects). The results will be later used for training a CNN.

I was wondering if there are other similar options, mostly free and citizen-science based.",MachineLearning
nfe7f1,1621353093.0,Data Challenge by Oak Ridge National Laboratory [News],If you are interested to play with large scientific data generated by various divisions of ORNL. Please visit [https://smc-datachallenge.ornl.gov/data-challenges-2021/](https://smc-datachallenge.ornl.gov/data-challenges-2021/),MachineLearning
nfdta3,1621352151.0,[R] Facebook Transfer Learning Method Boosts Code Autocompletion Accuracy by Over 50%,"A research team from Facebook shows how the power of transfer learning can enable pretraining on non-IDE, non-autocompletion and different-language example code sequences before fine-tuning on the autocompletion prediction task to improve model accuracy by over 50 percent on very small fine-tuning datasets and over 10 percent on 50k labelled examples.

Here is a quick read: [Facebook Transfer Learning Method Boosts Code Autocompletion Accuracy by Over 50%.](https://syncedreview.com/2021/05/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-21/)

The paper *Improving Code Autocompletion with Transfer Learning* is on [arXiv](https://arxiv.org/abs/2105.05991).",MachineLearning
nfcvio,1621349934.0,[P] AI-generated music video | What happens when OpenAI's CLIP meets BigGAN?,"[https://youtu.be/rR5\_emVeyBk](https://youtu.be/rR5_emVeyBk)

I used OpenAI's CLIP model and BigGAN to create a music video that goes along with the lyrics of a song that I wrote. The song lyrics are made from ImageNet class labels, and the song itself is performed by me on a looper.

&#x200B;

OUTLINE:

0:00 - Intro

1:00 - AI-generated music video for ""be my weasel""

3:50 - How it was made

7:30 - My looping gear

9:35 - AI-generated music video #2

12:45 - Outro & Credits

&#x200B;

Code and references: [https://github.com/yk/clip\_music\_video](https://github.com/yk/clip_music_video)",MachineLearning
nfanmt,1621344288.0,[R] New directions in Neural Differential Equations,"Hello everyone!

I'm happy to say we got three new papers accepted at **ICML 2021**, all on neural differential equations, and (shameless self-advertising!) wanted to share them here.

One is on neural ODEs, one is on neural SDEs, and one of them introduces the new concept of ""neural rough differential equations"".
(Yes, another ""neural XYZ differential equation""!)

Hopefully you should find one or more of them interesting if you work on GANs, RNNs, time series, or (of course) neural differential equations.

---

**""Hey, that's not an ODE"": Faster ODE Adjoints via Seminorms**:
*(With Ricky T.Q. Chen)*

Solving an ODE numerically typically means accepting that you're going to make some numerical error.
We show that by being a bit more careful about where you make the numerical error, in particular in the gradient calculations, you can reduce the number of steps needed in the ODE solver by as much as 62% (~train twice as fast; YMMV based on the problem).

What's great about this is that you can basically drop it in to anything you're already working with.
It's now supported natively in `torchdiffeq`, so all you have to do to use this is `torchdiffeq.odeint_adjoint(... adjoint_options=(norm='seminorm'))`.
As an approach it has essentially zero downsides.

[Paper on arXiv](https://arxiv.org/abs/2009.09457)
[Code on GitHub](https://github.com/patrick-kidger/FasterNeuralDiffEq/)

**Neural SDEs as Infinite-Dimensional GANs**:
*(With Xuechen Li and James Foster)*

We demonstrate that the modern machine learning of GANs is very similar to how we've been fitting SDEs for decades.
SDEs, being random, are basically generative models. So joining up all the dots, we show how you can train Neural SDEs as incredibly flexible models for time series.

If you work on GANs, then this should be pretty interesting as a pretty unique application of GANs.
If you work on RNNs then these are basically continuous-time generative RNNs: diff eqs are a great prior on model space.
If you work on SDEs or math-finance, then compared to traditional SDEs these have essentially unprecedented modelling capacity.

[Paper on arXiv](https://arxiv.org/abs/2102.03657)
[Walkthrough example code on GitHub](https://github.com/google-research/torchsde/blob/master/examples/sde_gan.py)

**Neural Rough Differential Equations for Long Time Series**:
*(With James Morrill, James Foster, and Cristopher Salvi)*

We showed in our [Neural Controlled Differential Equation](https://arxiv.org/abs/2005.08926) paper last year that you can train ""Neural CDEs"", as essentially continuous-time RNNs. This gives you a nice way to handle irregular data, and a great prior on model space.

(This kind of thing is actually a pretty long-standing connection; we give some examples in the Neural CDE paper going back to the 90s.)

Now we're back with a generalisation. Essentially, the mathematics of rough differential equations deals with how to handle fine-scale ""wiggliness"" in your input data. And what else has fine-scale wiggliness? Long time series! By, essentially, very carefully binning the data to extract information on how the wiggles drive a differential equation, we manage to extend the Neural CDE model to tackle long time series (up to 17k in length), without the usual issues like expoding/vanishing gradient, or indeed the model just taking a long time to evaluate.

[Paper on arXiv](https://arxiv.org/abs/2009.08295)
[Code on GitHub](https://github.com/jambo6/neuralRDEs)

---

Thanks for reading! Questions? Comments? Let me know.",MachineLearning
nfak4u,1621344029.0,[R] Ways To Stop AI From Recognizing Your Face In Selfies,"We upload so many personal photos on the internet, so we might have questions like who else would have access to them, what would they do with them—and which [machine-learning](https://www.technologyreview.com/topic/artificial-intelligence/) algorithms would be trained with this data?

[Clearview AI](https://en.wikipedia.org/wiki/Clearview_AI), an American facial recognition company, has already provided a facial recognition tool trained on millions of such photos scraped from the public web to US law enforcement agencies. But that was likely just the start. It’s easy for anyone with basic coding skills to develop [facial recognition software](https://www.technologyreview.com/topic/artificial-intelligence/face-recognition/). Thus, it’s easier to abuse tech in everything, from sexual harassment and racial discrimination to political oppression and religious persecution.

To address this issue, there’s a requirement to develop ways to make sure AIs can’t learn from the personal data people upload. **Emily Wenger** at **the University of Chicago** and her colleagues developed[ one of the first tools to do this](https://arxiv.org/pdf/2002.08327.pdf), called **Fawkes**.

Summary: https://www.marktechpost.com/2021/05/18/ways-to-stop-ai-from-recognizing-your-face-in-selfies/

Paper: http://people.cs.uchicago.edu/\~ravenben/publications/pdf/fawkes-usenix20.pdf

Project: https://sandlab.cs.uchicago.edu/fawkes/

Codes: https://sandlab.cs.uchicago.edu/fawkes/#code",MachineLearning
nf7861,1621333979.0,[D] Why the limitations in Quantum ML?," I was reading about Quantum ML and found out that the number of qubits one can have on a quantum circuit is limited. That is we can not put in 1000s of qubits( without quantum annealing) onto the circuit. This in return limits the kind of models we can train on the circuit. For example, images which typically have 32\*32\*3 input size can not be used.

My question is;
If we consider qubits analogous to  neurons, Why is running a 1000-neuron neural net on a 32-bit machine a possibility but the same can not be done in Quantum ML ?

I am not entirely sure if the analogy is correct and might be having certain gaps in my knowledge on how actually a 1000 dense neural net can be processed on a modest 32-bit machine.

Would love your insights on this",MachineLearning
nf57k0,1621326531.0,"[D] What platforms do ML professionals use to express themselves? For entertainment, you have tons: TikTok, Instagram etc. Where can one find a more meaningful place for knowledge exchange?","

[View Poll](https://www.reddit.com/poll/nf57k0)",MachineLearning
nf4wwd,1621325461.0,"OpenPose Caffe Dependancy Links Down, Anybody Have a Backup ?[P]","I was trying to install OpenPose today and was encountering a lot of difficulity. It seems like the links that they configured with Cmake to download the Caffe and OpenCV are down meaning that installation isn't going to work.

https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation/1_prerequisites.md

Does anybody have a version of caffe_opencl, caffe3rdparty and opencv configured for the OpenPose framework to share?",MachineLearning
nf3wqu,1621321678.0,[D] Doubt with updating a policy considering a sliding window state space.,"Consider a trajectory with `x` states. Using discounted rewards of `i` to `i+x` states I  am updating my network for the `i`th state. Now sliding the window towards the next state and calculation the loss for `i+1`th state by discounted rewards of `i+1`th to `i+x+1`th I will again update the policy. This time wrt `i+1`th state. This will go on as this algorithm is for a live reinforcement learning model.

Doubt:
When I am updating the model for `i+1`th state the loss I calculated was based on the rewards of the previous network. I see this as incorrect. Am I doing things correctly? What can be done to make thing right?",MachineLearning
nex48f,1621299840.0,"[D] How do you work through a modeling project in a notebook? Do you follow specific steps, or handle it free-style?","I'm currently helping to onboard some interns and was hoping to put together an in-depth guide for working through modeling pipelines in a Jupyter notebook-style environment.

I'm hoping to crowdsource a bit with understanding differing practices on these kinds of problems: imagine a hypothetical situation in which you're provided a dataset for the purposes of trying to build a predictive model.

Here's my current outline; if you do something different in your day-to-day, or if you think I'm wrong about something, lemme know!

-----------------------------------------------------

1) Clearly establish the problem statement. Is there a model and metric already being used, or is this a new project? Try to understand whatever limitations there are surrounding the current methodology; is there a source of irreducible bias? Do stakeholders insist on a particular metric?

2) Load the dataset and do some exploration; understand the types of features in the dataset (categorical, numerical, otherwise), and overall data quality (is there a lot of data missing?). Important things to find out: if this is

4) Data preprocessing/feature engineering (i.e. clean up text fields; create dummies as necessary; perform bucketing; if necessary, treat Null fields/missing values; etc., etc., etc.)

3) Data splitting (devising appropriate train/test/dev splits; is stratification important? is data/covariate shift apparent in your dataset? note that some types of preprocessing can only take place after this step -- e.g. standardization, normalization -- else you experience data leakage)

4) Put forth some models that you'd like to try, based off the problem type, data provided, and other concerns (if you have to defend your results in front of a client, interpretability might be important! Some models are known to work particularly well with e.g. text, like Naive Bayes)

5) Tune Parameters: When you're ready, use cross-validation in tandem with GridSearch/Bayesian Optimization to find parameters that optimize for your target metric.

6) Evaluate results on the dev dataset; is your model experiencing high bias, high variance? Take steps to improve your model's performance; this can involve further feature engineering, introducing regularization, adding more data, or any number of other steps.

7) When you're happy with your model and the parameters chosen, evaluate the test dataset to get a best estimate of your model's performance in the ""real world.""",MachineLearning
nevtz1,1621296079.0,[D] Loss Function in Generative Models,"Say I have :

* training data x (e.g. texts, images)
* a parameterized model m(θ) that generates those kind of data (e.g. an RNN)

Usually such model is trained with a loss function such as BCELoss(m(θ), x), for good reasons. However, has any one done XXXLoss(f(m(θ)), f(x))?

That is, what if I am interested in generating images that have a similar saturation level (here f(image) would output the image's saturation as a scaler) or generating sentences that have a similar anger level (here f(sentence) would output the sentence's anger level as a scaler), assuming we are given such function f() as a differentiable blackbox? Would greatly appreciate some reference of papers doing this, or on why this is hard to do. Thanks!",MachineLearning
nety9g,1621290763.0,[D] Reviewing for Workshops: What is an appropriate standard of an accepted paper,"I am reviewing for an ML workshop at ICRA for the first time (have reviewed for conferences before). While giving the rating for a project that is clearly WIP, I am confused as the how strictly / leniently I should grade the paper. I can provide appropriate subjective insight but I am finding it difficult to translate it to an appropriate objective rating. Any help would be appreciated!!",MachineLearning
neto5w,1621290017.0,[D] Books to learn EDA and Feature Engineering?,"I have been reading Hands on Machine Learning with scikit learn and tf 2 by Aurelien Geron, on and off, for the past 1.5 years. I honestly love the book. But recently while I was taking part in a hackathon I felt the knowledge I had for EDA and Feature Engineering was really limited. I only knew whatever I had learnt from the 2nd chapter of the book and didn't really have more to go with. I had felt similar when I was trying the Titanic challenge on Kaggle

So please recommend some books, which can help solidify my understanding of EDA, feature engineering and other things required to approach a real world ML problem.

I am looking for something that gives a more end-to-end knowledge",MachineLearning
nerayn,1621284168.0,"[D] Large dataset overfitting -- epochs, iterations and batch size","I  have a very large dataset and I want to make a statement on how of that  dataset I need to attain a certain accuracy for my predictive model,  which is a neural network. I use early stopping criteria (observing  validation loss) with a particular patience. All this is implemeneted on  Keras.

I started observing that  as I increased my dataset, after a certain point, my test error (on an  unseen dataset) started increasing.

After thinking a second about it, I came up with the thought:

\-  for each epoch, we do n\_iterations given by:  training\_set\_size/batch\_size, which then means that as I increase  training\_set\_size, I do more iterations per epoch.

\- Thus, I do more gradient updates per epoch

\-  Empirically, I observe that as I increase my training dataset, my early  stopping criteria kicks in faster (i.e. I use less epochs overall)

Does  it make sense to think that I am converging ""faster"" to a minimum when I  have a larger dataset because I do more updates per epoch? And if I am  not careful (e.g. have a too large patience for the large dataset), can I  actually accidentally start overfitting because I use a larger dataset?",MachineLearning
nepbkz,1621279501.0,[D] Any paper formally pointing why softmax-based neural networks don't return proper confidence scores?,"I've been reading about uncertainty estimation and almost every paper says that softmax is not a suitable certainty score, so we need other methods to calibrate or correctly estimate uncertainty measurements. My question is if this statement is purely empirical or if there exist some paper formally proving (doing the math) that softmax is not a uncertainty score.

The paper that I found closer to this problem is ""Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem"".

Thanks is advance.",MachineLearning
nep0fa,1621278779.0,[D] Evil Geniuses Data and Tech in Esports Event,"Hey everyone, my name is Sean and I’m an intern at Evil Geniuses working with the data and tech team. We will be hosting a workshop this week **(5/19 at 11 AM PT / 2 PM ET)** focused on the use of data in esports. The two panelists who will be running the workshop are **Soham “valens” Chowdhury** (Head of Data Science) and **Zach Kamran** (Head of Tech and Analytics). I have copied the Eventbrite link below, please free free to sign up, the event is completely free. If you have any questions, please don't hesitate to reach out to me on twitter (@reegs191)!

Eventbrite: [https://www.eventbrite.com/e/data-and-tech-innovation-in-esports-tickets-154295117851](https://www.eventbrite.com/e/data-and-tech-innovation-in-esports-tickets-154295117851)",MachineLearning
neny1v,1621276254.0,[Project] Evolving beyond 100 billion recommendations a day - How Reddit does recommendations,[https://www.reddit.com/r/RedditEng/comments/neknjg/evolving\_beyond\_100\_billion\_recommendations\_a\_day/](https://www.reddit.com/r/RedditEng/comments/neknjg/evolving_beyond_100_billion_recommendations_a_day/),MachineLearning
nemm2t,1621273156.0,[R] On The Role of Knowledge Graphs in Explainable AI," Very interesting Paper: ""On The Role of Knowledge Graphs in Explainable AI""


by  Freddy Lecue


""The current hype of Artificial Intelligence (AI) mostly refers to the success of machine learning and its sub-domain of deep learning. However, AI is also about other areas, such as Knowledge Representation and Reasoning, or Distributed AI, i.e., areas that need to be combined to reach the level of intelligence initially envisioned in the 1950s. Explainable AI (XAI) now refers to the core backup for industry to apply AI in products at scale, particularly for industries operating with critical systems. This paper reviews XAI not only from a Machine Learning perspective, but also from the other AI research areas, such as AI Planning or Constraint Satisfaction and Search. We expose the XAI challenges of AI fields, their existing approaches, limitations and opportunities for Knowledge Graphs and their underlying technologies.""

&#x200B;

link to paper: [http://www.semantic-web-journal.net/system/files/swj2198.pdf](http://www.semantic-web-journal.net/system/files/swj2198.pdf)",MachineLearning
nemglt,1621272809.0,[D] Recommended Stack for Deploying pre-trained Machine Learning Models?,"Hello guys so I have a pretrained  Pix2Pix GAN (pytorch) model that takes an input edge drawing and from one folder and output the drawing colored in essentially. Im currently trying to build a web application that would allow for users to upload there own drawings and receive the generated results.


Off the top of my head a webserver hosting this model and building an api to handle the post request to talk to the server to process the images would be one way to go about this but im not really sure if this is best practice?


The application is built in react and node js . I was wondering what is a recommended stack for trying to implement what i am aiming for ?

&#x200B;

I've come to the conclusion that training and running models locally vs deploying them are 2 different beast 😅.",MachineLearning
nekxoi,1621269325.0,Manually calculating probability from XGBoost model in python [Discussion],"Hi, I’m trying to manually calculate probability from XGBoost in python. I have used predict_proba function to get the probabilities but would like to calculate them on my own.   Can someone please help me with the formula/code.",MachineLearning
nekuuc,1621269136.0,"[P] Project CodeNet: IBM releases 14M sample coding dataset for ""AI for code""","IBM Research released Project CodeNet, a dataset of 14 million code samples to train machine learning models for programming tasks.

Key highlights:

\- Largest coding dataset gathered yet (4,000 problems, 14 million code samples, 50+ languages)

\- The dataset has been annotated (problem description, memory/time limit, language, success, errors, etc.)

Possible uses:

\- Translation from one programming language to another

\- Code recommendation/completion

\- Code optimization

Analysis:

[https://bdtechtalks.com/2021/05/17/ibms-codenet-machine-learning-programming/](https://bdtechtalks.com/2021/05/17/ibms-codenet-machine-learning-programming/)

GitHub:

[https://github.com/IBM/Project\_CodeNet](https://github.com/IBM/Project_CodeNet)",MachineLearning
neg8u1,1621258050.0,[D] Python package for a R cran package.,"Hey everyone, I am doing forecasting for retail data, used custom model as forecasting model but now the main problem is updating the other lower level data which is called forecast reconciliation.

In R, it was recommended to use FoReco, which has different reconciliation algorithms. So, if anyone found similar package in python else I am thinking of rewriting it in Python in free time.

Link to R package: [FoReco ](http:// https://cran.r-project.org/web/packages/FoReco/vignettes/FoReco_package.html)

Thank you for helping out.",MachineLearning
neg6af,1621257858.0,"[D], [P] Which possible approaches for comparison of two data (time series) transformations without real metrics?","Imagine that there are many time series and the problem of finding significant drops in the level of each series is being solved, if there are heavy drops in it.

We also have two methods for detecting such level of series drops.  However, there is a problem: we make the decision about the catastrophic fall in the level of the series on the basis of the series itself, but we do not know how much the real business metric corresponds to our finding .. for one of the methods, it is possible to evaluate the business sense of the found falls in the series after the fact, and we have a certain amount  such assessments.
How (theoretically) can such two methods be compared?

I would like to come to the basic metrics: accuracy, precision, recall, errors of I&II types, etc., but unfortunately the feedback is either completely absent or given delayed and indirectly, and also not accurate (for example, one method signals that a catastrophic fall  the level of the series happened on May 1, and in the feedback to it there may be information that according to other (data inaccessible to me) problems have been observed, say, since April.

I think that useful metrics could be confirmation of the happened fall of the series according to the later data of this series (for example, the level of the series fixed at a lower level or continued to fall for the next n days)

 Also other useful metrics could be the qualitative characteristics of the method, the conditions in which it can be applied and the restrictions on the data that it imposes.

But all of these methods of assessment and comparison are designed around the method itself, and yet I need to somehow tie to the business metrics. But they are clearly not given and they need to be constructed somehow.",MachineLearning
neeb3s,1621252766.0,[D] Memory efficient transformer,"What's a good, memory efficient transformer for causal sequence generation? Preferably with Pytorch implementation. The faster the better.In my particular task, any model smaller than 140M parameters cannot generate sensible output. I'm using an 11GB GTX 1080 Ti, and the longest input I can with has a length of 512, with a batch size of 6. I want to increase this length to 2048. Can local attention or sparse attention help with that? Huggingface has these candidates: BigBird, GPT Neo and Reformer? Does anyone have experience with training these? Comparing to standard Pytorch models, I have found out that Huggingface models use 1-1.5 GB more memory, which is a deal breaker for me. Since my data is MIDI, I have to train from scratch. There is another Reformer implementation on Github but the model is so slow. I think what I'm looking for is a simple transformer implementation with local attention, and I can't find any. Thanks in advance.",MachineLearning
nedrar,1621251055.0,[P] Magic Cards classifier in streaming,"Hi guys, first post here and also first serious project with ML :)

My master degree's thesis consists in a tool that detects and classifies *Magic: the Gathering* cards during a tabletop streaming (no online games). MtG official tournaments have some streaming procedures to follow, like a top-view camera, card positioning on the table, a certain lighting etc that can help the machine a lot by avoiding harsh conditions.

**Main Issue:** There are around **20.000** different cards, and some of them have more than 1 image representing em (alternative artworks or frames). Is classification with that number of classes even doable in a reasonable training time?

**How to react:** I could accept training on a smaller subset (like maybe the newest cards), but I would like to create something useful, and not just a demonstrative project. So for now I'm adopting a predictive pipeline to reduce the problem complexity and dispatch the classification to one of many networks trained on a specific different subsets of cards. This should be the standard for face recognition, so maybe it's the right answer. With that, every network should work ""only"" on \~1000 classes (with **very few datapoints per class**, sadly), and I don't know if it's the right path to follow.

Do you think there's a better approach to this kind of problem?

P.S. Macro-features are recognized with a \~99% accuracy, so they're not a problem at all.

&#x200B;

https://preview.redd.it/3dzrzfup0oz61.png?width=1862&format=png&auto=webp&s=89b3adf4539baca8fbfa54af62233b78a572c6ab",MachineLearning
necuzi,1621248138.0,[P] [D] How are you approaching prediction uncertainty in ML systems?,"Most models return a point estimate of some sort, regardless of the task. In some situations (e.g. finance and risk management), the uncertainty in the prediction is just as important as the prediction itself. How are people dealing with these scenarios?

I usually turn to generative models - e.g. probabilistic programs and Bayesian inference. I’ve written-up [my thoughts](https://www.bodyworkml.com/posts/serving-uncertainty) on how to engineer these into a ‘production system’ deployed to Kubernetes, using PyMC and [Bodywork](https://github.com/bodywork-ml/bodywork-core) (an open-source ML deployment tool that I contribute to).

Given the simulation-based nature of generative models, perhaps it’s unsurprising that the resulting system is a little slow. I’d be really interested to get some feedback on the approach or hear about alternatives!",MachineLearning
nec2r1,1621245434.0,"[N] Semantic Scholar introduces Semantic Reader, An AI-Powered Augmented Scientific Reading Application","[**https://www.semanticscholar.org/product/semantic-reader**](https://www.semanticscholar.org/product/semantic-reader)

While everybody knows the the pain of reading PDF, it will unlikely to go away anytime soon due to its portability.

I'm quite excited with the new reader, it allows you to click on a citation to see the reference, click on math symbol to see their definition and usages, and many more features in the future.

[https://youtu.be/yYcQf-Yq8B0](https://youtu.be/yYcQf-Yq8B0)",MachineLearning
ne9xid,1621237633.0,[D]- How can machine learning help improve SEO?,"Can machine learning models help improve SEO performance in any way? For example Google analytics is able to track data without cookies with the aid of machine learning.

Any other ways in which SEO can be revolutionized by machine learning?",MachineLearning
ne9kcr,1621236299.0,[D] Summarising feature importances - best way?,"Hi,

I am running a binary classifier and I have a pipeline with 5 or more different type of classifiers such as Random Forest, XGBoost, EasyEnsenmble, etc. I also collect the feature importance of each classifier.

What would be the most valid way to summarise feature importance? Can I simply average the feature importance value for each of the classifiers and then plot it? What if my classifiers have different performances, would that still work with feature importance?

&#x200B;

[This is how I do it now](https://preview.redd.it/bme7y756umz61.png?width=1204&format=png&auto=webp&s=2801e1af9d8881f36a33c264943f469032b41992)

Thank you",MachineLearning
ne5rf0,1621222780.0,[R] How to create a model like BERT or GPT?,"I am a sophomore and have studied ML and DL for last 6 months. Recently I started working on NLP. I was wondering how these models (BERT, GPT) are created. Following are some questions

1. Is it possible to create my own model? I was thinking of making a hybrid of encoders and decoders of transformers.

2. Is it even feasible to create a model at my stage?

3. How much time would it take to create it?",MachineLearning
ne5ovh,1621222549.0,[D] M1 Macbook for Machine Learning?,"I will be starting my PhD in a few months + have an RA for summer 2021 in Machine Learning. I really need a new laptop within a month which can last for atleast the next 3-4 years. I already have an ipad pro which is just amazing to use! I hear similar positive reviews for M1 macbook regarding battery life, compactness, ease of use etc + I can use the ipad as a secondary screen with macbook.

But I hear some negative reviews on M1 chip for Machine learning applications and Tensorflow/sklearn/external GPU connectivity giving a hard time for M1 users. Referring to comments posted [here](https://www.reddit.com/r/datascience/comments/k2aqq9/buying_new_macbook_m1_or_no/) 5 months ago. Are there any interesting develpments since that post? Most of my model training will happen via ssh on university servers and I will need Tensorflow/pytorch/docker/anaconda on device either for practice or to develop POC architectures. I am from India and am ready to go upto $2000 (1,50,000 Rs) for a Machine Learning friendly + Lightweight laptop (I am aware of the incompatibility of my requirements! :D). I am super excited for M1 mac but I don't want to invest in something just for the aesthetics. Are there other really good laptops which satisfy my requirements? Please do help. Thank you!",MachineLearning
ne589r,1621221081.0,[D] Simple implementation of 2D convolution neural network (CNN),I am looking for a good reference implementation (code) of 2D CNN (convolution neural network) using simple math operations instead of framework's high level tensor operation. This is for inference only. Many open source code implementations out are quite complex and utilize high level operations.,MachineLearning
ne52hx,1621220590.0,Keyword/key phrase extraction[D],Hey guys am a beginner at NLP and I want to create a model to extract keywords from text/sentences. Predefined models aren't detecting enough keywords. I've collected a dataset where a column is full of sentences and another column that has manually extracted keywords. Any ideas on how to create a model?,MachineLearning
ne46pz,1621217792.0,[D] Any issues with Ubuntu with dual boot and ROCM?,"Currently working using a friend's old build with a ryzen rx 5700 xt (The GPU market being what it is right now). The support for deep learning is nonexistant for AMD/ROCM on windows 10, so I plan on creating a dual boot to Ubuntu and using a Docker as my setup. As I am quite unfamiliar with such an environment, I wanted to ask if anyone has ever encountered problems with such a setup before?",MachineLearning
ne40mg,1621217258.0,"[R] help me to decide conference to submit my paper (CORL, etc)","Hello

I recently submitted to ICML and I got 2A and 2R, and my paper got rejected. My paper is on RL and has mujuco experiments. I am looking to submit to CORL. I don't have too much experience on the robotic domain. Do you know if CORL must contain robotic component?",MachineLearning
ne3p3n,1621216244.0,[D] How Does ADAM fix problems from stochastic gradient descent?,"I found this link over here that discusses the problems of stochastic gradient descent and various extensions of gradient descent (e.g. ADAM) which can be used to fix some of these problems: https://ruder.io/optimizing-gradient-descent/

There are newer extensions of gradient descent that use concepts like ""momentum"" that can better guide the neural network in finding out the minimum of the cost function.

Are there any mathematical justifications that show why regular gradient descent is prone to get stuck and how ADAM is able to resolve these problems? Or is all this just based on empirical observation?",MachineLearning
ne271z,1621211517.0,[D] Looking for Case Studies on Churn and/or Risk-Rating Models,"I've been trying to locate some industry papers/blogs on churn and customer risk rating, but all of the results that seem to turn up are McKinsey-esque in that they only address higher-level concerns.

I'm hoping to find guidance on the engineering aspects of these applications; think systems design, model architecture, best practices for database maintenance, etc.

Put another way: pretend I'm starting a company and want to learn all there is about how machine learning (and MLE) intersects with churn and risk-rating models.

thanks!",MachineLearning
ndvi5w,1621192340.0,"[D] Understanding the application and the relevance of the ""representor theorem"" in machine learning","I have often seen the ""representor theorem"" mentioned in machine learning, but I have never been able to fully understand the application and relevance of this theorem in machine learning:

https://en.wikipedia.org/wiki/Representer_theorem

https://analyticsindiamag.com/what-is-representer-theorem-in-machine-learning/

Can someone please try to explain this in a simpler way? How is it different from mercer's theorem?

Thanks",MachineLearning
ndv4if,1621191319.0,"[P] Understanding Loss Function Optimisation of ""Large Margin Nearest Neighbour""","I am currently trying to implement a paper which involves K Nearest Neighbours with ""Large Margin Nearest Neighbour"" for distance metric learning to improve KNN's performance. I have checked out the paper ""Distance Metric Learning for Large Margin Nearest Neighbor Classification \[[https://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf](https://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf)\]"" which had introduced the LMNN idea. While I am clear about the role of LMNN in KNN and other aspects, I am not clear about how the loss function for LMNN algorithm is optimized (authors have mentioned an algorithm for optimization but I am finding it complicated to understand). The project is actually an Android app (Java/Kotlin), so can't take advantage of the Python libs (also I would really like to learn the optimization algo so don't want to blindly use a lib too). So question is -- is anyone here aware of how the optimization works for LMNN or do you have any resources where this otpimization algo is explained in simpler way? Would really appreciate any help.",MachineLearning
ndu993,1621188916.0,[D] Machine Learning International Internship,"Hi guys.
I am looking for an international internship in machine learning or computer vision.
I am really enthusiastic about these areas but I had no luck in finding an appropriate internship whether remote or not. I am located in the middle east.
Do you have any suggestions where can I gain experience in this area?
Thanks in advance.",MachineLearning
ndtxf2,1621188018.0,[D] Automated Explainable Feature Generation For Customer Modelling / Analytics," My company, [integrate.ai](https://integrate.ai/), is currently testing an alpha product (free to participate and test it out), which expands datasets to enable a new kind of customer insights/analytics generation and ML modelling. This is done through a combination of reusable ML pipelines and model ensemble methods, to generate synthetic data from our network of datasets for almost all downstream tasks.

An example would be providing a propensity if a user is likely to shop at a discount store, or determining if a user is likely to be the top 1% spender to be used as axis in cluster analysis, segmentation or look-alike modeling.

The current focus is on transactional data sets (time series transactional data), and joining them to your data sets through non-PII indicators.

So if you have datasets that generally fit this shape there is a good chance the features we’re adding could help your use case. The data augmentation is done in a privacy safe way to protect the underlying data in these features - done through data anonymization and differentially private methods.

If you’re interested, please DM me, or drop any questions in the thread.",MachineLearning
nds1x8,1621182723.0,[P] Face tracking for musicians,"&#x200B;

https://reddit.com/link/nds1x8/video/r975f497fiz61/player

**Usecase**

While digitalization is transforming our lives, 99% of musicians are still playing with physically printed scores. In contrast to printed books, this is not because they like them, they are quite a pain actually:

\- You must buy/print them and therefore you cannot just spontaneously try out a piece

\- If you play longer pieces you must interrupt your playing to flip the page or ask someone to do it for you

\- They often fall off or get blown away by the wind if you are outside

But sad truth is that there isn't really an alternative yet. Of course there are apps but there you must interrupt playing all the time to flip the page or preset a speed that is super-annoying, which is why musicians have always stuck to printed scores.

**Concept**

By flipping the pages via facial expression - e.g. by opening the mouth or turning the head rapidly (in the end there have to be several options to accommodate different instruments/preferences) - digital scores become super-handy and easy to use. All one needs is an app for smartphones and tablets that can recognize facial expressions via the front camera and flip the page. Building on that, one can implement lots of premium features (e.g. a pedal) to make the app profitable as well.

**Technical Solution**

I have already built a little Python prototype (--> video) with OpenCV facial landmarks where one flips pages by opening the mouth. Obviously, it's very vulnerable to changing light conditions and from what I could find out online, the process should be too tough on computing power for most smartphones/tablets. Therefore, I'm open to taking a different approach to the development of the actual product. One approach that came to my mind:

1. Take a dataset with e.g. 50 000 human faces and use Open CV (or something comparable) to label them according to the degree of mouth opened and later blinking/head turned etc. Label the ones where landmarks don't work manually and ideally check all the other ones as well.
2. Train a Neural Network on the labeled dataset \[assuming that running it later requires less computing power than landmarks\].
3. Implement the Neural Network in the mobile app. Assuming that Python wouldn't be efficient enough, I am thinking of PWA, for example, Xamarin or React Native.

**Context**

I'm myself a recent architecture graduate; therefore, my coding skills beyond Python and C# are slightly limited. I did the course on Machine Learning by Andrew Ng and did a few projects (like the prototype), still I wouldn't consider myself advanced in the field. Even worse, I haven't ever written a mobile app yet.

**I'm looking for**

1. Your feedback and your input - particularly on the Technical Solution.
2. **You**: I'd be more than happy to share this adventure; feel more than free to contact me!

Cheers,

Julian


In case there's trouble with the vid: [https://www.youtube.com/watch?v=GZR9S1HFnUg&ab\_channel=JulianKlausTrummer](https://www.youtube.com/watch?v=GZR9S1HFnUg&ab_channel=JulianKlausTrummer)",MachineLearning
ndq965,1621177518.0,"[P] Pretrained models in Jax/Flax: GPT2, StyleGAN2, ResNet etc","I created a repository of pretrained models in Flax that can be easily installed via pip.
Github: [https://github.com/matthias-wright/flaxmodels](https://github.com/matthias-wright/flaxmodels)

**Current models**

* GPT2
* StyleGAN2
* ResNet{18, 34, 50, 101, 152}
* VGG{16, 19}

I will also add more models in the future.

**Here are some notebooks to play with on Colab**
[GPT2](https://colab.research.google.com/drive/1j58Bnt1n-k4UJRQI9jnJAJIxME8ZDZjj?usp=sharing), [StyleGAN2](https://colab.research.google.com/drive/1klNP4LbrXK5P3KwFM9_PqCVx5MwwilCI?usp=sharing), [ResNet](https://colab.research.google.com/drive/1hjOV3_3OT5xz0iaj4fdCJurL7XWBJUWc?usp=sharing), [VGG](https://colab.research.google.com/drive/1wIzRnxlxJmrZNsUthtjKWPKULKzvacPD?usp=sharing)",MachineLearning
ndpry9,1621176146.0,[P] XLNet - Annotated Paper + Paper Summary,"Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.

In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don't worry if you don't get it on the first go. Check out the links below and happy reading!

Paper Summary -  [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)",MachineLearning
ndo4j2,1621170975.0,[D] Can anyone recommend papers for machine learning in credit-based fraud?,"Hello, all!

I wanted to ask the community whether there are any recent good papers that concern general credit fraud or perhaps even financial fraud in general that you'd recommend. I'm aware there's a lot of content based on the famous credit card fraud dataset, however, I'm more interested in credit fraud that doesn't concern that specific dataset. I'm also open to hearing about machine learning applications that could be considered/adapted for such modelling.

Please feel free to plug in your own research too. Thanks in advance!",MachineLearning
ndmvp9,1621166577.0,[D] Can the AI/ML community learn more from naturalists?,"There are certain behaviours in AI/ML models that mimic natural phenomena.

Zebras confuse their predators with the striped pattern on their body. This is similar to adversarial attacks on ML/AI models.

Could we possibly learn more from naturalists as the AI/ML community? What other phenomena are there?",MachineLearning
ndkdk4,1621156223.0,[Discussion] Is the NAACL worth it?," Hello, i am an undergraduate student with a goal of getting into ML research and academia. Recently i was informed of the NAACL conference (which is conducted virtually) and it seems that i qualify for the Student fee which is 25$ however one must register for an ACL membership (for 50$) so in total it's 75$.

Im not cheap but to be honest im not financially doing very well currently, but if the benefits from attending the conference out weigh the costs for an aspiring researcher then i can register.

The question is, do the benefits out-weigh the costs?",MachineLearning
ndhqy5,1621144619.0,[P] Visualizing latent feature spaces throughout the layers using UMAP,"we always imagine how classes get more and more clustered throughout the network. In this simple demonstration, I took a trained VGG13 on CIFAR10, and show a UMAP on the unraveled features at every latent space throughout the layers.

[UMAP of selected layers of a model trained on MNIST ](https://preview.redd.it/8139slgg9fz61.jpg?width=2225&format=pjpg&auto=webp&s=ffe30f8604df809c8827e481d3d4117c7cd492aa)

[UMAP of layers of trained VGG13 on CIFAR10](https://reddit.com/link/ndhqy5/video/7ye9tr0d9fz61/player)

Full Post: [https://twitter.com/ml\_norms/status/1393687280049696774](https://twitter.com/ml_norms/status/1393687280049696774)",MachineLearning
ndbzgm,1621123405.0,[D] Feedback for the first edition of The Gradient's newsletter,"Hi there. I am one of the editors from [The Gradient](https://thegradient.pub/), which I think (or hope) many on here have seen and like. Having been around for more than 3 years now, we've decided to branch out beyond what we've been doing and just released [the first edition](https://thegradientpub.substack.com/p/update-1-fbi-usage-of-facial-recognition) of our newsletter, The Update.

Though admittedly I am making this post partially to promote it, since it's the very first one I also really want to ask for your opinions on the format/length/content of it and whether you find it compelling. We discussed how to create something we thought was different from other newsletters out there and actually interesting/worth reading, but it's hard to tell if what we came up with is actually good.

So would appreciate your feedback!",MachineLearning
ndane6,1621119206.0,[P] How to tune the number of food boxes deliveries to optimize sales,"Hi guys,

I'd like to ask the community for a problem I am trying to solve at the workplace.

We have a client that owns a series of restaurants over the territory. Every week, these restaurants receive food deliveries and our client keeps track of how much food is given to them vs how much it is sold.

The idea is simple: he uses an in-house algorithm that tunes the number of items a specific restaurant should receive for the week so that the number of unsold items doesn't (hopefully) go under a ""dangerous"" threshold. If the restaurant consistently sells most of the food it receives, the algorithm flags it as consistent and keeps on sending a similar number of food pieces every week. Otherwise, the number of deliveries is reduced to attempt to balance the number of unsold items.

This has worked quite well for the client, but he has asked me and my team to improve this process.

He has sent us data from a single restaurant that holds data from the beginning of 2021. The columns are the following -> restaurant\_id, date, type (delivered / sold), quantity, food\_description.

Do you have any ideas on how this problem can be tackled? I was thinking of linear regression and to use the number of sold items as my X to predict the y, which would be the number of items to deliver. I still don't know if this makes sense, so I am asking around for some ideas.

Thank you,",MachineLearning
nd93ye,1621114586.0,[D] Which websites/apps do you use for organizing your downloaded research papers?,"Some that I know of:

* [https://www.paperswithname.com/](https://www.paperswithname.com/) (free) for downloading Arxiv papers with the title as filename.
* [Mendeley](https://www.mendeley.com/download-reference-manager/) (first 2GB of storage free) for organizing papers and storing them in the cloud.
* [Zotero](https://www.zotero.org/) (free?) for organizing papers locally.",MachineLearning
nd8plp,1621113407.0,[D] 10 popular Keyword Extraction Techniques in NLP,"This blog lists out (All?) popular Unsupervised Keyword Extraction Algorithms in NLP.

Here, I summarize almost 10 papers w.r.t all these techniques. Enjoy the read! 🎉


https://link.medium.com/4ah0jdgXhgb",MachineLearning
nd81yo,1621111484.0,[D] Confidence Intervals for Classification Models,"The idea of creating confidence intervals in regression models is quite straightforward.

For example :
https://www.researchgate.net/profile/Folorunso-Oludayo-Fasina/publication/284729754/figure/fig2/AS:300625800777756@1448686184816/Scatter-plot-with-linear-regression-fit-and-a-95-confidence-interval-for-reported.png

But do confidence intervals carry over to classification models?

1) For example, in this picture here (confidence interval for an ROC curve corresponding to a classification model ) https://i.stack.imgur.com/Y7KSNm.png - can the lower limit of the confidence interval from this ROC curve be used to gauge how well this model might generalize to new data?

2) For a classification model, can we make a confidence interval for the prediction of an individual observation? For instance, I wrote some R code (you can directly copy/paste the code) for a particular example where a random forest (i.e. classification model) is used to predict whether if an observation will be ""approved"" or ""rejected"" (see here for the code: https://shrib.com/#Madelyn_NMjYE8) .

Thus, for each observation, the classification model predicts the probability that this observation will be ""approved"" or ""rejected"". Whichever probability is higher, the model selects that outcome for the given observation.

Also, the higher one of these probabilities are, this means the classification model is more confident with its prediction (e.g. for two observations, the ratio of approved:rejected 0.9:0.1 vs 0.6:0.4 . The model is more confident about the first prediction)

Thus, is there anyway to apply the notion of confidence intervals to the probabilities for individual predictions?

Thanks",MachineLearning
nd7bsf,1621109238.0,[D] Before I (re)attempt Docker GPU pass through on Windows......,"Promising signs from WSL 2 GPU support for Docker on Windows....

Is Tensorflow GPU acceleration now possible running in Windows based Docker containers?

Before I revisit this and sink huge amounts of time trying to do the impossible (again) has anyone had success with this?

The learning experience was ‘fun’ the first time, but probably much less so the second.",MachineLearning
nd6an5,1621106204.0,[D]: Paperfella. Where we learn from research papers together.,"Hello everyone!

Want to join the place where people learn from research papers while talking to each other?

Paperfella is an app for that. It currently has two main functionalities.

1. It creates a smart real-time chat per research paper.
2. It improves the research papers so you can read it in vertical mode in your mobile without zooming. And you can also break down a word or expression to its most basic meaning by just touching the word or expression (Cambridge Dictionary's API). It also applies better styles on the typography and math symbols.

I want to talk to some people who'd like to help me with this idea or are interested in it.",MachineLearning
nd5uyj,1621104987.0,[D]: how to combine auxiliary data and image data in deep cnn," I have an image regression task. For example, to predict a person age given an image of his face. But I have some more auxiliary information for each image that is known to be correlated with the prediction - For example, weight, gender, race, etc.
How can I combine the auxiliary data with the image data ?
So naturally I can quantize the auxiliary data into a finite number of options and train a neural network for each dataset. But this is a poor option for many reasons, a main one is because I am using only a portion of the data for each network.
Can you refer me to a paper or architecture that use auxiliary information with a CNN ?",MachineLearning
nd5if1,1621103994.0,[D] Where the ML research is headed. And a thank you to the community that made it possible.,"Mark writes ([https://twitter.com/yieldthought/status/1393589699357429761](https://twitter.com/yieldthought/status/1393589699357429761)):

>I increasingly feel like conferences matter less than Twitter+GitHub. By the time a paper hits conference the state of the art is two papers further. Acceptance by u/wightmanr into timm and hitting u/karpathy’s arxiv-sanity trending is arguably more impactful than a NeurIPS talk.

&#x200B;

Andrej Karpathy writes ([https://twitter.com/karpathy/status/1393616063598776333](https://twitter.com/karpathy/status/1393616063598776333)):

>There’s a few other prestigious venues like [@ykilcher](https://twitter.com/ykilcher) YouTube, paperswithcode, [@ak92501](https://twitter.com/ak92501)et al tweet streams etc :) but yes. I rather like the emerging hybrid model where the new cheap low latency async distributed consensus layer coexists with the legacy “Layer 1 chain” (pubs)

&#x200B;

Arguably, this subreddit is also playing a role in this trend. Without being part of the traditional academic community, I feel like I have learned more about AI and ML without the need to do a Ph.D. or attend a conference. And I am deeply grateful this is possible. Thank you!


What are the thoughts of others on this trend?",MachineLearning
nd4d2t,1621100779.0,[R] Dynamic View Synthesis from Dynamic Monocular Video,"[Chen Gao](http://chengao.vision/)  [Ayush Saraf](https://free-view-video.github.io/#)  [Johannes Kopf](https://johanneskopf.de/)  [Jia-Bin Huang](https://filebox.ece.vt.edu/~jbhuang/)

**Project:** [**https://free-view-video.github.io/**](https://free-view-video.github.io/)
**Abstract**:  We present an algorithm for generating novel views at arbitrary viewpoints and any input time step given a monocular video of a dynamic scene. Our work builds upon recent advances in neural implicit representation and uses continuous and differentiable functions for modeling the time-varying structure and the appearance of the scene. We jointly train a time-invariant static NeRF and a time-varying dynamic NeRF, and learn how to blend the results in an unsupervised manner. However, learning this implicit function from a single video is highly ill-posed (with infinitely many solutions that match the input video). To resolve the ambiguity, we introduce regularization losses to encourage a more physically plausible solution. We show extensive quantitative and qualitative results of dynamic view synthesis from casually captured videos.


https://reddit.com/link/nd4d2t/video/7td8275wmbz61/player",MachineLearning
nd40nf,1621099806.0,[D] A decentralized network for training and distributing Deep learning based AI,"Is there anything like this being developed? Like distributing training of Deep learning systems among computers around the world and then hosting it the same way. No single point of control or failure.

I think it could be an interesting way to have truly open development of AI systems controlled by the people not behind paywalls. Could possibly be tied to a crypto to incentivize donating resources to the forward and backward computations.",MachineLearning
nd08gn,1621089295.0,[D] GPU Render Farm + Machine Learning,Hi. I'm building my own GPU Render Farm on NVIDIA RTX 3080 and 3090. I rent out my systems to 3d designers to render their projects. It's interesting to me if I can provide AI developers with powerful systems to do AI tests and so on. Do they need such rigs for calculation? What do you think?,MachineLearning
ncz9ft,1621086432.0,[R] Is there a mathematical model of the Mind? Join us for a Google-Workshop this Mon May 17th.,"**Is there a mathematical model of the Mind?**

Please join us for a virtual Google workshop on “[Conceptual Understanding of Deep Learning](https://sites.google.com/view/conceptualdlworkshop/home)” 

**When**: May 17th 9am-4pm PST. 

**Where**: [Live over Youtube](https://www.youtube.com/watch?v=g5DGBWjiULQ),

**Goal:** How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of “conceptual” understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.

The speakers and panelists include **Turing award** winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou, and experts from diverse backgrounds including, ML/AI, algorithms, theory, and neuroscience ([full-details](https://sites.google.com/view/conceptualdlworkshop/home)).

**Panel Discussion:** There will also be a panel discussion on the fundamental question of “**Is there a mathematical model for the Mind**?”. We will explore basic questions such as “Is there a provable algorithm that captures the essential capabilities of the mind?”, “How do we remember complex phenomena?”, “How is a knowledge graph created automatically?”, “How do we learn new concepts, function and action hierarchies over time?” and “Why do human decisions seem so interpretable?”

Twitter:[ \#ConceptualDLWorkshop](https://twitter.com/search?q=%23ConceptualDLWorkshop&src=recent_search_click). Please [Retweet](https://twitter.com/rinapy/status/1384311169519788032). Hope to see you there!

Rina Panigrahy

([http://theory.stanford.edu/\~rinap](http://theory.stanford.edu/~rinap))",MachineLearning
ncyoos,1621084653.0,[D]Bits per character (BPC) misuse?,"Hi All,

I developed my own simple character level language model.  If I use natural log, I get the loss of \~1 for english. However, literature reports \~1 bit per character which is far ahead of mine. The natural log and log2 differs at a factor of ln2.

My question (double check): is it possible that  the literature acturally mis-reported natural log rather than log2? for example I see minGTP reports natural log loss.",MachineLearning
ncymw1,1621084488.0,[D] Paper Explained - DDPMs: Diffusion Models Beat GANs on Image Synthesis (Full Video Analysis),"[https://youtu.be/W-O7AZNzbzQ](https://youtu.be/W-O7AZNzbzQ)

GANs have dominated the image generation space for the majority of the last decade. This paper shows for the first time, how a non-GAN model, a DDPM, can be improved to overtake GANs at standard evaluation metrics for image generation. The produced samples look amazing and other than GANs, the new model has a formal probabilistic foundation. Is there a future for GANs or are Diffusion Models going to overtake them for good?

&#x200B;

OUTLINE:

0:00 - Intro & Overview

4:10 - Denoising Diffusion Probabilistic Models

11:30 - Formal derivation of the training loss

23:00 - Training in practice

27:55 - Learning the covariance

31:25 - Improving the noise schedule

33:35 - Reducing the loss gradient noise

40:35 - Classifier guidance

52:50 - Experimental Results

&#x200B;

Paper (this): [https://arxiv.org/abs/2105.05233](https://arxiv.org/abs/2105.05233)

Paper (previous): [https://arxiv.org/abs/2102.09672](https://arxiv.org/abs/2102.09672)

Code: [https://github.com/openai/guided-diffusion](https://github.com/openai/guided-diffusion)",MachineLearning
ncygcg,1621083908.0,[D] Highlights of PyTorch ecosystem days,"Recently Pytorch held an ecosystem day - event, that brings developers and practitioners together to share how they integrate their recent software/packages with Pytorch. Original post is [here](https://irregularadel.substack.com/p/highlights-of-pytorch-ecosystem-days).

[How one of the most popular DL frameworks builds the whole ecosystem of software and packages around itself.](https://preview.redd.it/7407gil77az61.png?width=1571&format=png&auto=webp&s=fe591337b0ff229cf8d5eb8c56a231cfdcb736ab)

When I first saw it, I registered straight away. But boy, I must say, the schedule and organizational part disappointed me. The info and schedule were in Google docs (and yes, Google develops a direct competitor framework), it was big, overloaded, and hard to understand. In comparison, Google created a simple, easy to use and fancy [webpage](https://events.google.com/io/program/schedule?lng=en-US) with the schedule of their similar Google I/O event. As a Pytorch fan, I feel a bit ashamed.

Still, the event is full of content! It’s great that Pytorch and the Community support each other in better tools development.

To the content!

# Summary:

First of all, I see that products based on Pytorch are growing rapidly, and packages are becoming more and more domain-specific.

There are wrappers over PyTorch like Pytorch-lightning, Ignite, fastai, Catalyst - they meant to make high-level API with lots of SOTA features implemented.

The level of specification of pytorch ecosystem goes deeper each year - we now can find not only CV/NLP packages but also biomedical imaging, audio, time-series, reinforcement learning. 2D/3D Augmentation libraries, MLOps solutions. Some packages help to diagnose your models, like finding model drift, mitigate unfairness, compress them. I even saw a separate MLOps package for automated driving\*\*.\*\*

The whole ecosystem is [here](https://pytorch.org/ecosystem/), and it quite interesting to dive into it. There are in total 60 (!) tools, libraries, and packages there. Soon, they will need an advanced filtering/categorization system. 

It is amazing, how fast this ecosystem grows, curious to see the next step of this evolution.

# Posters:

They are here - [https://pytorch.org/ecosystem/pted/2021](https://pytorch.org/ecosystem/pted/2021)

I decided to start from the posters. and not from the videos, since imo posters are more interesting.

There are posters for such wide-known products like huggingface, pytorch lightning, etc. - I won’t mention them. Below is the list of something new/interesting that I personally want to mention.

* [**PyTorch development in VS Code**](https://assets.pytorch.org/pted2021/posters/A4.png) **-** they have profiler and tensorboard integration. I am using PyChram right now, but thinking more and more about switching to VS code.
* [**Upcoming features in TorchScript**](https://assets.pytorch.org/pted2021/posters/A5.png)
* [**AI Model Efficiency Toolkit (AIMET)**](https://assets.pytorch.org/pted2021/posters/D4.png)\- about model compression
* [**Enabling PyTorch on AMD Instinct™ GPUs with the AMD ROCm™ Open Software Platform**](https://assets.pytorch.org/pted2021/posters/K8.png) **-** nice to see that AMD is catching up finally
* [**TorchStudio, a machine learning studio software based on PyTorch**](https://assets.pytorch.org/pted2021/posters/F4.png) **-** yes, Pytorch focused IDE. Product is not ready but looks interesting
* [**High-fidelity performance metrics for generative models in PyTorch**](https://assets.pytorch.org/pted2021/posters/K3.png)
* [**UPIT: A fastai Package for Unpaired Image-to-Image Translation**](https://assets.pytorch.org/pted2021/posters/A7.png)
* [**CompressAI: a research library and evaluation platform for end-to-end compression**](https://assets.pytorch.org/pted2021/posters/D6.png)
* [**pystiche: A Framework for Neural Style Transfer**](https://assets.pytorch.org/pted2021/posters/D7.png)

# Videos:

There are opening talk videos for EMEA and APAC.

* [Morning/EMEA Opening Talks](https://www.youtube.com/watch?v=MYE01-XaSZA)
* [Evening/APAC Opening Talks](https://www.youtube.com/watch?v=CjU_6OaYKpw)

They are more or less the same. To be honest, I would recommend skipping those and watch cuts from them instead.

[**My Journey to PyTorch by Piotr Bialecki @Nvidia**](https://www.youtube.com/watch?v=rZcWPG-7zA0)
You probably know Piotr Bialecki if you are using pytorch - he is the guy who answers most of the questions in pytorch forum. Piotr is the Technical Lead of The PyTorch Team @ NVIDIA.He speaks about his path in ML/DL, how he started to use pytorch, he reflects on the past and looks forward.You should watch that, if you need a little inspiration.

[Youtube comment about Piotr](https://preview.redd.it/ts3bn1qv7az61.png?width=362&format=png&auto=webp&s=eba87e5982119e4d2aca7ef2766be4301e30d183)

[**PyTorch Release by Joe Spisak**](https://www.youtube.com/watch?v=BLG4o7RCqTg)
You should watch this video, If you want to learn more about latest pytorch release features from PyTorch Product Lead u/Facebook AI. Joe speaks about

* python code transformations with FX (it is a toolkit for pass writers to facilitate Python-to-Python transformation of nn.Module instances - not sure everyone will need this)
* torch.linalg - provides NumPy-ish linear algebra operations support
* torch.fft that cover discrete Fourier transforms and related functions
* pytoch native profiler (yay!) with tensorboard plugin
* distributed training (including support of AMD *(sic!)* GPUs)

[**PyTorch Partner Collaborations by Geeta Chauhan**](https://www.youtube.com/watch?v=Ff4o9xX98eY)
Geeta leads AI Partnership Engineering at Facebook AI. Nice lecture for the ones who want to know recent collaboration features. She talks about:

* more details on **profiler,** with use cases, integrations into partnering frameworks, etc.
* scaling in production with torchserve (meant to be model serving framework for PyTorch that makes it easy to deploy trained PyTorch models performantly at scale without having to write custom code)
* MLOps with Kubeflow (building pipelines)
* MLOps with MLFlow (from model artifact serving to auto-tracking of pytorch training metrics, hyperparameters search)

[**Disney's Creative Genome by Miquel Farré**](https://www.youtube.com/watch?v=KuDxEhHk2Rk)
Miquel is Senior Technology Manager u/Disney. He speaks about Creative Genome - a project aimed to provide curated time-based metadata. On top of this metadata, they are building their models to recognize their characters in movies/animations/comics/series, detect certain activities and events.

[Capitan Alice in wonderland](https://preview.redd.it/5giswmvl8az61.png?width=738&format=png&auto=webp&s=62bc9da6fb0cbb1064dfaa04b1fd2fc1ff5ae32f)

[**Community Updates by Suraj Subramanian - PyTorch Developer Advocate @Faceook AI**](https://www.youtube.com/watch?v=0c53X2tiwps)
Well, the name speaks for itself. Suraj gives some statistics on contributions into PyTorch, and also speak a bit about the ecosystem.

[**Applications of AI and PyTorch in Asia Pacific by Ritchie Ng**](https://www.youtube.com/watch?v=VSC7WBFMuZo)
Ritchie Ng is the CEO of Hessian Matrix, an AI systematic global hedge fund based in Singapore. He provides an overview of APAC, speaks about CV in e-commerce and retail, NLP in finance.

# More resources:

* [Contributor Newsletter](https://pytorch.org/resources/contributors/) \- Includes curated news including RFCs, feature roadmaps, notable PRs, editorials from developers, and more to support keeping track of everything that’s happening in our community.
* [Contributors Discussion Forum](https://dev-discuss.pytorch.org/) \- Designed for contributors to learn and collaborate on the latest development across PyTorch.
* [PyTorch Developer Podcast (Beta)](https://pytorch-dev-podcast.simplecast.com/) \- Edward Yang, PyTorch Research Scientist, at Facebook AI shares bite-sized (10 to 20 mins) podcast episodes discussing topics about all sorts of internal development topics in PyTorch.

Good luck diving into that!",MachineLearning
ncxw3y,1621082097.0,[D] Is this a typo in Resnet's paper?,"In page 4 of Resnet's original paper ([https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)), it says "" **When the dimensions increase (dotted line shortcuts in Fig. 3) ""** but looking at the network's architecture, the dimension of the input is decreasing due to the strides=2 and the depth is increasing instead, so I wonder if this is a typo or whether I missed something?",MachineLearning
ncx317,1621079313.0,"[R]Great Paper: ""Forbidden knowledge in machine learning refections on the limits of research and publication.""","""Forbidden knowledge in machine learning refections on the limits of research and publication.""


by Dr. Thilo Hagendorff


""Certain research strands can yield “forbidden knowledge”. This term refers to knowledge that is considered too sensitive, dangerous or taboo to be produced or shared. Discourses about such publication restrictions are already entrenched in scientifc felds like IT security, synthetic biology or nuclear physics research. This paper makes the case for transferring this discourse to machine learning research. Some machine learning applications can very easily be misused and unfold harmful consequences, for instance, with regard to generative video or text synthesis, personality analysis, behavior manipulation, software vulnerability detection and the like""

&#x200B;

Linkt to paper:  [https://link.springer.com/article/10.1007/s00146-020-01045-4](https://link.springer.com/article/10.1007/s00146-020-01045-4)",MachineLearning
ncwn25,1621077674.0,[Discussion] GAN Training: Tracking of gradients w.r.t. input noise vector?,"When training a GAN, should you track gradients w.r.t. the input noise vector? So if you have code like this:

```python
z = torch.randn(...) # generate noise vector
z.requires_grad = True # Is this necessary?
generated = generator(z)
```

Is the `requires_grad` necessary? What would it actually _mean_ if we were to track gradients in the input noise?",MachineLearning
ncwgnq,1621076996.0,[D] Why is using TPUs with tensorflow so hard?,"I have been trying to convert my tensorflow model to one that works with TPU but can't seem to do so. I have been trying to do so over a month now.

I am getting this error: InvalidArgumentError: Unable to parse tensor proto

So I  used a takedataset of 10, reduced the batch size to 16 and reduced the image dimensions. Still the same error.

What is wrong? Are TPUs worth the hassle of conversion in terms of speed?",MachineLearning
ncr58p,1621054663.0,[R] How do you use RL on Multi-modal Embeddings for Image2Text Retrieval?,"For my mini-project, combining Computer Vision + NLP + RL interests me. I've come across this paper -- Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images where the main task is trainingg a neural network to learn a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task. 

It also has an image to recipe retrieval where theye evaluate all the recipe representations for im2recipe retrieval. Given a food image, the task is to retrieve its recipe from a collection of test recipes.

It also includes some embedding properties like word2vec.

They basically use CNN for encoding the image and RNNs to encode both the recipe and the instructions and then have a joint embedding for the recipe and instructions. Their embedding is created using a cosine Similarity loss and one semantic regularization loss.

For introduction of RL to image captioning, I've seen the they incorporated RL by having their Deep Q Network to learn through action - the next word of the imagecaption, state (the current words on the caption on time t) and reward being some score.

I was wondering how do I introduce Deep RL for this scenario on embeddings. Hopefully you can help guide me.",MachineLearning
ncqxvb,1621053755.0,Has anyone used Visdom on Google Collab?[project],"I'm using a GPU hosted runtime on Google collab and trying to use visdom for visualisations. I started the visdom server using my computer's terminal and hosted my localhost using ngrok and passed  the generated url inside visdom.Visdom() in Google collab. I'm getting an error saying connection timed out, and as a result another error saying Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with use_incoming_socket=False",MachineLearning
nclk9m,1621033934.0,[P] Cossover with Genetic Algorithm?,"I am curious as to how other have efficiently implemented crossover of neural network in regards to genetic algorithm.

In the past I have typically have very small networks of < 100 weights and would simply use my CPU to loop through and swap weights 50% of the time - thisnworked well for my needs.

Today my networks have > 10 million weights each and manually lopping through and swapping value will obviously not work due to time constrains - hence this post.

I have a few ideas of how I could get these to work, specifically by using XOR over the entire matrix.

Any ideas as to if this would work? Are there better alternatives you can think of?

Thanks.",MachineLearning
ncj87y,1621026941.0,[P] Genetic algorithm for feature selection,"+ There are many ways of improving machine learning model performance.

+ One such is feature selection.

+ Amongst many feature selection techniques, genetic algorithm is one.

+ I have created a python library that helps you perform feature selection for your machine learning models.

+ It helps you identify the best set of features for your model. Feel free to use it.

pip install EvolutionaryFS


Example notebook: https://www.kaggle.com/azimulh/feature-selection-using-evolutionaryfs-library

Pypi page with documentation: https://pypi.org/project/EvolutionaryFS/",MachineLearning
ncj6e6,1621026804.0,[D] The AI Grad School: An Industry Analogy. (Satire),"*This is satire, treat it as such. Don't take it personally. I know everything is not like this.*

Terminology

1. Professor = CEO
2. PhD student/Postdocs = Program/Product Manager
3. Master's/Batchelor's students = Code Monkeys, Independent contractors, Unpaid Interns
4. Paper = Product
5. Publishing Paper in big venue = Product release
6. NSF/Amazon/Google/Facebook/Jeffery Epstein/Other Funding Souces = VC Funds.

Life Cycle of A Product:

1. CEO thinks of some company vision and hires some program managers. Sells the vision of a product as equity to some dreamy-eyed employees who become the code monkeys.
2. CEO parallelly makes different code monkeys work on same vision while program managers are chilling.
3. One code monkey from the army comes up with some new neural lego that works after months. CEO becomes super happy with the outcomes of the lego. Other code monkeys are told to keep working on a problem when there is already a working solution that even they can know.
4. CEO tells winning code monkey lets make a product out of the lego. Step In Project Managers. No clue of how the lego was built, start dictating how to productize it.
   1. Winning Code Monkey asks to give spec on what is needed for product release, Project manager gives some requirements. Code monkey satisfies requirements. One week later project manager changes the requirement. The pattern keeps repeating and code monkey keeps getting frustrated.
5. Winning code Monkey keeps working on the product but CEO and project manager all have their visions on how to sell it.  Winning code Monkey asks for code and detailed information to run lego along with all results be fully open-sourced with the product. CEO and project manager tell the winning code monkey to fuck off because exposing too much information is not good for the product.
6. On product release, the CEO goes to VC funds for more money to hire more project managers.
   1. If multiple products succeed, Bask in VC Money.  If fail, no more funds and no more project managers.
7. On product release, winning code monkey's contract is done and the project manager takes over the product, and post-release the product is shelved because it helped get new funding for the new project managers. Other code monkeys hopelessly play with neural lego dreaming of hopefully productizing one day with some other new vision of the CEO.

Code monkey very upset that the code got no value in this product space. Code monkey also upset that working with many monkeys in an AGILE way could have made the product much faster but Program managers and CEO didn't like that too much as equity sharing on product becomes the issue.

But what do I know. I am just a code monkey with a tiny tiny product experience.",MachineLearning
nciv12,1621025970.0,"[D] In BERT, what is the purpose of the [SEP] token when Segment Embeddings are already included in the input?","During pretraining of BERT, two sentences A and B are given, transformed using WordPiece- and position embeddings, and are made distinct from each other by including two extra features into the input:

- The [SEP] token, which is inserted between sentence A and B,
- The predefined Segment Embeddings, which are added to the the embedding layer.

 What I cant figure out is, why are both of these included? Shouldn't either one by themselves do the job?

The [SEP] token in particular seems redundant to me, as it isn't even used for the Next-Sentence  Prediction pretraining task which instead trains on the [CLS], if I've understood everything correctly.",MachineLearning
ncie5p,1621024716.0,[D] Possible Strategies for Language VAE using Transformers,"Could you suggest possible strategies for Language VAE using Transformer?

Language VAE with RNNs uses the encoder output as an input with Gaussian noise into the decoder RNN.

1. Is it effective to follow a similar strategy for Transformers as well by passing Latent Vector as the start token?
2. Use outputs of the encoder with Gaussian noise as the attention weights into the decoder?

If you find better strategies, please do suggest any.",MachineLearning
ncica0,1621024582.0,[R] Why Are We Using Black Box Models in AI When We Don’t Need To? A Lesson From An Explainable AI Competition,"

Very interesting & insightful article: ""Why Are We Using Black Box Models in AI When We Don’t Need To? A Lesson From An Explainable AI Competition""

by Cynthia Rudin and Joanna Radin

""In 2018, a landmark challenge in artificial intelligence (AI) took place, namely, the Explainable Machine Learning Challenge. The goal of the competition was to create a complicated black box model for the dataset and explain how it worked. One team did not follow the rules. Instead of sending in a black box, they created a model that was fully interpretable. This leads to the question of whether the real world of machine learning is similar to the Explainable Machine Learning Challenge, where black-box models are used even when they are not needed. We discuss this team’s thought processes during the competition and their implications, which reach far beyond the competition itself. ""

Link to paper: [https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/5](https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/5)",MachineLearning
ncfieu,1621017035.0,[P] Machine learning applied to game theory resource?," Hey Friends- you probably get posts from people not in the field who are curious all the time, so apologies.

I'm  looking for any resource I can on tools, applications, companies, or  resources that apply an AI/machine learning approach to game theory  problems. For example, in a COVID like situation where there is a  production limited good (i.e. the vaccine), and there are various groups  of people with different beliefs (1- the vaccine will be lifesaving, 2-  It may be lifesaving, but was developed too quickly, etc. etc. etc)-  I'm interested in modeling different outcomes given different starting  conditions. I won't continue to use the vaccine analogy, as it starts to  break down here- it's just for illustrative purposes.

So  with that being said- I'd love even simply being pointed in the right  direction for where to look for a tool, application, company, or other  resource.",MachineLearning
ncf0a6,1621015711.0,[D] What are the best practices for fine-tuning ResNet?,"I'm trying to fine-rune ResNet-50 for a multiclass classification task. I have around 10k samples and 10 classes (about galaxies), but they're not balanced.

I've currently done the following steps (with some decent results):

* Added on top of resnet 2 Dense layers and a 0.5 dropout
* unfreezed the last 3 layers of ResNet
* added weights to the loss function to account for the imbalanced dataset
* some data augmentation (rotatation and flipping mostly)

What else could improve the results? I'm still new to this so I might have missed something important.",MachineLearning
ncezu9,1621015679.0,"[D] Will conferences like NIPS, ICLR, AAAI, ACL ever be in-person again?","With COVID and border restrictions slowly easing in the US And Europe (whereas getting worse in India), do you guys think that all these top machine learning and NLP conferences will be in person any time soon?

What is the community view regarding in person conferences?  Do people think virtual conferences are the new norm and more productive/less carbon footprint/more visibility etc...biggest con:   no free travel :( ?",MachineLearning
ncdy6m,1621012965.0,"[R] Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs","A research team from Google shows that replacing transformers’ self-attention sublayers with Fourier Transform achieves 92 percent of BERT accuracy on the GLUE benchmark with training times seven times faster on GPUs and twice as fast on TPUs.

Here is a quick read: [Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs.](https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/)

The paper *FNet: Mixing Tokens with Fourier Transforms* is on [arXiv](https://arxiv.org/abs/2105.03824).",MachineLearning
ncduqj,1621012722.0,[D] How to improve image inversion with Gaussianized latent spaces explained,"# [Improving Inversion and Generation Diversity in StyleGAN using a Gaussianized Latent Space](https://t.me/casual_gan/38)

🎯 At a glance:

>In this paper about improving latent space inversion for a pretrained StyleGAN2 generator the authors propose to model the output of the mapping network as a Gaussian, which can be expressed as a mean and a covariance matrix. This prior is used to regularize images that are projected into latent space  via optimization, which makes the inverted images lie in well conditioned regions of the generator's latent space, and allows for smoother interpolations and better editing.

[Samples from the model](https://preview.redd.it/1058coadc4z61.png?width=1219&format=png&auto=webp&s=42af3487e9d073a608b54ad12d067396e5931b5d)

\[[5 minute summary of main ideas](https://t.me/casual_gan/38)\] \[[arxiv](https://arxiv.org/pdf/2009.06529.pdf)\]


P.S. Thanks for reading!
If you found this useful check out other popular ML papers explained on [my channel](https://t.me/casual_gan)!


**Links to other recent papers explained:**

* [VQ-VAE2](https://t.me/casual_gan/30)
* [StyleGAN2-ada](https://t.me/casual_gan/28)
* [MLP-Mixer](https://t.me/casual_gan/35)",MachineLearning
ncchgt,1621009160.0,[R] A new baseline and codebase for self-supervised learning (SSL) with ViT/Swin-Transformer (Microsoft Research),"Github: [https://github.com/SwinTransformer/Transformer-SSL](https://github.com/SwinTransformer/Transformer-SSL)

Tech Report: [https://arxiv.org/pdf/2105.04553.pdf](https://arxiv.org/pdf/2105.04553.pdf)

## Highlights

* **The first work to** i**nclude down-stream evaluation for SSL using Transformers**: provide results of the transferring performance on down-stream tasks of object detection and semantic segmentation
* **Light tricks**: lighter additional tricks than in previous works, such as MoCo v3 and DINO
* **High accuracy on ImageNet-1K linear evaluation**: 72.8 vs 72.5 (MoCo v3) vs 72.5 (DINO, no multi-crop aug.) using DeiT-S/16 and 300 epoch pre-training; 75.3 using Swin-T and 300-ep training",MachineLearning
ncbk3e,1621006781.0,"[D] What are your thoughts on DL works on Nature, Science?","Usually a multidisciplinary work. Usually with fancier images than ML/DL conferences.

But for arch. most only use simple combination of models like CNN, resnet. LSTM.

What are your thoughts on those works?",MachineLearning
nc9tuk,1621002266.0,"Is this type of problem possible with ML if so, how? [D]","I have a dataset of 10 labels. I want to give an input and the model outputs the top 3 similar labels from that input. The input will NEVER be one of the 10 labels, however, I want to see which 3 labels the input is most LIKE. What sort of ML problem is this?

I hope that makes sense",MachineLearning
nc7ddx,1620995078.0,[N] ‘Minecraft’ structures that build themselves,"Hello Guys,

We  are going to have Sebastian Risi to discuss his latest research on  ‘Minecraft’ structures that build themselves and regenerating soft  robots through neural cellular automata, if you have any questions you  can send them here: [https://docs.google.com/forms/d/e/1FAIpQLSfQNaOhf\_OflZuiNzjhb-zH2vUDB4vLYCSI\_Qf7VYpEcBIEHg/viewform?vc=0&c=0&w=1&flr=0](https://docs.google.com/forms/d/e/1FAIpQLSfQNaOhf_OflZuiNzjhb-zH2vUDB4vLYCSI_Qf7VYpEcBIEHg/viewform?vc=0&c=0&w=1&flr=0)

For more details:

\[1\] Growing 3D Artefacts and Functional Machines with Neural Cellular Automata : [https://arxiv.org/abs/2103.08737](https://arxiv.org/abs/2103.08737)

\[2\] Regenerating Soft Robots throughNeural Cellular Automata: [https://arxiv.org/pdf/2102.02579.pdf](https://arxiv.org/pdf/2102.02579.pdf)

&#x200B;

&#x200B;

&#x200B;

https://preview.redd.it/3pyxrh63x2z61.png?width=2586&format=png&auto=webp&s=7b5cb627251c1e7880fdaa237319a71572fe4f7f",MachineLearning
nc72uo,1620994140.0,"[P] Machine learning workflows to summarize, translate, transcribe and more","&#x200B;

https://reddit.com/link/nc72uo/video/f0fqtjfwt2z61/player

What if we want to extract and summarize text from documents, also handle translation, combine the   outputs and load it into an Embeddings index. Enter workflows! The demo above takes a list of GitHub project pages, extracts text from HTML, summarizes the text and builds a similarity search index. This same concept could be applied towards a list of company pages, wikipedia pages and more. This is just one example of what txtai workflows can do.

txtai workflows are a simple yet powerful construct that takes a callable and returns elements. Workflows are streaming by nature and work on data in batches, allowing large volumes of data to be processed efficiently. The amount of functionality provided by machine learning models continues to grow rapidly. txtai provides an easy way to interface with these models. The following is a non-comprehensive list.

\- Questions - Extractive question-answering using a text context
\- Labels - Apply labels to text using a zero-shot classification model
\- Summary - Abstractive text summarization
\- Text Extraction - Extract text from documents
\- Transcription - Transcribe audio to text
\- Translation - Machine translation

Workflows  allows joining these models together to create powerful data transformations. Workflows can also be constructed in JavaScript, Go, Rust and Java via the API.

See the following links for more information.

[GitHub](https://github.com/neuml/txtai) | [Workflow builder](https://github.com/neuml/txtai/blob/master/examples/workflows.py) | [Documentation](https://neuml.github.io/txtai) | [Article](https://towardsdatascience.com/run-machine-learning-workflows-to-transform-data-and-build-ai-powered-text-indices-with-txtai-43d769b566a7)",MachineLearning
nc4s31,1620985625.0,[R] Finding best function in an interval with ML,"Hi all, I'd like to use ML/DL for a different objective than usual. I want to find the f(x) in [a,b] that best respects some constraints both on f(x) and on x.
To be clearer, the result of the optimization should be a polynomial function, so anything like ""x³+3x"" or ""2x²+8"" ecc. The reason for using ML and not some bruce force approach is that the ML optimizer can learn which kind of functions better respect the constraints by trial and error and eventually finding the way, but that's just an idea. Maybe ML can't even be used.

I tried to search something in literature but I couldn't find anything. Could you help me out a little, at least for knowing what to look for? Thank you in advance!

EDIT: To be more specific, I have a function f(k,n) that, with fixed k=k0 and varying n (discrete), is something like a bell. Now the problem is that, when k0 increases, the bell width of f(k0,n) increases too. However, instead of f(k,n), I'm allowed to use f(g(k),n), where g(k) is polynomial in k. Now the question is: how can I find the best g(k) such that, when increasing k0, I have that f(g(k0),n) has a constant-width bell? (Let's assume that the width is the number of points on the n axis inside the bell)",MachineLearning
nc4qh5,1620985444.0,[P] CompreFace - Free and open-source self-hosted face recognition system,"Free and Open-Source Face Recognition System that can be integrated into any system without prior AI knowledge: [https://exadel.com/solutions/compreface/](https://exadel.com/solutions/compreface/)

You may also subscribe to CompreFace News and Updates to never miss new features and product improvements: [https://exadel-7026941.hs-sites.com/en/en/compreface-news-and-updates](https://exadel-7026941.hs-sites.com/en/en/compreface-news-and-updates)",MachineLearning
nc4g35,1620984264.0,[D] sub/list of only high quality papers?,"Is there such a resource? There are a lot of new papers these days but not all of them are actually good. Is there a resource where somebody else has already gone to the effort of sifting the wheat from the chaff so that we can see what a great paper should be like?

Alternatively, what are the papers that you think are the most well-written, do ""science"" in the best way, best explanations, actually reproducible based on the paper, don't fluff results?",MachineLearning
nc3qb9,1620981296.0,[D] Deploying ML model for inference on user devices v2,"Hi all,

This is technically a repost of a previous post: https://www.reddit.com/r/MachineLearning/comments/n6rqlk/d_deploying_ml_model_for_inference_on_user_devices

I'm still looking for an optimal way to be able to infer my convnets and GANs on user macOS and Windows devices using their GPUs.

I went through torch to tflite conversion: https://towardsdatascience.com/my-journey-in-converting-pytorch-to-tensorflow-lite-d244376beed

But it doesn't seem to support user GPUs, and frankly I'm stuck looking for optimal solutions.

Any suggestions are super welcome, thank you.",MachineLearning
nc3ogn,1620981072.0,[D] Inference server alternatives,"Hi there, in the startup I am working we are exploring which might be viable alternatives to serve our ML models. Our product is mostly a (AI) service, queried via mobile app. We are looking for a solution which is scalable and maintainable, for when requests will grow in number.

Up to now, we have opted for NVIDIA Triton but I am asking for suggestions and/or your feedback on possible (better) alternatives.",MachineLearning
nc29uk,1620974817.0,[D] reviewers at top conferences,"I have been submitting to top medical imaging conferences (miccai and isbi), I feel like half of the reviewers either didn’t thoroughly read the paper or they were just not familiar with the topics or the conference requirements. I heard reviewers at other conferences are pretty noisy as well, so I’m wondering how we can improve the quality of the reviews. I’m gonna provide a few examples from my personal experience

1. A paper of mine was accepted as ISBI and there were 2 reviewers. One of them thought my methods could do a lot of things that it was not capable of. I feel like they didn’t understand my method and just thought my results looked cool, since it’s pretty easy to see the limitations of my algorithm. The other reviewer obviously didn’t read my paper carefully either. I explicitly explained that the only thing I had in common with a competing previous work was that we both used a graph representation, but the actual methods were completely different. I literally spent most of the introduction explaining this. Then that reviewer claimed my method was not much different from the previous one.

2. This paper were rejected at miccai. While the reviewers’ concern were valid and they wanted to see more experiments, it was only a 8-page single-column paper. There was no way I could fit all the ablation studies in there. I have already included 3 experiments that were both quantitative and qualitative. Also, a reviewer had a really weird comment regarding this paper. I was using a hierarchical conditional VAE, and the reviewer said the difference between my method and the original VAE was not clear.

3. I’m not sure if this is a misunderstanding but a reviewer straight up said my results were suspicious because the numbers kind of counter intuitive at first glance. I might need to analyze the results more but I thought the claim was kind of rude.",MachineLearning
nc23hb,1620974053.0,[D] Improving topic modeling,"Hi all, I’m trying to implement some topic modeling for employee training survey responses. I have 200 different training courses with between 10 and 400 survey comments each. I want to use LDA to extract topics, and then I’d like to make a word cloud with the actual topic titles colored by the average sentiment.
 - Is there any way to automatically infer the topic labels (see idea below)? New training are being developed each week that have new topics like excel or providing feedback to the people you manage.
 - Additionally, does anyone know of any way to have a variable k number of topics auto selected by course (some courses are a single topic one hour course, while others are a week long with several training topics)?

 - *Idea for auto-tagging: I’m thinking about extracting the nouns from my lemmatized text since I’m truly looking for topics. Thinking I could then create a noun list and label topics by using the most frequent noun in each topic.",MachineLearning
nbzv92,1620964989.0,[R] Unsupervised Progressive Learning and the STAM Architecture (IJCAI 2021),"Check out our recent work, which was accepted by the 2021 International Joint Conference on Artificial Intelligence (IJCAI 2021)! We pose the **Unsupervised Progressive Learning (UPL) problem**: an online representation learning problem in which the learner observes a non-stationary and unlabeled data stream, learning a growing number of features that persist over time even though the data is not stored or replayed. To solve the UPL problem we propose the Self-Taught Associative Memory (STAM) architecture, which leverages online clustering, novelty detection, outlier forgetting, and prototypical feature storage (rather than a replay buffer of raw examples).

https://arxiv.org/abs/1904.02021",MachineLearning
nbxj75,1620957231.0,[Research] [R] Extreme Face Inpainting with Sketch-Guided Conditional GAN,"Link: [https://arxiv.org/abs/2105.06033](https://arxiv.org/abs/2105.06033)

Recovering badly damaged face images is a useful yet challenging task, especially in extreme cases where the masked or damaged region is very large. One of the major challenges is the ability of the system to generalize on faces outside the training dataset. We propose to tackle this extreme inpainting task with a conditional Generative Adversarial Network (GAN) that utilizes structural information, such as edges, as a prior condition. Edge information can be obtained from the partially masked image and a structurally similar image or a hand drawing. In our proposed conditional GAN, we pass the conditional input in every layer of the encoder while maintaining consistency in the distributions between the learned weights and the incoming conditional input. We demonstrate the effectiveness of our method with badly damaged face examples.

&#x200B;

[Using edges as sketch condition](https://preview.redd.it/tqhnts8nszy61.png?width=1115&format=png&auto=webp&s=be9708fdc17d18fbc3b735c46eb7df884932b130)

[Using the hand-drawn sketch as a condition.](https://preview.redd.it/tjgz3w8nszy61.png?width=1680&format=png&auto=webp&s=522baee91e1d45e745264407d529922e162663c6)

&#x200B;

We were supposed to publish this paper in 2019, but due to unforeseen issues, we had to delay to EI2021.",MachineLearning
nbsp3t,1620943475.0,[D] Disentangling Medical Image features using Normalizing Flows?,"Recently I found out about NFs and their property of being inherently invertible and also allowing conditional generative modelling.


What are some cool works that apply these conditional NFs to medical images? Are there works that try to disentangle features of images using these techniques?",MachineLearning
nbqmus,1620937871.0,[D] Cloud instances vs owning physical hardware for deep RL training,"I want to train a bipedal robot to walk using a deep RL controller. What sort of hardware resources would you need to run this training in hours not days?

Options like the NVIDIA DGX Station A100 cost upwards of $150k, but are as close to a data center in your office as you can get. How much does this sort of system speed things up? Amazon has its GPU cloud instance on similar hardware but if you are iterating often does renting end up costing more than just buying hardware?

Is there a general benchmark performance that you need to be able to do RL using sensors like lidar/cameras efficiently?  If so, what hardware fits this category?",MachineLearning
nbn16r,1620929074.0,[D] Why positional encodding is learned in Vision Transformer ?,"Hello everybody,

I read the vision transformers paper and then looked at the implementation in pytorch.

&#x200B;

It is usual in transformers to use positional encoding (using a purely deterministic sine and cosine embedding).

&#x200B;

However in the Vit implementation, the positional encoding is learned by the model itself.

&#x200B;

Someone can explain me: Why a standard positional encoding is not used ? And what is the meaning of learning this positional encoding ?

Thanks you !",MachineLearning
nbm3b6,1620926806.0,[D] Hugging Face - Summarization adding wrong information,"Hi guys,
I am using the summarization from hugging face: https://huggingface.co/transformers/task_summary.html#summarization

In some of my summarizations I have realized that some information is added by them model without being present in the input.

Is there any of you experiencing that issue?
If yes how did you resolved it?

Thank you for your help and experience sharing.",MachineLearning
nbk34d,1620921805.0,[D] GAN training - aren't the double discriminator calls wasteful?,"I've noticed that a lot of GAN codebases runs the discriminator (D) on the gen'd data once for training the generator (G), and then again on the same data for training D. I guess this is mainly as a convenience because G and D's losses have opposite signs? Is there another upside or do we accept 50% (ish) extra processing time just to avoid a small hassle? Two ways around it I can think of:

1) use a minimizer on G and maximizer on D (a.k.a. negative learning rate)

2) somehow flip the sign of the gradient when backprop'ing from D to G.",MachineLearning
nbjt9h,1620921116.0,[R] DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation,"A research team from DeepMind explores how neural networks can be fused with algorithmic computation and demonstrates an elegant neural end-to-end pipeline that goes straight from raw inputs to general outputs while emulating an algorithm internally.

Here is a quick read: [DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation.](https://syncedreview.com/2021/05/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-18/)

 The paper *Neural Algorithmic Reasoning* is on [arXiv](https://arxiv.org/pdf/2105.02761.pdf).",MachineLearning
nbisqb,1620918471.0,[D] Why is the baseline for fairness and bias zero?,"When we talk about ML models' accuracy and other metrics, nobody cares whether they are better than random or not (I am exaggerating a little bit). What people care about is whether the model is *better* than humans' performance.

For some reason, this doesn't seem to be the case for bias and fairness. Whenever people talk about controversial potential algorithms (for instance, AI immigration officers or AI hiring such as HireVue) people get very defensive and say that the algorithms are going to be biased. Of course!

But are they going to be *more* biased than humans? I highly doubt that. I bet an AI  wouldn't ask me to open my luggage so frequently after I land in London just because I have a beard and am not too white.

In any case, I don't understand why the baseline for fairness/bias for AI algorithms is zero and not human performance.

Now, I recognize that the expectation of AI from users (e.g. interviewees from HireVue) are much higher than of humans and they might also feel more uncomfortable. So, yes, I do see why we want a fairer/less biased AI than humans but the conversation needs to go deeper than this.

There are costs and benefits to introducing AI -- if it's more accurate than humans, less biased than humans and cheaper than humans, chances are it should be used.

My point is simply saying ""AI is biased"" and putting a period, in my opinion, is not the right way to go about it. A Human is also biased and, in many cases, significantly more biased than the AI.",MachineLearning
nbioy3,1620918207.0,[P] Twitter bot that tweets trending ML papers,"Hey everyone!

I created a twitter bot that tweets trending papers in the AI & ML category (cs.AI, cs.CL, cs.CV, cs.LG and stat.ML) on arxiv.org

[@arxivaiml](https://twitter.com/arxivaiml)

Tweets are based on the engagement score of Feedly. The algorithm is simple and naive implementation. If you have any idea to improve the bot, please let me know!",MachineLearning
nbie4p,1620917404.0,[D] Defect Passed The Inspection From Machine Vision,"

Hello all, I'm new member here. I solely create Reddit account for gaining knowledge in manufacturing area.

Need your help guys as I am curious about machine vision (Cognex, Keyence, Basler etc).

Place where I work have several machine vision for IC packages defect detection (for molding, leadframe, marking). What I don't understand is sometimes the vision system cannot detect the defect even though when we try to do offline test or verification on the machine it could detect the defect on IC package.

(FYI, we use Basler as 9 main camera and 3rd party vendor for software plus machine).

What do you think guys the common cause of this inconsistencies?

Is it common problem in manufacturing industry as well?",MachineLearning
nbidfh,1620917354.0,[D] Would it make sense to use a RNN to approximate a linear system?,"I'll start with a very simple example.

Let's say I want to compute something similar to exponential moving average of time-series data, but with only N previous input values being averaged. I can make a vector of exponentially decaying weights and compute dot product of this vector and N previous inputs, getting the result I want.

But of course it's inefficient and for large enough N it doesn't give much of a difference from a standard exponential moving average, computed using feedback. So I can just use EMA as a good approximation of my desired result. In some sense, I approximated a large memoryless linear system using a small linear system with memory.

I was wondering about a more general version of this idea: What if my weights were different, but with magnitudes still decaying ~exponentially, and I was only interested in approximation being ""good"" on a small subset of possible inputs. An example of this could be an artificial reverberation, which also works by taking a large weighted average of shifted copies of an audio signal.

To me, this seems similar to the way RNNs work (i.e. taking advantage of internal state and restricted input space to find a good approximation of a non-trivial transform of time-series data), but since they're typically nonlinear I'm not sure if it's a good idea to use them here. On the other hand, I couldn't find much information on RNNs with purely linear activation functions.

Has anybody here seen something similar to this? Are there issues or complications that I'm missing?

Thanks",MachineLearning
nbhy7p,1620916203.0,[D] What kind of tools for data annotation have you used?,"I want to know what types of tools are available out there.

Would be good if you recommend both desktop based and webapps.

Also free or paid.

I want to explore data annotation tools for all types of labeling.

Text/Image/Video/Audio/Other.",MachineLearning
nbgb6a,1620911523.0,[D] Are ResNets as good as it gets?," TLDR: For training from scratch on non-classification tasks with humble computation resources, are ResNets roughly as good as it gets? This has been my experience, although the literature (and the hype surrounding it) does not seem to agree with me at all. Please prove me wrong.

In the past years visual models have transitioned from ResNets to EfficientNets (and more recently Vision Transformers), and temporal/sequence models have transitioned from RNNs to Transformers. While the latter, in my experience, constitute a clear step forward for almost all aplications and resource-scenarios, the former, in my experience, has never really worked for me.

While I'm well aware that pre-trained efficientnets perform extremely well on ImageNet, and are quite successful for finetuning on other classification tasks, and even segmentation, for me they have never worked well for new tasks such as generation from visual features, or self-supervised learning. I have seen some threads about this here and there, but it does not seem to make a dent on the efficientnet hype overall.

There are also other models, such as RegNets and Vision Transformers, but these are still substantially slower during training time than normal ResNets without massive performance improvements (in fact, for vision transformers, this underwhelming behaviour was acknowledged in the recent DINO paper). So basically I am left with the questions: 1. are ResNets roughly as good as it gets?, or 2. Have I not found the good new visual models? or 3. Has my extensive experimentation with these new models led to misleading conclusions?

The fact that very recent self-supervised learning literature is still focused on ResNets (excluding very recent SSL vision transformer works), and that most practicioners I know that do not work strictly with classification still use ResNets, leads me to believe that perhaps there is something to this, and I am not totally deluded. Please prove me wrong. Cheers.",MachineLearning
nbf7j8,1620908015.0,[D] Anonymous Walk Embeddings (Graph ML Research Paper Walkthrough),"This research talks about using Random Walk inspired Anonymous Walks as graph units to derive feature-based and data-driven Graph Embeddings in an unsupervised fashion. 🔥

https://youtu.be/VVml3nDiM3E",MachineLearning
nbe1r2,1620903919.0,[D] AskReddit: what can you do with datasets with non-commercial licenses?,"Recently, I've been looking into a number of publicly available datasets, and some of them have non-commercial licenses such as
[SKU-110K](https://github.com/eg4000/SKU110K_CVPR19) and [RPC](https://rpc-dataset.github.io/). My question is: where should you draw the line with commercial use?

Let's say we're doing some work for a profit-seeking company. Training on the datasets for a model that they intend to monetise is clearly not allowed. But what about transfer learning from the models that the authors trained? That seems less clear cut to me, but still quite sketchy. And what about using the dataset to confirm a hypothesis before going out and collecting your own images and annotations?

Any opinions, comments or experience on this that you could share would be most appreciated!",MachineLearning
nbdn8m,1620902323.0,[Research] Could anyone get Invariant Risk Minimization (IRM) to work in a practical problem?,"Hello everyone. I am interested in getting something like IRM ([https://arxiv.org/abs/1907.02893](https://arxiv.org/abs/1907.02893)), i.e. a model that I can explicitly optimize doing something better than Empirical Risk Minimization.

My problem is a numerical regression tabular data problem, and I would like something that learns from a few tables and generalizes correctly to other tables.

I liked the IRM paper, it introduces a relatively simple loss function and the code is provided. However, I did not fully understand whether it will work when using arbitrary NN. There are some follow up critics ([http://proceedings.mlr.press/v130/kamath21a.html](http://proceedings.mlr.press/v130/kamath21a.html), [https://openreview.net/forum?id=BbNIbVPJ-42](https://openreview.net/forum?id=BbNIbVPJ-42)) and enhancements ([https://arxiv.org/abs/2103.12947v1](https://arxiv.org/abs/2103.12947v1) ).

Is this worth a try or should I stick to serious validation hyperparmeter tuning?",MachineLearning
nbc5ue,1620896043.0,[R] Google AI Introduces ‘ALIGN’ to Scale Up Visual and Vision-Language Representation Learning with Noisy Text Supervision,"Excellent visual and vision-language representations are crucial in solving computer vision problems such as image retrieval, image classification, video understanding. That is why visual and vision-language models rely on curated training datasets such as [ImageNet](https://www.image-net.org/), [OpenImages](https://opensource.google/projects/open-images-dataset), [Conceptual Captions](https://ai.google.com/research/ConceptualCaptions), which require expert knowledge and extensive labels. All these datasets need non-trivial data collection and cleaning steps, limiting the size of datasets and hindering the trained models’ scale. In comparison, NLP models use large-scale pre-training on raw text *without* human labels and have achieved SotA performance on [GLUE](https://gluebenchmark.com/) and [SuperGLUE](https://super.gluebenchmark.com/) benchmarks. 

Google researchers propose a technique to bridge this gap by using publicly available image alt-text data (text appearing in place of an image on a webpage when the image fails to load). The team employs these image alt-text data to train larger, state-of-the-art vision and vision-language models. 

Summary: [https://www.marktechpost.com/2021/05/13/google-ai-introduces-align-to-scale-up-visual-and-vision-language-representation-learning-with-noisy-text-supervision/](https://www.marktechpost.com/2021/05/13/google-ai-introduces-align-to-scale-up-visual-and-vision-language-representation-learning-with-noisy-text-supervision/)

Paper: [https://arxiv.org/pdf/2102.05918.pdf](https://arxiv.org/pdf/2102.05918.pdf)

Google Blog: [https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html](https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html)",MachineLearning
nbbfzd,1620892897.0,"[D] - How to track down elusive paper materials? Case study: ""Wasserstein Dependency Measure for Representation Learning""","Here's my problem. I would like to investigate claims made in a paper. AFAIK, the following is true:
1. Paper has no official code repo.
2. Paper has no presentation/explanation/demo video.

The paper in question is ""Wasserstein Dependency Measure for Representation Learning"" https://arxiv.org/abs/1903.11780

I was grateful to find at least one open source implementation, but I'm not confident it's enough to reproduce the results in the paper, because the focus of the experiments are different.
https://github.com/SeongokRyu/mutual_information_and_self-supervised_learning/tree/master/predictive_coding

Has anyone reading this post tried to implement this paper?

Do I pretend like the paper never happened, because the results can't be replicated?

Generally speaking, what do you do when you find yourself in this situation?

What do?",MachineLearning
nb9ifz,1620884590.0,[P] Enigma: GPT-2 trained on 10K Nature Papers and an interactive game where you have to tell the difference between real abstracts and generated ones,"Project Enigma: https://stefanzukin.com/enigma/

[Stefan Zukin](https://twitter.com/StefanZukin/status/1392503331231342610), a grad student, trained [GPT-2](https://en.wikipedia.org/wiki/GPT-2) on 10,000 Nature papers and created an interactive game with the model, where you try to distinguish between a real abstract and one that is computer generated.

Some of them are quite hard: https://stefanzukin.com/enigma/",MachineLearning
nb8t3s,1620881754.0,[D]getting a good p-value and confidence interval for cross-validated AUC,"In the case of data being not so big, the AUC can be relatively random. That is why in this kind of cases you want to do cross validation and average the out-of-fold AUCs to have something close to the real one.

However in order to have an idea of how accurate this AUC is, it would be best to have a p-value for it. I did research and learned interesting things. One way would be to use boostrapping and it should work not too bad, however best would be to use actual stats, like you can find here:

https://statisticaloddsandends.wordpress.com/2020/06/07/what-is-the-delong-test-for-comparing-aucs/
https://www.rdocumentation.org/packages/pROC/versions/1.17.0.1
http://pamixsun.github.io/papers/sun2014fast.pdf
https://github.com/yandexdataschool/roc_comparison

fact is that there is good stats to actually model the AUC, get an estimate of the variance and a confidence interval.
However in the case of the average of AUCs like in the case of cross-validated AUC, I don't rly know about stats that much. (as is the case with most ML engineers I guess) what would happend with the p-value/confidence interval ?

I think its a very interesting topic and thanks for your help !",MachineLearning
nb6gnn,1620873535.0,[P] Gourdian Free Dataset Download: Project Sunroof - Solar Electricity Generation Potential by Census Tract/Postal Code,"Hi there! We've just added a new dataset to Gourdian, this one courtesy of Google's Project Sunroof. This dataset essentially describes the rooftop solar potential for different regions, based on Google's analysis of Google Maps data to find rooftops where solar would work, and aggregate those into region-wide statistics.

It comes in a couple of aggregation flavors - by census tract ( https://gourdian.net/g/eric/sunroof_solar.solar_potential_by_censustract#summary ), where the region name is the census tract id, and by postal code ( https://gourdian.net/g/eric/sunroof_solar.solar_potential_by_postal_code#summary ), where the name is the postal code. Each also contains latitude/longitude bounding boxes and averages, so that you can download based on that, and you should be able to do custom larger aggregations using those, if you'd like.

This dataset seems like it'd be interesting to cross reference with things like weather, and perhaps electricity prices, to find the best places for people to invest in rooftop solar. If you have any other ideas of what it'd be good to combine with, let us know, and we can try to prioritize ingesting those!",MachineLearning
nb5vs7,1620871784.0,[D] What algorithms beat deep learning and in what application,"Hi there,
Deep learning is taking over a lot of other machine learning algorithms in industry.

I was curious in what applications do other algorithms still outperform deep learning. And what algorithms are they?. I am mostly curious on this over in the industry world. If you could provide in the comments 1. The algorithm 2. The application and 3. The industry it would be awesome. Any comments are welcome!",MachineLearning
nb5fhf,1620870379.0,Library for plotting image clusters based on distance/affinity matrix? [D],"Are you familiar with the diagrams where image thumbnails are grouped in 2D automatically based on a distance/affinity matrix? Do you know what they are called? Does a python library for plotting them already exist?

*Thank you!*",MachineLearning
nb38w1,1620864008.0,"[R] Review of ""Can Vision Transformers Learn without Natural Images?""","&#x200B;

https://preview.redd.it/64iczbg37bz61.png?width=2172&format=png&auto=webp&s=808a3889573ae66abc4e25647e6bf7deabf45a2c

**Paper:** ""Can Vision Transformers Learn without Natural Images?""*Kodai Nakashima, Hirokatsu Kataoka, Asato Matsumoto, Kenji Iwata, Nakamasa Inoue*[https://arxiv.org/abs/2103.13023](https://arxiv.org/abs/2103.13023)

**TL;DR:**  An intriguing study showing that a computer-generated database of  fractals can replace ImageNet to pre-train vision transformers for small  datasets. It would be interesting to try this pre-training method on more challenging tasks, such as ImageNet with 1% labels. **Link to full review in the comments**",MachineLearning
nazf8m,1620853588.0,[D] How deep have you stacked RNN layers?,"When it comes to convolutional networks I see a lot of techniques for creating deeper and deeper models.  These include relu activations, batch norm between layers, residual networks, highway networks, etc.   However, when it comes to stacking RNN layers on top of each other all I ever see is maybe a few stacked layers and a dense output.  I don't see any reason why for instance you can't build something like a resnet out of RNN layers...

x\_skip = x
x = LSTM(512)(x)
x = LSTM(512)(x)
x = x + x\_skip
x\_skip = x
x = LSTM(512)(x)
x = LSTM(512)(x)
x = x + x\_skip
...


So what I am asking is how deep have you ever stacked RNNs?  Has anyone tried/seen something like what I have above?  Would there be much point in doing so?",MachineLearning
naz2ey,1620852664.0,[P] Questions relating to model evaluation with multiclass.roc & Matthew Correlation Coefficient - Rstudio user,"To anyone who reads this Thank you. I appreciate the help. I  have tried searching online but to no avail, so I'm hoping reddit and people with more knowledge than myself may help.

As per the title I have 2 questions.

First, currently I am trying to predict a multiclass output of that can be one of  4 different options. When trying to use multiclass.roc from the pROC library to obtain the AUC after building models(for this model/case assume cross validated rf) I am getting an error relating to predictor must be numeric or ordered. Currently my y variable is structured as factors. I did not have this issue prior with an output of 3 possible classifications (different model). Is this just a limit of what the capabilities are for this function? In other words is this not possible?


Second, I have come across Matthews Correlation Coefficient as another means of model evaluation outside of such things as: accuracy, rmse, f1score, logos, etc. Is this only applicable to categorical data/models that can take factors/categorical data (i am using the yardstick package here) and not to numerical models such as knn or svm (I did OHE categorical variables as well as scale them depending on the model)?

If you read this far thank you",MachineLearning
nay0h2,1620849915.0,[D] dataset or simulator for sea/waves/marine maneuvering,"We want to mess around with autonomous maneuvering at sea. This regards waves, winds and currents - the navigation part is easier.

Are there any datasets/simulators to start with?

Many thanks for any info",MachineLearning
nave7m,1620843208.0,[D] Anyone here who can comment on the Professional MS ML course provided by MILA?,"I have been selected for MS CS in BU and two Canadian universities. For Canada, my option is MS CS at Concordia and Professional MS ML program at MILA. Since Canada has friendlier immigration policies, I am leaning more towards it and Concordia is not exactly known to be an ML powerhouse so that leaves me with professional MS ML at MILA.

Can somebody who has gone through the program comment on it's quality? I have been offered a scholarship so my costs would be much lower in MILA but I've heard mixed feelings about the course online. Can anyone who has gone through the program give me an idea about how good the program is? My goals right now are strictly professional, but I may look into research in the future.",MachineLearning
natw1i,1620839446.0,[D] The effect of Fully Connected layers in CNNs,"Hello  everyone, I have been working in this field since 2 years. In this  whole time, I have been experimenting several stuffs with CNNs, and I  personally think that Fully Connected layers are of no use, and  sometimes adversely affects the CNN.

I  am looking for certain experiments that provide a base for this, or  maybe a base for something opposite to this. Can you guys recommend some  good reads and/or resources for this?

Or maybe we can start a discussion here. I would like to contribute my views/ideas.

Thank you..",MachineLearning
nas50r,1620835154.0,"[D] HuggingFace BartForConditionalGeneration model, bias tensor remains zero","Hey Guys,

I'm looking at the source code of BartForConditionalGeneration, where the language model head has a bias per each vocabulary token, however, this is a non-trainable element and never changes from zero. I don't think this has been the intended behavior, any thoughts?

&#x200B;

https://preview.redd.it/5pu3yjfjppy61.png?width=1980&format=png&auto=webp&s=1df2dece226875734b6f895101a15a36253f2e8b",MachineLearning
nas44u,1620835087.0,[D] Should i use CNN or MLP for my project?,"Hi, I'm working on a project that has an 8x8 matrix as input and it has 4 classes as output.

Should I use a Convolutional neural network to preserve the relationship between my input data or should I flatten my data and use a simple Multilayer Perceptron?",MachineLearning
nartc5,1620834317.0,[D] It's really funny how authors introduce dozens of new variables and notation to explain really basic concepts so that the paper would seem more formal.,That's the post.,MachineLearning
naqzis,1620832216.0,[N] HuggingFace Transformers now extends to computer vision,"HuggingFace just released version v4.6.0 of their [huggingface/transformers](https://github.com/huggingface/transformers) framework, with support for three vision transformers: **ViT** by Google, **DeiT** by Facebook Research, and **CLIP** by OpenAI!

These three architectures can now be loaded from PyTorch and load either original checkpoints contributed by the model authors or any checkpoint uploaded by the community on the [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=image-classification), with support for inference widgets like the [image classification widget for ViT](https://huggingface.co/google/vit-base-patch16-224).

ViT and DeiT get state-of-the-art results in image classification, and CLIP can be used for a flurry of tasks including image-text similarity and zero-shot image classification.

See the release notes for version v4.6.0; ViT and DeiT heavily benefited from Ross Wightman's [timm](https://github.com/rwightman/pytorch-image-models) framework which offers a number of great vision models.

It is released alongside a few notebooks to play with the models: [Inference with ViT](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Quick_demo_of_HuggingFace_version_of_Vision_Transformer_inference.ipynb) and [Training ViT](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb).",MachineLearning
naq75f,1620830217.0,[D] End priming transformers -- techniques?,"I'm interested in techniques to prime the end sequence of a transformer and am wondering if anyone knows of any papers or has suggestions on the best way to do this.

Here's what I mean by end priming: Let's say we're training a generative language model and want to generate a sequence which ends with ""straw.""

So, ""That's the last straw."" and ""That's the final straw."" might be valid completions that the network could give us.

I've tried two techniques so far and haven't had good results with either:

Technique 1: Alter the attention mask such that all time points can access the last N tokens (with N being the length of the primer). This approach results in training instability (the loss starts to oscillate widely after a certain point in training). So I modified it further such that I do ""crop"" the loss and do not include the last N tokens in its computation. This, too, is unstable and I've had to reduce the learning rate further but have still gotten poor results.

Technique 2: Place the primer at the start of the sequence (while leaving the attention mask alone -- i.e. each time point can only see itself and the past time points). For example, I'd want the model to output something like ""straw. This is the last"" Technique 2 also results in learning instabilities. When I reduce the learning rate low enough to avoid them, I'm left with convergence to a poorly performing model.

I'm able to train vanilla transformers just fine, so I believe it's unlikely there are problems elsewhere in my pipeline.",MachineLearning
naplzs,1620828694.0,[D] Are AAAI and IAAI tier I conferences?,Are [IAAI](https://aaai.org/Conferences/IAAI/iaai.php) INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE and AAAI Conference on Artificial Intelligence considered as tier I conferences in AI? Both of these seem to be quite popular but I am not sure if these could be called tier I. How can I find out if a particular conference is a tier I conference?,MachineLearning
najnjg,1620807526.0,[R] The Modern Mathematics of Deep Learning,"[PDF on ResearchGate](https://www.researchgate.net/publication/351476107_The_Modern_Mathematics_of_Deep_Learning) / [arXiv](https://arxiv.org/abs/2105.04026) (This review paper will appear as a book chapter in the book ""Theory of Deep Learning"" by Cambridge University Press)

**Abstract:**  We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding what features are learned, why deep architectures perform exceptionally well in physical problems, and which fine aspects of an architecture affect the behavior of a learning task in which way. We present an overview of modern approaches that yield partial answers to these questions. For selected approaches, we describe the main ideas in more detail.",MachineLearning
nafi31,1620790507.0,"[D] Has anyone ""experienced"" ML recommending actions based on data?","So this is going to be a controversial question so I appreciate you giving me the benefit of the doubt in your answers. I have been working with machine learning solutions for a while now and I am becoming increasingly agnostic about the fact that machine learning can provide large companies with ""actionable insights"" based on data.

I understand that it can identify patterns and all that, but has anyone really, and I'm saying, you've experienced using a system that can actually tell you what to do? And you are confident enough about its recommendation that you'd apply it for a billion dollar company?

For example look at this article, this looks more like a puff piece than reality...what are the not telling us here...
https://www.businesswire.com/news/home/20210427005364/en/Tellius-Raises-8-Million-to-Close-the-Data-Insights-Gap-with-AI-Driven-Decision-Intelligence",MachineLearning
naf90w,1620789628.0,[project] Looking for a music Machine learning program,"Sorry I don't know if this type of post is accepted here, but I was looking hoping to find a program that creates music (preferably with words) based on multiple samples it is fed. I'm trying to create a simulation program of music style differentiation over time based on this so it would have to be either open source or accessable from command line so i can use it through other code.
Let me know if theres anything that fits that description or if not if you think it would be a good idea to try to make one.",MachineLearning
nadxkq,1620785333.0,[P] Binary Survey Data Imputation,"Thanks is advance. Developing a ML model from multi-year survey data and am having trouble trying to determine the best way to impute missing values. All the data features have been binarized except year. What adds to my trouble is that not all questions were asked every year leading to consistent missing values for some years. Here are some of the options I came up with:

1. I don't want to simply remove items with missing data as that would remove a significant portion of the data where questions were not available for that year. So I could take that data as-is and utilize a decision tree based approach similar to XGBoost that handles missing data.
2. I could fill the missing nan values with a large constant (i.e. -9999) which would never appear in my binary data (1/0). Then I can use any classification based approached.
3. Search for a data imputation technique for binary survey data?

Am I missing anything? Are there other options available and what about the options that I have proposed above. Thanks again!!",MachineLearning
naczlx,1620782328.0,[P] A new codebase for self-supervised learning with vision Transformers that provides evaluation on down-stream tasks of object detection and semantic segmentation,"The codebase includes an SSL implementation tuned to achieve 72.8% top-1 accuracy on ImageNet-1K linear evaluation using DeiT-S/16 and 300-epoch training. It is slightly higher than that of MoCo v3 and DINO at similar training budget, but with lighter tricks.

The project also includes evaluation of transferring performance to down-stream tasks, which is missing in previous related papers and codebase. This goal is achieved by involving Swin Transformer as one of its backbones, which is friendly for down-stream tasks of object detection and semantic segmentation.

The method part basically has no new things, and is just a combination of MoCo v2 and BYOL.

Has anyone gone through the codebase, and is there any comment about following this codebase to do some exploration?

[https://github.com/SwinTransformer/Transformer-SSL](https://github.com/SwinTransformer/Transformer-SSL)

[https://arxiv.org/pdf/2105.04553.pdf](https://arxiv.org/pdf/2105.04553.pdf)",MachineLearning
nacy0c,1620782190.0,[P] Custom Image Data Pipeline Using Tensorflow,"While using convolutional nets to perform image classification, I encountered several difficulties importing image data using the native Tensorflow functions. So, I created my own custom image data pipeline, which gives the user finer control and more flexibility when importing image data. I hope it is useful to you guys as well. Let me know what you think.

https://github.com/nenyehub/tf-image-pipeline",MachineLearning
nabksd,1620777876.0,[P] Real2Sim Interactive Demo with AOgmaNeo,"[Link to blog post and interactive demo](https://ogma.ai/2021/05/real2sim-with-aogmaneo/)

This is a ""real2sim"" demonstration (not to be confused with ""sim2real"") I made using the online-learning biologically-inspired fast learning system I work on called AOgmaNeo.

The demo is interactive, and can be controlled with WASD. It works by learning a world model for a real life robot arm environment. By associating my gamepad commands with the visuals it was seeing through a camera, it learned a controllable model that I then created a WebAssembly application for. It's far from perfect, but you can notice that it learns some basic physics (especially with the marble, since it always rolled left in the real environment, and does in the simulation as well). It has trouble with ""illegal"" actions that are very out-of-distribution, resulting in some awkward behavior sometimes. To create this demo I controlled the arm for about 5 minutes.

If you want to know more about how AOgmaNeo works, [here is a guide.](https://github.com/ogmacorp/AOgmaNeo/blob/master/AOgmaNeo_User_Guide.pdf)

Let me know what you think!",MachineLearning
na7oo3,1620767064.0,[D] Any recommendations for image annotation software?,"I've been using Supervisely Enterprise at work and it's been going really really well, but my work has been paying for it. Meanwhile, my grad research work is requiring a large-scale annotation effort and my advisor is queasy about forking over grant money just to annotate. We can't use the community version because HIPAA. I've been looking at other free annotation software and I'm trying to make a decision on which to use. Any suggestions on what has worked for you?",MachineLearning
na36i1,1620755933.0,[P] Unity Tool for generating a 2D images of 3D objects from several viewpoints,"Hi guys, for my research project I have created a Unity tool that allows the creation of image datasets by taking snapshots of 3D objects from a variety of viewpoints. You can change the latitude and logitude area, the distance from the object, the lightning, and some more things.

So today I have decided to clean it up, get rid of some unnecessary features, and write some documentation. Check it out and let me know what you think :)

[ValerioB88/UnityML\_DatasetGenerator (github.com)](https://github.com/ValerioB88/UnityML_DatasetGenerator)",MachineLearning
na2yfp,1620755355.0,[D] Gpu memory is used but not its computation power,"I am running a single shot learning model which needs 3 GPU right now to run my model. However, when I check the GPU utilization using ""nvtop"" , I see that memory is used completely but  its not using GPU all the time. I can see the sudden spikes in GPU usage graph but its just lasts for 10 seconds.  What can be the reasons for this?

Data I am loading using torch dataloader with GPU.",MachineLearning
na2kuw,1620754454.0,Testing a new feature for a model in production [Discussion],"I  work at a startup and we use ML in production. For most parts, like  training, deployments and serving we leverage AWS Sagemaker. We have a  nice pipeline written in Python which gets the data from the warehouse,  applies transforms and initiates the training job, everything automated.

However  the difficult part comes when we have a new feature idea and the  decision has to be taken whether or not to add it to the pipeline. The  idea is to get a quick analysis for the new feature (or features).  Currently we do this in a notebook, where we randomly sample the actual  training datasets, train two models - one with new features added and  one without and compare the metric on the test set. We do not initiate a  complete training job as we think that might be an overkill. I would  like to understand from others int the community,

* firstly is this a common problem across industry
* secondly what is the best way to solve (or get around) the above problem, and
* thirdly, what are some of the best practices to handle a new feature from idealization to production",MachineLearning
na263b,1620753440.0,[D][R] What is the most relevant SOTA in deep NN interpretability ?,"Hello, I am currently working on a project in which I would like to find which parts of an input are most important for the forward propagation in a quite complex NN regressor.

I know that Grad-CAM is quite popular in CV, but it is also a bit limited since it is mainly relevant for images, I found only people using it for classification (although I don't see a reason why it wouldn't work for regression?), and you have to select a convolutional feature map in particular for it to work, as far as I understand. So, my question is, what is the current SOTA alternatives to Grad-CAM aiming at doing similar things but for more general settings (e.g. MLP, regression...) please ?

Thanks.",MachineLearning
na1llo,1620751999.0,[D] Can't Reproduce Paper: What Next?,"For 3D object detection tasks, I've been intrigued by the recent papers focusing on processing lidar data as a range image, in works such as Lasernet and RangeDet. However, neither paper shares code and there are no popular 3rd party implementations, so I decided to work on one. For Lasernet, it's basically just a Resnet that includes some downsampling convolutions and upscaling transpose convolutions. The original dataset is Uber's private dataset, so I chose the Waymo dataset as a reasonable alternative. However, implementing it using the original training parameters (batch and lr schedule) I'm getting loss plateauing early and garbage results when testing on the training set. I've even corresponded with an author to get more information on parameters not mentioned with no improvement. When trying to reproduce papers without original code or data, are there any tips for reverse-engineering the results? I've ruled out any obvious bugs in the code using tensorboard graph to verify correct architecture, my best guess is either I'm missing an important detail from the original model architecture or training setup or the data is just bad.",MachineLearning
na0ovc,1620749713.0,[R] ETH Zurich Proposes a Robotic System Capable of Self-Improving Its Semantic Perception,"A research team from ETH Zurich combines continual learning and self-supervision to propose a novel robot system that enables online life-long self-supervised learning of semantic scene understanding.

Here is a quick read: [ETH Zurich Proposes a Robotic System Capable of Self-Improving Its Semantic Perception.](https://syncedreview.com/2021/05/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-16/)

The paper *Self-Improving Semantic Perception on a Construction Robot* is on [arXiv](https://arxiv.org/pdf/2105.01595.pdf).",MachineLearning
na042w,1620748191.0,[P] MLP-Mixer-Pytorch: Pytorch reimplementation of Google's MLP-Mixer model that close to SotA using only MLP in image classification task.,"Google's MLP-Mixer didn't use CNN and Transformer, but only using MLP, showing close performance to SotA in the image classification task.

The MLP-Mixer will soon be merged into the \[vision transformer repo\]([https://github.com/google-research/vision\_transformer](https://github.com/google-research/vision_transformer)) and has been reimplemented to simplify the use of the official model with the pytorch version.

To verify reproducibility, I will be comparing the results on the cifar-10 dataset.

&#x200B;

MLP-Mixer github: [https://github.com/jeonsworld/MLP-Mixer-Pytorch](https://github.com/jeonsworld/MLP-Mixer-Pytorch)

paper: [https://arxiv.org/abs/2105.01601](https://arxiv.org/abs/2105.01601)",MachineLearning
na03vh,1620748176.0,[P] Launching Jupyter notebooks on AWS with a single command,"After my [last post](https://www.reddit.com/r/MachineLearning/comments/mrcv7y/p_nimbo_run_jobs_on_aws_with_a_single_command/) on [Nimbo](https://nimbo.sh) a few people asked if we had an alternative to Google Colab but for AWS. Well, we now do :D.

If you [setup Nimbo](https://docs.nimbo.sh/getting-started), you can just run `nimbo notebook` and it will sync your code, data, and environment and launch a notebook on a remote instance which you can access in your localhost.

Now you can make use of your AWS credits to get a Colab-like experience (or dare I say, better than Colab, because we do all the setup for you).

I hope at least some of you find this useful, and as always I'm happy to receive feedback :).",MachineLearning
n9zxo0,1620747704.0,[P] A list of available datasets for machine learning in manufacturing,"I have created a list of manufacturing related datasets for machine learning. You can find it here. I hope you find it useful :-)

[https://github.com/nicolasj92/industrial-ml-datasets/blob/main/README.md](https://github.com/nicolasj92/industrial-ml-datasets/blob/main/README.md)",MachineLearning
n9zb7i,1620746040.0,[D] Why do we pass the reward of the previous time-step as input to the LSTM in RL?,Many recurrent-based RL agents pass the action and reward of the previous time-step as input to the model. I was wondering about the intuition of this?,MachineLearning
n9x9n0,1620740460.0,[P] Building a data flywheel for data-centric ML development,"We've been working for a long time to provide an easy way to implement the data flywheel for CV. I'm happy to present you v0.1.

The data flywheel is the idea of having an ML-pipeline which allows you to flag mispredictions in your production environment (you could pick the ones with the low confidence, for example), pushing these images back to your annotation environment to relabel them, retraining your model with the new data and then put it back to production again. By this, you’ll have an ever-improving model.

This will enable an easy way to do model-centric ML development. Check out the blog post to learn more and how to implement the flywheel yourself: [https://medium.com/hasty-ai/uncovering-hidden-biases-in-your-data-93e978daf432](https://medium.com/hasty-ai/uncovering-hidden-biases-in-your-data-93e978daf432) The flywheel comes up at the end of the text.

As said in the beginning, this is only v0.1 and we have much more things planned for the future.",MachineLearning
n9w6oh,1620737147.0,[D] (Paper Overview) Barlow Twins: Self-Supervised Learning via Redundancy Reduction,"

**Video**

[https://youtu.be/fNyyKJ22P8Y](https://youtu.be/fNyyKJ22P8Y)

**Paper**

[https://arxiv.org/abs/2103.03230](https://arxiv.org/abs/2103.03230)

Code

[https://github.com/facebookresearch/barlowtwins](https://github.com/facebookresearch/barlowtwins)

**Abstract**

 Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn representations which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids such collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the representation vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. It allows the use of very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.",MachineLearning
o72qw9,1624547164.0,[Q] Mann Whitney U corrected for ties?,"Hi guys!

I’m currently working on my thesis’ result section and I planned to use an independent t test for one of my hypotheses. Unfortunately, the data wasn’t normale distributed which brought me to the Mann Whitney U test. I never heard or worked with this test, but I think I get most of it now.

I reported the p value and put ‘corrected for ties’ next to it. In the feedback my supervisor gave me she commented ‘what does this mean?’ on the ‘corrected for ties’ part. I don’t know if she is asking herself/ me this question or that I have to elaborate this in the result section, but that is something for me to figure out later.

My question for you is: what does it mean?

Since I have to defend my thesis at the end of next month and I think it would come in handy if I could proper explain what the test does, why it doesn’t assume normality, and what the ‘corrected for ties’ means.

Could someone give me an ELI5 of this test? Or at least an ELI5 about the ‘corrected for ties’ part?

Thank you in advance!",statistics
o72qrc,1624547151.0,[EDUCATION] P-Hacking Your Way To Fame | Part 1 of 6 - What is P-Hacking?,"Here's a new video (by me) about p-hacking in statistics. I'd love your feedback.

&#x200B;

http://jeffgalak.com/datademystified/index.php/2021/06/24/p-hacking-your-way-to-fame-part-1-of-6-what-is-p-hacking/",statistics
o72qa3,1624547115.0,[Q] Pearson's r in psych,Does anyone have an objective interpretation of correlation coefficients for psych/social science? The only citation I can track down is the textbook by Dancey and Ready and I'd like a non-textbook source.,statistics
o72kie,1624546663.0,[Q] Where to get room rent data?,"So I'm looking for historical data on rents for renting rooms in northwestern Europe, mainly the UK, Netherlands, Germany, Belgium and France. I will generate insights for students based on this data.

I have tried to find it in Eurostat, Statista and CBS but couldn't find anything on rented rooms.

Rent/m^2 (yearly or monthly) could be a suitable metric or just average room rent as most likely I could look at the average room size to get to my preferred metric. As long as I have some data to work with.

(studio's/apartaments rents would also be a possibility but not preferred)

I hope somebody knows where to find this!",statistics
o729sk,1624545729.0,"[Q] Research Paper - Dissertation - ""Stock Price Reactions to Climate Change Protests"".","Hi All,

I'm studying my Masters degree currently, and am undertaking my dissertation on stock price reactions to climate change protests. (specifically stock price reactions for firms regarded as 'non-environmentally friendly')

I've done a literature review, and found papers on protests from hong kong affecting the financial markets useful. (one of the problems I've found is that climate change protests don't happen sporadically - there is no 'shock', due to the planning undertaken beforehand, which affects the event window approach as a precise date cannot be used)

Originally I was going to do an event study to regress the data of ESG stocks against normal benchmark (FTSE or S&P), but my literature review has made me question that methodology.

Would anyone like to weigh in on which method they would recommend to regress the data?

(I am still deciding to do one event or use a range of events from different countries and pulling the results together.)

I find statistics fascinating and before collecting my data wanted to see if anyone had anything to add regarding the methodology in order to make this a great project and paper.

Kind Regards,

james6006",statistics
o71xeq,1624544674.0,[Q] Do any of you actually regret not doing a PhD in Statistics/Data Science,"Hello, my goals are to work as a data scientist in industry. At this point I’m just kind of unsure if I should pursue a PhD or not. My goals are to just be a data scientist in the industry. For any of you in industry, and I’m sure this is also based on the specific industry type, do you guys regret not getting a PhD in statistics for your job? My plan is to get an MS in stats and work, but for any of you, did you regret not finishing through after your MS? If you do have regrets what are they, and how had the MS limited you if any?",statistics
o718js,1624542499.0,[Q] Multiple comparison: Find statistical significance from list of p-values,"Suppose I performed some experiments (as part of one investigation) and extracted one p-value from each of them, I now have a list of p-values. I would like to find the number of experiments in the list that are statistically significant (where null-hypothesis can be rejected). If alpha = 0.05, can I assume that 5% of the experiments will yield a false positive and then subtract this 5% from the number of experiments where p-value is less than alpha?

Or do I need to do Bonferroni correction or Holm-Sidak correction? What if instead of the number of statistically significant experiments, I need to know which experiments are statistically significant?",statistics
o70ada,1624539259.0,[Q] What sort of distribution will help me with my problem?,Not sure if links are allowed but I was playing [this game (warning: its about matching the crime to mugshot](http://www.thesmokinggun.com/time-waster/match-arrestee-their-alleged-crime-124530) and was wondering what kind of distribution will allow me to calculate the probability of getting a certain number (0-5) guesses correct. Its kind of like a binomial distribution but without replacement i guess. Any help will be greatly appreciated,statistics
o6pviw,1624495206.0,[C] BS in Statistics,"I recently graduated with a BS in Statistics. I’m curious if anyone here has the same degree and if so, what do you do now?",statistics
o6plhb,1624494219.0,[D] measure the similarity between two datasets,"Suppose you have two datasets: each dataset contains continuous variables (x, y, z) and 1000 rows. Let's say the first dataset is from a hospital in California and the second dataset is from a hospital in New York.

Are there any common ways to measure how ""similar"" the two datasets are?

Thanks",statistics
o6pizx,1624493965.0,[Q] need suggestion on distribution selection,"Given that X is a IID RV that are positive real numbers (0,1,2,3.......)
, where
P(X=0) = 0.7
P(X=1) = 0.1
P(X=2) = 0.05
....
and E(X) = 2.7

(no more information was given)

what discrete distribution would you fit this data set with?",statistics
o6pa7t,1624493080.0,[E] 4+1 ms stats summer after Bachelors,I am an undergrad doing math/Econ and trying to get an accelerated ms in stats. This summer I am at an REU and loving the research world. Next year I will graduate with my BA and I want advice on what to do next summer. Are there similar programs for recent grads who plan to return to school after? I am also interested in tech industry internships to learn about that world but research work is preferred.,statistics
o6ni1s,1624486998.0,[Q] methodology check (psm),"Looking to see what is missing from my methodology idea .
I am trying to develop a plan to take a look at some healthcare claims data. I have two types of physicians in my data. type A and type B. I plan on propensity scoring their patients and then either matching or weighing the patients so that I can compare a plethora of outcomes between type A and type B physicians . This would be done over the same time period of claims .

If I just do statistical tests on the outcomes my understanding is that what I am saying is that there is some type of difference between group A snd group B physicians that is not occurring by chance . If I want to quantify the impact of being in one of these groups I would need to take the analysis further to something like difference in diff ?

I have some outcomes that span across time too and one of the questions I am trying to answer if over time this outcome is different between the two groups and within the subgroups of each group . Could I just use an Anova to answer this after propensity matching ?
I have a very huge ever evolving list of outcomes and question types which honestly confuses me.

Any help appreciated . Thank you",statistics
o6kos3,1624478366.0,[Q] How does R's coxph function handle gaps between time spans?,"Hello all,

I am working on survival data with multiple observations per participant. I'm curious how the coxph function handles situations where for example a participant has a gap between successive (start, stop\] intervals. A participant may be a no-show for a period of time and suddenly re-appear at a follow-up visit. Participant 2 is an example of this where there is a 10-unit time gap between successive time spans. The 'event' and 'x' columns are there for illustrative purposes.

&#x200B;

|id|start|stop|event|x|
|:-|:-|:-|:-|:-|
|1|0|5|0|3|
|1|5|18|0|4|
|2|0|5|0|2|
|2|10|18|1|1|

Will participant 2 be included in the risk set for events occurring during the span from (5, 10\] ? If so, is there an argument I need to set to let R know this?

Thank you reading my post.",statistics
o6k13a,1624476454.0,"[Q] Confusion about FWER and Bonferroni correction when tests are not ""independent""","So as someone not really as familiar with frequentist stats, I have a question about the statement that a Bonferroni correction is appropriate in the context of posing multiple *independent* hypotheses, in contrast to [statements](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6082) like:

>One of the most widespread of these misunderstandings is that the method would be based on an assumption of independence between p-values. This misunderstanding comes from a frequently used, but deficient motivation for Bonferroni, saying that the probability of making a false rejection if all m0 p-values of true hypotheses are independent, and we perform each test at level... By this reasoning, Bonferroni seems like a method that only provides approximate FWER control and that requires an assumption of independence for its validity. In fact, the method of Bonferroni provides exact FWER control under any dependence structure of the p-values.

The context of my problem involves linkage-disequilibrium score regression, and specifically estimating the extent to which heritability for a collection of non-independent features / phenotypes is conditionally enriched across overlapping (so not independent) sets of loci surrounding overlapping sets of genes. The genetical non-independence of traits can be seen in this [genetic correlation matrix](https://i.imgur.com/wq7p1gG.png) I estimated. The non-independence of gene sets can be seen in a jaccard similarity matrix I estimated but don't have on hand -- but it wasn't too bad, on the order of ~0.1-0.2.

The usual approach here is bonferroni correction, since the gwas used tend to have high n, and so are pretty highly powered seeing as at the end of the day there probably aren't any true nulls. But this seems like the exact context where the bonferroni would not yield the desired FWER -- where it might be ""overly conservative"" -- if the former wishy-washy statements were the case.

To explore this problem, I wrote a small [R script](https://pastebin.com/8S1AwpTT) where I simulated multivariate normal data according to some correlation matrix (sampled from a flat LKJ), estimated sample correlations among that data, and computed the corresponding p-values. I then estimated regression coefficients between these samples x and independently generated data (i.e. from y = a + 0*x + e), and then computed the corresponding p-values. After bonferroni correction, the FWER was at the desired value. Which is unsurprising, given that a pearson correlation is iirc just the ols estimate of the regression coefficient when both predictor and outcome have been rescaled to unit variance. This would also apply if the correlation structure / non-independence were in y, given the symmetry between y~x and x~y.

Neither of these situations quite maps to my original problem, where it's not so much the individuals in the GWAS that covary (though they do, given population structure), but rather the coefficients themselves, given pleiotropic effects. But then I'm not quite sure how to simulate that, since the whole point is to simulate from a null / nil model where the true value of those coefficients is set to 0.

Otherwise, my vague intuition about this non-independence multiple testing correction thing is that the whole independence / non-independence idea applies to the sampling distribution of model parameters across different tests? Maybe? But I'm both unsure of how to specify that sampling distribution, and also unsure of how exactly to accommodate it in hypothesis testing.

Any help or insight would be appreciated!

PS, I'm actually not 100% sure how what sort of hierarchical model would appropriately regularize estimates of pairwise correlations in the Bayesian case. You could maybe use an LKJ, or its implied marginal distribution (r_ij + 1) / 2 ~ Beta(η−1+K/2,η−1+K/2) w/ η to tune, but that would center things on r_ij = 0. Using a plain beta would get you off that, but then your estimate of the matrix as a whole would not respect any sort of PSD constraint. Any thoughts there would also be nice!",statistics
o6j4ew,1624473633.0,[Q] How do I calculate P significance of a simple regression plot.,"I need to figure out if my regression plots are significant or not. The issue is that since I am plotting regressions over such a large amount of plots, I plotted the regression manually in python to iterate over each plot. I successfully plotted a regression for each set of data correctly, however I am not generating a stats summary or returning a P value. Is there a way to manually calculate the significance of a regression line? Any help is greatly appreciated. I used polyfit() from numpy to calculate and plot my simple linear regressions.",statistics
o6ie3u,1624471453.0,[Q] Question about Linear Mixed Models for Longitudinal Analysis,"From my understanding, using mixed effect models is one way to look at longitudinal data.

Let's say that I wanted to look at student's final exam score vs the amount of time they spent studying over months. So I repeatedly measured their time studying and then I looked at their final exam score.

Is the mixed effect model appropriate in this case? I'm not sure if the dependent variable can just be one point.",statistics
o6idah,1624471385.0,[Q]Test for LARGE dataset?,"
I have an extremely large dataset of hourly temperature over almost two years. The temperature is for the differences under solar panels, and are under the same panel but in different areas. I want to see if there are significant differences in the temperature between these solar panel areas. Is the Willcoxon signed rank test an appropriate test? My data is generally not normally distributed. There might be a month or two where it’s close to normal but on a monthly basis it’s extremely skewed right.",statistics
o6hhl8,1624468796.0,[Q] Help with Poisson distribution,"I am really stuck with a statistic approach. I have data of outgoing calls from a month with the hour of the day and day it was made.

What I first did is groupby hour of the day and count the number of calls for the entire month, and I noticed it has the shape of a Possion distribution (left skewed). What I want to do is to get the pdf so I can now the probability of finding anyone doing a call at a given hour of the day.

Yet I am really confused because of...

1) Time unit, I am graphing the entire month and I would just like to calculate the probability of one day of the month, so should I take the mean of calls at each day and hour, and then fit the distribution?

2) Besides count an event like how many cars with pass in 1 hour. I would like to count the hour passed in one day. For example, X=1, means an hour has passed from 12pm and this is the probability of finding someone doing a call. Is that possible?

I would really appreciate your help or any reference. I feel like I am overthinking it",statistics
o6ggct,1624466053.0,[S] Mplus Question: How to get more decimal places,"I'm trying to figure out a way to get more decimal points for my estimated correlation matrix for the latent variables. I'm using TECH4 to call up the results, but I need 10 decimal places, not the default 3. Any help? Thanks so much in advance!

               ESTIMATED CORRELATION MATRIX FOR THE LATENT VARIABLES
                  IN            DJ            WE            PJ            DJCPJC
                  ________      ________      ________      ________      ________
     IN             1.000
     DJ             0.622         1.000
     WE             0.247         0.061         1.000
     PJ             0.643         0.400         0.262         1.000
     DJCPJC        -0.010        -0.016         0.135        -0.006         1.000",statistics
o6fkxv,1624463455.0,"[Q] Let X ~ Normal(0, 4). Is 4 the standard deviation? The variance? Or (god forbid) the precision?","Likewise, we summarize random variable Y as 3±0.4. Does this interval represent the mean ± 1 standard deviation? A standard error of the mean? Some Z% confidence interval? Nobody can say -- certainly not the text.

(edit: and by text I mean as it exists in some applied context, not in a textbook or methods paper)

What other cases of notational ambiguity do you often see? How often do you reckon the above described cases map to each of the options presented, or perhaps to other options?",statistics
o6epls,1624460875.0,[Q] Controlling for confounding of unmeasured with a correlated but non-causal covariate?,"Howdy,

&#x200B;

TL;DR:

I have an outcome variable `A` and a continuous treatment variable `S` (observational, not experimental). Variable `A` has a set of potential confounders `U` that I have not measured. I also have variable `B`, which has a similar relationship to confounders `U` as variable `A` and where `S` == 0. Is it plausible to use variable `B` to control for confounding by `U` on variable `A` and isolate the effect of treatment variable `S`? I think a causal DAG would look something like this:

`S`  \-> `A`  <- `U` \-> `B`

&#x200B;

&#x200B;

Full context:

I'm working on a marketing measurement model to estimate ROI for ad spend (something akin to a Media Mix Model). The marketplace is entirely digital and we only use digital ads. We can generally tell in aggregate how much we've spent on certain kinds of ads (Video, Display, etc) and how many times those ads have been viewed each day, as well as if someone who viewed an ad made a purchase and the revenue from that purchase. We aren't able to tell specifically which individuals saw the ads and what their outcome was - only aggregate, daily numbers. We also have (in aggregate) the total sales for the marketplace. By subtracting the sales with at least one ad impression from the total sales, I can separate the sales into two streams:

&#x200B;

* Ad-attributable sales (customer saw at least one ad prior to purchase). These sales are possibly caused by the ad impression, but it could also be that we showed an ad to someone who would have purchased anyways.
* Completely organic sales (customer definitely didn't see any ads prior to purchase). These sales are definitely not caused by an ad impression as we know the customers didn't have any ad impressions.

&#x200B;

A Media Mix Model would generally be fit as a log-log linear model with the ad spend in different buckets as the covariates as well as indicators about seasonality, economy, etc. with the total sales as the outcome to reason about the causal effect of ad spend on sales. This high-level approach is used because it often includes ad channels such as radio, TV, etc. where you can't really know who saw the ad or if they purchased or not. In my case, while I can't say specifically that customer A saw this ad and then purchased, I can say that 1000 customers saw this ad and then 50 of them purchased.

&#x200B;

We can follow the media-mix approach and regress the ad spend against the attributable sales to get some kind of measure of ROI, but without controlling for seasonality, economic factors, etc. the ROI will be overstated and further from the causal truth. However, sourcing the data for the potential confounders (particularly economic) is time consuming and adds a lot of complexity to the model and project.

&#x200B;

I am wondering - since I have the ad-attributable sales AND the completely organic sales - if it would be reasonable to use the completely organic sales to control for all of the above. The completely organic sales would also be affected by seasonality, economic factors, promotions, etc. in a similar way to the ad-attributable sales, without the obvious potential influence of the ads.

&#x200B;

Thoughts?",statistics
o6d99c,1624456390.0,[Q] Appropriate data types for PCA,"Hello,

This is related to a previous question ([link](https://www.reddit.com/r/statistics/comments/o5tmt1/q_pca_principle_components_what_are_they_and_when/?utm_source=share&utm_medium=web2x&context=3)), but is covering different points so I am asking it separately.  Also, I'll be posting in both r/bioinformatics and r/statistics to get as wide an audience as possible.
 Hope that's OK (and hope the below makes sense!).

As I understand, PCA is classically applied to continuous data.  I am looking to apply it in two separate analyses.

One is looking at binary data, representing the presence/absence of various genomic structures within separate genomic stretches.  PCA would ideally be applied to compare the different genomic stretches according to the presence/absence of the genomic structures (e.g. stretch 1 vs stretch 2 vs stretch 3).

The other is looking at discrete numerical data, representing the aggregate counts of the genomic structures mentioned above within separate groups of genomic stretches.  PCA would ideally be used to compare groups of genomic stretches (e.g. group of stretches 1, 2 and 3 vs group of stretches 4, 5 and 6 vs group of stretches 7, 8 and 9).

I've found a paper that discusses PCA applied to binary data ( [Principal component analysis of binary genomics data - PubMed (nih.gov)](https://pubmed.ncbi.nlm.nih.gov/30657888/) ).  Can anyone tell me if it is appropriate to apply classical PCA to discrete numerical data (integer frequencies of structures) rather than continuous numerical data?  As I understand, PCA is commonly applied to discrete numerical data for differential gene expression in RNA-seq - you are looking at integer transcript counts for a specific gene ( [StatQuest: Principal Component Analysis (PCA), Step-by-Step - YouTube](https://www.youtube.com/watch?v=FgakZw6K1QQ&list=PLblh5JKOoLUJo2Q6xK4tZElbIvAACEykp&index=5) ) which is analogous to looking at the integer aggregate counts for separate structures in a groups of stretches (I think?).  So I'm hoping this would be fine...

Thanks!

A baby bioinformatician",statistics
o6bcoo,1624449612.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
o69u21,1624442824.0,"I was flipping a coin and got tails 7 times in a row, how likely is this? [Question]","Im not sure if this the right subreddit to ask, but this has been eating me up lately! One day i was deciding what i wanted for dinner, one was something i didnt like but shouldn't have. The other i liked but is unhealthy. So i decided to flip a coin when it said to eat the thing i didnt like, out of frustration, i flipped again and again, and one more for good measure, until i felt like the coin was rigged for some reason, and got tails THREE more times until i finaly got heads. This cant be very likely at all right? Am i crazy? Does this mean im going to die or the world will end!? Anyone... Please... Help me, this not a joke or exaggeration.",statistics
o69hmx,1624441101.0,[Question] 1461 poem combinations,"Hello,

I have a rather special question:

I would like to ""write"" a set of sonnets (a poem with 14 sentences) that would have as many poems as there are days in four years (so 1461 poems).

Each poem would be a unique combination taken from a group of sentences.

The first line would be chosen from X sentences, the second from Y other sentences... Some lines might not change.

In short, I would like to know how many sentences I would have to write (the minimum possible) to reach the 1461 poems.

I hope my question is clear (English is not my first language)

(Sorry I forgot about the Flair)

Thank you in advance for your help!",statistics
o62dl2,1624411465.0,Asynchronous time series [Q],"I have two time series, A and B. B = A + C. A is a random walk, and C is an Ornstein-Uhlenbeck process. Im trying to estimate C. The challenge is that my measurements of A and B alternate, so I can never observe A and B simultaneously.

Ie I see:
A1,B2, A3,B4, etc. I've considered some kind of kalman approach to estimate C, but that requires some assumptions on the relative variances of A and C in each time step, I think.  Are there some approaches you'd recommend to dealing with this? Thanks!",statistics
o606qs,1624404498.0,[Question] What R^2 values are typical in Engineering Design of Experiments?,"Developing a model of a physical process (think how a material property changes with respect to temperature, time, etc.), and I'm trying to find what range of R^2 values I should expect to be reasonable for this field. I know alone it's not a good indication of fit, so I'm looking at S too, but I don't even have a gauge for what a reasonable R^2 value looks like. 0.4? 0.8?

Edit: brain fart moment. Changed to proper values",statistics
o5z8gx,1624401561.0,[Q] Prediction variance using GPR,"Hello,
In GPR framework, one can get at an unobserved point not just the value of prediction but also the variance. One knows that this variance only depends on the position of the observations, the point where we want to get the prediction and the kernel. Here is my question: if you have 2 different kernels, you can get two very different variances. So, can you really use this  information?",statistics
o5yeuk,1624399126.0,"[D] has anyone here studied ""association rule mining"" beyond the classic ""grocery store example""?","https://en.m.wikipedia.org/wiki/Association_rule_learning

Has anyone ever looked into more advanced applications of ""association rules mining""? ""Association rules"" can also be used for prediction/classification purposes (e.g. https://rdrr.io/cran/arulesCBA/man/CBA.html) - this allows you to obtain a fully interpertable algorithm that can provides ""a set of conditions"" for making predictions. However, these rules are usually not very ""powerful"".

Does anyone know if there are more recent spinoffs of this algorithm, perhaps where a neural network or ensemble models can be used to ""learn"" these rules?

Or in general, does anyone know any machine learning based algorithms that provide ""rules""?

Thanks",statistics
o5xvu4,1624397630.0,[Q] Question regarding the use of dummy variables in regression models,"In order to incorporate categorical variables into a regression model, these variables need to be recoded into a new set of dichotomous variables. However, does the same apply for ordinal variables. For example, I have a variable which measures the highest level of education for each participant. The values range from 0 (indicating lowest possible level of education) to 5 (indicating highest possible level of education). Should these values still be recoded into dummy variables?",statistics
o5wtcm,1624394622.0,[E] MS in Statistical finance or MS in Data Science for quantitative finance?,I am currently a rising senior majoring in math with a CS minor.,statistics
o5tmt1,1624386106.0,[Q] PCA Principle Components - What are they and when are they useful?,"Hello,

Please let me know if the below makes no sense!

I'm trying to get my head around PCA Principle Components (PCs). I'd like to know how PCs work and how to predict whether PCA will be appropriate for a dataset. I've had a look at a source that has a nice description of PCs (quoted at the bottom) and a graphic (linked in main text).

From the source's graphic I can understand how to get the PCA for a graph of two variables - it is just the purple line. A link to the graphic is here [https://builtin.com/sites/default/files/inline-images/Principal%20Component%20Analysis%20second%20principal.gif](https://builtin.com/sites/default/files/inline-images/Principal%20Component%20Analysis%20second%20principal.gif).

I'm now trying to visualise how this graphic would translate to having more variables (e.g. 3). If I had a three-axis graph (1 axis per variable, axes are x/y/z), would the first PC-axis represent maximal variance for all three variables (so like the plot in the graphic, but with a z-axis, and the red lines in the graphic being applied in 3D space)? And so the first PC-axis represents the axis where maximal variance is achieved across every x/y/z axis for the data set, and then the next PC-axis is the orthogonal axis to the first PC-axis (whilst still being in the x/y/z axis 3D plot), with Nx PC-axis being found where N is the number of variables.

If that's correct, then I would expect a dataset whose points are not correlating in a specific direction (i.e. a cloud of points) to have large degrees of variance along multiple axis. Is this the kind of data that would result in a bad scree plot, where the first couple of PCs don't capture all of the variance? Could you also get this if you have a cloud of weakly correlated points with respect to one of the three variables (but the remining two show correlation)?

&#x200B;

>Geometrically speaking, principal components represent the directions of the data that explain a **maximal amount of variance**, that is to say, the lines that capture most information of the data. The relationship between variance and information here, is that, the larger the variance carried by a line, the larger the dispersion of the data points along it, and the larger the dispersion along a line, the more the information it has. To put all this simply, just think of principal components as new axes that provide the best angle to see and evaluate the data, so that the differences between the observations are better visible.

Source: [A Step-by-Step Explanation of Principal Component Analysis (PCA) | Built In](https://builtin.com/data-science/step-step-explanation-principal-component-analysis)

&#x200B;

Edit - this has nice visualisations  [Principal Components Analysis (okstate.edu)](http://ordination.okstate.edu/PCA.htm) ",statistics
o5sobw,1624383537.0,"[Q] Those who did graduate level stats research in Time Series Forecasting (PhD/MS), how much forecasting is used in your job?","Hello, was wondering for those of you who had studied graduate level time series in an MS or PhD program how much you are able to use these methods in your day to day work in industry. Is your role in a company as a “data scientist” or whatever job title it is to just be a forecaster? If you do research in Time series forecasting does your job in industry make you just assigned to forecasting tasks? Or are you expected to do other things to? How much of your day to day work is forecasting tasks in industry? And do you think some jobs in industry have more forecasting needs than others?",statistics
o5s1jq,1624381796.0,[Question] Free Graduate Student Courses,"Hey everyone,

I'm a graduate student working on my master's in political science. I'm in the middle of my data collection, but I've never taken a stats class before and I have no idea how to analyze my data. I know I'll probably need to use R or maybe I can get away with Excel (right now I'm using thematic coding to look for trends in documents related to coastal management), but I have no idea where to begin. I looked at MIT's Analytics Edge course, but it's a huge time sink (\~15 hours a week). I'm not sure what I need, but I doubt my analysis will require a mastery of stats or R, just some basic applied knowledge. However, I could be totally wrong. Ideally, I'd like to find a relatively quick (and free) online course that I could finish by the end of the summer.

Can anyone point me in the right direction? Thanks in advance!!",statistics
o5qciw,1624377263.0,[Q] Question about this chi-square test result.," Hi,

My friend is in an entry level statistics course, and they had a chi-square question on the exam. Usually when someone comes to me saying ""I think the professor is wrong here"" I take it with a grain of salt, but I actually think the professor is wrong about this. I just want to make sure before I tell her to argue the point. [Here is the question on the exam](https://imgur.com/a/DEB3hf7) and the work she did (this has already been submitted and graded, as you can see from the professors note on the first picture).

The professor says that this chi-square should be 3.76. However, my friend says it should be 2.74. She says that the difference in the answer comes from the fact that the professor gets the ""expected number"" of people in each cell by simply dividing the row totals by 2. So, the expected number of people over 40 who like chocolate would be 90/2 in the professors version. I think this clearly isn't right.",statistics
o5opt7,1624372904.0,[Q] Reporting Lin's Concordance Coffiecent APA-style?,"Does anyone know how to report Lin's Concordance Coffiecient in APA style?

Sample CCC() output:

    > CCC(x, y, ci = ""z-transform"", conf.level = 0.95)
    $rho.c
            est     lwr.ci    upr.ci
    1 0.2795453 -0.1218944 0.6023843
    $s.shift
    [1] 1.213954
    $l.shift
    [1] -0.2221029
    $C.b
    [1] 0.9582959
    $blalt
       mean delta
    1  28.0     2
    2  28.5     1
    3  24.5     1
    4  28.5     3
    5  25.5     5
    6  24.0     4
    7  31.5     3
    8  26.0     6
    9  25.5     3
    10 25.0   -10
    11 25.0     2
    12 21.5     9
    13 27.5    -1
    14 27.0     0
    15 26.0    -6
    16 28.0     2
    17 29.0    -6
    18 30.5    -3
    19 20.0     0
    20 30.5     1
    21 26.0     0
    22 28.5     1
    23 28.0     0",statistics
o5n810,1624368664.0,[Q] confidence interval question,"Hi. I am an economy grad who is trying to get around this confidence interval problem. I am self taught so I need someone to tell me if what I did is correct, thank you! Sorry if my explenation is kinda messy, I lack the english terminology to express the problem properly.


A sample of 20 people watches a certain TV show with an average time of 180 minutes and a deviance equal to 150. Find the confidence interval for the average watching time of the population with a 1% error
I have the deviance which means I have to calculate the variance equal to DEV/(n-1) = 150/19 = 7.89


That means the sample X follows a normal distribution with E(X)=180 and VAR(X)=7.89


The exercise wants an interval which implies an 1% error.
The formlula is  (X-Z(a/2)\*sqrt(v(X)/n), X+Z(a/2)\*sqrt(v(X)/n))


Given that a/2 is 0.005, I have to find on the table the Z value which corresponds to 0.995 which is 2.58


So according to the formula the interval is (179,638, 180.362)
Is that correct?


Thanks",statistics
o5kw08,1624361384.0,[Q] How to analyze a survey question where respondents rank 5 out of 10?,"I am currently trying to figure out how to evaluate a question from a survey I conducted for my thesis, but I am unsure of how to do it and I am grateful for every hint (disclaimer: I am not very good with statistics so far, I am still learning)

The respondents were presented with a selection of up to 12 value propositions and were asked to select their top 5 and rank them. Some respondents picked and ranked even more.

The problem I encountered is the following: I tried to just calculate the weighted average, but in some instances, a value proposition has been picked only once, but as no. 1 and now it looks like this value proposition is the most important when in fact there are other that have been picked multiple times, for instance 3 times as no. 1, twice as no. 3 and once as no. 5 etc.. Therefore, the average appears to be lower, when actually this value proposition should be more important. How do I best find out, which value proposition is the most important now?

I hope it was somewhat comprehensible what I tried to explain! I'm forever grateful for every possible solution on how to tackle this issue.

Lola

&#x200B;

Edit: Thank you guys so much for all the suggestions! I am slightly overwhelmed but working my way through all of them and figuring out what would be the best approach for my case! <3",statistics
o5jzlm,1624358204.0,[Q] Need help with sampling design for forest survey!,"

Hey everyone,

Long-time lurker, first-time post. Love y'all's work and I was hoping I could get some advice.

My MSc thesis is partially funded by an environmental consulting group here in Italy. I am trying to establish cheap, cost-effective, and simple methods for measuring and reporting ecosystem services. Part of this includes measuring for carbon sequestration and biodiversity, and I have chosen to analyze forest structure - tree height, diameter at breast height, the volume of deadwood, etc - as a proxy for biodiversity. My hope is that the same set of variables can help explain both carbon storage and biodiversity (forest complexity). Very simply put, the mean values will provide average carbon storage/sequestration data and the variance will provide data about forest complexity. This is all backed up by the literature.

So with that brief intro out of the way, I am hoping someone can help me come up with a sampling design that's feasible for a large group of forest smallholders distributed across thousands of kilometers and covering several different forest types. I am looking to balance the cost of the surveys with reliable, statistically sound data. Here are the basics:

THE POPULATION: \~2,500 hectares of forest land spread over several Italian regions and multiple forest types (mountain conifer, beech-dominant, riparian, lowland/plain, and Mediterranean). The exact area of each forest unit and the forest type is already known and mapped in QGIS. The smallholder group will be treated as a single large, dispersed forest.

SAMPLING DESIGN (PROPOSAL and QUESTIONS):

I think a proportionate stratified random sampling design will help me break down the variance between forest types and require fewer sample plots overall (I hope). I am thinking to stratify based on two criteria:

1. Forest type (conifer, beech, lowland oak/hornbeam, riparian, coastal, etc) and
2. The age of the forest (recently planted (<10 years), post-intervention (>10 years old), and old-growth (>300 years))

The second criteria is the most important - the question is: Can I demonstrate that management interventions have increased the complexity (variance) of the forest from a simplified structure (recently planted) toward a more complex structure (old-growth)?

I am trying to decide between 1,000 m2 sample plots (circular plots with a radius of 17.84m) or 1 hectare (50 x 20m) rectangular units. The smaller sample plots will be much easier to carry out in a work day (reducing travel costs and the need for multiple visits to the same site) but I don't know if I'm creating problems for myself by needing many more sample plots since they are smaller.

So here's where I'm really stuck: How to determine the sampling intensity and the number of plots required.

\- Should I simply set a threshold (5%) and then sample proportionally from each stratum? Even 5% would be a tremendous amount of work. Can someone explain why not 1%?

\- If I can estimate the variance/stdev and mean from National Forest Inventory data, should I plug in these numbers with an allowable error margin and confidence interval to determine the number of plots?

\- What should I set as the error margin/CI to balance accuracy/precision with feasibility? I can't exactly ask for thousands of dollars to carry out the survey and I only have a couple of months to gather the data. Is 90% enough? What about 50%? I can't find clear guidance on this, and I think it's more important that I can justify the design based on time/budget constraints than meet certain thresholds. It needs to be sound but it's also not a funded PhD to be published in a peer-reviewed paper.

I hope my questions make sense. Basically, I need to come up with a sampling design for a large and diverse forest. I am struggling to find the acceptable margin of error that reduces costs while providing sound data.

Thank you all so much in advance!",statistics
o5iouz,1624352968.0,[Q] Chi-Squared Test with Limited Variation,"I am doing a Pearson’s Chi-Squared Test to test to see whether or not the upload speeds of the new router compared to my old router. However, the issue is that there is usually limited variation in cases like this, because data speeds are also determinant on things like your internet package and etc. I am getting an average of 21.5 Mbps on my old router but my observed values are hovering around 25.8 Mbps, but the probability is like 20%. Is there any way to augment the test to account for situations that may have less variation than others? Thank you.",statistics
o5ibgs,1624351320.0,[Q] Calculate the probability of an individual having sex through Tinder?,"Hi guys,

I want to prove to my friend statistically he has a low probability of having sex via tinder. I have the amount of times he’s had sex through tinder, the amount of times he’s had sex overall and the amount of times he’s got rejected through tinder.

What’s the best method for calculating this with the limited data?

I know it’s a strange one, thanks!",statistics
o5ib3k,1624351278.0,[Q] Textbook recommendation for Fundamentals of Statistics on EdX,"I am busy with [one of the earlier courses](https://www.edx.org/course/probability-the-science-of-uncertainty-and-data) at the moment and am going to buy [the textbook](https://www.amazon.com/gp/product/188652923X?psc=1)  as its giving me a hard time and I want to understand the material more  fully. The amount of work required caught me a little off guard, it  definitely puts the MOOCs that I'm used to to shame.

From the reviews it seems the [stats course](https://www.edx.org/course/fundamentals-of-statistics)  will be even more work so I also want to get a textbook to follow along  with it when I get there. I couldn't find any universal recommendations  by searching this sub, they are all context sensitive (or just random  for all I know). So, can anyone make any recommendations for a book that  would be a good companion to the course?

My  background consists of an electrical engineering degree completed  around four years ago and a few months of refreshing my calculus and  linear algebra knowledge.",statistics
o5fdzw,1624339905.0,[Q] Proof of Working-Hotelling Procedure Confidence Coefficient,I tried looking online for a proof that the Working-Hotelling procedure captures the entire regression line with the specified confidence coefficient but couldn't find anything. Is there a relatively straightforward proof of this?,statistics
o5ai5q,1624323884.0,[Q] Assesing probabilty of an individual sample having been clustered incorrectly for further testing,"I have a truth set for some samples that have been clustered into discrete ordinal classes based on a single continous variable, where the larger the indipendant variable the higher the class number will be. So 0.4 might go into class 1, 0.9 into class 2, 1.5 into class 3, 2.6 into class 4 for example.

&#x200B;

I know that there are samples that are being misclassified, and that even a 'perfect' model would misclassify some samples, as, for example,  a sample which should be classed as 3 has a lower indipendant variable associated with it than even the highest indipendant variable associated with with class 2 samples.


All samples that I am less than 99% (or other cut-off) of having been clustered correctly, I will send for further varification using other methods. I want to identify which samples that applies to. I want to minimize the number of samples that I have to test with other methods.

I am given, by software I am using, the classification and the indipendant variable. There are batch effects, so I am currently unsure if pooling data for multiple batches will work. So I am not sure if I can use my truth set to mix-in with the new batches for anaylsis, or if I should perhaps include some samples that I have ground truth on into each batch.

&#x200B;

I am lacking the correct terminology to find literature (books/papers) discussing assesing the confidence of the classification of an individual sample. I know Bayes classifiers do give some information, but I don't think is really helpful with only one variable. Also the prior distribution in general is heavily weighted towards class 2, but individual matches may vary from that.


What I would ideally want is some way of telling if a datapoint is ""inside the margin"" in an SVM and having that margin defined in a way that 99% of calls outside the margin are True positive.",statistics
o59zs1,1624322313.0,"[Question] When one can claim a variable is a ""risk factor""?","Suppose we have conducted a study and it turns out variable A, like being high on trait Neuroticism predicts a specific outcome like Depression, but can we claim A is a risk factor for B? Or do we need a causal framework/design to claim such a thing?",statistics
o59qhl,1624321512.0,Best Way to Normalize Data [Q],"Hello,

I'm a new data analyst and wanted some insight on a particular problem. I have a dataset that has the sum of ""hits"" (related to businesses) in each county in the US on an hourly/daily/weekly/etc. basis. Some counties are more populated than others, for instance somewhere like LA county will naturally have a lot more hits than in some random county in Kansas. I need to normalize this data. What's the best way to normalize this sort of data/how can I tell which way is best? I've researched various transformations but figured someone here has encountered this sort of problem before and may be able to steer me a particular way. I've read about min-max, z-score, creating some sort of index by dividing by the population and multiplying, etc.",statistics
o591tc,1624319444.0,[D] Urgent! Can someone please review my statistical methodology?,"I just realized that I might have made a big mistake in applying a certain type of statistical model and desperately trying to figure out a way to fix this mistake - or determine if I made this mistake. Can someone please review the following?

I am working with this algorithm called ""survival random forest"" (https://arxiv.org/pdf/0811.1645.pdf). This algorithm allows you to use the ""random forest"" algorithm in the survival analysis context.

The way I understand it:

1) a ""decision tree"" (in the context of survival analysis) finds ""optimal partitions"" (i.e. terminal nodes) within your data - then, a separate kaplan-meier curve (i.e. survival function) is generated for all data points in each terminal node.

(so, at this stage: if you have a new data point, the decision tree will decide which terminal node the new data point belongs to. the new point will be sent to that terminal node, and is said to have the same survival function as all other data points in that terminal node.)

2) next, many decision trees are made. ""survival random forest"" performs ""bootstrap aggregation"" (bagging) using all these trees.

3) once you have a new data point, each tree within the survival random forest estimates a survival function (again, kaplan-meier) for this new data point. then, all the survival functions for that new point are averaged, and a single survival function for that new data point is produced.

Goal: as a result, if you have 5 new points : the survival random forest can produce 5 different estimated survival functions - you can then proceed to compare these 5 different estimated survival functions to obtain some desired information (e.g. what is the median survival time for each of these 5 new observations? which of these 5 new observations will take the least time to reach a  ""survival probability"" of 0.5 ?). You can also use the C-index to quantify the performance and accuracy of the survival random forest that you create.

Can someone please tell me if my understanding and ""goal"" are logical, mathematically valid and statistically make sense? At this point, I am only interested if the methodology makes sense and my understanding of the algorithm/process is correct.

Hoping for the best - Wish me luck!
Much Appreciated,
Thanks",statistics
o56bpy,1624311607.0,[Q] Are there any other GLM other than Loglinear Model and Logistic Model?,"I'm studying for my exam of statistical models, we're covering simple and multiple linear regression models and Poisson's (loglinear) and Bernoulli's (logistic) models. I was wondering, are there any other GLMs other than these two?",statistics
o55udv,1624310327.0,[Q] Can I use Logistic Regression in a Case Control Analysis?," I'm watching a linked in learning course that says that a general rule of thumb is that a cross sectional analysis logistic regression is not appropriate if less than 10% of your rows have a 1 in the dependent variable column. In that case, you should do a case control analysis instead.

My understanding is that, in cross sectional studies, the entire subpopulation is used and those w/ the outcome are compared to those w/o the outcome. But in case control analysis, since the outcome is rare (<10%), you take all those with the outcome and only a portion of those w/o it so you get a more balanced dataset (a 1:1 up to 1:4 case to control ratio). So why can't you just do logistic regression on that dataset just like you would in a cross sectional analysis? Or is it okay to do that, you just interpret the results differently (in cross sectional, the odds ratio represents how strongly the exposure is related to the outcome, whereas in case control it represents how strongly having the outcome is related to also having the exposure)?

Just want to make sure I'm understanding things properly. This is all very confusing.",statistics
o5560z,1624308565.0,[Q] Is there a way I can run data through something that will give me many many different statistical model results?,"I'm only familiar with people able to get 1 result out from something at once (I use R, but I'll learn something else or use a different tool).

I'd want to see if I can run data through something and let it crunch numbers for a bit and give me info on all sorts of different models.",statistics
o5557z,1624308505.0,[Q] How to test if the differences of a subgroup significantly different from the total group?,"I am ashamed to admit how much time I have been searching for some answer on this. I feel like it it is simple and I am just missing something.

I am looking to compare whether the gender split in a subgroup is significantly different from the gender split of the full group (technically those not in the subgroup). For example, lets say I want to see if the HR depts for companies in a state have a gender split that is significantly different than the rest of their company.

The null hypothesis would be the gender ratio of the subgroup is the same as those not in the subgroup. Could i use an independent T-test to compare?",statistics
o5431n,1624305781.0,[Q] statistical test for comparing proportions of single population over time?,I have a sample population and am trying to compare whether the proportion of the sample who belonged to a certain weight category changed after March 2020. So I have data on the proportion of participants whose weight was <200 lbs and the proportion that was >200 lbs before March 2020 and I have the same 2 proportions post-March 2020. Which statistical test can I use for this? I was thinking about a 2 proportion z test but I wasn't sure if this was only for 2 separate populations (vs in this case I am looking at the same population just at 2 different time points). I don't know much about stats so apologies in advance if this is a silly question. Thanks!,statistics
o5288n,1624300966.0,"[Q] Is there a term for analyzing a single set of data using multiple approaches? I thought it was something like ""all possible worlds"" but haven't been able to find this.",,statistics
o51ntz,1624299457.0,"[Q] Ordering data by low, medium, high on SPSS","As part of my study I asked presented participants with a list of behaviours and asked them to tick which ones they believed to be associated with a learning disability.

I have since ran a frequency test on SPSS for each behaviour which tells me how many participants selected or did not select the behaviour.

I now want to sort the data into groups such as High frequency, medium frequency and low frequency. How can I do this without thinking of an arbitrary number as a cut off for each group?

Thank you

Edit: the data is nominal as I coded 1 = selected 2= not selected",statistics
o4yx09,1624292378.0,[Q] Adjusting probabilities based on historical data?,"I've searched the sub and found things that seem related, but nothing (that I saw, anyway&mdash;it's possible I could've missed it or searched the wrong terms) that directly addresses this.

Not being super into stats myself, I figured I'd ask to get some direct answers.

**TL;DR: while probabilities are ""fixed"" (i.e. 50/50 heads/tails for coin flips) can we adjust or weight probabilities based on historical data sampling and apply that as an assumption going forward?**

For lack of (knowing) a better term, I'll refer here to ""theoretical"" probability and ""historical"" probability. To define how I use these terms:

Theoretical probability is the probability on paper; that is to say, with a coin flip, the theoretical probability of hitting heads or tails is 50/50.

The ""historical"" probability, as I'll be using it, would be adjusted based on data. Over, let's say, 100 flips, you hit heads 80 times and tails 20 times. So, in this scenario, your historical probability of getting heads was 80% and tails 20%.

I know, statistically, no matter what the historical data shows, every individual flip has a 50% chance of being heads or tails. And, as the sample size increases, the results will trend that way; after 1,000 flips, you might see 700 heads and 300 tails, for example, and after 10,000 it might be 6,000 and 4,000.

However, is it fair to say for smaller sample sizes, that an adjusted probability can come into play, based on historical probability? Keeping with the 80/20 example for coin flips, would it be fair to say that, based on the 100 flip sample size, future flips have a weighted probability skewed from the theoretical? Something like `(50 + 80) / 2 = 65%` for heads?

So, dropping the simple coin flip example, I'm looking to apply this to the lottery (as a fun exercise, not with any hopes of ""beating the odds"" or hitting the jackpot). I simply find that the lottery has some interesting data patterns.

I have been playing with the statistics of the Lotto Max (national Canadian lottery) and have noticed some data points that I found interesting. For example, while theoretically every combination of odd and even numbers is just as likely as any other (to my knowledge, anyway...could be wrong here), the winning numbers tend&mdash;at a rate of about 30.84%&mdash;to contain 4 odd numbers, and 3 even numbers. See the table below:

Odd/Even|# draws|% of draws
:--:|:--:|:--:
7/0|	5	|0.69%
6/1|	37	|5.12%
5/2	|104	|14.38%
4/3	|223	|30.84%
3/4	|209	|28.91%
2/5	|108|	14.94%
1/6	|36|	4.98%
0/7	|1|	0.14%

Based on this, while theoretically (I think anyway, but again, I could be wrong) you should be just as likely to have 7 even numbers as you should 4 odd/3 even, the data shows that choosing 7 even numbers will probably not be the winning combination. Your best odds are with 4/3 or 3/4.

Then there's also the individual numbers. The numbers run from 1-50, inclusive. While every number has the same probability of being drawn as any other number at that same point in time (1/50, 1/49, 1/48, ...), the data shows that the number 50 is the lowest occurring number, having been drawn only 31 times. The number 39, on the other hand, has the highest rate of occurrence at 128 draws. So, then, would it make sense to adjust the probability of 39 to say that it is more likely to be redrawn?

Does any of this make any sense to anyone, or am I way off base here?",statistics
o4w39v,1624284948.0,[Q] Preferable to use MAD or Standard Deviation?,Is it generally better to use Mean or Median Absolute Deviation as a measure of spread compared to standard deviation?,statistics
o4w2ed,1624284878.0,[D] are statistical models able to make predictions about individuals?,"Are statistical models in theory able to make predictions about individuals? Suppose you have an individual with observed covariate information (x = a, y = b, z = c) : in theory, can a regression model (trained well on some data) predict the expected value of this individual's response variable?

I heard today that statistical models are not designed to make predictions about individuals. They are only designed to predict the average behavior of a large group of individuals - and in theory, should not be used to make predictions about individuals.

Is this correct? Does this mean that any time statistical models are used to make individual predictions, this is going against the intended use of statistical models?

Thanks",statistics
o4w2e8,1624284878.0,[D] are statistical models able to make predictions about individuals?,"Are statistical models in theory able to make predictions about individuals? Suppose you have an individual with observed covariate information (x = a, y = b, z = c) : in theory, can a regression model (trained well on some data) predict the expected value of this individual's response variable?

I heard today that statistical models are not designed to make predictions about individuals. They are only designed to predict the average behavior of a large group of individuals - and in theory, should not be used to make predictions about individuals.

Is this correct? Does this mean that any time statistical models are used to make individual predictions, this is going against the intended use of statistical models?

If I understand correctly: this means that when a statistical model makes a prediction about an individual with observed covariate information (x = a, y = b, z = c) - it's making a prediction for the behavior of ALL individuals in the universe with observed covariate information (x = a, y = b, z = c) . Is this correct? Does this mean by definition, the idea of  making predictions for individuals is a fallacy?

Thanks",statistics
o4w2e3,1624284878.0,[D] are statistical models able to make predictions about individuals?,"Are statistical models in theory able to make predictions about individuals? Suppose you have an individual with observed covariate information (x = a, y = b, z = c) : in theory, can a regression model (trained well on some data) predict the expected value of this individual's response variable?

I heard today that statistical models are not designed to make predictions about individuals. They are only designed to predict the average behavior of a large group of individuals - and in theory, should not be used to make predictions about individuals.

Is this correct? Does this mean that any time statistical models are used to make individual predictions, this is going against the intended use of statistical models?

Thanks",statistics
o4uy6z,1624281514.0,[Q] Masters in Financial Engineering Programs or Stats PhDs for quant finance?,"Hello, I’ve not completely decided on it, but have given thought to going into quantitative finance. I plan on going to graduate school for statistics (MS/PhD) programs, but don’t know if it’s worth it rather than doing a two year Masters in Financial Engineering program.

From what I’ve heard, MFE programs are quite competitive, and to really get into a good job after you have to really come from one of the top MFE programs (CMU, NYU), and I guess it kind of puts you in the role of quant finance from the beginning so you can’t really apply the degree elsewhere.

The alternative was doing a stats phd, with a thesis related to something in quantitative finance, and the benefits to this is,  the doctorate will show I have the credibility, but also because if I decide I don’t really like quant finance I can go elsewhere in other industries with a stats PhD.

For anyone out there in quant finance, could you shed light on which of these routes is “better”? Or maybe speak to the benefits and cons of each and what you would recommend to a student?

For background, I’m a stats major whose math background consists of real analysis courses, linear algebra, and calculus, as well as the other stats classes, probability theory etc",statistics
o4t3gq,1624275449.0,[Question] Why does 'e' and 'pi' show up in the Normal Distribution PDF?,"I have often noticed that students and aspiring statisticians learn the formula of normal distribution PDF through rote learning. However some curious people do ask the right questions instead of rote learning. One such question is why does 'e' and 'pi' show up in the pdf of normal distribution.

Quite clearly there is nothing to do with circle in the pdf for the 'pi' to feature (perhaps there is , I don't know). Neither is there a some interest rate for 'e' to feature.

So what could be an intuitive explanation for 'Why 'e' and 'pi' feature in the normal distribution PDF?",statistics
o4sglw,1624272886.0,[Q] Pairwise comparison organiser,"Does anyone have access to a free piece of software I can use to organise my pairwise comparisons? I have run a One-Way Anova with a Tukey Post Hoc on some data I have. The trouble is is that I have 15 different groups which means I’m having trouble sorting through the comparisons and writing the correct subscript letters on my bar graphs.

Any help here would be greatly appreciated, thanks in advance!",statistics
o4qzy3,1624266217.0,[Q] Some help understanding mixed model in R,"I have very simple data
Y =  Dependent Variable (continuous)
X1 = Independent Variable 1 (continuous)
X2 = Independent Variable 2 (continuous)
X3 = Independent Variable 1 (Discrete)

My hypothesis is X1 & X2 influence Y. Additionally, X3 not only influences Y, but also changes how X1 & X2 influences Y.

Is the following code in R correct for above?

    model <- lmer(Y ~ X1 + X2 + (1 + X1|X3) + (1 + X2|X3), data = data)",statistics
o4lwua,1624245751.0,[Q] math needed to study Time series forecasting & analysis in grad school?,"Hello, I’ve been thinking about graduate level studies, mainly PhD programs in statistics. I enjoyed my undergraduate level time series forecasting classes, and I want to pursue a research topic within this area of statistics.

One thing I was warned about by my professor was that while I did well in the undergrad course for time series, graduate level time series is “a whole different beast”, and said I’d need a ton of extra math.

With that being said, what extra math would I need to study time series forecasting and analysis at a deeper level enough for a PhD topic one day?",statistics
o4kwp6,1624242324.0,[Q] Reputable crash courses to catch up to speed,"Long story short, I haven’t taken stats in about 10 years. It’s sort of a blur. I know of the terminology but can use a refresher. I’m a CS Master’s student, but taking Data Science electives. I’d just like to sort of catch up on standard deviation, variances, confidence intervals, that stuff.

I know it’s not easy, but I’m mostly looking to see if anything online could help me catch up, do some examples and not be as lost on my data viz course as I currently am. Tried LinkedIn Learning but found it very meh. But any input would be appreciated if possible",statistics
o4h8vw,1624229801.0,[Q] Average probability of a Type II error for a range of values by integrating over rejection region,In Wackerly Mathematical Statistics the author states that you can only compute the probability of a Type II error for a single given specific value in the rejection region. Wouldn't it be possible to integrate over a range of values in the rejection region and find the average probability of a type II error?,statistics
o4e4ld,1624220402.0,TOPSIS and inverse rating [Q],"In other Multi-Attribute Decision Making methods, it is okay to use the inverse of values if that attribute has the property where the smaller the better (such as cost of expenses).

In reading about TOPSIS, it uses a different approach of instead manually determining which criteria has a positive or negative impact on the decision making. My question is that if you could just take the inverse of particular attributes (where smaller is better), then you would not have to manually determine which has a positive or negative impact.

Can anyone see, possibly mathematically, what could be problematic about taking inverses? (And still normalizing these inverse values)",statistics
o4dxy9,1624219865.0,[Q] Terminology question: Wald Tests,"I have a question about what is meant by Wald tests. Based on the contexts of where I have read it, as well as some notes like the Wikipedia entry, my understanding is *any* test that is formulated by a measure of distance between the estimated value and hypothesized value is a Wald Test?

So the distribution of the test is not relevant, just if it is a distance it can be called a Wald Test? so a T test, F test, z -test, chi-square etc. are all types of Wald Tests, that have a particular distribution?",statistics
o42cde,1624183340.0,"[Q] Those of You Who Did A Master's In Statistics, How Did You Fund Your Degree?","Hi, I am a rising junior undergrad majoring in math and statistics. After deciding a Ph.D. is not for me, I've begun looking into master's programs; however, they all seem exorbitantly expensive especially if you go out of state (incredibly unfortunate for me because my current state has no well respected stat program). I've also been hearing that finding funding through RA's or TA's is much harder for a master's student. So my question is, how did you fund your education? I don't think the jobs available to someone with only a Bachelor would be satisfying for me at all in the long run, but, at the same time, if the only way to fund such a degree is by taking ou at least 60k in loans, I'm uncertain on my options are. I'm at the point of considering applying to Ph.D. programs with the intent to drop out after I obtain a Master's in passing. (Which can burn bridges and be overall unwise)

To add some perspective. I will note that I have a 4.0 math gpa currently, a gre score in the 98%ile, and when I graduate I'll have coursework through some graduate level mathematics. I don't know if that will make any difference in my ability to get funded for a master's. I'd appreciate any advice.

Thanks",statistics
o3pvzf,1624136881.0,[Education] Should I pursue a biology major along with statistics?,"I hope this is an okay place to ask.

I’m a rising sophomore majoring in biology and statistics, and was wondering if there would be benefits to keeping the biology major. I was originally just majoring in biology & decided to take on statistics (hoping to go into biostats).

My concentration in statistics is applied statistics and biometry. I spoke to students at my university who said the most overlap between the biology and statistics majors would be taking the computational biology concentration.

Is there a concentration that would be both applicable to stats and expand fields/career options? For reference, the concentrations within the biology major include:
- biochemistry
- computational biology*
- general biology
- genetics, genomics, development
- microbiology
- molecular & cell biology*
- neurobiology

( * )these are the ones I’m strongly considering.

Sorry for the broad question. Any guidance would be greatly appreciated— thank you in advance!",statistics
o3plti,1624136022.0,[Q] What exercises to do in Casella Berger?,"Hi,

I am to start my MSc in Machine learning late this year. However, my statistics background is weak as I took a few years to work in industry.

After much searching, I have been told that there are two books I should work through:

1. Casella Berger
2. DeGroot and Schervish

Both these books have a lot of end of chapter exercises. As my time is limited, I would like some sort of guide to which problem I should solve. One of the resources I found was this:

[http://www.stat.columbia.edu/\~liam/teaching/4109-fall10/](http://www.stat.columbia.edu/~liam/teaching/4109-fall10/)

This lists all the exercises I need to do as I work through 2. Is there something similar for 1. that anyone here is familiar with?


Would more experienced folks recommend working through 1. as opposed to 2.?


Any pointers would be much appreciated!",statistics
o3nlx8,1624130091.0,[Q] why do we believe stochastic processes are not actually deterministic?,"is it because most processes cannot be studied in strict isolation and are always subject to secondary drivers (what we call ""noise""), and thus influence the underlying process itself?

or is the prevailing belief that there will always exist some randomness to every process, no matter how strictly we isolate it

the former implies that, given sufficient computational power and insight, we could simply model these conditionalities via some extremely multivariate model and/or additional models to explain the noise, does it not? that we could conceivably drill down the uncertainty / noise down to a series of deterministic models that when run in unison could perfectly predict any process

I know this is of little practical importance, but I am just curious",statistics
o3lb3a,1624124079.0,[Q] How can I describe the following equation?,"Hello, how should I name this type of statistic measure?

Is this some sort of exponential moving average based standard error?

 https://imgur.com/cRPD57m",statistics
o3bjl3,1624091959.0,[Question] Power Transformations,"I'm using a Yeo Johnson transformation, but I don't get how it works. I read that lambda is chosen in a way, that it fits to my data, and then the data is transformed like Yeo Johnson says, okay cool. But how exactly is lambda determined?",statistics
o39s1d,1624083842.0,[D] [E] Intuitive explanation for the shape of the normal distribution,"Here is my attempt to explain where the distinctive bell shape comes from, in a simple and intuitive way.

[Visual article: Why the normal distribution has a ""bell-curve"" shape](https://showmethedata.live/bell-curve/)

I would be interested to read your comments / feedback / ideas ...",statistics
o399gj,1624081541.0,[Question]Help me,"50 randomly selected couples interviewed for family planning, 31 use some sort of family planning. What would be the expected magnitude of variation in the proportion of practising couples if another sample of same size is drawn from the same population",statistics
o38p6i,1624079070.0,[Q] What does the following say about the 2 variables?,"Say you have 2 variables: A and B. When plotted in a lin-lin plot, they have a positive correlation (correlation coefficient = 0.5), but when plotted in a log-log plot, they have a stronger positive correlation (correlation coefficient = 0.7).",statistics
o37ig8,1624074737.0,"[D] How do models like ARMA and ARIMA fare against ""sporadic memory""?","Is it fair to assume that standard time series models like the ARMA and the ARIMA model are not well designed to handle ""sporadic and irregular"" memory patterns? As I understand, these models are usually used to handle data with well-behaved notions of ""trends"" and ""seasonality"" (e.g. you specify these in a given ARIMA model) . When you start to deal with more complicated and irregular patterns, do ARMA/ARIMA models tend to perform poorly? Was this the motivation for eventually moving towards neural network based models (e.g. RNN, LSTM) for time series analysis?

Thanks",statistics
o355cf,1624065965.0,[Q] Thinking about approaching people in the street surveys...,"I was just thinking about a job I did for a fortnight or so some years back. What we had to do was patrol a relatively small area (e.g. the main street of a town or this [desolate wasteland](https://imgur.com/a/PDTeIo8)) and approach absolutely everyone we could. We'd then ask them if they wanted to be in our survey. If they said no, we counted that on a tally sheet. If they said yes, we then asked them an exclusion question. If they weren't excluded, we then took their email and sent them a link so they could do the survey at a later date. (I think there was a prize draw.)

(There was also a bit where we had to determine the age of the respondent... those under 15 were excluded. And we couldn't go inside any properties, not even shops... which was an issue since the exclusion test was geographically defined and **very** strict, like, 10/113 people who wanted to be in the survey could actually do it.)

Is there any inferential validity to this kind of survey? Like, how do you do probabilities of selection?",statistics
o33up0,1624061295.0,"[Q] I’m applying for a job in biostatistics, what topics should I brush up on?","As the title says, I’m applying for a job internally where I currently work for a Biostatistician position. I was recommended for this but haven’t brushed up on statistics topics since I graduated last year. Any suggestions for topics to refresh for the possibility I land an interview? All help is welcome! Thank you!",statistics
o2wt2d,1624040977.0,[Q] Comparing linear regression models using dummy variables,"For my research I've explored the effects of predictors on green space visitation before and during the COVID-19 pandemic. The result is two linear regression models over two periods of time for the same population group. I was wondering how to compare these two models, and have found online that an alternative to a Chow test is to 'run the model with dummy variables'. I know what dummy variables are, but am confused how this method would work in practice. Is anyone familiar with this method? Any help is appreciated!",statistics
o2s9c6,1624031504.0,[Q] Beginner Question Regarding Chi-Squared,"I have a couple questions about the chi squared statistic.

1. I have seen around that the chi squared is given by sum(residuals\^2 / sigma\^2). In a fit of a line to data, how do I calculate sigma if I don't know the errors on the data points I'm fitting my function to.
2. I have also seen that the chi squared is just given by sum(residuals\^2) for example here [https://lmfit.github.io/lmfit-py/fitting.html](https://lmfit.github.io/lmfit-py/fitting.html). What is the difference and which is more acceptable?


Edit: this specifically applies to the Levenberg-Marquardt method for fitting. I want to know how one would calculate the chi squared after having found best fit parameters through the LM method.",statistics
o2pcnk,1624023662.0,"[D] can someone please explain what the ""white color shades"" mean in this picture?","https://martin-thoma.com/images/2016/01/ml-classifiers-2.png

These pictures are supposed to show the decision boundaries of different machine learning algorithms on a binary classification task. There are two classes for the response variable: ""red"" and ""blue"".

Shouldn't all the decision boundaries either be fully red or fully blue? What do the shades of white mean? Does this mean ""an overlapping decision boundary""?

Thanks",statistics
o2o0cl,1624019462.0,[Question] How to calculate the standard error of the difference between regression coefficients of different regression.,"I am performing analysis for my master thesis and found a paper that gave me a good idea on how to analyze my data. In this, I am performing an FF3 regression in order to check whether the 2 portfolios are significantly different from each other. In this, I've got excess returns for 2 portfolios for the same time frame, the thing I would like to create now looks like this:

Alpha                     RMRF                         SMB                     HML

High ESG Portfolio   0,0029\*                1,1882\*\*\*                -0,0069             -0,2420\*\*\*

(0,0015)                 (0,0376)                   (0,0698)             (0,0582)

Low ESG Portfolio      0,0013                  1,086\*\*\*                  0,0725              -0,1324\*\*

(0,0016)                (0,0392)                   (0,0728)             (0,0607)

Difference                  0,0016                   0,1017                     -0,0795              -0,1096

What I am looking for now is how to calculate the standard error of the differences between these coefficients based on the regressions outputs. How would one go about this to see whether the difference in returns and risk factors is significant?",statistics
o2na44,1624016985.0,[Question] Can you measure interaction in a Chi-squared test of independence?,"I have statistical data where I want to look at differences of frequencies with a Chi-squared test of independence. My main hypothesis includes 2 independent variables (gender, marital status), and I want to add another variable (country of origin) and look at its effect.

If this were a continuous variable I would use ANOVA and check for a statistically significant interaction, but since I am looking at frequencies I use Chi-squared. Is there a way to measure interaction in Chi-squared tests? Or should I use another test?

Thanks",statistics
o2k1zm,1624004060.0,[Question] Is generalization of the statement 'Correlation is not causation' correct or not correct ?,"Recently I stumbled upon some tweets which were critical of the latest book "" The noise by Kahneman, Sunstein and Sibony. The criticism was mainly centered around the fact that the book had stated 'causation implied correlation.""

However one tweet by caught my eye, The author is perhaps hinting that sometimes ""correlation can be a sign of causation"".? (I hope I am not misinterpreting his statement). Below it the quoted tweet.

>Correlation: everyone who I've ever seen mention ""correlation is not causation"" in conversation has been a fool.
>
>Causation: anyone who mentions ""correlation is not causation"" in conversation is a fool.
>
>In my experience, both statements are true.

That apart...

In my statistical practices too, I often notice in my client meetings that some smarty pants makes the comment ""Hey but correlation is not causation"", whenever I or my colleagues say ""X is strongly correlated with Y"".

Somewhere I feel the over generalization of the statement ""correlation is not causation"" has caused more harm especially at the hands of layman. The layman outright rejects any reports and analysis with the words ""X is correlated with Y"" with a quip ""correlation is not causation"".

My question : Is the generalization of the statement ""Correlation is not causation"" correct ? Also, is the author in the tweet correct to hint that sometimes ""correlation can be a sign of causation?""

P.S. I don't have a training in causality. I understand that there is a huge body of work under the topic of causality. So thought somebody in this group with a better understanding about this subject than me can help.",statistics
o2i6ul,1623996359.0,[D] Modern Time Series Analysis,"Does anyone know what are the most modern statistical models being used for time series analysis? I have heard of transformer and attention mechanisms models that are used for modelling sequential data - but these seem to be more relevant for modelling data from the NLP domain. When it comes to classical time series modelling (e.g. a vector of temperature measurements) : does anyone know what are some of the more modern models being used for this? I did some searching online : it seems like ARIMA style models were some of the first ones, followed by state space models/hidden markov, and the more recent ones being RNN and LSTM.

Are LSTM and RNN the most modern models that are being used for classical time series problems?

Thanks",statistics
o2e742,1623982659.0,[Q] Is switching null and alternative hypothesis based on estimators valid?,"We have a problem where an investor states that the average profit of certain economic sectors is greater than 1.
So I think that we should test every sector with the following hypothesis set:

H_0: \mu <= 1
H_1: \mu > 1

My teacher says that isn't right, and we should get the point estimator (average) of every sector, and then set the alternative hypothesis for that sector according to what the estimator suggests, e.g: The estimators of 3 sectors are: 2.1, 0.5, 1.1

So for sectors 1 and 3:
H_0: \mu <= 1
H_1: \mu > 1
For sector 2:
H_0: \mu >= 1
H_1: \mu < 1

Why am i worried? I feel like what the teacher is suggesting is like cheating as the null and alternative hypothesis are not symmetric, but I'm gonna take an exam on saturday, he's gonna grade me and I lack the expertise to formally argue for my position.

I also don't know what to do. Should I dance to what he says or stick to my position even when I don't know how to argue for it?",statistics
o2bfp9,1623973903.0,[Question] Modelling the optimal interval for two dose vaccine administration?,"I'm curious about the statistical approach is to this problem:

There are a number of wrinkles to the question: efficacy of one person with two doses vs one fully vaccinated vs two partly vaccinated; the level of virus in the community at the time (which may itself feed back into the immunization status).

That is, you have less efficacy in an individual with one dose rather than two, but getting a first dose in more people sooner may offer more population health benefit. Additionally, you have what appears to be an enhanced immune response with a longer delay - but have to weigh that against while one might get better immunity by waiting longer, if you become ill before getting that second dose you've lost that bet.

Leaving aside the factual specifics -- which are subject to investigation -- what is the statistical apparatus for thinking about these kinds of contingent scenarios?

\[all premised here on a two dose regime in which the first does confers some efficacy but is not optimal till some time after the second dose\]",statistics
o28tuk,1623966517.0,[Q] Forecasting Principles and Practice or Time Series with Applications in R,"Hello which of these books is more suited for an undergrad in a stats major, hyndman’s forecasting principles and practice or Time Series with Applications in R? I’ve taken calc 1-3 and some linear algebra. Which one would you all recommend for an undergrad?",statistics
o28mbu,1623965965.0,[Q] Expectations of Conditional Distribution,"I need to work out E\[Y\] where Y= 0 if X<1000 and Y= X - 1000 if X>1000. I've looked at the memo given and it largely makes sense however I'm not sure how to work with conditional expectations and conditional probabilities in general. We're told that Y = X - 1000| X>1000 which makes sense, however I don't understand how to go about working out E\[Y\] with this.

&#x200B;

What I tried to do was work out E\[Y\] = E\[0\* P(X<1000)\] + E\[(X-1000)\*P(X>1000)\]. However this doesn't provide the right answers, why doesn't this give the correct answer and how should I go about solving this?

For additional info X is lognormal with mean = 2640 and sd = 3460",statistics
o28gld,1623965538.0,[Q] Does using an ANOVA test make t-tests unnecessary?,"   Sorry if the question sounds stupid; statistics is not my strong point. I'm writing my master's thesis that concerns 2 independent variables and 2 dependent variables. Subjects can be in one of four groups: exposed to both IV's, exposed to only the first IV, exposed to only the second, and exposed to neither.

   Concerning each DV, I want to use an ANOVA test to see differences in them between the four IV categories. Will using an ANOVA essentially get all the same results as conducting a bunch of t-tests between two categories at a time would? Is there any information I would be missing out on by not conducting t-tests and just using the ANOVA? Also, is there a difference between the results I would get conducting a two-way ANOVA to assess both IVs at the same time vs conducting an ANOVA for each IV?",statistics
o289nt,1623965030.0,[Question] How many random events do have to occure in a year for each day to have atleast one occurance ?,"I'm no mathematician so I appologize if I don't phrase this right.
Given a class of random events, that occur at any given time, let's say deaths or births. How many such events would have to occur in total, in any given year, so that we have atleast one occuring each day of the year? How do I calculate this ?This is not school work, it's just pure curiosity from a debate I was having with a friend (he asked me how many employees should a company have for it to have atleast one death every day of the year). And I realized I have not really any idea how to calculate this correctly.

To rephrase in different words. Let's say we take the global population, and for population of this size ""someone dies everyday"" holds generally true. My question would be how small the population could get that the assumption ""someone dies everyday"" would still hold generally true (say to 99% confidence)",statistics
o26z5q,1623961683.0,[Q] Prediction interval for ARIMA models in multi-step forecast,"I have an ARIMA model & I want to make a forecast over the next 6 time steps. Not only do I want the predictions, but I also want a prediction interval (with say 95% probability). I'm able to generate a confidence interval, but this isn't what I want, as this is just the confidence of the fit parameters not the residual error (please feel free to correct me if I'm mistaken). If I only care about a one-step prediction, I believe I can just take the standard deviation of the residual errors and make a prediction interval out of that - but in my case I want more than just the one step.

How can I make this 95% prediction interval for multiple steps into the future? I imagine it's some combination of my confidence interval and the standard deviation of my residuals, but I can't figure out.",statistics
o244ud,1623954595.0,[D] ability of statistical models to extrapolate to new data,"Recently, I have been reading about some interesting research that talks about the theoretical limitations of certain machine learning algorithms to effectively extrapolate to new data (e.g. ""Decision Trees Do Not Generalize to New Variations: , http://www.iro.umontreal.ca/~lisa/pointeurs/bengio+al-decisiontrees-2010.pdf ). For example, researchers mathematically proved that Decision Trees can not generalize to data they have not seen before (i.e. an infinite number of points is required to guarantee a certain level of generalization).

Another interesting result is ""Runge's Phenomenon"" (https://en.wikipedia.org/wiki/Runge%27s_phenomenon) that shows polynomial are likely to highly oscillate and become unpredictable outside of data they are exposed to.

2 questions I had:

1) Does anyone know if piecewise splines suffer from the same theoretical constraints such as Runge's Phenomenon? Or does strategic combination of many splines somehow mitigate this problem? From the Wikipedia page on ""spline interpolation"" (https://en.wikipedia.org/wiki/Spline_interpolation), splines apparently have an advantage over methods like polynomial regression, since they can achieve similar errors but maintain a low degree than polynomial regression models (e.g. a popular choice of splines are cubic splines, i.e. 3rd order/degree splines). It seems to me that this might be related to the ""bias-variance tradeoff""? That is, it might be beneficial to approximate the target function using several 3rd order polynomials (i.e. splines) compared to a 8th order polynomial regression model? Are splines known to struggle with extrapolation?

2) I have been reading more on the ability of neural networks to extrapolate to unseen data - supposedly, neural networks are optimistically described as some of the few machine learning algorithms that at least have the theoretical structure that could permit extrapolation. Apparently, this is due to properties such as ""adaptive basis functions"" and ""distributed representation"" - these allow neural networks to better handle adversarial attacks (e.g. small changes to inputs are less likely to produce drastically different results) ,require fewer examples to generalize (""better bang for your buck"") and are able to use all the variables in unusual combinations to make more complex decision surfaces that can better model complex data. All in all - is this correct?

Thanks",statistics
o23rve,1623953690.0,[Q] Mann Whitney U test or Correlation?,"For context my IV is experimental condition (between subjects design) and my DVs (3 in total) are measured on Likert scale (therefore ordinal).

Am I correct in thinking that because I want to look at the differences between the two groups in their responses to the likert scale items I would use a Mann Whitney U test as the data is ordinal? Or would I be better off using a correlation for non-parametric data?

Essentially, does the method of analysis depend on how I phrase my research question? For example, if i state I want to look at differences between the two groups I would use a Mann Whitney but if I said I wanted to examine the relationship(or association) between condition and response I would use a correlation?

I think I’ve just got myself a bit confused. Any help is appreciated as I am very much a novice. Thanks!

Edit: I have a small sample size (15 Participants in each condition if that makes any difference)",statistics
o22tr3,1623951279.0,[D] history of non-parametric models,"I have been reading about the use of non-parametric models in machine learning (e.g. kernel methods like svm, kernel regression ... decision trees, gradient boosting, random forest) - and I tried to contextualize the reasons why these methods emerged (in my head). This is the conclusion I reached:

1) Parametric models (like standard regression models) are tricky. Parametric models require certain assumptions about the data to be true, also require the analyst to manually specify interaction terms within variables - but the biggest drawback: regression models tend to require more beta coefficients to capture more complex patterns within the data. A regression model with many beta coefficients behaves similar to a higher order polynomial function: and higher order polynomials are notorious for behaving in very unpredictable ways outside the range of observed data (runge phenomenon) - this basically explains why higher order regression models have a bad reputation of overfitting training data and generalizing poorly to new data. This is all related to the bias-variance tradeoff.

2) Non-parametric models do not require interaction terms between variables to be manually specified (e.g. in a decision tree, you don't need to specify this - the decision tree will try to recover these interactions by itself), and have less stringent assumptions about the data (e.g. choice of kernel). The appeal of non parametric methods was an attempt to defy the bias-variance tradeoff: the idea of trying to make a less complex model with the ability to make predictions comparable to a complex model, with the hope that the lack of explicit complexity leading to better generalization on test data.

3) the popularity of neural networks (a parametric model) is due to the fact that researchers found out ways to make these explicitly complex models generalize to unseen data (e.g. effective regularization methods).

Is my interpretation of the history correct?

Thanks",statistics
o21usr,1623948795.0,[Question] Can I use sample sizing to estimate return rates for a product?,"Given we produce 10000 items if we tests a sample size of 370 and get a 10% failure rate we are 95% confident that this is going to be our failure rate with a 5% margin error.

In real life though that production will always run therefore population would increase what can we do to calculate a sample size?

[Link with formula](https://www.qualtrics.com/experience-management/research/determine-sample-size/)",statistics
o202co,1623944002.0,[Question] Does a correlation between two percentages constitute statistically significant enough evidence to be used/cited in a scientific context?,"Let's say 5% of people have x property, and 5.2% of people have y property. When combined with other evidence indicating a link between posession of the two properties, would the similarity in percentages be valid enough to cite in a scientific/research context?

Disclaimer: I know almost nothing about statistics, I am just really curious and couldn't find the answer with a Google search.",statistics
o1zwtl,1623943604.0,[EDUCATION] Uncertainty in Statistical Modeling Explained Intuitively,"Here's a video (by me, a Professor at CMU) about how to think about uncertainty and confidence in statistical modeling. I'd love your feedback!

&#x200B;

http://jeffgalak.com/datademystified/index.php/2021/06/17/uncertainty-in-statistical-modeling-explained-intuitively/",statistics
o1zuzm,1623943469.0,[Q] Any (intuitive) resources for understanding rotations in PCA/factor analysis?,"Interactive websites, videos, or text (less preferred) would be really helpful. Thank you in advance :)",statistics
o1yn3t,1623940258.0,[Q] What has a 24% and 13% chance of happening?,"I am trying to convince someone to wear their helmet while at work (no I can't fire or report them). From what I read and understand there's about a 24% chance of a TBI to be inflicted upon an employee while on a work site. If they wore their helmet, it would reduce those odds by 52% (.24*.52=.1248)

I want to highlight the dramatic reduction in probability of a Traumatic Brain Injury by comparing those two odds.

(Also, if I messed up my math I'd still like to know because that's just a random conversation started I can have with friends)

Edit: Ok yeah I had a lapse in logic. The odds of an accident at a construction site is 10%, meaning .024*.052=.01248

.024*(50 work weeks*5 days a week)=6 times per year an accident occurs

.01248*(50 work weeks*5 days a week)=~3 times per year an accident occurs

What else happens at about those frequencies?",statistics
o1talr,1623922934.0,"[Q] Survey weighting: is a smaller sample with low average weights, or a larger sample with larger average weights better to generalise to the population?"," Hi everyone,

As I work in social survey research, I often weight samples to be representative on several fronts. This is very effective as we tend to have a problem recruiting specifically lower-educated, and they are underrepresented in samples compared to the population. For a study I am doing, I have a sample of 10 000 respondents, but lower-educated are quite underrepresented, with these respondents having an average weight of 6. One of my colleagues suggests to randomly sample from my high- and middle educated respondents to decrease the sample size, such that the proportions will be closer to the population, and weights will be smaller. This will lead to a smaller effect size etc.

However, I do not see the use for this unless the effective sample size actually goes up, which will decrease the margin of error on my results. My idea is to keep the originally weighted data (n = 10 000, design effect = 5), and use analyses adjusted for weighted data (eg survey weighted confidence intervals that reflect the original smaller n that was blown up to be representative), as I do not see the use. Do any of you have advice as to which of both methods would be the most helpful to check the effects of a certain variable in the population?",statistics
o1q00x,1623909685.0,"[D] Understanding ""likelihood"" in simple language","Supposedly, ""likelihood"" means : the probability of observing your data, given your model.

How do you understand this? Suppose I want to make a regression model that predicts someone's salary based on weight and height. I have a dataset of measurements for salary, weight and height. I make a regression model, e.g. salary = 15 * height + 23 * weight + 7

I struggle to understand how the definition of likelihood applies here : the probability of observing your data given your model.

I understand that ""maximum likelihood estimation"" can provide you with equations to estimate the values of the regression coefficients for height and weight - but in this question, what does ""likelihood"" mean? I made a regression model using available data ... why should I be interested in the ""probability of observing this data given my model""? What exactly does that mean? I have seen software like R and SAS where you can calculate the likelihood value for a regression model ... but I am not sure if this answers the question.

Can someone please explain this? Wouldn't the data still exist, even if I had not decided to make a model? How is the model related to or influence the existence of the data? Should it not be the other way around - the model coefficients depend on the data?

Thanks",statistics
o1i4t8,1623884552.0,[Q] Combining multiple known correlations into one master equation,"Hi, I'm doing a research project and have an idea, but I'm not sure how to set it up. It involves determining how a person might react emotionally to situations.

It involves several independent variables: a type of personality, a mood, and the quality of an external reaction. Each of these are defined by various numeric levels. For example, personality could be defined by Extroversion, Agreeableness, Conscientiousness, Neuroticism, Openness, each on a scale from 0 to 1. Mood could be defined by two variables: valance and arousal.

Now, say that I knew, or declared, one such correlation that made sense. For example, someone with low valance and high arousal would respond angrily.

My idea is two write these facts as linear equations with lots of variables. Then, solving the equations simultaneously would result in one equation that represents all of the facts.

So the equation for the above would look something like:

mood^valance + mood^arousal = reaction^angry

However, I am not really sure exactly how to write the equations. Does anyone have a better idea on how the equations could be written? Thank you!

edit: should note this will be implemented using computer programming

edit2: I think ""multiple linear regression"" might be relevant/what this is. Still looking for feedback on how exactly to set it up though",statistics
o1hw6y,1623883890.0,[Q] R language loading library,"I've recently started using R for a new project because of an interested pacakage called CMAverse for MI applications. [https://github.com/BS1125/CMAverse](https://github.com/BS1125/CMAverse)

A lot of issues came up as I was installing it according to instructions. I received a lot of missing dependencies that this library requires, and when I tried installed some requirements, those reqs gave more missing dependencies etc. Is it supposed to be like this? Or am I possibly doing something wrong? Any suggestions would be appreciated!

Running R using vim-r plugin on Manjaro Linux, not sure if that has any effects.",statistics
o1h6tj,1623881938.0,[Q] A simple(?) question about a dice game,"Who gets to do the dishes after dinner is often decided by a game of dice where I live. Oftentimes we play this particular game, and I've been trying to get my head around the statistics of it.


Let me preface by saying if anyone knows the english name of this dice game, then I'd appreciate the name because someone probably already worked out the statistics.

Here are the rules:
Single dice
Each player takes turn throwing the dice a maximum of three times.
The goal is to end the game after a full round with the highest number.
1, 3, 4 and 5 adds to your score
2 and 6 halves your score
An initial 2 or 6 is rerolled.
You can stop rolling at any time before the maximum of three rolls.
Decimal places are included (3.5 for example)


So these are my thoughts
For the initial roll the average toss would be (1+3+4+5)/4 = 3.25
And after this I'm kind of stumped, because I'm having trouble wrapping my head around the halving of the scores.
So there would be a 2/3 chance to roll an average of 3.25 and 1/3 risk to half your score so far. What's the math here?


There are mainly two things I'm interested in here:
What's the average outcome of one player rolling thrice when disassociated from the other players playing the game (when have I rolled above the average roll, and would it be advantagous for me to stop rolling).
What is the average increase in score for the second and the third roll of the dice?


Thank you in advance, and if this is the incorrect forum to ask this, could you kindly redirect me to somewhere more appropriate?",statistics
o1gtkv,1623880960.0,[Q] Confused on how to compare two predictor variables in a logistic regression model which are of completely different units,"For some context I’m doing a Linguistics study which (in a nutshell) seeks to predict when a complement clause will be full or empty, e.g, ‘I think I’m sick’ vs ‘I think that I’m sick’. The ‘that’ being the binary outcome variable.

Logistic regression is typically used in these types of linguistics studies so this is the correct method in this case.

For this particular notion (called an ‘alternation’) there are several predictors, for clarity and succinctness I’ll refer to them as Word Information and Dependency length. Word information is given in Bits, so anything from 0 to around 3.5 but these numbers tend to have many more decimals e.g. 2.3462538. Dependency length is the distance between the verb in the sentence and the following clause, so something like ‘I realised on Monday last weekend in the park (that) I was sick’, would have a long dependency (9 units or so depending how you count in this case).

Higher values for each of these independent variables are theoretically known to correlate with a greater probability of a full clause, e.g. using the word ‘that’.

The problem is, whilst these can be used in a logistic model and the coefficients interpreted accordingly, it’s difficult to compare them given the different units. How can a meaningful comparison be made? Is this a common problem?",statistics
o1fcor,1623877168.0,[R] Non-inferiority for diagnostics - how is this done?,"This field is too damn big, I didn't touch a lick of this sample size planning / diagnostics in my master's and google shows nothing.

Any tips on how I can plan a study for checking, say ""is this covid test any less accurate for males than it is females?""

It depends on the chosen metric of course, but let's say I want to use AUC, and I want to make sure i show that AUC for males is no more than 3 points less than AUC for females. Should I treat it is a non-inferiority proportion problem? (because the AUC is the probability a randomly drawn positive has a higher score than a randomly drawn female, which is like a proportion)",statistics
o1euk3,1623875876.0,[C] Have Any of You Managed To Find a Job With a Four Day Work Week?,"Hi,

I'm a current undergrad majoring and math with a minor in statistics. I was wondering what work life balance is like for most of you in the industry. How flexible are your bosses with your schedule? Have any of you managed to find job with a four day work week? How much vacation time have you been able to negotiate? Etc.",statistics
o1bui3,1623868308.0,[Q] How do you compare a population subset proportion to entire population proportion?,"I am working on a research project where I have collected data on cult members in another country. I have the data organized by province and calculated the percentage of the total cult member population I sampled who are in each province. I want to compare this to the overall percentage of the whole country's population that lives in each province to show that where the cult is recruiting is significant and difference from the overall national population distribution. Any suggestions on what tests or methods I could use? I also have the average age of the cult members and the standard deviations calculated for each province and would like to see if provincial identity impacts age people join cults (although based on my significance tests so far, nearly all average ages by province fall within the 99% confidence interval for the overall cult population so I'm not sure if this would be useful or not)",statistics
o18ia6,1623859929.0,[Q] Sample Dataset Resources,"Hey guys not sure if this is the right place to ask but I was wondering where I could find sample right-censored datasets, currently doing research on survival analysis and looking to test some code out, cheers!",statistics
o15eeo,1623851558.0,[D] Euro 2020 Predictions Update,"Last week, I posted some predictions for the 2020 Euro.  Now that the first round is over, we can examine some of my performance.

My predictions and results for the first round are shown in [this](https://i.imgur.com/qkY6SQc.png) table (sorry it isn't prettier).  I achieve an average log loss of 0.92, where assigning all outcomes as equiprobable yields an average loss of 1.1.  My multiclass ROC for predicting the outcome is 0.77.  In short, in the first 12 games I perform slightly better than random guessing (which is honestly fine for me).  However, most people who have watched international football wouldn't assign all match events as equally likely (is Italy drawing Turkey really as probable as Italy losing to Turkey?  No).  Its hard for me to measure against a ""reasonable guesser"".  My work pool records all our guesses, and so at the end of the group stage I can use that as a sort of ensemble method to compare against.  We'll see.

[Here](https://i.imgur.com/mZaivJY.png) are match predictions for the remaining group stage games conditioned on the results of the first games.  The model is not perfect, and still makes some weird predictions.  For example, Portugal is given higher probability to beat France than they are to beat Germany even though France beat Germany in the first round.  If you subscribe to some sort of sports law of transitivity, this may sound weird.

My predictions for the second round and the results of the first can be found [here](https://github.com/Dpananos/Euro2021Predictions/tree/main/predictions).",statistics
o14ige,1623849032.0,[Q] What test to check for correlation between variable and classification into 5 classes (Likert ratings)?,"Apologies if the question seems basic, but I am not very experienced in statistics.

I have collected data concerning different properties of objects, e. g. animals, that are classified into 5 classes. The classes are Likert ratings 1-5 (let's say 1 = very low weight, 5 = very high weight). So the data looks something like this:



Animal | Class | Property1 | Property2 | Property3 | ...
---|---|----|----|----|----
Fish | 1 | 0.5 | 2 | 2.2 | ...
Cat | 3 | 0.2 | 1 | 1.3  | ...
Horse  | 4 | 1.2 | 4  | 3  | ...


Each object (animal) belongs to a class 1-5, and the properties are all numbers.

How do I test whether there is a correlation between the classification into the 5 classes and a certain property? (For example, if property 1 was volume, then surely low volume would correlate to lower classes/lower weight, and high volume would correlate to higher classes/higher weight.) I could obviously just get the averages for each property per class and then compare, to see if there is a trend from 1-5, but that doesn't seem ""statistically sound"".

If I wanted to check for correlation between any two properties, I suppose I would just use a correlation test, however I am not sure what to do to test for a relation between the classes and any one property.",statistics
o1373f,1623844816.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
o10rhh,1623835320.0,[Q] Very varying views on Log transformation in the context of regression. When exactly is it correct to use Log transformation in Regression? very confused,"I have read through many websites, medium articles, Kaggle notebooks, and many of them have different justifications for the ""log transformation."" Some of the top ones I came across are:-

1. If your residuals vs fitted values are not random or have heteroscedasticity, then log transform the variables.
2. If your variables are skewed, then log transform them for regression.
3. If your variables have a non-linear relationship. Log transformation helps express them in linear terms making it easy to understand the model.
4. If your variables follow a log-normal  distribution, then transform them to get a normal distribution
5. When log transforming makes 'sense' on the scale since the variable is now expressed in % terms

I am just so confused because all of them give varying reasons.

Let's say I have 2 variables and they seem to have some sort of a linear relationship based on the scatterplot, but the residual plot is crap. After I log transform one of the variables, the scatterplot has a clear linear relation now, and the residuals are much better. Is this a valid reason to log transform?",statistics
o10c71,1623833503.0,[Q] How do I support using the median instead of the mode as measure for central tendency in 5-point likert items?,"I chose to use the median as measure for central tendency, instead of the mode. I can't however find any literature supporting use of the median over the mode or visa versa. Is there a clear explaination on why the median is the better choice? Or is the mode perhaps a better measure.",statistics
o1028c,1623832246.0,[C][E] Job prospects in the private sector after a PhD in Mathematical Statistics ?,"So I'm currently finishing my Master's degree and I'd like to pursue a PhD afterwards, and I'm currently in the process of reviewing/applying to various PhD programs I'm interested in.

Broadly speaking, my interests are in Mathematical Statistics and Learning Theory. It turns out that I've found a PhD offer with the following aims : study of mathematical properties of Bayesian algorithms in semiparametric problems and investigating the choice of priors for optimal posterior sampling. Needless to say I am super interested in that offer (and it turns out that the University's location is ideal for me, and the pay is decent as well so it's pretty much jackpot for me).

However, I'm wondering whether it'd be the right choice for me to pursue such a PhD if I am not absolutely sure that I want to continue in academia afterwards. Indeed, I don't see what kind of job prospects there would be for someone who spent the last 3-4 years e.g. proving theorems for the choice of optimal priors in Bayesian modelling.

All I know for now is that I want to do a PhD in Mathematical Statistics because I like it a lot, I find the field super interesting, there are many problems I'd be interested in solving and overall I could (as of now) very well see myself doing it all my life. However, I don't know if that will still be the case after completing my PhD and I would therefore like to have decent opportunities in industry if I change my mind.

Therefore I want to ask : Are there any interesting job prospects in Industry for someone with a PhD in Mathematical Statistics ? Or should I rather only apply for more ""applied"" PhDs in stuff like Data Science and Machine Learning if I'm not sure I want to continue in academia ?",statistics
o0wm3s,1623817591.0,"[Question] How do you respond to ""what is statistics?""","I was wondering how do people respond to questions like:


* What is a statistician?
* Why did you choose statistics?
* What is statistics?

I have friends who often express curiosity of my major, and I feel like I don't give it justice in explaining it. I'll mention something about ""data analysis"" ,""creating models"", or something like ""applicable to many fields""


I was wondering how do others explain what statistics is and make it sound interesting. Has anyone ever explained it during a conversation with a positive response, if so, how did you describe it?


I feel like statistics is definitely useful, but its difficult to explain how cool it is unless you're someone who is using it.",statistics
o0w6h7,1623816008.0,[Q] What is this r computed from t statistic and df?,"in the last row in the table in https://www.peggykern.org/uploads/5/6/6/7/56678211/ttestformulas.pdf,

> r = sqrt( t^2 /  (t^2 +  df))

What is r? Is it Pearson correlation coefficient r https://en.wikipedia.org/wiki/Effect_size#Pearson_r_or_correlation_coefficient?

Why does the relation hold? Is there some book explaining that?

Thanks.",statistics
o0rffm,1623799599.0,[Q] How do I calculate the average of irregular intervals?,"Hello, first off, english is not my main language and I'm sorry if my question is not 100% clear.

I conducted a survey for my Bachelor thesis and I'm now trying to analyze the results. I'm trying to calculate the average time (in minutes) that the respondants need to go from point A to B, based on 5 different intervals:

1 to 5 minutes: 14 respondants5 to 10 minutes: 42 respondants10 to 15 minutes: 35 respondants15 to 30 minutes: 20 respondants30 minutes or more: 1 respondant (ugh)

I know that if it were regular intervals (if that's how they're called in english), I'd simply need to take the average of each interval, then multiply that by the number of respondants for that interval.

But in this case, the 4th interval is 15 wide while all the others are 5 wide. Can someone please explain to me how I can solve this?

Bonus question: Is there anything I can do with the one respondant that answered 30+?

Thank you very much!",statistics
o0ol5u,1623791162.0,[D] Causal Language - Do you agree with this?,"[https://twitter.com/cecilejanssens/status/1404477565285408771/photo/1](https://twitter.com/cecilejanssens/status/1404477565285408771/photo/1)

This is a list of words that authors suggest should be avoided if the study is observational. I would like to know your take on this. I'm not sure if words like ""contribute"" or ""determinant"" point to causality.",statistics
o0muw4,1623786338.0,[Q] How to analyze survey-based data with Likert-scale predictors and a either binary/Likert outcome?,"I'm designing a study for my Master's on factors influencing Information System acceptance. The literature so far has provided conflicting and inconsistent data as to how to analyze the results. I see some sources treat Likert questions as continuous (and thus fit for linear regression if outcome variable is a Likert) while others classify them as nominal? I am carrying out a survey with relatively representative sample of my target population. Here is how my predictors and outcomes are structured:

**Predictors:**

4 main constructs, with 4 5-point Likert-scale questions each. The responses under each construct will be added to obtain a score from 5-20.

**Outcome** (I am trying to decide which is best for an outcome variable, my two alternatives so far are as follow):

A binary outcome with either a positive or negative decision (Eg: Do you believe you will use this system within X amount of time), or, another (or multiple) Likert-scale question to measure the strength of their intention/decision (for example: ""How likely are you to use this particular system"")

**Analysis goal:**

To see how well each of the four constructs (with a score from 5-20) is associated with the outcome variable

Preliminary research points towards multinomial logistic regression, which I know is used in classification type problems.

If it is not too much to ask, can I get some insights as to what is the best way to analyze my data, which type of outcome is best (binary vs Likert), or what types of analysis I should read up on?


Edit

Some questions:

* Can I do multiple linear regression if both my predictors and outcomes are Likert?
* Is multinomial logistic regression a real option?
* Does having a binary outcome turn this into an easier 'classification' problem, and do you think it is recommended in the context of the study?

Thanks a mil!",statistics
o0lkz6,1623782919.0,[Q] [R] Does anyone have a citation for the equivalence of an interaction regression model between binary regressors and using dummy variables for each combination between the binary regressors?,"It's pretty easy to show on paper that the two models must be equivalent, but my professor (who isn't the greatest at stats) wants a  citation anyway. The problem is, this is such a trivial result that I'm having trouble finding an academic source that actually spells it out.  Any recommendations on where to look?",statistics
o0kz1e,1623781309.0,[Q] Just a guy whos confused,"

A poll reported 56% support for a statewide election with a margin of error of 2.89 percentage points. How many voters should be sampled for a 90% confidence interval? Round up to the nearest whole number.

90%= 1.645.

I have been struggling with this for days and cant seem to get it.  Is there a way to type this in excel or a calc?",statistics
o0kcx4,1623779724.0,[Q] Project scaling and power analysis,"The instrument I am using to survey is somewhat expensive. If I am trying to minimize the number of surveys I give out for evaluation (even though the number of individuals we are treating is increasing), does my a priori power analysis change if I am scaling my RCT project from n=500 to n=5000? My initial thought is no because the a priori analysis would indicate that I need a certain number of surveys to meet power to detect a certain level of effect size, but just wanted to see what others think.",statistics
o0k0re,1623778819.0,"[Q][E] Trying to choose between masters programs, how important is the degree title?","I'm trying to choose between 3 masters programs for statistics, with the following titles:

1. MSc in Mathematics - Concentration: Statistics/Data Analytics
2. MS in Applied Statistics - Concentration: Data Mining
3. MSc Statistics - Concentration: Statistical Theory

If one were trying to get a job as a data scientist, would the title of any of these degrees have a noticeable impact on being hired, generally speaking?

For example, would an MSC in Math with a concentration in Statistics be considered lesser to an MSC in Statistics?

I apologize if this is the wrong place for a question like this but any insight is appreciated!",statistics
o0jtu1,1623778329.0,[Q] Can you find individual significance from T-Test?," If I do a paired two-tailed T-test (p<0.05) on two different sets of data and get p-values for two groups, is there a way to determine which sets from the group were a significant change to determine efficiency change?

For example, if there were two store groups, Walmart and Kroger, selling apples, I could get p-values for their change from week 1 to week 2. Is there a way to find out which individual Walmarts or Krogers more efficiently sold apples as determined by the p-value?",statistics
o0hwxb,1623773297.0,[Q] How do I create a ZSCORE of variable A based on mean/SD of variable B in SPSS?,,statistics
o0ewyd,1623765268.0,[D] Theoretical Performance of Machine Learning Algorithms on Imbalanced Datasets,"Suppose you are working on a supervised binary classification task. You have patient medical information (e.g. age, weight, gender, height, blood pressure, etc) and whether they have a certain disease or not (this is the response variable, ""yes"" or ""no""). Let's imagine that determining if patients have this disease is time consuming and costly - so a machine learning approach is being considered.

Let's assume that this disease is very rare. In your data set, only 1% of patients have this disease. Thus, the dataset is imbalanced.

Intuitively, we know that any machine learning algorithm trained on this data will likely perform poorly. That is, the performance will likely be deceptive: you might get an accuracy of 99%, but misclassify all of the patients who have the disease.

Mathematically speaking: is there any mathematical explanation for this very logical concept?

 E.g. if only study 1 hour for a chemistry exam, I might only learn how to solve 2-3 types of problems - thus, on a true/false style chemistry exam, there will be many questions that I don't know how to answer because I never saw them before, and I will be likely to perform badly on material that I have not prepared for. Do machine learning models work the same way?

For popular algorithms like neural networks, xgboost and random forest - can it be shown that for classification problems, you need a minimum number of observations or a minimum proportion of the minority class to probabilistically achieve a certain model performance?

On a more abstract side, I have heard that researchers are interested in trying to make machine learning models generalize without seeing thousands and thousands of examples. E.g. a 5 year old child can ""learn"" what is an ""elephant"" after seeing a few pictures of an elephant (e.g. it's perfectly reasonable to expect that a young child would see a picture of the cartoon character Dumbo and identify Dumbo as an elephant after coming back from a zoo), but a machine learning algorithm would likely need thousands and thousands of pictures of elephants (and likely require to see the same pictures upside down, inverted, with added noise, different color scheme, etc) prior to be able to generalize and learn the concept of an elephant. Perhaps the same analogy applies to machine learning models struggling to correctly classify patients with a rare disease, since there are so few of them?

Does the above concept have anything to do with the ""bias-variance tradeoff""? Or is it just logic - if there is not enough variability and information within the data, the machine learning model just learns the ""noise"" within the dataset? I am really curious to see if such a threshold for measuring ""minimum level of variability within the data"" has ever been studied?

PS: in a 1 dimensional sense, on a number line, if you have a ""point"" at 3 and another ""point"" at 5 - you could consider all inferences outside of 3 and 5 as ""extrapolation"" and all inferences between 3 and 5 as  ""interpolation"". When dealing with higher dimensional data, could you simply consider observations from the test set that have a smaller euclidean distance to other observations from the training set as ""interpolation"" and observstions that are farther away as ""extrapolation""? In reality, can you just consider all prediction as extrapolation - small scale extrapolation for closer points, large scale extrapolation for further points?

Thanks",statistics
o0e49e,1623762991.0,[D] Generating New Points with SMOTE,"

There is a well-known algorithm in statistics called SMOTE (Synthetic Minority Over Sampling Technique) which is often used to ""balance"" and ""imbalanced"" data set:

[https://en.wikipedia.org/wiki/Oversampling\_and\_undersampling\_in\_data\_analysis](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis)

[https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python](https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/#:~:text=SMOTE%20(synthetic%20minority%20oversampling%20technique)%20is%20one%20of%20the%20most,instances%20between%20existing%20minority%20instances)

[https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)

If I have understood correctly, the premise of the SMOTE algorithm is as follows: Suppose you have a dataset containing information for medical patients that are ""healthy"" and ""not healthy"". But, let's assume that the majority of the patients within your dataset are ""healthy"" (the composition of healthy: not healthy being 95:5) . If you want to make a statistical model for this data, the data does not contain enough information for ""not healthy"" patients, and it will be very challenging to build a reliable statistical model that can make accurate predictions for ""not healthy"" patients. Thus, the SMOTE algorithm can fix this problem by:

1. ""rebalancing"" the data set (e.g. after SMOTE, your data set can have a composition of 70:30)
2. creating ""new"" data points from the ""existing"" data : as I understand, this is done by multiplying a given vector corresponding to a randomly selected individual observation, by some random number between 0 and 1.

This leads me to my question: Suppose you have already have a balanced dataset (e.g. the healthy: not healthy has a composition of 60:40), but let's assume that you have a relatively small dat set to begin with (e.g. 500 rows). Can you use the SMOTE algorithm to create new data points so that your dataset is bigger? I understand that no algorithm can magically compensate for data quality issues, but at the same time I don't see any major flaws with using SMOTE on already balanced data?

For reference, I illustrated this process below using R:

I would be interested in hearing a second opinion - Thanks!

    #load and install libraries
    remotes::install_version(""DMwR"", version=""0.4.1"")
    library(DMwR)

     #create some fake data and put them into a data frame called ""f""

    var_1<- rnorm(100,1,4)
    var_2 <-rnorm(100,10,5)
     var_3<- c(""0"",""2"", ""4"")
     var_3 <- sample(var_3, 100, replace=TRUE, prob=c(0.3, 0.6, 0.1))

     response<- c(""1"",""0"")
    response <- sample(response, 100, replace=TRUE, prob=c(0.3, 0.7))

     #put them into a data frame called ""f""

    f <- data.frame(var_1, var_2, var_3, response)

     #declare var_3 and response_variable as factors
    f$var_3 = as.factor(f$var_3)
     f$response = as.factor(f$response)

    #SMOTE algorithm
    #simulate new points from the first class

     smoted_data_over <- SMOTE(response~., f, perc.over=100)

     #simulate new points from the second class
    smoted_data_under <- SMOTE(response~., f, perc.under=100)

    #combine everything together into a final new data file
    final <-rbind(f, smoted_data_over, smoted_data_under)",statistics
o0aqw9,1623751403.0,[Q] Can you calculate effects size from prevalence when doing a meta analysis?,"I'm new to using Stata16, trying to run a meta analysis comparing prevalence data from 21 observational studies, is this possible?",statistics
o05k0o,1623730906.0,"[Q] I've implemented nonparametric bootstrapping, but I still don't believe that it should be able to give useful statistics. What should I look at to better understand why bootstrapping works?",,statistics
o02xbi,1623722406.0,[D] Assumptions of K-Means Clustering,"I have often seen blog posts like this

:

https://blog.learningtree.com/assumptions-ruin-k-means-clusters/


http://varianceexplained.org/r/kmeans-free-lunch/

Which show that K-Means Clustering Algorithm is unable to handle complicated data, and can only recognize clusters within ""spherical clusters"".

I have often seen this shown empirically (like in these blogs), but are there any mathematical justifications that explain why K-Means is unable to recognize clusters in more complicated data (e.g. concentric circles, crescents, etc.).

Why is k-means only good for specifically spheres? Beyond empirical demonstrations, are there any reasons why K-Means receives a lot of criticism?",statistics
nzzwmw,1623712850.0,[Q] extend to a 5th year just to get a math minor?,"Hello all, I’m currently a rising 3rd year at my university in the US majoring in statistics. I’m considering going to phd programs after college. I’ve heard from people that my major isn’t the strongest for theoretical math prerequisites for top schools, but I can get into a mid tier school with my current classes . I will be taking intro real analysis (not the rudin one), linear algebra (lower div), and introduction to proofs (logic class), these are all part of my stats major. I don’t have any topology, measure theory, or other stuff under my belt with regards to theoretical math. I’m a stats major so I have stats classes, but I’ve been told I’d be at a disadvantage for some top PhD programs because I don’t have intense math rigor. With that being said, I do have the option to do a math minor in addition to my stats major to take more math, but since I will be a third year in the fall this would require for me to do a fifth year. How does a fifth year look to phd programs? Do you think I should do it if it will make me get into more top schools? Will doing a fifth year for the minor be a waste? And should I just get into whatever program accepts me?  Does the prestige of your PhD grad school really affect job chances? (I want research scientist roles). Any advice would be appreciated thanks. I will most likely have two papers published by the time I graduate from undergrad research but I’ve heard some grad schools don’t care about it and only care about your grades in theoretical math classes. I will also have 4 profs who will give me letters of recommendation, and currently have a 3.4 gpa, (screw general Ed courses).",statistics
nzzmz3,1623712054.0,[Q] What is being assumed by the sampling process if one uses randomization inference/permutation tests vs calculating standard errors 'normally',"Say I am regressing a dependent variable y on a treatment indicator to get an average treatment effect.

I could calculate standard errors and p-values by taking the variance of the difference in means, taking the square root, and then using t/z tests to calculate p-values.

I could also do randomization inference, where i randomly assign units in my sample treatment status, run the regression, and see the proportion of times these are at least as large as my actual effect.

Why use one over the other? what assumptions are being made when one uses either? does the first assume i could resample a new pair of units and assign treatment again, and the latter assumes my sample is the population of interest?",statistics
nzzmf8,1623712010.0,"[Q] Outliers, Robust vs. Standard Mahalanobis","I'm cleaning some messy survey data that I've collected with a dozen or so psychometric instruments. I've been reviewing it with the Careless and Routliers R packages.

I've got literature for both methods, but there seems to be less literature showing the effectiveness of using the robust Minimum Covariance Determinant (MCD) on psychometrics. What do we think about choosing one or the other Mahalanobis?

Thanks!",statistics
nzxryr,1623706775.0,[Q] What testing problems are the outlier detection methods using Z-score and on Mahalanobis distance based on?,"I heard that there are two ways of detecting outliers:

- For univariate: use Z-scores with an alpha of .001 to eliminate very extreme values. This corresponds to a Z-score of +/- 3.

- For Multivariate:
Use Mahalanobis distance, which is is distributed as a chi^2 distribution, with an alpha of .001 to eliminate very extreme values.

Are the two outlier detection methods   based on some statistical hypothesis testing problems? (Looks like yes to me, because there is level alpha of significance involved)

If yes, what are the testing problems?

Thanks.",statistics
nzxq7j,1623706639.0,[Q] Book Recommendation on SNPs,"I work as a statistician but need to know a lot about biology. Current I need to know about SNPs/variants. Does anyone have any suggestions for books, articles, or something I can use to study?",statistics
nzwk7c,1623703552.0,Finding relationships when making crypto predictions[Question],"Hi,

 I only know basic stats currently but will be learning more via this.

I am looking at tests to find relationships.

The data will be a time series for each token/coin.

I am planning to use: Granger causality, Dickey-Fuller for stationary of the series, maybe a usual chi squared test. Maybe I need one looking at correlation

After performing these tests and possibly more, I will use machine learning and see what that has to say - this will involve regression.

** I am here to ask what other tests may be useful and what methods could help for time series forecasting? **

Thank you",statistics
nzta1a,1623694907.0,[Q] What kind of job would I be able to score in data science / analytics?,"This  is an unorthodox question in this thread, but I've been thinking  lately, so here we go. Basically, I'm a Ph.D. candidate in a  Humanities/Social Science field, but since I've been doing experimental  work for more than 5 years, I've had to delve into applied statistics  and analytics fairly deeply because the methods I needed for my actual  work were not covered in the university curriculum. Lately, I have been  considering (or rather, playing with the thought of) switching careers  to something more lucrative than my original field, and trying to get  into data science would seem like an obvious choice, given my  background. However, since I do not have a formal data science /  statistics degree, I'm wondering: what kind of data science/analytics  jobs would I be able to get (if any) with the following skillset (which I  can demonstrate at any time at a job interview, despite having no  papers), and what kind of payment would I reasonably be looking at?

\-  I am fairly proficient in the use of SPSS (around 6 years experience  doing own research and tutoring others), doing data manipulation,  preparation, cleaning, essentially every kind of statistical test SPSS  is capable of (besides Neural Networks, I'm not a ML guy)

\-I  have experience using R (around 3 years, on and off), and with some  online help and example code, I can do whatever I need that SPSS cannot  do (cumulative logit models, DWLS factor analysis, visualization,  whatever) but I admit I'm slower in R than I am in SPSS. I would say I'm  an intermediate user.

\- I have  some experience using Python (studied it as part of a compulsory course  at university, but I have never followed up on it, and forgotten most of  it. ). I would probably be able to brush up on it in a few months if it  was really required, but I would prefer to use R or SPSS, since I never  really liked Python (compared to C++ which I also had to study).

\-I have substantial experience with IBM AMOS for Structural Equation Models / CFA

\-I have working knowledge of Excel/Word, obviously, I'm somewhat more familiar with the latter, but not LaTeX

\-  I have been exposed to SQL very briefly as part of a summer  crash-course, but I wouldn't say I'm an independent user in any way.

\-I  am not 'extremely' good with the pure, theoretical  mathematics/mathematical statistics part (well, I'm not a statistician  by training) but I have a fairly solid understanding of the basics of  probability/linear algebra, and I would say I have a better conceptual  understanding than the majority of ""applied"" researchers coming from a  non-stats background with a ""cookbook"" approach to stats.

What  other skills would I need to hone to stand a chance at scoring a job  (even something like junior analyst) at a decent company?

Thanks for the feedback!",statistics
nzspi8,1623693412.0,[Q] Bayes’ Theorem & Precautionary Principle,"Hello, I’m currently reading up on Bayes Theorem in preparation for handling environmental statistics next semester, and I have some questions about the information:

- Is the line drawn much like walking a tightrope, when we discuss Bayes rule and the precautionary principle?
- Is Bayes rule & theorem the form of statistics best suited to tackle questions of precautionary principle (I.e. when we discuss pollution’s impacts on human health. Is Bayes’ theorem best suited to answer questions of where the invisible ‘line’ between too much restriction on a pollutant and too little restriction? (Based on metric of human health and negative impacts on it and the environment.))
- OR is the very application of precautionary principle a further “bias” when handling data?",statistics
nzs1av,1623691598.0,[Q] Statistics question: ANCOVA or Linear Mixed Model?," We have a DV (depression) measured at 3 time points. Two IVs, one is a binary IV based on therapy time, using random assignment. The other IV is a continuous variable measured only once called alliance score (this measures how well the patient and therapist worked together). We want to know whether depression is significantly related to the two IVs. Again, we have 3 measurements for depression (baseline-T0, 3 months-T1, and 6 months-T2).

I am curious what analysis most people would run here? I have two thoughts:

1. A two-way ANCOVA method (with no interaction), where the DV would be Depression in T2 and the IVs would be treatment, alliance score, and depression at T0. The idea is to see if there is a treatment effect (or effect of alliance) controlling for baseline (T0) depression. This would mean not using T1 (or possibly doing 2 models, where depression at T1 is a DV as well)
2. A linear mixed model, where time is nested with each person. This way uses T0, T1, and T3 for depression as the DV and then the IVs would be treatment, alliance score, and time. An interaction between time and treatment would tell us whether the two groups experienced different rates of change in depression over time.

I would prefer to the run the first, given its simplicity. I think either analysis could be justified, and want to know what some experienced researchers think.",statistics
nzrjej,1623690296.0,"[D] are all statistical models based on the concept of ""similarity""?","Do all statistical models indirectly work based on the concept of ""similarity""? E.g. two data points that are very close to each other share more similar properties with each other compared to some point that is further away? Is this one of the ""inductive biases""?",statistics
nzqdr9,1623687231.0,[Q] Are these three models for simple linear regression the same?,"In Casella and Berger's Statistical Inference,
*11.9.2  Best Linear Unbiased Estimators: A Statistical Solution* gives a model at the beginning of the section on p544~545:

> (11.3.13) Y_i = alpha + beta*x_i + eps_i,   i=1,...,n
>
> where  eps_1,...,  eps_n are uncorrelated random variables with
>
> (11.3.14)  E eps_i = 0, and Var eps_i = sigma^2

and then show the least square estimators are the BLUEs under the model.

(1) At the end of the same section on p548:

> The fact that least squares es­timators are BLUEs holds in other linear models also. This general result is called the Gauss-Markov Theorem  (see Christensen 1996; Lehmann and Casella 1998, Section  3.4, or the more general  treatment in Harville 1981).



Isn't the model at the beginning of the section the model for Gauss-Markov Theorem?

If not, what is the model for the Gauss-Markov Theorem? Or what is the difference between the two models?

(2) Is the model at the beginning of 11.3.3 the same as the model (11.3.1) and more given at the beginning of *11.3  Simple Linear  Regression* on p539?

Thanks.",statistics
nzo7mc,1623681360.0,[Q] What prevents automated exploration of alternative model parameterizations in MCMC?,"I have a Q regarding the use of MCMC to sample from the target distributions of varying geometries, specifically wrt the automated exploration of joint posteriors of models with both centered and [non-centered](https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html) parameterizations. I feel that when implementing e.g. hierarchical GLMs in Stan, I must often rely on vague heuristics (re: the prior magnitude of the parameters themselves) for whether one one form or the other will improve sampler efficiency, and sampling of some parameters in the same model may benefit from the non-centered form where sampling for other parameters may not. Often the final arbiter of what’s appropriate where is observed performance, since occasionally the non-centered form will sample more efficiently.

Since reparameterization is such a straightforward & rote procedure, why not incorporate it into something like the warm-up process? A user could specify the model in its fully centered form (which, read aloud, is often much easier for me to parse, at least), and an algorithm could toggle on-and-off different parameterizations and try to adaptively identify which transformed target distributions are easiest to explore (according to convergence & mixing diagnostics like E-FMI or w/e). Is the reason this is not done just that warm-up would have to start from scratch with each parameterization (but would it?).

Even so, it seems like something that would be fairly straightforward to implement, even at the cost of lots of early redundancy (certainly faster than doing everything by hand). Just something that enumerates (some subset of) possible non-centered parameterizations, launches however many independent samplers, and then prunes the ones that are sampling poorly might offer considerably improved convenience and efficiency.

Alternatively, if there are hard and fast rules re: when one parameterization is more efficient, it seems like those too could be caught and implemented automatically.

Am I missing something here for why this isn't done?",statistics
nzmkco,1623676603.0,[Q] What are relations and differences between ANOVA and n-sample problems and independence problems?,"Is one-way ANOVA (with a n-level factor) basically an n-sample problems?

Is two-way or m-way ANOVA basically similar to independence testing problems?

Thanks.",statistics
nzi0un,1623659055.0,[Q] Skewing Results by Filtering out any Item with Missing Values?,"Taking entry level statistics here and working with SPSS. For my statistics class I'm doing a regression on certain stats on different countries, however one of the 3 independent variables I'm using just happens to have a good amount of missing values. I decided to filter out every country with missing values but of the 198 countries I had only 66 remained. Will this skew the statistics terribly?",statistics
nzgd1n,1623651653.0,[Q] Statistics of data pooling?,"Are there any statistical methods for qualifying the combination of two datasets, i.e. data collected by two different research teams with their own experimental setups?

This is obviously quite a common occurrence in medicine trials, and in engineering the most obvious example I can think of is the Moody diagram, which was constructed from pressure drop experiments by a wide variety of researchers.

Would the justification be based on verifying that the same experimental conditions were used by both teams? If so, this seems a bit ‘loose’, since it would neglect any influence uncontrolled variables (say, ambient temperature) might have on the results. Alternatively, is there some quantitative statistical method of proving, for example, that the relationships between the response and independent variables are not statistically different?",statistics
nzdhot,1623641242.0,[Discussion] Predicting Euro 2020 matches with Bayesian statistics,"See my repo [here](https://github.com/Dpananos/Euro2021Predictions).

Basically, Andrew Gelman has a little world cup case study for Stan.  When a coworker approached me to fill in some predictions for the euro group stage, I thought I should use that model.

I collected qualifying match data along with EUAFA rankings for each team and built a Bayesian model to predict the outcomes of each game.

The model does well...for now.  Using prediction = argmax(P(x)), I've succesfully predicted 5/7 games (I predicted Denmark to beat Finland, but a tragic event likely affected the players on that team and so I chalk that model error up to unpredictability).  With numbers, I'm averaging a log loss of about 0.8.  Random guessing of team A wins v. Team B wins v. Draw would result in average log loss of 1.1.  When I fit the model to Euro 2016 data, it has an AUC to predict the winner of approx 0.72.  This may not be impressive to a seasoned football fan, but for a guy who passively follows international matches, its been a huge improvement.

Lots of time for me to screw it up.  I write up some thoughts about the model and some model checking in the linked repo.  Would love to hear what other people have to say.",statistics
nz6b3x,1623619231.0,[Q] book recommendations for college supervisor,"Hi everyone! I am looking for book recommendations.
I am finishing my Masters degree soon and I would love to give a present to my supervisor, as he was amazing to me and helped a lot. I thought about sending him a book, but I am not really advanced in fields of statistics, machine learning or data science and it's hard for me to choose anything advanced enough to buy anything that would be special.
So my question is, are there any books that you would love to have, or have and absolutely love? Thank you all in advance.",statistics
nz4snl,1623615016.0,[Q] Using a t-Test to compare baseline and end value?,"Hello, I hope someone here would be kind enough to help me with this:

I have a group of people with weight data, which we measure during 6 weeks; the average weight increases towards the end.

Now, in a similar case, one of my colleagues has done a t-Test to compare whether the difference between the baseline (mean) value and the final (mean) value (after 6 weeks) is significant. However, a statistician I talked to said that a t-Test in this case doesn't make sense and that one shouldn't do it. Could you help me understand why? Or did I misunderstand something.

Thank you kindly for answering my question in advance",statistics
nyzin4,1623600181.0,"[D] Is this the correct understanding of ""partial dependence plots""?","I was reading about ""partial dependence plots""

https://christophm.github.io/interpretable-ml-book/pdp.html

https://blogs.sas.com/content/subconsciousmusings/2018/06/12/interpret-model-predictions-with-partial-dependence-and-individual-conditional-expectation-plots/

https://rpubs.com/vishal1310/QuickIntroductiontoPartialDependencePlots

Just to clarify, is this the right idea? Suppose you have a model : blood_pressure = 1.4 * height + 3.2 * weight

A partial dependence plot could help you understand the effect of ""height"" on ""blood pressure""? If you were to make a plot of ""height vs blood pressure"", you would be indirectly modelling the impact of ""weight"" as well. A partial dependence plot is able to completely isolate the impact of ""height"" on ""blood pressure""?

Is this correct?

Thanks",statistics
nyzgig,1623600035.0,[Q] Is there a way of working out prevalence with multiple variables and over time?,"Hello, I'm trying to extrapolate prevalence data for a medical disorder that impacts both upper and lower extremities, and how that prevalence has changed over time, is this possible?

n=1,736
baseline prevalence: upper limbs 30%, lower limbs 41%.
5 year follow up prevalence: upper 36%, lower 56%

This particular line has confused me:  ""Time trends were as follows: the proportion of residents who had no contractures on admission remained contracture-free after 5 years was 59.7% for upper limbs and 39.8% for lower limbs, while the proportion of residents who had developed new contractures after 5 years was 15.1% for upper limbs and 26.5% for lower limbs.""

Because there was no data available on those who were affected with both upper and lower, I'm uncertain as to how to continue. Thanks in advance",statistics
nyrwmm,1623572895.0,[q]spc,"Hi

I doubt I'll ever fully understand when I should use spc charts to monitor process. I get figures each month from a region which are an amalgamation of several hospital figures in the region. I want to know if I can and should be using spc on this data.

For example.

This month I got for the region 22.  Which is 4 hospitals that submitted figures 2 10 5 5. So my boss has asked me about doing an spc taking previous month's data. I'm just not sure if it SHOULD be used here. He wants to see if when they are constantly reporting high if this is just their normal.

Any help much appreciated.",statistics
nyr3t3,1623569052.0,[Q][E] What level of Abstraction in Linear Algebra is Appropriate for Coursework in a Statistics PhD Program?,"Really is two questions. 1) In a stat phd program, to what level of abstraction in linear algebra do the courses typically get? I find Linear Algebra Done Wrong and Axler's Linear Algebra Done Right on two levels, with the latter having more difficult exercises.


2) What is the expected level linear algebra training for a student beginning first year curriculum in a stats phd program? Is it at the level of say Strang OR at the level of Axler? And specifically what parts of linear algebra are particularly important in the first year? I suppose we wouldn't be doing too much Gauss Jordan elimation, or reproving rank nullity...",statistics
nyqzp1,1623568520.0,"[Q] Could someone ELI5 p-values for me, please?","I’m stuck on an infernal statistics sections in my psych. textbook and it’s about p-values. They are introducing them to us, in relation to experiment results and I just can’t wrap my head around it.

*This is what I think that understand so far:*

A p-value can help decide whether it’s more efficient to use either the mean, median, or mode for the central score, I think. It will also tell if the difference in data between the experimental group and control group falls within the realms of chance, or if there’s a probability that the difference was the result of the actions taken to influence the experimental group.

*And here’s where I’m having trouble:*

The problem with using a p-value is that the curve ranges from “convincing to unimpressive”. I think by convincing they mean that the deviation is probably a result of something done in the experiment. Another problem “is that we should care about the size of the effect and not wether or not it occurred. **given a large enough sample, it would be possible to even for a tiny effect with no practical importance.”**

I don’t know why. It’s just not clicking for me, especially that last line. Math is not my strong suit. I would greatly appreciate if someone could put this in dumber terms for me.",statistics
nykqjw,1623544355.0,[Q] How to find correlation between two independent variables?,I am very new to statistics and I am trying to do a statistical analysis on these two independent variables? This might be very basic question but could someone share what could be a good way and also what online resources I could use? Thanks!,statistics
nyfov4,1623529762.0,"[Q]How can I measure the relationship between one independent variable and multiple dependent variables, but the dependent variables are a mixture of both continuous and categorical variables?","The independent variable is continuous. Which model would be most appropriate?  I would appreciate being directed to any solution using python packages, such as sklearn or statsmodels.api.",statistics
ny8wwe,1623510718.0,[Q] AIC Questions,"Hi there, I'm new to statistics and have two question about the AIC.

1. Why is it that I see a lot of people say that the max of the likelihood function can be approximated as the sum of the square residuals? I understand that this might be a simple questions, so a link to a paper or textbook would be helpful too.
2. I have seen that the AIC is calculated using AIC = 2k - ln(L) yet when I look at the lmfit module in python for example, I see they use something like 2k + N\*ln(sum\_of\_residuals\^2/N). What is the difference and is the second still useful?

Thanks for the help and patience.",statistics
ny0vvl,1623481606.0,[Q] What test would I perform in the case of a continuous independent variable versus a categorical dependent?,"I know that if this was flipped around, I would either do a T-test or linear regression, but am unsure what to do when the independent variable is continuous rather than the dependent, ack. Does anyone have any suggestions? A humongous thank you!",statistics
nxz6y7,1623474693.0,"[Q] Steve Kirsch COVID 19 Vaccine claims , one of the worst misuses of statistics in recent memory?","

Hi,

I recently listened to a podcast from Bret Weinstein which features Dr. Robert Malone and Steve Kirsche. Kirsche has put together a paper claiming that he has evidence that research shows that in one study the vaccine has cause a miscarriage rate of 82%. It is #3 on his key points [https://trialsitenews.com/should-you-get-vaccinated/](https://trialsitenews.com/should-you-get-vaccinated/)

The link leads to his paper, where he has cited a study done in the New England Journal of Medicine ( [https://www.nejm.org/doi/full/10.1056/NEJMoa2104983](https://www.nejm.org/doi/full/10.1056/NEJMoa2104983)) and altered some of the findings.

The results of the study in the New England Journal were "" Among 3958 participants enrolled in the v-safe pregnancy registry, 827 had a completed pregnancy, of which 115 (13.9%) resulted in a pregnancy loss and 712 (86.1%) resulted in a live birth (mostly among participants with vaccination in the third trimester). Adverse neonatal outcomes included preterm birth (in 9.4%) and small size for gestational age (in 3.2%); no neonatal deaths were reported. ""

Now he has taken that quote and claims "" the authors report a rate of spontaneous abortions <20 weeks (SA) of 12.5% (104 abortions/827 completed pregnancies). However, this rate should be based on the number of women who were at risk of an SA due to vaccine receipt and should exclude the 700 women who were vaccinated in their third-trimester (104/127 = 82%)""

My background is in math, not statistics, however this seems very odd to me. Can someone please articulate what is going on here?",statistics
nxw9dm,1623464352.0,[E] Any tips/suggestions on how best to utilize the rest of my summer prior to my combined MS in Biostatistics/Bioinformatics?,"I come from a Biological sciences background, but have taken Calc I-III. I've been allowed to take Linear Algebra in my 1st semester of the program.

What topics/subjects would you guys recommend I revise in this interim period before my program?",statistics
nxv294,1623460269.0,[R] Modelling Baseline for longitudinal research,"Hi have a question about study design i'd hope brighter minds than mine can help with

Let's say i'm trying to run a linear mixed model (LMER in r for example) with a single repeated measurement, random slope and random intercept. I have a cognitive measurement as DV. The researchers have measured baseline three times over three days prior to intervention

Let's say for example we treat times 0 1 and 2 coded as time 0 for a repeated measure. How would this effect the covariance structure? Would this just merely provide more variance for the baseline intercept? Would this bias the slope given the increased n for baseline?

What would be the benefit of this method over lets say averaging the scores for 0,1,2 as a baseline score?  I could imagine that having some knowledge of the individuals variability for cognitive score may be useful...Would there be a third option?",statistics
nxn6mg,1623437138.0,"[D] Can we begin to understand possible mathematical reasons as to why algorithms like ""xgboost"" and ""random forest"" win Kaggle Competitions, instead of neural networks?","Could there be any mathematical reasons behind why algorithms like random forest and xgboost are known to win Kaggle competitions (i.e. perform well for medium sized tabular datasets) compared to deep neural networks and linear regression models?

Heuristically, here are my general conclusions:

1) GLM (general linear models) perform best on smaller sized datasets, provided certain statistical assumptions are met.

2) boosting and bagging algorithms (e.g. random forest and xgboost) perform best on larger tabular datasets, and do not require many statistical assumptions.

3) deep neural networks perform best on very large datasets, preferably on non tabular datasets (e.g. tensors, pictures, audio, computer vision, text/nlp).

But can there be any mathematical reasons that try to explain these general conclusions (provided these conclusions are correct)?

For instance, suppose there is one response variable and one predictor variable, and when graphed together they look like a sine wave - it seems unlikely that a linear regression model could perform well. Perhaps this is because a linear model can only capture a linear trend? Perhaps it is too hard to understand the exact assumptions required for GLM models to work on real world data, or they are too prone to overfit on complex data?

The same way, is there any math that explains why alphaGO, self driving cars and Google's BERT NLP model are all based on neural networks - and not using random forest and xgboost? Is this because there is some mathematical property of random forest and xgboost which severely hinder their performance on very big and complicated datasets? Perhaps it can be shown theoretically that random forests require an exponentially large amount of trees to model complex data, which is just not computationally possible ... or would surely result in overfitting?

And the same way, is there any math that explains why deep neural networks aren't as successful as random forest and xgboost on medium sized tabluar datasets? Do deep neural networks simply require too much effort to select the right combinations of hyperparameters, and its just not worth it for medium sized datasets when random forests work well given significantly less effort? Are deep neural networks to prone to overfit medium datasets?

Of course, all of this comes to down to trial and error: if a certain model fits the training and test data well - then use that model. But just using mathematical logic and intuition, can we develop some general guidelines that tell us which conditions and types/size of data are favorable for specific algorithms? This could potentially save us a lot of time by directly trying better suited models for the task at hand (e.g. not even trying to use logistic regression for alphaGO).

So in the end: Beyond empirical results, could there be any mathematical reasons behind why random forest and xgboost are chosen in kaggle competitions compared to deep neural networks? And beyond empirical results, could there be any reasons why random forest and xgboost are not chosen for the ImageNet competition?

Thanks",statistics
nxer3f,1623414300.0,How would you go about to prove/analyze a model with a quadratic effect on the dependent variable? [Q],"I will try not to go into too much detail.
I have data on the number of times someone is late at a particular event (the dependent variable) in relation with their success, age, and a number of other personal characteristics.
I want to predict the number of times someone is late based on these characteristics. So, I have a model with a count variable, as dependent variable, which has a Poisson distribution.
I expect, and can observe in the univariate analysis, that the success of a person at first is negatively related to the number of times he is late (the less success someone has, the more this person is late). However, for very persistent latecomers (high values of the dependent variable), this relation becomes positive (i.e. the more success the person has, the more this person is late). In other words, I get a parabola where the axis of symmetry is horizontal. A relation with a quadratic effect on the Y-variable.

The problem off course is that this is not a function because for these kinds of relationships you have multiple X-values for a given Y-value.

Hence my question; How would I best go about to model this relationship and statistically prove/show the non-linear effect of success on ""being late"" without disregarding the other control variables?

I now use a multinomial logistic regression were every value of my dependent variable is a ""category"" so I can show that the sign of the relationship between ""number of times late"" and ""success"" is reversed at a given value of ""number of times late"" (i.e. the ""top"" of the horizontal parabola).

Thanks!",statistics
nx6nrf,1623383597.0,[E] University Major,"Not sure if this is the right place to ask but any answer is greatly appreciated!

I'm in my second year (out of 3) of university but still have the space to change majors. I'm unsure what I want to do after uni but definitely in trader/quant/DS/ML field. Currently I'm taking a DS and Econometrics Major at University of Sydney in Australia. I'm wondering if these majors are the right ones to pick for the jobs listed. I didn't take DS/Stats because the way I'm specialising in DS, I will already be qualified for a stat major (even though not recognised by the uni). The other major I was thinking about is Financial Maths and Statistic, which goes through optimization, stochastic processes, financial derivatives and the likes. Currently in econometrics I'm taking classes like forecasting, econometrics in ML, financial markets, and in DS I take probability, applied linear models, and statistical machine learning.

My main question I guess is am I on the right track in terms of choosing classes, and is it worth for me to switch my econometric major to the financial mathematics and statistics? Thanks in advance!",statistics
nx46kz,1623375406.0,[Q] Is there a forum or website where I can post job offerings for stats?,"E.g., I have a very straightforward stats job offering (basic chi squares only with no corrections) that would take a max of 5-6 hours to do, but as I'm always at work I would prefer to pay someone to finish things up (I wouldn't mind stats grad students!). Is there somewhere appropriate where I can post an offer like this? Thank you all so much!",statistics
nx21l5,1623368813.0,"[Q] Any (intuitive) resources for understanding fixed-, random-, and mixed-effects models; and, how to decide which is appropriate in a given context?","Interactive websites, videos, or text (less preferred) would be really helpful. Thank you :)",statistics
nwvbgc,1623351125.0,[Q] How to deal with reports of mother's and fathers statistically.,"Hi everyone,

I have reports of teens on how they percieve their mothers and fathers. What I am finding in the correlation matrix is that the mother and father variables generally display the same relationship with variables, and are correlated with one another by about .45 to .68. Would it be possible to combine reports on mother's and fathers into a single parent variable? If so, what would be the best practice to do so in SPSS. I have heard of people combining mother and father variables and taking the mean of the two together as an option. Is that a good practice or a better alternative?",statistics
nwudtw,1623348820.0,[Q] Is there a standard for measuring how noisy a signal is over time with respect to a ground truth?,"So let's say I have a machine learning application and I want to compare two models.

Let's say I have a signal output that ranges between 0-1 for 100 timestamped samples. The ground truth (correct answer) would be 0.5.

Model 1 outputs 0 for 50 samples then 1 for 50 samples.

Model 2 outputs 0,1,0,1...  alternating for all 100 samples.

Both models will have the same average error, but one is less ""stable"".

Is there a way to measure this stability? I'm guessing the naive approach is just to sum the absolute difference between each subsequent sample? Is there an industry standard way of measuring this?

And what if the timestamp between samples is not uniform? As in some samples have a different time delta between subsequent samples?",statistics
nwudi0,1623348794.0,[Q] Help with IF/THEN Statements in SPSS,"

Hi everyone,

This might be a very stupid question but I am having a lot of trouble figuring this out. I am using SPSS.

I am trying to categorize people into one of two groups (1 or 0) based on their attraction ratings to various ages.

I want to assign people to get a ""1"" if their score for male/female 18-25 years olds is greater than all other groups (i.e. male/females 26-35, 36-45, 46-55, 56-65, 66+). So basically, to get a score of 1 you need to have a higher attraction rating for males OR females 18-25 than all the other possible groups.

So far, I thought I could go to Compute Variable -> ""If..."" -> ""Include if case satisfies condition"" -> plug in ""18-25M/F > (all my other group variable names)"" and then once I continue back to the compute variable section I would just input ""1 ELSE = 0""

This doesn't work. I have also tried it a different way by just putting it straight into the Compute function but I get the same error, which is: 127 EXECUTE During execution of the indicated command, one of the operands of AND or OR had other than a valid logical value. The valid logical values are 0, 1, and missing. The invalid value has been treated as a system missing value.

I appreciate any help with this... Thank you!",statistics
nwtvkx,1623347559.0,[Q] Trouble with understanding mixtures,"Hello everyone. I've been studying gaussian mixtures for a project of mine, and I can not for the life of me understand what they represent. So far I assumed a gaussian mixture with 5 components was essentially a weighted 5-dimensional normal distribution. However, in some papers I've read, the number of dimensions of an observation is bigger than the number of mixtures.

Is there a transformation of variables that I'm missing? Or did I completely misunderstand the subject?",statistics
nwrobu,1623342046.0,[Q] Calculating a significant statistical difference between the numbers of three groups,"Calculating a significant statistical difference between the numbers of three groups

Hi,

I should start by saying that I am statistically illiterate. I am writing a review on a scientific paper. and would like to know if I can write that the difference in 'lost to follow-ups' in each group is significantly different (statistically). By significantly different I mean a less than 5% chance that it is a random occurrence.

There are three groups, at the beginning of the study they had:

 * Group 1: 41 participants

 * Group 2: 39 participants

 * Group 3: 39 participants

Over the course of the study 20 participants were lost to follow-up (dropped out) and these where divided as:

 * Group 1: 8

 * Group 2: 9

 * Group 3: 3

I have tried using some of the various calculations and my brain did a little melty. I then triumphantly gave up. Somewhere a small spark went off in my brain that said the absolute wealth of ability that resides on the various subreddits of the world would delight in completing this piece of arithmetic for me.

If anyone can help me I would be incredibly grateful and pay you with kudos.

I basically only want to know about group 3. It is not beneficial for me to know if there is a difference between 1 and 2.",statistics
nwp824,1623335910.0,[Q] Could you give me suggestions on how to get better at statistics?,"This is kind of a broad question. I'm not in the stats field, but I need statistics for my degree (social science). I wanna improve in interpreting data. That includes making sense of the math and stats. But I'm not good at either of those.

I've been recommended some textbooks on statistics (e.g., Gravetter, Levine, etc.). I don't have a copy of the books yet. Before I get them, I wanna ask, do you have any recommendations for textbooks or even online courses (coursera, etc.) for stats?

Recommendations for math stuff like calculus, if that's helpful or necessary, would be good, too.",statistics
nwmzhe,1623329870.0,[Q] Use case for a Hidden Markov Model?,"
Hello guys, I work with my schools baseball team and I built a markov chain to simulate pitch sequences given after the first pitch was thrown. So day fastball was thrown, what was the next most likely pitch, or maybe 20 most likely.  they said that they wanted me to include outcomes in my markov chain, as in, just simulating pitches wasn’t enough they wanted to know, what kind of pitch sequence would produce a specific outcomes, such as an out, strike, etc.

In other words, what sequence of pitches has the highest probability in yielding a specific outcome.

My first through was to use a hidden markov model, saying my hidden states are pitch types “fastball, curveball, change up, slider”, and my observed variables are the specific outcomes (strike, double play, out, etc)

That way I can get the sequence with the max probability of yielding a specific outcome that’s observed.


For example the coach told me “our main pitcher had 7 strike outs one game using the same sequence of curveball,slider, curveball, and he usually has a weak curveball, so we don’t know how that happened but if there’s a pattern between what outcome there is and the specific sequence, we want to know which sequence had the highest chance at yielding strikes or outs”


So would this be a good opportunity for using a hidden markov model? Any other suggestions?",statistics
nwlgpj,1623325205.0,[Q] Trying to examine if there are statistically significant differences between multiple variables in 4 groups,"So I have 4 groups of data (grouped by me), and in each group there are 5 measured variables. These are all vectors, with different lengths (different numbers of samples) between groups.

I have tried using tests like Kruskal-Wallis and ANOVA, but these only allow me to compare 1 variable at a time between the groups.

I have also tried MANOVA (and Linear Discriminant Analysis), but hit a bit of a dead end with that because my data re-projected into 2D space didn’t show that it was split into clear regions of the plot (by group - and isn’t it meant to?)

What I want is to be able to do is,

1) examine if there are statistically significant differences between the groups (in terms of the measured variables)

2) given a value for each of the variables, *predict* which group that data point would belong to. Can anyone offer any suggestions?",statistics
nwkbbw,1623321153.0,[Q] How would I calculate the standard error of (b1/b2) in regression model?,"Let's say I estimate the following regression model

Q= \\alpha+ B1x + B2y + e

I rearrange it to

Q= B1(x- (alpha/B1)) + B2y + e

How would I calculate the standard error of (alpha/B1)? I want to calculate the if this value is different from a number P but of course I'll need the standard error. Also, what do I about the distribution? check the distribution of (alpha/B1)? or assume normality",statistics
nwj7e8,1623316587.0,"[Question] Would it be right to say ""Normal Distribution is popular but not the most prevalent"" ?","In statistics and probability, people often assume that the data generating process follows normal distribution. Most of the assumption about error especially errors in linear regression is assumed normal. I have worked in Data Science and NLP, I often find that the process does not always have a normal distribution. Even talking to data scientist /statistician friends from different industry, I get to know that , 'Normal distribution' is perhaps a theoretical assumption, but in realty it is never the case.

However detractors always point to central limit theorem and law of large numbers. Would it be right to say ""Normal distribution is popular but not the most prevalent"" . What examples can one give from their line of work or from statistics itself to prove this point?",statistics
nwbzqo,1623289442.0,"[Q] How to represent many different ""types"" of results for one sample and/or in one figure? (""opposite"" of PCA?)","Sorry for the vague title, I don't know how to word this. I'm looking for a way to simply visualize a lot of data.

I'm picturing the solution to this problem as like the ""opposite"" of PCA, though I don't know if that's the best way to describe it. Essentially, whereas in PCA you condense many variables into like two, I need to condense many ""categories"" or ""types"" of results into just a few so I can cleanly present them in only 1-2 figures.

Data related to the kind I want to present has been presented as a complicated stacked bar graph, but with all the data we want to show, it would be way too cramped and ugly to use as a published figure.

I'll try to describe the data I'm working with as simply as possible, but it may still seem jumbled. sorry in advance.

For a group of many individuals, some reacted to a stimulus and others did not. We want to compare the following for the two groups (so I guess each group could be split into its own figure):

\- for each individual their data consists of info on 4 types of molecule found in their sample: g1/g2/g3/g4 (all 4 are relevant in our dataset)

\- each type of molecule can be modified with modifications a1, a2, a3, etc up to a8 (all 8 are relevant in our dataset)

\- the abundance of each modification type is given for each of the 4 molecules

\- for example: for sample X, 90% of modification a1 is on molecule g1, 0% of a1 is on g2 and g3, and 10% of a1 is on g4. Then, 50% of a2 is on g1, 5% of a2 is on g2, 30% of a2 is on g3, and 15% of a2 in on g4. Repeat for the rest of the modifications, a3-a8, on each molecule g1-g4

\- repeat all of that for each individual sample

So this is where my idea of the ""opposite"" of PCA comes in, though I don't know if such a thing exists. Is there some kind of graph that could condense many ""types"" of results for a single sample into one dot on a scatter plot? It sounds pretty dumb to type it out, I really doubt there is such a thing lmao.

Right now, for each individual sample we have grouped bar charts, grouped by modification and each bar is the moledule g1-g4. looks nice but we need that condensed into one figure for many samples, and like I said a cramped stacked bar chart is our last resort.

But Maybe there is a kind of graph out there I have yet to learn about that could help visualize this data. Can anyone help me? Thanks!",statistics
nwbl95,1623288171.0,[Question] Canasta Odds,In a game of canasta there is a deck of 108 cards (2 card decks + 4 jokers). When you starting the game you deal 13 cards to each player. There are 4 red threes in this deck (2 decks of standard cards). What are the chances that you get ONE red three in your starting hand?,statistics
nw93gy,1623280463.0,[D] Finite networks,"I m looking for pointers on literature of statistics of finite networks. To be more concrete, i d like to know what methods there r out there when my data are different graphs (possibly of different sizes).",statistics
nw760i,1623274951.0,[D] Glivenko-Cantelli Theorem vs Law of Large Numbers,"Has anyone heard of the ""Glivenko-Cantelli"" Theorem in statistics before?

https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem

This theorem states that ""the empirical distribution function of a variable"" will converge to the ""cumulative distribution of this variable"" (I am not sure and do not understand what kind of ""convergence"" this is, but the way I understand it : the cumulative distribution and the empirical distribution will be equal to each other when the number of observations increases).

Is the Glivenko-Cantelli Theorem similar to the Law of Large Numbers? Do both of these attempt to describe a similar concept: the relationship between the ""observed"" and the ""theoretical""?

Thanks",statistics
nw759u,1623274896.0,"[Q] Pair trading w/ mean reversion (Cointegration? ADF?, etc.)","Hi everyone.  At work I've been tasked with a pair trading side project.  I'm taking two pre-selected securities, finding their last prices over x number of years using pulled data from Bloomberg and plotting/outputting the buy and sell points throughout that time based on abnormalities in their ratios (rolling z-scores?).

I'm midway through an undergrad Computer Engineering degree, so I have some background in programming (currently using Python, Excel and Bloomberg for this project), though have only taken one intro class in Statistics and another in Linear Algebra over the last couple yrs.

My price data is all from Bloomberg.

**How I've gone about it so far:** I scraped ~200 securities from different sectors on Bloomberg, got their price histories (weekly prices from 3 years ago until today) on several different Excel workbooks (one for each sector) and read those Excel workbooks into my Python program.  I've maintained separate dataframes for each sector's securities' pricing histories.  I wrote a cointegration function, applied that to all pairs within each dataframe and for a p-value < 0.02, I ""kept"" those pairs.  I've landed up with ~100 pairs of securities that exhibit cointegration.  From there, the user can input any pair on a separate Excel sheet that will give the daily last prices of both securities over the last 5 yrs.  I take in the ratio of the two securities, do a rolling z-score test and if it's above/below 2 SD, I indicate a buy or sell opportunity for each security within the pair.

**Where I'd appreciate guidance:** A number of my pairs (based on pre-cointegration test price ratios) do not have normal distributions -- I'd say around half.  I'm confused on when I test for normal behaviour (before or after cointegration), what to test for normal behaviour (the price ratios or each security itself), how to test for normal behaviour in this context (Shapiro test? something else?) and how that relates to a rolling z-score (is this even needed if I have a normal distribution test) and/or the ADF test.  Is my methodology for finding the buy/sell points correct?

If anyone here would like to take this offline / tutors, I wouldn't mind chatting as a session or two going over this could be very helpful for me.  I've read a lot in the last couple weeks but because I have elementary knowledge, many concepts are starting to become jumbled up.

Thank you!",statistics
nw62qp,1623272027.0,[Q] How to interpret a LCL that is under 0? (when it is realistically not possible),"

So I am doing a rate.

It is realistically impossible for a rate to go below 0.

But when doing a UCL & LCL, the LCL is below a 0.

How do I interpret that?

If the LCL ends up below a 0, would the LCL be set at 0?",statistics
nw5l33,1623270727.0,[Q] Pursuing a degree in stats even though I haven’t always had the best relationship with calculus. I have a lot of questions and I would appreciate your help!,"1. I took a look at the courses I have to take, and there are only two calculus courses. How important is calculus in order to understand statistics anyways?

2. How much studying did you do when you were getting your degree?

3. *WOULD REALLY APPRECIATE IF YOU ANSWER THIS* What would you do differently if you had the chance to go back in time and do your degree all over again? Any subjects you would focus more/less on? Any courses you wish you took/hadn’t?

 4. Have you ever met someone who didn’t have the strongest background in mathematics yet still did very well in this field?

Thanks to anyone who takes the time to read or answer. Appreciate it!",statistics
nw46xk,1623267048.0,What is the culture of a Statistics work environment? Would anyone be willing to share their experiences? Preferably looking for those who have worked in the UK to share but I would still appreciate experiences in different countries.,"Hi, I have posted this on a few subreddits already but I would love to hear as many people's opinions as possible.  I'm looking into to studying statistics or applied statistics. I was wondering what the work culture was like? Is there a lot of pressure? The pressure/stress of the job is something that I am particularly interested in hearing people's opinions on so any input would be appreciated. Or does it vary by employer, assignment , and the field you are working in?

Thank you",statistics
nw2yab,1623263823.0,[D] role of stochastic process (e.g. martingale residual) in survival analysis,"I am trying to better understand why certain concepts from stochastic process are used in survival analysis.

For example, there is a popular model in survival analysis called the ""cox proportional hazards regression model"". This model is used to study the survival rates and the hazard rates of observations/groups within the data. This model uses the predictor variables associated with each individual to model the hazard.

It seems like a popular method to check whether a trained cox proportional hazards regression model is a good fit for a given dataset, is to evaluate the ""martingale residuals"" for this model (i.e. checking the proportional hazards assumption). If I understood correctly, the martingale residual (predicted value subtracted from a martingale term) follows a certain probability distribution. For each predictor variable, you can simulate thousands of ""paths"" corresponding to the theoretical distribution of the martingale residual. Then, you can see how the actual martingale residual (calculated using the data) compares to all the theoretical simulations. If the actual martingale residual fits somewhere between all the simulations - we can say that this is a reasonable behavior and the model assumptions are valid.

Can someone please help me:

1) did I correctly understand the role of the martingale residual in survival analysis?

2) can someone please help me understand the motivation for bringing martingales and stochastic process into survival analysis? Why is this necessary? Why is the martingale residual useful for validating the proportional hazard assumption (i e. The contribution of each variable to the overall hazard does not depend on time)? Why is the proportional hazards assumption important to begin with?

I tried researching this online, but all the material I found was either to vague/beginner, or too complicated.

Can someone please help me understand this?

Thanks

https://stats.idre.ucla.edu/sas/seminars/sas-survival/

https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_phreg_examples09.htm

https://www.jstor.org/stable/2336057

http://www.csam.or.kr/journal/view.html?doi=10.29220/CSAM.2017.24.6.583

https://arxiv.org/abs/1003.0188

https://en.m.wikipedia.org/wiki/Martingale_(probability_theory)",statistics
nw2grm,1623262557.0,[D] Temporal Network Graphs,"Has anyone ever worked with ""temporal network graphs"" before? Basically, these seem to be graphs in which :

A) new nodes can appear and old nodes can disappear as time progresses

B) edges between nodes can appear/disappear as time progresses

These seem to be newer methodologies. Has anyone tried to perform algorithms like community detection, node classification or edge prediction on temporal graphs?

I was trying to find more examples of this kind of stuff and all I was able to find was the Twitter github page (https://github.com/twitter-research/tgn) and this one general blog on temporal graphs with R:

https://programminghistorian.org/en/lessons/temporal-network-analysis-with-r

And

https://rstudio-pubs-static.s3.amazonaws.com/373665_283622728cdb4116af38768eea28473e.html

Can anyone please recommend anything else?

Thanks",statistics
nvzxck,1623255977.0,[Q] How to combine probabilities to establish consensus,"Hi all - Hope someone could provide me pointers to address my problem.  Problem statement is below.

I have a list of probabilities that are calculated realtime that looks like below.

[ P^Hot, P^Cold, P^NeitherHotNorCold ], [ P^Hot, P^Cold, P^NeitherHotNorCold ], [ P^Hot, P^Cold, P^NeitherHotNorCold ]...

At each step t^0, t^1 and so on, P^Hot predicts the probability of next hour being hot, P^Cold predicts the probability of next hour being cold and so on.  These probabilities are arrived independently of each other and is bit noisy and not perfect. What are the best ways to combine them and arrive at a consensus probability at a given time ? I could do simple averaging of previous windows and vote the one with highest probability - but it feels like there must be some smarter way. Any pointers ?",statistics
nvzcp9,1623254522.0,[Research] Are my statistical methods sound?,"  Apologies if this is basic, or if my explanation doesn't make sense.  This is my first analysis so I'm still learnign the ropes.

I have a study with a two factor design. Basically, my participants are completing two tasks (one control, one cognitive) in two conditions (one condition is a control). I'm working with 4-D imaging data (3D imaging data collected at 2 second intervals) and am using a program to compute the statistics that essentially has a drop down list where you select your statistical tests.

I want to find out the effect of the condition on the cognitive task. To do this, I have to subtract the control task from the cognitive task (filter out baseline activity) and then subtract the control condition from the condition of interest (so that I am sure the activity I am looking at reflects only changes due to the condition of interest). I know that in order to get the difference between the conditions, I want a paired t-test. I thought I would also need to used a paired t test to determine the difference between the two tasks. So, I first separated my data by condition and within each condition did a paired t-test to determine the difference between cognitive and control tasks. Then I took the two results and did another paired t-test to see the difference between conditions.

However, I got some weird results that are telling me I did something wrong. Is nesting paired t-tests something that is ok to do? If not, what is another way to go about this?

Thanks! I really hope this made sense!",statistics
nvz8p3,1623254252.0,[Discussion] Digesting Statistics Textbooks,"I was wondering if others would be open to sharing their process and thoughts as they digest a textbook with the intent to do well in a  upperdivsion / graduate level statistics course.

Topics
- do you read sections before lecture
- how many times do you read / how do you time manage
- how do you effectively digest? Do you read and summarize, do you read and take notes, do you read completely a section before taking notes, or perhaps take notes?
- Ideally one would like to do as many practice problems as possible, but in consideration of managing time, life, and school (avoiding diminishing returns and maximizing value), what is your approach to practice?
- what are some habits that pays it dividends long-term
- More efficient tips please hahahah",statistics
nvwtvt,1623247750.0,[R] Creating even levels based on number of patients using R," Hi everyone, I wanted to ask a stats wiz here if they can help me and my lack of stats training.

I am conducting research with hospital data and pulled socioeconomic variables of the patients from american community survey (ACS).

With this, I created an SES index with principal components analysis (PCA) method, giving each patient an SES index ranging from -10 to 10.

**QUESTION/PROBLEM:**

**-I have around 6000 patients in the group. I am aiming to create 5 separate socioeconomic levels based on the SES index (think 5= low SES, 4 = moderately low, 3= average, 2 = moderately high, 1 = high SES)**

**-I want to split the groups evenly so that roughly, the same number of patients are represented in each group. Would anyone have a statistical approach they recommend to do this?**

Let me know if the question isn't clear! Thanks in advance.",statistics
nvu2c5,1623240017.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
nvsf9o,1623234087.0,[Q] What does it mean if a predictive test has a high specificity but a low PPV?,"Hi, what does it mean if a predictive test has a high specificity but a low PPV?

I know that high specificity = unlikely that a person \*without\* the disease will receive a positive result, therefore a positive result means that they likely have it.

However a low PPV = large percentage of positive results were false positives?

How can have both a high specificity but low PPV at the same time?

Thanks for any help :)",statistics
nvqt9b,1623227517.0,[Q] A/B testing book recs,"Hi all!

I’m about to graduate from college and was lucky enough to have gotten a position as a financial analyst.

However, my interest is not finance but data driven marketing. I’d love to work as a marketing analyst or business analyst so was wondering if anyone know of any great books for A/B testing and other methods?

Also, if anyone is in the marketing analytics field would you mind sharing what your day to day looks like?

Thank you :)",statistics
nvmn7v,1623211018.0,Which family function to use for my GLMer? [Q],"Hello, I have plotted out my response variable and I'm not sure whether I should use poisson, negative binomial or a gamma function to model this response variable. It is a discrete count variable. https://i.imgur.com/Ycg08sR.jpg I actually filtered the response variable when it was equal to 0 because I was interested in only those who have received one or more promotions. Otherwise the response looks like this and maintains the same pattern. https://i.imgur.com/5gFEO3R.jpg I will be using the glmer package because there are random effects in my model.",statistics
nvjb4y,1623199959.0,[Question] Why the stats language is so messy?,"I mean, I feel like you have a lot of words for the same concepts, but I'm not sure, I might be mistaken.

For instance, recently I read the word ""heterogeneity"" and I thought wow what could this mean! Then it turned out it means ""diversity"" or I just came across ""interdependence"", which I think means ""correlation"", and a lot more similar examples (multi-level modeling, hierarchical modeling, mixed-effects modeling; apparently, all have the same meaning.)

What should I do to be less confused? I'm a just beginner but stats is very important to me and I want to excel at it.",statistics
nvgp5h,1623192020.0,[Q] Crossroads with my Masters Thesis and Future Career Path,"Hello all,

I am currently a master of applied statistics student finishing up my final year with my thesis. I've just begun the process for my topic approval, and my advisor said my topic is fine, but with how much similar literature there are it may be difficult to publish. My methodology at the core is doing an in depth comparison of a plethora of machine learning methods to determine which one is best for a given dataset. Since it's quite empirical, it may be easier to publish if I were to do this on a newer dataset than a well known dataset from UCI or Kaggle (I was looking into the Wisconsin Breast Cancer dataset). Now I'm wondering if it's worth to switch datasets into something with less literature, or if the quality of my comprehension and comparisons will be more valuable in determining whether or not my results are publishable even if there have already been quite a few pieces of lit done with that specific dataset.

Beyond my thesis, I have been at a crossroads for my career path once I graduate. Biostatistics seems to be a pretty ideal field for me if I can work specifically with statistical modelling and clinical data in a biotech environment. I'm quite novel to stuff like Survival Analysis (only taken one course on it in graduate school) and I'm probably below average when it comes to stuff like experimental design. My undergrad and work experience were all around regression and classification modelling, so my skills are a bit more honed in that sense. But I feel my coding is not nearly good enough to compete for data scientist positions. I'm debating then whether or not I should continue to pursue this more narrow path in biostats, or maybe broaden my horizon and look into data science as well.

I'm also wondering what field would hold my thesis topic in a higher regard in terms of work experience (biostats vs. data sci.).",statistics
nvfzl1,1623190093.0,[Q] How would I go about checking if one group's results come from chance or Fraud?,"For example, I have a bunch of groups which recorded 1000 for A and 500 for Bbut i'd like to check one of the groups which recorded 100 for B and 50 for A. How would I know the chances for this to occur by chance or luck, or if its most likely that this difference is caused by fraud.

In theory there should not be population differences between the groups, they should all come from the same population.For example, if i have 5 groups which record:

\-100 A 50 B

\-90 A 48 B

\-110 A 45 B

\-80 A 57 B

\-10 A 100 B

In this case I would be kinda sure that the 5th group most likely came from fraud and is not a real result. What math would I use to figure out the confidence that its fraud. (or check that its at least 99.9% sure its fraud)",statistics
nvfsej,1623189610.0,"[Q] What can network analysis tell you that factor analysis can't, and vice versa?",,statistics
nvcutl,1623182277.0,"[Q] Book recommendations for statistical analysis, particularly hypothesis testing and analytical engineering?","Hi guys. I’m hoping that I could get some suggestions on statistics textbooks.

I’ve previously worked in data analytics involving energy modelling, but I’ve since moved onto a career in engineering aligned with my degree. I’m currently seconded to an analytical engineering department, but (like with my previous job) I’m surprised how little statistical theory is actually used in the analysis that is done. I’m by no means a mathematician, but I’ve studied analytical engineering topics and have probably an above average interest in statistics for my profession. One of the reasons I was successful in my previous job was because I managed to show them the power of using more advanced statistical analysis techniques and R-based modelling, most of which I self-taught from various sources.

Basically, I want to put some of that into practice again, but I need a bit of a refresher (and supporting literature) since it’s been a while since I did this stuff. The topics I’m mainly looking at are:

Hypothesis Testing
Experimental Analysis
Modelling (Regression, or even Machine Learning)
DoE (to a lesser extent)

Reference to R is a bonus too.

Thanks in advance.",statistics
nvayt8,1623177215.0,[Question] How air/car travel safety statistic is calculated?,"Always hear that air travel is safest, but how exactly it is compared to other forms of travel? Distance traveled, time spent in an airplane/car?",statistics
nvaxr5,1623177130.0,[Q] Interpretation of covariance matrix,"I am trying to get my head around principal component analysis in the context of statistical risk models. So I have a set of stock return time series as inputs. Can someone explain to me what ,from a practical perspective, it means if my matrix is not positive semi-definite and invertible und what in the data could causes that, so I could pre-condition the data ? And also why would these two criteria cause issues when running the pca ? thanks",statistics
nva296,1623174765.0,[Q] Graphing continuous and ordinal data,"Situation: I'm working on a scoping review and would like to visualize longitudinal data from multiple studies on a single figure. However, some authors have presented continuous data (i.e. measures taken at each age), while others have presented ordinal data (i.e. from ages 6-9, 10-13, 14-18 etc.).

I'm struggling with how to do this. One idea was to layer a line graph (continuous) on top of bar charts (ordinal), but this will be messy as the individual studies used a range or ranges. Another option might be to force the ordinal data to be continuous by plotting the same value for each age within that range.

I would greatly appreciate any suggestions or links to resources, thank you in advance :)",statistics
nv57q5,1623162267.0,[Q] Research or Internship in prep for phd applications?,"Hello all, I’m currently an undergraduate stats major who will be a junior in the fall. My goals is to apply to PhD programs in senior fall. If I wanted to look at opportunities for the summer prior to it, should I look into doing research within say the stats dept? Or should I be trying to look for an actual internship at a company? My research interests are within statistical learning, so I was thinking a research role would be better suited for me than some data analytics position at a company.

I feel that it will be hard for me to get on any papers or do research because I won’t have a ton of theory knowledge, but I’m hoping I can get on something more applied.

So what do you think? I feel like trying to get a research role would be better when applying then doing SQL all day at a company for a summer, chances are even if I expressed my case as I want to do some more data science and quantitative sort of internship it wouldn’t be as good as if I did research with a prof.

I will be applying to stats PhD programs.",statistics
nv53o2,1623161970.0,"[Question] Which statistical test to use? Log-binomial, Cox, something else?","I am wanting to perform a multivariate analysis of a binary outcome.

Participants entered a testing period at different times and were tested at random (some were never tested, other were tested many times). Most tests were negative & only 1.5% of all participants ever returned a positive test. All testing periods were abruptly ended at the end of the study.

There are a few covariates, including the number of times a person is tested. I would also like to include the length of the testing period (in days).

What would be the most appropriate test to perform a multivariate analysis, where the outcome is whether the participant tested positive (1) or not (0)?

Logistic regression? Log-binomial to get risk ratio? Or would a Cox model be more appropriate?

Thank you for any help you may offer!",statistics
nv219f,1623152430.0,[Q] Are sections for permutation tests in Lehmann's TSH applications of UMP Unbiased Tests for Multiparameter Exponential Families?,"In Lehman's TSH, Is Chapter 5 *Unbiasedness: Applications to Normal Distributions; Conﬁdence Intervals* an application of Theorem 4.4.1 on p121?

Is Theorem 4.4.1 based on a parametric model of an exponential family (4.10) on p119?

Are sections 5.8 *Permutation Tests* and 5.9 *Most Powerful Permutation Tests* for nonparametric models?

Are sections 5.8 and section 5.9 applications of

- Theorem 4.4.1,
- section 4.4 *UMP Unbiased Tests for Multiparameter
Exponential Families*, or
- chapter 4 *Unbiasedness: Theory and First Applications*?

If none of the above, whose application are section 5.8 and 5.9 about permutation tests?

I am lost in the relation of sections 5.8 and 5.9 with respect to the earlier sections in chapter 5 and chapter 4.


Thanks.",statistics
nv1g2k,1623150208.0,[Discussion] FREE WEBINAR - Automating Data Annotation with MicroModels - Automating processes within the workflow to improve efficiency & guarantee high quality,[https://www.re-work.co/events/webinar:automating-data-annotation-with-micromodels?utm\_source=Promo&utm\_medium=Promo&utm\_campaign=LK\_Promo\_Sama\_Webinar](https://www.re-work.co/events/webinar:automating-data-annotation-with-micromodels?utm_source=Promo&utm_medium=Promo&utm_campaign=LK_Promo_Sama_Webinar),statistics
nv0eem,1623142918.0,[Q] Would need some help to define a reasonable threshold for biological samples.,"Hi,

I just established a new experiment type in our lab and got the first data from a pilot study. Because this is a new experiment there is no existing ""standard data analysis workflow"". In the next paragraphs I will describe the experimental approach as well as the possible threshold formulars that our lab is using and why I feel they are suboptimal.

So lets start with some details:For my experiment I have patients (n=15) suffering from nosocomial infections caused by different common viruses (virus\_1, virus\_2, virus\_3) and a healthy control cohort (n=15). I measured different protein values (protein\_A, protein\_B, protein\_C) for patients and controls. Our hypothesis is that virus\_1 causes an increase in the concentration of protain\_A, virus\_2 in protein\_B etc. However these viruses are extremely common and can also cause asymptomatic infections. So it is somewhat likely that also in the control group some protein concentration could be mildly increased, but in the patient the increase should be way higher. I wanted to use the control group to set a threshold for every single protein (A-C) as ""healthy background"". In the next step I would check which patients have higher protein concentrations and thereby predict the infecting virus. Since we also have the clinical data I would be able to compare my protein-based prediction with the clinical diagnosis.

This made a lot of sense to me an my colleagues. But when we saw the real measured data the definition of the threshold gave us a lot of headache and since we are no statistical experts our tools are rather limited:

1. Mean + 3xSDnote: way to prone to outliers. As in prot\_C controls you can see there is one outlier that would screw the mean based approach a lot. In addition we can expect a right-skewed distribution for the data.
2. Median + 3xIQRnote: looks already way better. But there are still a lot of data points in the controls that would be included and are thereby false positive. I would favor to have rather false negative cases (not able to predict the causing virus) than false positive (predict someone healthy as infected).
3. trimmed Mean + 3x trimmed SDnote: somewhat similar to 2). However, the guy who gave us the advise to use the trimmed mean also said: just go for some nice even number like 10% or 25 % trimming. What sounds really arbitrary to me. But if this is the way to go: What amount of trimming would you recommand?

Overall I noticed that I get relatively good results with simply using 100 as threshold (unless the control thesholds (using 2) or 3) ) are higher, in this case I would go for the calculated thresold). But this is totally arbitrary and extremely unsatisfying. It would be really great if someone could come up with a smart, reliable and easy idea for the threshold calculations. Why easy? First: no one in our lab is able to write and run fancy R scripts and second: Our PI is hard/unable to convince to publish complex statistics because ""they might be mathematically more correct, but not the usually way in our field"". And yes, statistics in biosciences are... hmm... blunt? But maybe one of you has the solution I am looking for =)

&#x200B;

Example Dataset:

|prot\_A (ctrl)|prot\_A (patient)|prot\_B (ctrl)|prot\_B (patient)|prot\_C (ctrl)|prot\_C (patient)|
|:-|:-|:-|:-|:-|:-|
|5|7|32|223|1|63|
|20|1|238|1|96|1|
|1|4|1|51|8|339|
|1|4|15|7|1|3|
|3|1|420|13|13|19|
|2|1|1|23|1|1|
|1|147|1|30|1|8|
|6|323|242|1|1755|1|
|33|20|71|78|9|25|
|3|4|7|59|1|84|
|1|147|11|99|8|71|
|2|25|3|45|4|8|
|3|1|2|542|4|14|
|1|59|4|196|4|415|
|4|4|3|14|1|7|

&#x200B;

PS: I did run a PCA but since the original data set is way bigger and more complex, there was no reasonable result.",statistics
nuvwuv,1623125153.0,[D] When statistics asks about itself,"[http://asksiri.us/blog/2021-02-10.md](http://asksiri.us/blog/2021-02-10.md)

Hi,  looking for critiques to my blogpost. It's all self-reflective  statistics questions and the contradictions that can arise from  self-referential questions like it.",statistics
nuvtm7,1623124850.0,[Q] Sampling variability from collapsed survey data?,"Hi all,

I'm using some survey data (of individuals) that have weights. Let's say I wanted to collapse this individual-level survey data to the geography-level (for the purpose of learning about locations, not individuals or individual-weighted locations).

After doing so with the appropriate weighting option, is sufficient to regress my now collapsed variables simply as reg Y X?

Ignoring survey clustering and stratifying, I can't help but suspect that such a regression does not capture the sampling variability from the initial survey. The initial survey features uncertainty regarding population means, but after the collapse, there is no uncertainty in principle.

Of course, I could be wrong---but this has been picking at my brain for a while!

Thanks so much!

NB---this is not a coding question, but you can surely see I'm using Stata here",statistics
nuvsgw,1623124760.0,"[Q] Is there a term for when a correlation is discovered, and the discovery ruins the correlation?","For example (I'm making up this scenario), let's say it's discovered and becomes well known that the team in basketball that scores the most 3 pointers has a high correlation of winning the game.

Upon learning about this correlation, teams start chucking up well defended 3 pointers in order to make more. So they might make slightly more, but their shooting percentage goes down so their overall scoring goes down. So now that teams are doing this, the correlation is no longer as strong.

So basically is there a phrase/term for when the discovery of a correlation affects the correlation?",statistics
nush7r,1623114013.0,three way interaction model with more terms has lower AIC than two way interaction model [Q],"I made an linear mixed effect model in R, the dependent variable is salary and there are three main features that I am looking at: gender, promotion level, and team. There are 2 genders, 9 different promotion levels, and 8 different teams. A two way interaction effect model with the formula salary ~ promotion:gender + gender:team has an AIC of 115,000, while the three way interaction model of salary ~ promotion:gender:team has an AIC of 52,000. Unfortunately the amount of terms increases from 32 to 129. In the three-way interaction model, only a handful of terms have a T value below 1.96.

Comparing the two models with each other, the model with the lower AIC would indicate that it is a less complex model but with 129 covariates it doesn't seem that way.",statistics
nur2r1,1623109594.0,[Q] Strange results calculating a robust Cohen's d (Q) using Wilcox's shiftPBci() and shiftes(),"Wilcox's Q is purported to be a robust equivalent to Cohen's d.
I have vectors with <1000 and >1000 items. For the vectors with <1000 items, shiftPBci() seems to work well. When there are more than 1000 items, the Q.effect returned is outside the confidence interval returned from shiftPBci(), and the upper and lower bounds of the confidence interval are equal.
The culprit would seem to be the shiftes() function, which tests for the number of items in the two vectors passed to it. If less than 1000, a simple `outer(x,y,FUN='-')` is executed. If greater than 1000, a maximum of 50 samples are selected from each vector, and the outer product is calculated and appended to the vector L, whose median is eventually taken and used to calculate the elements above or below the median, etc. If I add the vector `v` to the variables returned form shiftPBci(), I see that all 500 entries in it are the same, and thus the high and low values of ci are the same as well.

I'm not as well-versed in R (and statistics) as other languages, and would greatly appreciate any help.
The source for the two functions are pasted below, and a link to Wilcox' WRS package is here:
https://dornsife.usc.edu/assets/sites/239/docs/Rallfun-v38.txt

And a link to the paper that talks about the method:
https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=2726&context=jmasm

	shiftPBci<-function(x,y,locfun=median,alpha=.05,nboot=500,SEED=TRUE,...){
	  #
	  # confidence interval for the quantile shift measure of effect size.
	  # (Same as shiftQSci)
	  #
	  if(SEED)set.seed(2)
	  x=elimna(x)
	  y=elimna(y)
	  n1=length(x)
	  n2=length(y)
	  v=NA
	  ef=shiftes(x,y,locfun=locfun)$Q.Effect
	  for(i in 1:nboot){
	    X=sample(x,n1,replace=TRUE)
	    Y=sample(y,n2,replace=TRUE)
	    v[i]=shiftes(X,Y,locfun=locfun)$Q.Effect
	  }
	  v=sort(v)
	  ilow<-round((alpha/2) * nboot)
	  ihi<-nboot - ilow
	  ilow<-ilow+1
	  ci=v[ilow]
	  ci[2]=v[ihi]
	  list(n1=n1,n2=n2,Q.Effect=ef,ci=ci)
	}

	shiftes<-function(x,y,locfun=median,iter=100,SEED=TRUE,...){
	  #
	  #  Probabilistic measure of effect size: shift of the median.
	  #
	  ef.size=NA
	  ef.sizeND=NA
	  Q.size=NA
	  x=elimna(x)
	  y=elimna(y)
	  n1=length(x)
	  n2=length(y)
	  if(n1>=10 & n2>=10){
	    #nt=n1*n2
	    nt=max(n1,n2)
	    if(nt<10^3)L=outer(x,y,FUN='-')
	    if(nt>=10^3){
	      if(SEED)set.seed(2)
	      L=NULL
	      nmin=min(c(n1,n2,50))
	      for(i in 1:iter){
	        id1=sample(n1,nmin)
	        id2=sample(n2,nmin)
	        L=c(L,outer(x[id1],y[id2],FUN='-'))
	      }}
	    est=locfun(L,...)
	    if(est>=0)ef.sizeND=mean(L-est<=est)
	    ef.size=mean(L-est<=est)
	    if(est<0)ef.sizeND=mean(L-est>=est)
	    Q.size=(ef.size-.5)/.5
	  }
	  list(Q.Effect=ef.size,Non.D.Effect=ef.sizeND,Scaled.effect=Q.size)
	}",statistics
nuq12y,1623106443.0,[Q] Should you drop dimensions with poor reliability from an EFA? In particular ICC = .39,,statistics
num76g,1623096500.0,[Q] Creating Synthetic predictor variables in time series,"my goal here is to use a predictor variable to assist in the forecasting of performance in a test market where we launched a new media campaign. this forecast will be used as the counterfactual in my causal impact model.

i have time series data broken out by country and am wondering if there are ways of creating synthetic predictor variables to be used as regressors in a bsts model.

Another idea i am playing around with is aggregating a group of regions to use as a highly correlated predictor variable and optimizing towards correlations between those aggregates and the test region, but cant seem to formulate a process for this.

any assistance is greatly appreciated! thanks in advance",statistics
nuktod,1623093267.0,"[Q] NAME THAT ANALYSIS: Assume you calculate a rate of change across 1-10 trials of task, then compare whether performance on trial 11 is or is not consistent with the trajectory you would predict based on the slope of change across trials 1-10. What is this analysis called?!","Someone suggested an analysis like this for a set of data I'm working  with where after n trials, participants get new information on trial n+1  - potentially impacting their performance. However, neither of us can  remember what this time of counterfactual inference approach is called -  making it hard to get appropriate information before setting it up.

EDIT: We believe my colleague is talking about an 'interrupted time series' design.",statistics
nuj6jy,1623089276.0,"[Q] After PCA, I have 98% variance explanation on the first component. Does that mean there is only 1 important feature in my dataset?","Say I have a dataset with 5 features. I want to display my data in 2D so I reduce the dimension with PCA. It turns out the first component explains 98% of the variance (I computed it with the ratio of eigenvalues). Does that mean there is only one important feature in my initial dataset?

I am currently not so sure because the relationship between the initial features and components produced by the PCA is not straightforward.",statistics
nuj0sy,1623088899.0,[Question] Conditional probability of several variables?,"I am wondering what is the joint probability of several variables that do not follow each other as in the following way: P(A|B,C)\*P(B|C)\*P(C) = P(A, B, C). In other words, I wonder what would be the joint probability of P(A|B)\*P(C|D). Is it going to be P(A, B| C, D)? On the other hand, if we have a case such as P(A)\*P(B|C) and P(A|C)\*P(B|C), I think that they are going to have different joints, but I am not sure how can they be written differently in a joint distribution notation. My question partially arises due to Bishop's Pattern recognition textbook, where he expresses p(**w**, a, b, t| **t**) = p(t|**w**, b)\*p(**w**| **t**, a, b) \* p(a, b|**t**). I interpret this as first multiplying the last two terms and getting p(**w**, a, b | **t**), which leads to p(**w**, a, b | **t**). Then multiply that with p(t | **w**, b). However, I am not sure how can we multiply two conditionals, namely p(t| **w**, b) and p(**w**, a, b | **t**) given that p(t|**w**, b) does not contain after the given notation all of the terms from the p(**w**, a, b | **t**) before the given notation.

Any help is much appreciated.",statistics
nuiswv,1623088371.0,[Q] How to model bimodal distribution,"Hey guys, I have some data I am analyzing (not homework) that appears to yield a bimodal distribution. In other words, it looks like two normal distributions squished together (two unimodal normal distributions added together closely). They merge in the middle a bit so they aren't fully distinct.

I did a lag plot and my data is strongly linear, and a run sequence plot did not look sinusoidal.

Knowing the data, I EXPECT it to give me two unimodal distributions, but I am unsure how to go about modeling this, especially since they overlap in the middle.

Any tips?

Edit: Solved :)",statistics
nuhag4,1623084590.0,[Q] Anomaly detection,"I work in the industry where people are often interested in knowing if the things continue to work 'normal'.

When monthly report, from some sort of the site, comes through they would like be able to use that data to assess if things are 'normal' there.

I am studying statistics and in last couple of semesters we have been focusing on model selection and variable selection - but that is pretty much where things stop.

So, lets say that I have some response that is a proportion. Lets say it is reasonable to use logistic regression. After doing some analysis we end up with a good model based on 3 factors from a historical monthly reports.

Lets say:

logit(p) = 0.30 - 0.5xfactor1 + 0.26xfactor2 - 0.12xfactor3

I wonder what would be next steps for moving to further analysis focusing on anomaly detection.

First of all is the above method of using historical data to build a model acceptable start for further analysis focusing on anomaly detection?

First thing that comes to my head is that I can build a prediction interval based on the above model and check if the new observations are in the interval. If it is outside I would mark it as an anomaly. It sound reasonable to me, is it?

Would there be any downsides to this approach?

How can I check if the interval is of any practical use, aka what in the modeling process could indicate that the interval will be for example too wide for any practical use?

Are there any better methods for anomaly detection?

What is a good read on the topic?

Thank you for your time. Any comments welcome. Especially the one that could point out where I might be wrong or how to look at the problem from a different perspective.",statistics
nued18,1623077397.0,[Question] Why Doesn't Betting on the Odds Stabilizing Work?,"Hi,

I've got a question that's really been bugging me. Why is it that you cannot bet on the odds of a ""random"" event stabilizing? That question is probably better explained with an example:

Say there is a game where a coin is flipped heads or tails. You have to bet on which side it lands on to win.

You notice that over 100 flips, heads was flipped 65 times, and tails was only flipped 35. You know that if this game goes on, this variance should decrease over time, eventually becoming nearly 50-50.

Why is it that you cannot bet on these odds? My monkey brain says that if you keep betting on tails after the game has overwhelmingly been heads, over time you should win since the odds are destined to even out over a long enough time (at least I think they would?)

So where is the flaw in my logic? I know I'm wrong, that cannot be the case. But it one of those things that *feels* like it should be true even though it isn't.

I'd really love a low-level explanation of where the problem in my reasoning is. Thanks!",statistics
nuea4y,1623077182.0,[Q] Calculating Probability with Binary Data,"I have a work problem that seems like it should be simple, but I can't figure it out. I'm working with attribute data (Pass/Not Pass), and there was a change. In the first set, we had 3 of 14 samples Not Pass, then we made a change, and now in a separate test with different parts, we had 0 of 11 samples Not Pass (all passed).

&#x200B;

How do I calculate the probability that the issue has been solved? Wondering if the first test is irrelevant or how it might factor in. Any help is appreciated!",statistics
nu87c2,1623058003.0,"[Q] Finding and optimising a three group classification criteria for a {0,1} response with one independent variable","I want to create a grouping algorithm that groups my data into 3 classes. Now imagine that we have one independent variable **X**, which can be either discrete or real, and a dependent variable **Y** that takes values in {0,1}. In general the **X** and **Y** are, on average, monotonically increasingly related (higher **X**, higher the probability of **Y**) and class **Y** is imbalanced (around 9:1). I have the following problems that I need to address as they are closely related.

1. Create a cutoff/criteria for **X** so that it can be used to classify cases into the three groups. I can transform **X** if needed (as in logistic regression).
2. Compare the three groups and find out if there is a significant difference between them based only on the response (**Y**), which can only take values 0 or 1.
3. Optimise the cutoff from point 1 so that the groups are optimally divided by the above criteria.

For the 1. point, the most crude criteria that exists is just setting the cutoff based on percentiles of **X**. The second idea I had was using logistic regression and then classifying based on the response, in other words the ""probability"". I guess I could also use linear regression and classify based on that response. Does this seem OK or is there any other method that I should try?

For the group comparison I am currently using a chi-squared test. But the problem arises when trying to optimise the cutoff. Should I just vary the cutoff criteria (values from point 1), optimising for the largest test statistic? I have also thought about using ANOVA, but the data aren't normal and I would again be stuck optimising the test statistic. Is there something else I should minimise/maximise? Minimise the within variance of groups maybe? Or should I use a completely different comparison? The problem for me here is that the response is either 0 or 1, meaning the only things that I can compare are the ratios or variances within groups.

As a bonus problem, group 3 should be the smallest, comprised of a minimal percentage of cases (say 1%). So the group size will absolutely not be the same.

I know this might seem trivial or futile, but it is what it is and would appreciate some advice on the procedure.",statistics
nu7fun,1623054514.0,[Question] Categorical variables sample sizes,"Evening all,

I have been scouring the internet trying to find the answer to this question. Imagine we have two categories - male and female. I want to know if there is a difference between, I dunno, heights.

To determine if there is a difference between them, one choice is the DMB/OVS - Distance Between Medians over the Overall Visual Spread.

* If the sample size is 30, then the critical value is 1/3.
* If the sample size is 100, the critical value is 1/5.

What I'm stuck on is the 'sample size'. Is this the overall sample size, i.e., 100 males and females. Or is the 100 males and 100 females? Most of everything I've read just says 'if the sample size is....' but does not specify if talking about the overall size or the group sizes.

Any help would be much appreciated. Thanks",statistics
nu7foe,1623054489.0,[C] How do I go about advancing my career / knowledge of statistics?,"Recent graduate here, and I realized far too late that statistics is something I want to pursue a career in. In my last year at my university where I obtained a bachelors in computer information systems (there was no option for a major in statistics and my minor was already completed in UX design), I studied under my professor after I was finished with her class where she gave me somewhat of an apprenticeship. I was hoping this would lead to some kind of internship after I was done with school.

Then covid happened. I was told it would probably be 2021 before I was able to get involved with a recommendation to a relevant firm, and in the meantime I should “keep my skills fresh.” Whatever, I worked a temp job the last year. Fast forward to now, I’m informed she “can’t guarantee me a spot on their team” because of how much time has passed.

Not sure if this is the right subreddit for this, but I’m not really sure what the best option for me is at this point. Should I go back to school somewhere else when I have enough savings? Do I attempt to get a job somewhere even with my lack of direct work experience / degree? Any help would be really beneficial. Thanks.",statistics
nu5q7l,1623047102.0,"[Q], [D] How can I show that ANOVA is better than t-test for comparing group means?","Preface: This is a a homework question where I had to choose a topic, form a question and answer it and so I felt that it was appropriate for this sub, since it is a topic of discussion for me. (if it isn't, please tell me a sub where I can ask this)

From what I understand, t-test is used to compare the group means for two groups with n<30, whereas ANOVA is used to compare more than 3 groups together.

I want to show why ANOVA is preferred for multiple groups rather than multiple t-tests.

  According to [this](https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide-2.php), multiple t-tests increase the error.

> Every time you conduct a t-test there is a chance that you will make a Type I error. This error is usually 5%. By running two t-tests on the same data you will have increased your chance of ""making a mistake"" to 10%. The formula for determining the new error rate for multiple t-tests is not as simple as multiplying 5% by the number of tests. However, if you are only making a few multiple comparisons, the results are very similar if you do. As such, three t-tests would be 15% (actually, 14.3%) and so on.

I want to prove this, either with an example or mathematically.  Are there any examples of this? Or any resources I can look into.

I was thinking of taking an example in R, where I perform multiple t-tests, however I don't know how to get the error from it, and moreover how should I perform the multiple t-tests?

Would every group be tested against every other group, say if I have n groups, would I need to run

(n-1)! tests?",statistics
nu39fh,1623038048.0,[D] can you still use survival analysis models without censored data?,"Suppose you want to use survival analysis models for longitudinal/time-to-event modeling. But suppose you are very ""lucky"" and have no ""censored"" observations. In theory, this should not prevent you from using survival analysis models?",statistics
nu0onp,1623029081.0,[Q] Choosing 9 squares in a row from a 5x5 grid of squares without choosing the square with a bomb in it. What is the probability of this?,"This is basically the game Mines from Stake casino (dont gamble!) and I was wondering what the probability of getting 9 squares in a row is vs the probability of choosing the one bomb (1/25).

I'm not sure how to approach this, I think it has something to do with combinatorics and the binomial coefficient formula, but I'm not sure how to apply it.

.

Anyway, let me rephrase it if it isn't clear:

**There is a grid with 25 squares. Only one of them has a bomb, the rest are gems. You need to choose 9 gems in a row without choosing the square that has the bomb. What is the probability of this?**",statistics
ntyoin,1623022383.0,[Question] How do I prepare for a PhD?,"Thank you to everyone who upvoted or commented on my [last post ](https://www.reddit.com/r/statistics/comments/nqbgy0/question_is_phd_right_for_me/?utm_medium=android_app&utm_source=share) about whether or not I should apply for a PhD in statistics. I have decided to go for it, and I'm very excited! I will take care of the GRE, transcript, letters of rec, etc and apply this winter for the following fall.

I like to read in my free time to learn. Now, I am thinking about tailoring my reading diet to be more stats-focused. Could you guys recommend any reading/course materials for me in preparation for a stats PhD? Here's some background:

1) I studied math with stat minor undergrad and did very well, but I've been in industry 3 years and I bet certain instincts/knowledge have atrophied.
2) Back in college, I took all the math/stats classes PhD programs usually recommend. (Linear algebra, real analysis, number theory, proofs, mathematical stats, stochastic processes, regression, advanced regression, time series, probability theory etc.)
3) I taught probability theory to undergrads for 3 semesters after I took the class, so that's pretty much burned into my memory. Everything else will be weak
4) I am pretty skilled in data manipulation in R and Python, and done some real work modelling in R

Any non-fiction books, textbooks, online courses or lectures you guys would recommend for me to brush off the dust and get ready for PhD-level coursework?

All advice is appreciated. Thank you!",statistics
ntx804,1623017985.0,"[R] A simple and concise introduction into the relationship between bias, variance, overfitting & generalisation in machine learning models!","I wrote an article where I explain, as simply as I can, the essence of the Bias vs Variance trade-off that plagues every machine learning model! I then go on to link this to overfitting, under-fitting and generalisation, using clear visual aids. I think it's a decent introduction to the concepts so hope it helps someone!

[https://joekadi.medium.com/the-relationship-between-bias-variance-overfitting-generalisation-in-machine-learning-models-fb78614a3f1e?sk=2a12bc701af8242c197a0532d82f2d45](https://joekadi.medium.com/the-relationship-between-bias-variance-overfitting-generalisation-in-machine-learning-models-fb78614a3f1e?sk=2a12bc701af8242c197a0532d82f2d45)",statistics
ntu4wb,1623009483.0,[D] Zaslavsky's Theorem in statistics,"Has anyone heard of Zaslavsky's theorem on hyperplane arrangement? Supposedly it says that there are only a finite number of ways that hyperplanes can be arranged? Does anyone know why this is important? Apparently it has implications to decision boundaries of machine learning classifiers?

Thanks",statistics
ntsmir,1623005379.0,[Q] One-Way ANOVA topic ideas that use secondary data?,"I'm doing a statistical activity at the moment and I am having a hard time looking for data that can be used for One-Way Anova Test. Any suggestions?


Thanks.",statistics
nts08r,1623003702.0,[q] Statistics book for university recommendation?,"
Hi everyone, I asked about a good probability theory book and got a suggestion for ""basic probability theory"" by Robert Ash, which is a great book. I need one for Statistics, the semester course consists of:

1. Statistical structure. Sample. Statistics. Ordinal statistics. Variational series. Sample moments and sample distribution function. Their properties.
2. Point estimate. Unbiasedness, consistency, optimality. The uniqueness theorem for the optimal estimate.
3. Likelihood function. Sufficient statistics, complete statistics. Factorization theorem.
4. Rao-Cramer inequality. Effective estimates.
5. The Rao-Blackwell-Kolmogorov theorem. Optimality of estimates that are a function of complete sufficient statistics.
6. Method of moments. Properties of estimates obtained by the method of moments.
7. Maximum likelihood method. Properties of maximum likelihood estimates.
8. Confidence intervals. Central statistics methods and the use of point estimation.
9. Testing hypotheses. Neumann-Pearson Lemma.
10. Kolmogorov's goodness-of-fit criteria and x-square.
11. Criteria for the homogeneity of Smirnov and the x-square.


If anyone has any good books to learn this I'd be very grateful, thank you!",statistics
ntqolr,1623000046.0,[Question] Effect Size Clarification,"My understanding of effect size is kinda weak (and maybe as well as my general statistics knowledge), if it would not be too much to ask:

I would just like to ask if comparing the Effect Sizes stated here is valid since they have the same ""units"" in effect:

**Spearman's r\^2** from student's t test on spearman's r

**Cramer's phi\^2** from X\^2 test on contingency table

**(Zmax)\^2 / n** from Kruskal-Wallis ANOVA + Dunn’s post hoc test

Concept is form this paper: [https://pubmed.ncbi.nlm.nih.gov/31318894/](https://pubmed.ncbi.nlm.nih.gov/31318894/)",statistics
ntna3o,1622990590.0,[Q] How do I determine a cutoff value within the answers of likert-type items,"Hello,

I am working on a problem analysis for a medical instrument and use the median and interquartile range of likert-type items to determine the central tendency and variation. I want to create a system to determine whether the answers indicate that a specific part or feature of the instrument is deemed problematic or not. Since recommendations to fix the problem will be made, it is necesarry that there is a cutoff between ""problematic or not problematic"".

My current system is simple: a median >=4 indicates that a problem is present and thus recommendations will be made.

I however doubt this method, it seems quite unprofessional and is not based on literature. Keeping things simple might however be the way to go.

Does anyone have any ideas or experience regarding this subject?",statistics
ntm48z,1622987201.0,[Q] Sample Trimming for SupWald formulation,"

Hello ,

I am currently working with some IVX theory. In some part of a paper a SupWald formulation is used to detect structural breaks where the breakpoint is unknnown and also the threshhold parameter is unidentified under the null hypothesis. So far so good, now they state that they used "" 10% trimming at each end of the sample"". I cannot find a good source explaining to me why this trimming is needed can anyone explain to me why we need sample trimming in the case of Sup Wald formulation? If i recall correctly trimming is not needed for standart Wald tests.

Thank you in advance!",statistics
ntia5j,1622973198.0,[Q] new to r and r studio dataset with na values,"Hey i have a dataset with 1028 observations, how can i get rid of na values?

Is it neccessary to get rid of them to do my analyse with some graphics?

Thanks in advance",statistics
nt8hga,1622936349.0,"[D] does anyone know why ""decision trees"" can only make ""rectangular partitions"" in the data?","I have often heard that the decision tree algorithm can only make ""rectangular partitions"" in the data:

https://raw.githubusercontent.com/Wei2624/AI_Learning_Hub/master/machine-learning/images/cs229_trees_3.png

Apparently, these ""rectangular partitions"" (I have heard these rectangular partitions being reffered to as ""linear hyperplanes"") are the reason why the decision tree algorithm is unable to capture irregular decision boundaries within the data.

Conceptually, I can imagine that the decision tree makes ""binary splits"" at each node. In a 2 dimensional grid, these splits will carve up the grid into mini rectangles. All these binary splits constitute the decision boundary corresponding to the trained decision tree algorithm.

But at the end of the day, is this sufficient justification for why the decision tree makes ""rectangular partitions""?",statistics
nt51x0,1622926235.0,[Q] How would you proceed in panel data modeling with countries as groups and only two years to compare?,"So I'm in a bit of a pickle in attempting to do panel data modeling.

I'm trying to model mortality from a certain medical condition (so dependent variable is a percentage value of the deaths within the population with said condition). I am doing a global comparison and attempting to indicate that there are disparities between rich and poor countries. I have various independent variables such as:

* the prevalence of said condition (%)
* undiagnosed % of population in country with said condition
* the prevalence of people at the borderline of getting the condition (also in % of population)
* out of pocket spending (scaled as % of GDP)
* percentage of population with the condition that is currently undergoing medical intervention

In data exploration, I have compared these dependent variables in income groups (Low, Mid, Upper Mid, and High) and I did consistently see differences for all of them.

I am now doing a panel data model (65 countries, only two years) to see if these variables (which behave differently depending on wealth) could be able to predict mortality within a condition or if they just so happen to behave differently due to wealth.

I know I could simply use the Hausman test to choose from Fixed or Random Effects models, but what would be the logical model to choose given what I have just said? In a theoretical sense, which between fixed and random effects models makes more sense for my scenario and supports my theory of disparities among countries due to wealth?

Furthermore, I am concerned with adding a dummy variable to indicate one of the two years - a dummy year variable. Does it make sense in doing so for either fixed or random effects? What logic does doing so give? All I just do is base it on the sign of the coefficient of the year dummy and just say something along the lines of ""mortality is higher/lower on this certain year"".",statistics
nt3qyk,1622922410.0,[Q] Insignificant -> Significant Regression,"Is it possible to say run a linear regression with X1 as the explanatory variable and Y as the response. When the regression is ran, X1 is insignificant with a high p-value.

Then, you run a multiple regression with X1 and X2 and Y as the response, and X1 now is significant with a low p-value.

Is this scenario possible?",statistics
nt2lfj,1622919135.0,"[Q] Introduction into linear models (GLM, multivariate linear regression, mixed linear models)","Hello everybody,

I am an undergrad student who wants to take a deeper dive into some areas of statistics. Specifically, I constantly read about GLM, multivariate linear regression or mixed linear models and think that I could really benefit from knowing more about it.

Since I am a complete beginner, I don't really now how to start, i.e. which topic to read about first (I don't even know if there is a big overlap between the types of linear models that I mentioned).

So my question is, if you could recommend me a order in which I should read about the topics, and maybe even point me to some freely available resources (big plus if it has some hands on examples with R)

Cheers!",statistics
nt1sji,1622916866.0,"[Q] Z-transforming Pearson correlation vs. converting to mutual information: they seem to be related, but how?","Given a Pearson correlation coefficient ρ, it is common to transform it using Fisher's Z-transform:

Z = (1/2)*ln((1+ρ) / (1-ρ))

I noticed that this is extremely similar to the formula for the conversion of a Pearson correlation coefficient to the mutual information (assuming only linear relationships):

I = -(1/2)ln(1-ρ*2)

They are clearly of a similar form, but it's not entirely clear how the relate to each-other. It seems like the FIsher's Z is doing something like turning into the correlation into a ""quasi-MI.""

Does anyone have an intuitive explanation for what is happening here? Or know of any literature I can consult to dig into more of this?",statistics
nt0ul1,1622914244.0,[Q] Measuring the effect of a new emergency dispatch system,"Hey guys, i'm in my master's program in emergency management in germany.

Our local 911 service tries a new way to dispatch it's emergency units (fire department and ambulances). The system tries to reduce the response time for emergencies in non-urban environment by taking the callers position and forwarding it to the units. By doing so, the should be able to arrive on scene earlier than previously, where they didn't have the exact callers position and literally had to hope to finde the scene in a reasonable time.

**My task is to prove if this system significantly reduces the time it takes the units to arrive or not.** I am able to use a data set of several thousand emergencies during the test period and like 60 000 emergencies are available for each previous year. For every emergency there is a huge set of metadata available, like time-stamps, position etc.

Given that the data might show the average time of arrival went down from an average of 10 minutes in the previous year to 9.50 for the test period, I'm not sure if this can be linked to the new system or is part of the usual variance.

This is because  the dependent variable in question, the driving time is depending on many more factors. First, it's dependent on the distance and average speed of the units. **Both are probably affected by the new method - but not only**. There are many many more factors to both these variables, like a different distance for each and every emergency, different weather conditions, different urgencies,...

**My question is: How can I show which role the new dispatch system plays? Do i need to do an analysis of variance or regression? Or a totally different approach?**

As you can see, my statistical knowledge is not to big, but I really like this question so I am motivated to put some work in it and learn a lot.

Thank you in advance!",statistics
nswa12,1622901383.0,[Q] How to learn about Weibull distribution sampling?,"I'm a biologist and I have some code I run to sample from a dataset of genes where most genes have skewed gene lengths (most being very small) but I can sample an equal number of genes across their gene lengths with this code, but I am stuck on understanding statistically how it is doing the equal sampling.

I do this in R with:

    #Input data view:
    Gene  Length
    Gene1  5
    Gene2  6
    Gene3  400000
    Gene4  1000
    Gene5  25000
    Gene6  10
    Gene7  50
    Gene8  4
    Gene9  100
    Gene10 2000

    classes <- df[order(df$Length)]
    classes$density <- dweibull(1:nrow(df), shape=0.1, scale=1)

    classes
    Gene Length      density
    1:  Gene8      4 3.678794e-01
    2:  Gene1      5 1.353353e-01
    3:  Gene2      6 4.978707e-02
    4:  Gene6     10 1.831564e-02
    5:  Gene7     50 6.737947e-03
    6:  Gene9    100 2.478752e-03
    7:  Gene4   1000 9.118820e-04
    8: Gene10   2000 3.354626e-04
    9:  Gene5  25000 1.234098e-04
    10:  Gene3 400000 4.539993e-05

    dfrep <- classes[rep(1:nrow(classes), classes$density*100000)]

    classes <- table(dfrep$Gene) density_calc <- classes/sum(classes)

    dfrep$density_calc <- density_calc[match(dfrep$Gene,names(density_calc))]

    density_prob = 1/dfrep$density_calc

    gene_sample = data.frame(sample(dfrep$Gene, size=100, prob=1/dfrep$density_calc))

I haven't been able to find any statistics resources to learn specific about sampling from a Weibull density, especially those that are not maths intensive, if that is possible for this.

In particular I don't understand the use of the word classes in this code, and how this code over-represents the short genes when creating `dfrep` and that somehow leads to equal sampling of both the short and long genes - I would've assumed increasing the number of short gene representation would increase the probability of those genes being sampled in `sample()` but I can see it doesn't do that somehow. Are there any resources I could find for learning about sampling methods like this?",statistics
nsvpio,1622899594.0,[D] Which regression model is best for analyzing Ordinal dependent and Binary explanatory variables?,"Hey everyone,

So i'm trying to run an analysis on some data I'm working on.

I'm working with 2 variables and want to compare them from  observations made in the years of 2000 and 2010.

\- Dependent: ""Health status"" 1=good, 2=average, 3=bad

\- Explanatory: ""Partner status"" 0=nopartner, 1=partner

I've  done some research and come across different regression models. I would  like to know which one would be the most suitable for what i'm after.  Any help would be greatly appreciated, thank you!

• cross-sectional OLS

• static linear panel data model (estimated by RE and/or FE)

• linear panel data model with dynamics

• cross-sectional binary logit/probit

• panel data binary logit

• cross-sectional ordered or multinomial logit",statistics
nsv5qp,1622897764.0,[Question] Calculating conditional Sensitivity,"Hey all,

Consider a population that I am attempting to create a cohort from. The population is described by  2 binary variables, A and B. My cohort will be composed of people who A = 1 and B = 1. I have 2 imperfect models (A\* and B\*) which may have correlated errors, which I will use to select my cohort. I can measure the sensitivity of each prediction individually (i.e., sensitivity of A\*, and sensitivity of B\*). My question is, how would you go about measuring how the performance of one model affects the performance of the other model when selecting the cohort?

&#x200B;

Some thoughts I currently have

1) Sensitivity of A\* conditioned on B = 1 and B\* = 1 (i.e., sensitivity of A\* among people who should be selected into the cohort). This approach however seems to ignore incorrect classification of B.

2)  Sensitivity of A\* conditioned on B\* = 1 (i.e., sensitivity of A\* among people selected into the cohort). This approach does not account for the correctness of B\* classification.

3) Sensitivity of A\* condition on B = 1 (i.e., sensitivity of A\* among people who should be selected into the cohort). This approach doesn't account for the correctness of B\* as well and does not describe the cohort of interest (A\* = 1 and B\* = 1).

&#x200B;

Perhaps I am approaching this with the wrong tool so I am certainly open to other suggestions. Thanks!",statistics
nssope,1622888366.0,[QUESTION] What does it mean when the significant difference is at 0.01?,Had an ANOVA result and most of the variables had a sig diff of 0.01. what does it mean? is it better/worse than 0.05?,statistics
nssivg,1622887669.0,[M] Statistics Discord Server,"Hey r/statistics I didn't plan on ever posting this again because it would be spam but unfortunately I tried editing the server invite to link to another channel on my [last post](https://www.reddit.com/r/statistics/comments/azfho5/stats_discord_server/) and automod deleted it because at the time of making the post there wasn't a requirement requiring tags in the title  :/

So here's the invite if you're interested: https://discord.gg/ZNsDTKk

We're open to all levels and have a friendly community, we'd love to have you around :)",statistics
nsr723,1622882112.0,[D] What would you include in a basic data literacy program,"Edit: Target audience is people whose role uses data but is not data centric.

Hi Everyone, What concepts would you include if you were training a group of people on basics of using/interpreting data.

I can think of the following. Could you please add to the list.

Thanks for your time.

\-------------------------

a. Averages. When to use median.

b. Importance of removing outliers

c. What is Standard deviation, why is it important in interpreting an average

d. Importance of segmenting and not looking at aggregates - Simpson's Paradox

e. What is a dashboard

f. KPI vs metric

g. Correlation not causation

h. Cumulative totals, why are they used, how to interpret

i. Moving averages, why are they used, how to interpret

j. How charts can be misinterpreted - comparing charts with different scales for example

k. when to use a line chart, when to use a bar chart",statistics
nspz6e,1622876798.0,[Q] Example of Berkson's paradox?,"I was discussing Berkson's paradox with someone and they used the example of an old baseball superstition they had.

*If you were on a winning streak, you DO NOT wash your socks. It is well known that if you wash your socks in the midst of a winning streak, you will lose the next game. Obviously, whether or not the team, collaboratively, or as individuals plays with clean or dirty socks has nothing to do with the outcome of the game. All I know is if we were on a hot streak, our socks could stand on their own.*

He went on to say: *P(loss | dirty socks) same logical value as P(win | clean socks)*

Isn't this more of the Gambler's fallacy than anything? I've been learning about Berkson's paradox recently and this example just made me doubt my understanding. Wouldn't comparing score and cleanliness of socks make for a better example of Berkson's paradox?",statistics
nsptjn,1622876131.0,[Q] Scaling of estimates after contrast coding,"Hi, I am trying to analyse subgroups of a mixed-effects model using custom contrasts. I have 2 factors F1 and F2, each with 3 levels. My interest is in comparing the groups like this:

1. F1_group1 vs. F1_group2and3
1. F1_group2 vs. F1_group3
1. F2_group1 vs. F2_group2and3
1. F2_group2 vs. F2_group3

I am using lme4::lmer(), and them emmeans::emmeans(). The model looks good, the contrasts look good (uncorrelated etc.). The things that ""should"" be significant are, and those that ""should not"" are not.

Problem: The estimates are obviously scaled. The exact values are way too large. If I do paired comparisons the estimates are fine. I do not understand how exactly and can't find information on this anywhere.

I am very interested in the exact estimates, not just the p-values, so I would like to figure out where the issue occurs. Any ideas or pointers?

Contrasts look like this:

| F1 | F2 | c1 | c2 | c3 | c4 |
|----|----|----|----|----|----|
| a  | a  | -2 | 0  | 1  | -1 |
| a  | b  | -2 | 0  | -2 | 0  |
| a  | c  | -2 | 0  | 1  | 1  |
| b  | a  | 1  | -1 | 1  | -1 |
| b  | b  | 1  | -1 | -2 | 0  |
| b  | c  | 1  | -1 | 1  | 1  |
| c  | a  | 1  | 1  | 1  | -1 |
| c  | b  | 1  | 1  | -2 | 0  |
| c  | c  | 1  | 1  | 1  | 1  |",statistics
nsoz2d,1622872590.0,"[Q] How to formalize the notion that a you can be more confident with a certain ""rating"" with more reviews?","Something that seems empirically true to me, but I am not sure how to formalize is the notion. For example, on Steam, a game is rating by thumbs up/down. It seems clear that game with 95% positive from 40,000 users will be more likely to be a ""good"" game to you than one with 95% positive and from 4,000 users. But how much?

Moreover, how can we compare one with 88% from 500,000 vs one with 93% from 5,000? Intuitively, it seems like the one with 500,000 should be more likely to be a good game than the one with 5,000 despite it's lower rating.",statistics
nsmz43,1622864993.0,[Q] How shall I understand the UMP test theorem via MLR?,"In Lehmann's TSH,   Theorem 3.4.1 (https://i.imgur.com/m8en00H.png) on p65-66  says

> Theorem 3.4.1 Let theta be a real parameter, and let the random variable X have probability density p_theta (x) with monotone likelihood ratio in T(x).

> (i) For testing H : theta ≤ theta0 against K : theta > theta0, there exists a UMP test, which is given by:

> phi(x) = 1 when T (x) > C, gamma when T (x) = C, 0 when T (x) < C, (3.16)

> where C and gamma are determined by

> E_theta0 phi(X) = alpha. (3.17)

> (iii) For all theta', the test determined by (3.16) and (3.17) is UMP for testing H: theta =< theta' against K: theta > theta' at level alpha' = beta(theta').

In (iii), is ""the test determined by (3.16) and (3.17)"" a size alpha test, according to (3.17)?   How can (iii)  be so sure that it is level alpha'? What is alpha' relative to alpha?

Is (iii) already mentioned in (i)? What is the difference between (iii) and (i)?

Thanks.",statistics
nsilq3,1622849918.0,[Question] Anyone know a good website/platform for hosting a Pairwise Comparison Survey?,,statistics
nshw8g,1622847644.0,[Question] Interpreting Test Percentiles/Bayes Rule Three Variables,"

Hello!

Hey everyone, I've been chewing on this for a few days and I'm hoping someone here can help. I'm trying to find out the percentage of people who got a better score than I did on a standardized test.

The test reports results in the following way:

The test has three parts, each part reports its own score. The scores are supposedly T-statistics with means at 50 and 10 point standard deviations. So, a 60 is one standard deviation above the mean, and a 40 is one standard deviation below the mean. No other information is given about the underlying distribution of the scores, but let's presume the distribution is normal.

The scores are reported cumulatively. Let's say I got a 59, 61, and 60 on each component (not my real scores), so I have a cumulative score of 180.

My first thought was that because \~34% of people are within 1 standard deviation of the mean in each direction, and I did 1 standard deviation better, then I'm probably around the 84th percentile. Then I got to thinking that was wrong.

If I assume that the events are independent then I can simulate the number of people with a 180 assuming random distributions around the score 50 with standard deviations of 10. I don't know how to upload an image, but in 1000 repeated simulations, a score of 180 was always better than between 96.5% and 95% of other scores.

The tests aren't truly independent though, so I would expect that someone who does better on test 1 would also do better on test 2. So I know this is some kind of Bayesian equation but I don't know how to begin. I found some people who volunteer their scores online and calculated the correlation between test components 1, 2, and 3.

Comp 1 and 2 corr = .2

Comp 2 and 3 corr = .18

Comp 1 and 3 corr = .33

(160 obsv in the volunteered data per test component).

Anyway, I've never done anything with Bayes' Theorem before, and I don't know how to start with three variables. If anyone has a solution, please let me know!",statistics
nsguam,1622844455.0,[D] How to build conversion tables from event logs,"[https://www.crosstab.io/articles/events-to-conversions](https://www.crosstab.io/articles/events-to-conversions)

Would love feedback on this piece, especially the term ""conversion analysis"" as a generalization of ""survival analysis"".",statistics
nsg5ka,1622842517.0,[Question] What layman example can one give to convince a person of their wrong interpretation of Null Hypothesis?,"I recently saw a Data Science 'guru's' video explaining Null Hypothesis testing. He wrongly kept saying ""We accept the null hypothesis"".

When I tried to correct him and said 'you can only fail to reject the null hypothesis, one can't accept it'.

He retorted and said 'how does it matter, it is just a word play !'

I understood that he was not getting the seriousness of the issue.

How would you try to explain the seriousness of the issue with an layman example.",statistics
nsdvk9,1622836401.0,[Question] How to handle wrong statements in longitudinal data set?,"Hi, I have the following problem. I'm writing a thesis and I'm using census data. Households get randomly selected and get questioned 5 consecutive quarters. I can idendify people over the quarters and I want to observe an effect over time (finding a job if certain criteria are met beforehand). But now i have the problem that a lot of the cases I find are based on wrong answers in the questionnaire, e.g. in January a person says they've been unemployed fror 4 months and 3 months later they say they've been unemployed for 9 months.
Now I can identify the obviously wrong statements in my key variables, but I  can't simply exclude them, can I? Excluding these people certainly influences the other people's weights. So how would I handle this situation?

Thank you in advance!",statistics
nsbprs,1622830713.0,[Q] Careers for MS Statistics without coding?,What careers are there for people with MS in statistics that doesn’t involve coding? I feel like for any good high paying job these days you basically need to be a great coder?,statistics
nsbd7o,1622829755.0,"[S] Hi all, I made a Python package to plot distributions / calculate probabilities, check it out!","Hi everyone,

I'm working on a Python package to do some applied statistics. I learned a lot of the theory behind this in mathematical statistics, so I wanted to try programming it all from scratch to do things like plot distributions, calculate probabilities, find MLE's, and perform hypothesis tests.

Check it out here: [https://pypi.org/project/applied-stats/](https://pypi.org/project/applied-stats/)

There's a jupyter notebook with examples of how to use the module here: [https://github.com/WillTirone/applied-stats\_examples/blob/main/Demonstration.ipynb](https://github.com/WillTirone/applied-stats_examples/blob/main/Demonstration.ipynb)

Obviously, you could probably do all of this with SciPy, but I'm mostly making this for my own learning sake. I also like how I was able to make plotting and filling in the distribution tails fairly quick, that depiction of a plot was always helpful to me when I was learning about these distributions.",statistics
ns9b6p,1622824443.0,[Q] Effect size calculation for lm_robust(),"My data fail tests of normality, and are also skewed.
I'm using lm_robust thus:

	> summary(gpa.lmro)

	Call:
	lm_robust(formula = mean_power_abs ~ condition, data = mont_gpa)

	Standard error type:  HC2

	Coefficients:
	            Estimate Std. Error t value  Pr(>|t|)  CI Lower  CI Upper   DF
	(Intercept) -0.09681   0.006705 -14.437 1.201e-45 -0.109955 -0.083659 2839
	conditionto -0.01441   0.009206  -1.565 1.176e-01 -0.032460  0.003641 2839
	conditionvf  0.02495   0.009326   2.676 7.502e-03  0.006666  0.043237 2839

	Multiple R-squared:  0.006129 ,	Adjusted R-squared:  0.005428
	F-statistic: 9.643 on 2 and 2839 DF,  p-value: 6.706e-05

condition has three levels, nf, vf, and to

For the same dataset, I relevel() and make vf the base level to get the vf-to comparison.

There is an R-squared and adjusted R-squared, but for the overall model. I.e. I don't know the R-squared of nf-vf (which I could use to calculate f^2). Is there a function that will calculate effect sizes for each combination of the three condition levels?

Should I use something like yuen.effect.ci() for the significantly different conditions, as determined by lm_robust()?

Would I then adjust alpha? If so, would I divide by the total number of possible comparisons (there are three: nf-vf, nf-to, vf-to), or the number of comparisons that I actually do. For instance, if nf-vf is significantly different, and that is the only comparison that is significantly different, would I use 0.05/1=0.05? Then if nf-vf and nf-to are significantly different would I use 0.05/2=0.025?

Thanks for any advice!",statistics
ns7zi3,1622820934.0,[Q] a few basic questions about gaussian processes,"Hi all,

So I've been exploring GPs these last few days after seeing a neat little interactive animation of them earlier this week (see earlier question [here](https://www.reddit.com/r/AskStatistics/comments/nrnfi1/what_does_the_wiggly_animation_in_this/) if anyone is curious). They're quite straightforward to work with so I was able to whip up [a quick demo](https://i.imgur.com/JM41c9Q.png) in R from scratch quite easily to e.g. visualize prior and posterior predictive distributions corresponding to arbitrary psd kernel functions.

(I have a bit of prior experience here, e.g. performing joint inference of ancestral states integrated over phylogenetic uncertainty in evo bio contexts, or approximating truncated Brownian bridges in biogeographic diffusions etc. But stats isn't actually my field -- my degree is in anthropology -- so apologies for any flagrant abuse of language or misunderstanding below)

I have a few questions, though, as I play around with this stuff:

1. It seems people often either fix the mean vector of their GP to 0, or else estimate for it a single scalar constant, i.e. an intercept. But it seems in many adjacent contexts e.g. phylogenetic regression, or when exploring geospatial confounding etc., what we'd really want the GP for is to accommodate pseudoreplication in our data to perform inference of some linear model parameters to answer some substantive scientific question of association between variables. This seems to me an entirely sensible procedure, but would the resulting model be identifiable? For example, say I stuck a linear model featuring some sinusoidal function on the mean -- if I used a periodic kernel for my GP to model covariation in the residuals from that linear model, wouldn't they sorta be capturing the same thing? Likewise, what if I stuck a linear model (w/ e.g. a log-link) on my dispersion term?

2. With respect to answering substantive questions given e.g. posterior distributions of model parameters, we might not necessarily care about the posterior predictive at all, our goal being inference. Are there maximum-likelihood (or other) estimators for these? (or can we exploit conjugacy to obtain their solutions in closed form, or must we resort to numerical methods?). Is the kernel trick still helpful here? It seems like it'd still be pretty intractable at even moderate-N (e.g. suppose we have a thousand observations -- evaluating the likelihood for each unique kernel matrix would require inverting a 1000x1000 covariance matrix, which seems like it would make moving across the space of linear model parameters utterly hopeless. Though I guess if you're not varying kernel function parameters too often you could transform the data by its Cholesky factor and explore the linear model parameters on that transformed space, back-transforming to evaluate parameter prior densities?)

3. Similarly, are there any conjugacy properties that we can exploit to obtain estimates for kernel function parameters in closed form? One thing I noticed from the interactive visualization is that they're all fixed, alongside the variance of the ""noise function"". But this is quite dissatisfying e.g. when I specify observations [that are tightly clumped](https://i.imgur.com/V6Ov3AG.png), since if I'd tossed e.g. an exponential and not a point-mass prior on that delta_noise down below, the model will have learned the clumpiness (I guess here I'm thinking of that extra gaussian noise as the sum of your ""meaningful"" kernel and a a separate ""scaled-identity"" kernel, per one's ability to sum psd kernel functions indiscriminately according to the properties of multivariate normals). Alternatively, in the case that we are just interested in the posterior predictive, can we marginalize over those kernel function parameters in closed form?

4. Looking at Wikipedia's list of [common kernel functions](https://en.wikipedia.org/wiki/Gaussian_process#Usual_covariance_functions), I have a question about the one corresponding to the OU process. In phylogenetics, we'd fit much more parameter-rich OU models, i.e. at its most basic form with parameters corresponding to ""phenotypic optima"" i.e. the locations of attractors, and with ""returning force"" parameters, corresponding to the strength of that ""attracting"" or ""returning"" force. In the stochastic diff eq these would typically be denoted by mu and theta, respectively, and we'd specify all sortsa hierarchical models with multiple optima and returning forces etc. that could shift according to e.g. changes in a ecological regime (as determined by some markov process) throughout the tree. The kernel function wiki gives for the OU process -- exp(-|(x-x')|/l) -- clearly lacks these parameters (though maybe the lengthscale corresponds to the returning force?). Can you help me map the OU process as I understand it to the one described by that kernel function? (e.g. does it assume the process starts at stationarity? What if I wanted to extend it to have a stronger returning force, or shifts in the location of the optimum throughout my input domain?)

Apologies for the length and thank you for any help!",statistics
ns78el,1622818990.0,[Q] Estimating Parameters of a Categorical Distribution That Changes Over Time,"I'm modeling a scenario in which a subject is asked to choose between K different options repeatedly over time. If it were the case that this subject's preferences didn't change over time (i.e. the observations are iid), I could model the probability that they choose each of the options as a categorical distribution with parameters p\_1, p\_2, ..., p\_n and use Bayesian estimation with a Dirichlet prior to estimate these p\_i parameters (or even just use the estimate p\_i = #times i was chosen/#observations).

However, suppose that the subject's preferences *can* change over time; if we had 1000 observations, the first 10 observations may be less relevant in estimating these changing p\_i's than the last 10 observations. My first instinct is to create some sort of a ""weighted"" model in which earlier observations have less impact on the estimate of the p\_i than newer ones; an example would be to have a rate γ at which observations decay so that p\_i = sum(γ^(N-t) \* I(X\_t = i))/sum(γ^(N-t)) where each index variable t goes from 1 to N (where N is the number of observations) and I is the indicator function. However, I'm not sure that this is necessarily the best way to go about this.

Is there any literature on this type problem or related statistical techniques that could be useful? Am I even approaching the problem the right way? I appreciate any pointers.

Edit: To be clear, I am primarily interested in predicting X\_{N+1} given the observations X\_1, ..., X\_n",statistics
ns5e6n,1622814055.0,[Question] Coin flipping probability.,"Hello.

I'm interested in statistics.

I want to understand the basics.

If I flip a coin for 20 times and got heads 83% of the times.

This means something or nothing?

Is there anyway to say: there is an 40% chance wich the coin will got heads the 83% or something like that?

And how to do the basics calculations?

Any recommended book for a noob?

Thank you.",statistics
ns3ie2,1622808326.0,[R] Interaction between year and treatment in LMM,"My trial consists of one single factor called SYSTEM in a completely randomized block design with four replicates. The dependend variable YIELD was mesuared every YEAR for eleven years.

The model I came up with in lme4 was:

lmer(YIELD ~ SYSTEM + (1|YEAR*BLOCK), data = data)

Many publications in my field suggest a random interaction between the treatment factors an the repeated factor, like adding (1|YEAR:SYSTEM) to my model but I don't understand why or when this is necessary.",statistics
ns12q4,1622799292.0,[Q] Difference between Cox regression and GLM with exp/log link function?,"I'm trying to learn survival analysis and the model specification for Cox regression looks \*very\* similar to a GLM with exp/log link function.

&#x200B;

I understand that there needs to be a distinction between censored and non-censored observations but can't that be achieved by modeling the conditional probability with the GLM?


I feel I'm either missing some critical thing about Cox regression or just forcing a similarity between it and exp GLM.",statistics
nrvfy1,1622777064.0,[D] Why was the Kaplan-Meier method considered so groundbreaking?,"https://en.m.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator

The kaplan-meier method was developed in the 1950's and is still considered to be quite groundbreaking and influential. It is used to estimate survival rates and mortality.

However, it seems that similar methods to estimate similar concepts had already existed for hundreds of years before. For example, ""life tables"" were recorded by Edmund Halley in the 1600's:
 https://vincentarelbundock.github.io/Rdatasets/doc/HistData/HalleyLifeTable.html

What was so special about the kaplan-meier method compared to its predecessors?

Thanks

Side question:

Can ""force mortality"" be considered as a hazard function?

https://en.m.wikipedia.org/wiki/Gompertz%E2%80%93Makeham_law_of_mortality

https://en.m.wikipedia.org/wiki/Force_of_mortality",statistics
nrtgvt,1622770410.0,[Question] Would a glm binomial model be appropriate for this outcome variable?,"Hello,

I have an variable in a repeated measures dataset who's distribution looks like [this](https://i.imgur.com/1EhYUhO.png) raw, and like [this](https://i.imgur.com/yd2nqmz.png) after doing a `groupby(participant_id)` (python3, seaborn). Would a binomial model be appropriate? Or a bimodal one?

My hypothesis (stats in R) is that the mean_variable can be predicted some demographic variables and an interaction.

For my variables:

* n = 31
* mean_variable - outcome, continuous (percentage) or binomial (thats the question)
* w - continuous, float
* x - continuous, float
* y - continuous, int (symptom measure)
* z - continuous, float (medication)
* days - ordinal, either 3 or 6. It is a covariate to control for having 2 datasets where in one the participants were treated for 3 and in the other for 6 days.

My code in R

```R
res.binom <- glm(mean_variable_bool ~ w + x + y*z + days, data = demos_mn, family = ""binomial"")

res.null <- glm(mean_variable_bool ~ 1, data = demos_mn, family = ""binomial"")

r.squaredGLMM(res.binom)

anova(res.null, res.binom, test = ""Chisq"")
```",statistics
nrqeku,1622760966.0,[E] A Concrete Introduction to Probability By Peter Norvig,"I thought [r/statistics](https://www.reddit.com/r/statistics/) might be interested in this code I just found in Peter Norvig's GitHub repo teaching probability.

[https://github.com/norvig/pytudes/blob/master/ipynb/Probability.ipynb](https://github.com/norvig/pytudes/blob/master/ipynb/Probability.ipynb)",statistics
nrom9e,1622756017.0,[Q] Too many observations in lme4-model to calculate df's,"Hi, I fitted a mixed-effects model using lme4::lmer. The data has around 11,000 observations. Model is great, but when trying to retrieve EMMs using emmeans I get into trouble. The df's cannot be calculated, but I need them for reporting. They are returned as Inf. Even when letting emmeans run with options set to ""do your thing"", my computer runs out of memory (Calloc error).

I could aggregate over one factor before fitting the model to get it down to 2,000 observations, but that would throw away information.

Do I have any other options?",statistics
nrncr2,1622752662.0,[Q] Have you ever had to derive a new estimator or test in industry?,"I'm curious under what circumstances a statistician would have to derive a new estimator or test in practice. I would love to get a chance to use what I learned in math stats someday, but I can't think of a situation I've encountered where I'd need to derive something new. If I have, I didn't recognize it and found an existing approach that was acceptable.

Are there certain application areas where this is more likely to happen?",statistics
nrn54v,1622752122.0,[D] Life Expectancy and Mortality Statistics,"Has anyone ever seen a graph that shows the ""hazard of dying"" for the average adult throughout their life? On this graph, the horizontal axis would be ""years"" and the vertical axis would be ""hazard of dying"". And this graph would show that when a baby is born, they face a higher hazard of dying ... then the hazard decreases ... but slowly increase as the adult enters old age? I tried looking on google images for a study/graph in which this trend is shown, but I was not able to come across this kind of graph?

Also, has anyone ever studied ""hazard functions"" and ""cumulative hazard functions"" in the domain of survival analysis before? Is the following statement correct?

A hazard function is free to increase and decrease, but the cumulative hazard function (as the name suggests) can only increase?

Thanks",statistics
nrmj2a,1622750539.0,[Q] What is the best way to quantify the strength of association between different things rated on the same dimensions/factors?,"I have x images rated on 25 dimensions. I also have x words rated on those 25 dimensions.

When I factor analyze the ratings, I get the same four factors for images and words (though extracted in a different order).

I want to use this to quantify which images/words are most similar/dissimilar.

I've done this by:

1. z-scoring each factor rating
2. taking the absolute difference between each image/word on each factor
3. averaging these differences

Is this a good approach, or is there something better I can do?",statistics
nrlmrf,1622748235.0,VAR vs VECM Models [Q],"What are the advantages and uses of VECM models? How do they compare to VAR models? When would you use each of them?

Can anyone summarise the purposes of these models.",statistics
nrjr2t,1622743396.0,"[Question] What are the different Statistical techniques to study ""associations"" between different variables of a dataset?"," I am new to the field of statistics and I came across this problem at work where we need to find associations between current penetration and a host of other variables. All the data is numeric.

My first intuition is to use regression and see how the two variables may be related, and to what degree, my explanatory variables explain the response variable. And then I also graph the data with the regression line to make it more visual to me and the reader.

I was also thinking about calculating the correlation between the variables (maybe a correlation matrix?).

Am I heading in the right direction? Are there any other techniques that can help me out and yield better results?

Thanks!",statistics
nriivz,1622740215.0,[Q] Spectral density under non-stationary processes,Does it make sense to talk about a time series in the frequency domain if it is not stationary in a weak sense? I'm asking because I've only seen it formulated in terms of the autocovariance function for weakly stationary time series.,statistics
nred75,1622729270.0,[D] regression models vs random forest,"I tried fitting a GLM style regression model to some data and it resulted in all the regression coefficients being estimated as 0 (i.e. model failed). Yet when I tried a random forest model on the same data, the model worked well and I was even able to get 70% accuracy on the test set.

My dataset has continuous and categorical variables, as well as a lot of ""naturally occurring zeros"".

I was just wondering: is this a common problem? I spent a whole day trying to tweak the regression model to work, but the random forest instantly outperformed it?

Thanks",statistics
nrda7i,1622726222.0,[C] Recent Statistics Graduate Unsure What Jobs to Apply For,"I graduated this year with my Bachelors in Mathematics and Statistics. I am 32 and do not want to pursue a graduate degree as I am wanting to begin my career. I am open to returning to school later, but right now I want to work. I have completed courses in linear and abstract algebra, calculus/real analysis, differential equations (ODE/PDE), data analysis (LM, GLM, GLMM, GAMM, etc,),  non-linear optimization, mathematical statistics, and probability. For computer languages I am most familiar with R, but I am also a capable user of Python.

I'm not sure what jobs I should apply for. I have applied to a few entry level Data Analyst and Data Science positions. I'm curious as to whether there are other types of jobs I should be looking into. I am also concerned with my resume and what to include in a cover letter. I have zero work experience in the field. I have completed assignments for school, but no real world experience. I have been (and still am) working retail to pay the bills while I completed my degree.

Any advice would be greatly appreciated.",statistics
nrbyzb,1622722319.0,[Q] Calculate sample size,"Hi! My assignment is to find out how big of a sample size I need to show that the anticipated incidence from a preliminary examination is existing IRL. But I have no clue which formula to use. I have used this [website](https://epitools.ausvet.com.au/twoproportions) to calculate the sample size but they dont show the calculation ;/ Any kind soul that can help? :)

The significance is supposed to be 0,01%, power 90% and ratio of sample ***(142 311/118 849 = 1,197)***

|Counties|Preliminary examination|Entitled to vote|
|:-|:-|:-|
|Kronoberg|22%| 142 311 |
|Blekinge|25%| 118 849 |",statistics
nr9tb8,1622714625.0,Adjusted R-squared and Colinearity [Q],"Hello everybody,

I recently took a statistics course on Coursera and the final project was to build a linear regression model based on a couple of variables to predict movies popularity, two of them being the movie audience score (my dependent variable) and imdb rating. The correlation between audience score and imdb rating is 0.86, if I fit the model without the imdb rating the adjusted R-squared is 0.23, if I include the imdb rating is 0.76, both are statistically significant with p-value~0. With that being said, was it a good call to exclude imdb score because of its high correlation with the dependent variable

Thanks!",statistics
nr92go,1622711521.0,[Q] how to use multiple variable correlation to determine midel,"I have been given sales data (units) as it relates to 7 different “Factors”. These factors are unnamed. All I’m given is their rating out of 10 on a given sales day. For example, Day 1: Sales 105, Factor 1 = 3.4, Factor 2 = 9.1, Factor 3 = 5.5, up until Factor 7. There are 50 days of data like this.

I understand using Excel’s data analysis tool how to find the correlation, but how can I use those numbers to figure out the model of how sales are determined. Or how can I figure out, for example, how sales will increase if I raise Factor 1 by 1.0.

Also, does it mean it is actually a significant Factor if the correlation is high? Or does it not necessarily mean that? How does one determine which Factor is “noteworthy”?",statistics
nr8go1,1622709003.0,[Question] Survival Analysis: Censored Quantile Regression and interpration of parameters,"&#x200B;

Dear Statisticians,

I'm approaching the censored quantile regression for survival analysis, a very intrestring approach expecially in cancer research where some treatments (e.g. immunotherapy) have a delayed effect and the proportional hazards assumption of the Cox Model can't hold.

I know it can be a niche approach but for this I would like to have the opinions of those who worked on it.

Normally the censored quantile regression models the quantile of the logarithm of time to the event, pretty much like an AFT model, but know we are talking about the quantile of the log and not just the log of the time to the event, and again, pretty much like an AFT model the covariates have a linear relationship. Since we are modelling the ""conditional quantile"" we do not have to assume any distribution for the time to event and this is a strong point for this approach.

Immagine i have only one covariate ""arm"" with values: 1 = Treatment and 0 = Placebo. I want to ask you about the interpretation of the parameters of quantile regression for the log time of the event in a survival analysis with just this covariate.

Immagine i want to estimate the parameters for the 20-quantile:

The parameters i would see, would be an ""intercept"" parameter and ""arm"" parameter. For my interpretation, the parameter ""arm"" is the difference between the 20-quantile of log(time) for arm=1 and for the same quantile for arm=0. And as you can immagine, for me the intercept parameter is the quantile of log(time) for arm=0. So by exponentiating the ""arm"" parameter i can obtain the ratio between the 20-quantile of TIME for arm=1 and for arm=0.

I ask you first if this above is correct

Moving on i ask you: from the parameters i can obtain modelling quantile of log(time), is there a way to obtain something not in terms of ratio between the quantile of time, but in terms of difference between the quantile of time between arms?

Thank you for your support",statistics
nr5ejn,1622696612.0,[Q] Solid textbooks on probability theory (advanced),"Hello, I’m a statistics Major who will be a junior in the fall, I took a probability class already but I felt it was too vanilla and was only a surface level class for probability theory. To be honest with you I think the class was just not all that I could have learned from a first probability theory class.

Does anyone suggest any textbooks which go more in depth into probability? I guess it could go into stochastic processes if it does, but it doesn’t have to necessarily. Just something which goes deeper into the “theory” side of probability theory.",statistics
nr2wyb,1622687855.0,"[E] A modern version of ""The Jackknife and Bootstrap - Shao & Tu""","Hi all,

i was wondering if any of you know a book like The Jackknife and Bootstrap, in the sense of mathematical rigurousity, for resampling techniques, but that is a bit more current?

This book is great, but 2 things I dont like. The notation is a bit cumberson for my taste, but more importantly is lacking in other resampling techniques, like permutation test.

&#x200B;

Also, since is more than 20 years old, theres probably some outdated content there.

Any help would be cool, thanks",statistics
nr2ptl,1622687184.0,[Q] Pros and Cons working as a contractor for pharma company?,"I am expecting an offer for a long-term contract as Sr. Data Scientist for a medium size pharmaceutical company. It is a unique position that I really like. However, I have never worked as a contractor so I want to be informed. Here are my thoughts:

Pros:

1. Big salary (and title) increase from my current Academia job
2. Get my foot in the doors of Pharma industry - I found it is almost a norm to start as a contractor

Cons:

1. Minimal benefit - bad insurance plans and very few PTO days - no more long vacation and may have to postpone family planing
2. The company is unlikely to invest in me for further career development. I had a Zoom interview with the hiring manager for \~40mins and he decided to give me the offer.
3. Uncertain whether or when a permanent position will open
4. Being treated as second class citizen, which is likely to happen anyway since I don't have a PhD or MD

Anything else?",statistics
nr15z1,1622682090.0,"[R] Three-way Mixed ANOVA (BBW) - sig vs no sig interactions, what now?"," Hello everyone,
I'm **desperately** trying to have an answer for this, but no luck so far.

**My RQ:**
\- Do students experience increased anxiety prior to their first laboratory (yes)
\- Can a short intervention reduce this initial anxiety
\- Is there a difference between gender (males vs females) or laboratory experience (Short vs Long)

n \~ 300 /year.
65% females, 35% males.
70% attend long laboratory, 30% attend short laboratory

**Study design:** Anxiety Measure 1 (continuous variable) ---> Intervention ---> Anxiety Measure 2 (same survey) ---> Attend first lab --> Anxiety measure 3 (same survey, post lab)

I figured Three-way mixed ANOVA BBW

The dependent variable is anxiety score 

The 1st between subjects factor is gender (two groups: male and female)

The 2nd between subject factor is lab experience (Two groups, long and short)

The within subject factor is time (which has three time points, T1, T2, and T3) 

**Problem (when I follow Laerd Statistics)**
Step 1: Do you have a statistically significant three-way interaction?  --> **No**
Step 2: Do you have any statistically significant two-way interactions? --> **No**
Laerd: If no – you do not have any statistically significant simple two-way interactions – end analysis and write up
If I listen to Laerd, there is nothing to write. However, by looking for significant simple main effects, however: I found that **males reported lower anxiety levels when compared to females at T1 (p = 0.015).**
By further looking into simple simple main effects, I found that at **T1, males in the longer lab show higher anxiety than females in the longer labs.**
And .... at **T2,** males in the longer lab show higher anxiety than females in the longer labs.
Ofcourse, the most important aspect is overall anxiety (Regardless of gender or laboratory experience) significantly decreased across all three time points (suggesting the intervention works (T2 - T1), and initial heightened anxiety was present (T3 - T1).

My confusion is, if I follow Laerd's stats, I only talk about not having three way interactions and two way interactions... However, as you can see, I have quite a bit of findings.

I am facing this issue across another cohort as well (dif year), where another intervention showed no three way interaction, but a two way interaction. However, according to Laerd, I can't look at simple simple comparisons for some reason.

Any help would be truly appreciated!",statistics
nr0bqy,1622679362.0,[Q] Comparing data formats for multilevel modeling and general linear modeling,"Suppose I have the same dataset, one in short format, one in long format. If I run a multilevel model on the long form data using subjects as a random effects term, then run a general linear regression model on the short form data, would I get the same results? I'm specifically thinking about correlation coefficients, p values and r-squared, but I'd love to know what you think would be different or the same! Thanks!",statistics
nqwrdm,1622669024.0,"[Q] Question about statistical significance with an ongoing customer satisfaction survey, with monthly reporting. I originally asked this in r/SurveyMonkeyPros, and was advised to try my luck here.","Hi, I send out the customer satisfaction surveys for our clients via Survey Monkey. I don't have much information available to me on statistics, I fell into this role because I handle email for our company.

I've read the general info for statistical significance on an individual survey, but I'm unsure how to apply it to my population as I send out invites almost daily (automated) and report on results monthly.

My overall population size is 10K people. These are active clients who can stay with us for up to five years as they work through our program. I don't invite all 10K to the survey each month, I rotate the invites so our clients receive them two to three times a year. At the moment, I don't tie the invitation to a specific interaction or occurance that takes place with the client, there are different surveys for that purpose.

My response rate is really low, like 40 respondents per month, out of 180 invites sent. I can tweak my automation and increase the number of invites I send, but I'm curious - if my population size is 10K, and my goal is a 5% margin of error, and I report on my survey results monthly, do I need 385 respondents per month?",statistics
nqup28,1622663642.0,[C] Career opportunities after masters in Statistics?,"I have recently completed my Bachelor’s of science degree in Economics Mathematics and Statistics from India. I enjoy statistics and it's application quite a lot. I am planning to pursue my masters degree in Statistics in the US. Is it a good country to pursue statistics? What are the career options after my masters? I do not have any work experience, will that be a problem? How can I improve and build my resume during my masters to become more employable?

Any suggestions?",statistics
nqui1s,1622663145.0,[Q] different coefficient signs with cross-sectional regression vs pooled OLS regression (panel variant),Hello! I have a data set with stock returns for a 21 day time period of 229 firms. When I run a pooled OLS regression on the data set i get significant positive variables where when I run a cross sectional regression on the sum of the returns (CARs) the signs of almost all variables in the regression change. What is the intuition behind this?,statistics
nqsjoe,1622658219.0,[Q] How do I create this regression output in RStudio?,https://imgur.com/4R6yK2t,statistics
nqs790,1622657410.0,[Q] [S] Kruskal-Wallis in Statistica," Hey, I'm trying to get the statistics for my thesis. I've maneged to obtain K-W multiple comparison of mean rank, but I would like to show the results on a bar plot (with \* or letters). Anyone knows how to do that?",statistics
nqrvcs,1622656554.0,"[Q] I have two correlated metrics, and want to use one to forecast the other - but the relationship isn't linear.","I have two metrics - Sales Backlog, and Customer Deposits. I know they are correlated (over .95 correlation coefficient, according to excel). As the Backlog increases (the time between making a sale and delivering a product), so will our Customer Deposits (money from customer set aside from a sale until we deliver it).

But the relationship isn't 1:1. They don't rise and fall at the same rate. Meaning the ratio between the two isn't constant.

How can I predict what the Deposits number will be in the future, given a specific Backlog number? I've got a few years history for the relationship between the two, but am not sure how to turn it into a forecasting equation.",statistics
nqro3o,1622656025.0,[Q]Stat test to use when comparing discount amount to sales,"I've taken a few statistics classes and understand the basics up to ANOVA, Regressions, Chi-Square, and basic non-parametric tests. I am currently trying to determine if the discount level on a given product in an e-commerce site has a significant effect on level of sales. I believe my hypotheses would be as such:

H0= Discount level has no effect on sales numbers

H1= Discount level does have a significant effect on sales numbers

and my data is structured as shown in the following example:



Date| Sales | Discount amount
---|---|----
01/01/20 | $100,765 | 0
01/02/20 | $105,643 | .1
01/03/20 | $96,765| 0
01/04/20 | $97,000| 0
01/05/20 | $100,765 | .15


let it be noted that the above data is an example and is only shown to demonstrate the way my data is structured. I appreciate any and all help!",statistics
nqnww4,1622646498.0,[Q] Question about standard deviation with respect to the summands of a sample mean.,"I'm teaching myself statistical learning and ran into something I don't really understand. Im using the book Introduction to statistical learning with applications in R. On the last sentence page of 65 it says ""We have the well known formula Var(mu hat) = sigma^2 / n where sigma is the standard deviation of each of the relatzions of y_i of Y. I understand the formula and how it's derived as I have taking calculus based probability and statistical inference before, but what I don't understand or remember is how does a single y_i have a standard deviation? Isn't y_i just one of the summands in the sample mean y bar? In other words I thought y_i is just a data point, so how does it have variance or standard deviation?",statistics
nqnrht,1622646050.0,"[Q] Excel forecast function, help please"," So I'm taking a statistics class and I need to do a forecast for specific values. Basically, I have Covid cases/ covid deaths day by day in a month(30 days). and I have to use the forecast function to predict how much deaths would occur given a specific case number on the 31st day. How would I go about doing that? I tried using the linear forecast function but the numbers that came back were pretty weird. Can someone tell me how to do this? I have x values, y values, 30 days in the month, 1 day to predict given a specific case number.",statistics
nqky08,1622637881.0,[Q] How much of an emphasis is there on “software engineering” skills in non-tech industries,"Hello, I’m a undergrad whose looking to do an MS in stats or applied stats. i have read a lot of posts about MS applied statistics vs MS statistics and how the MAS can prepare you with software engineering skills more than MS can etc. however, something got me thinking that a lot of these programs which have an emphasis on software skills feels like it’s just prepping students for a job in tech. Which makes sense, hence why data structures and algorithms is so common as a requirement.

However, my question is, outside of tech, say in banks or other companies, is there as much of emphasis on software skills as opposed to stats knowledge? I know that coding is always there, but outside of tech is there as much of an expectation for MS stats or AS candidates to have extremely good coding skills? Like the tech Industry? Or is it more in the emphasis on the stats side?",statistics
nqklp0,1622636741.0,[Q] Which variable do I need to omit?,"Hi everyone,

I'm working on my thesis and I am running a simple OLS regression with multiple dummy variables to control for industry types i.e. IT, Healthcare etc. I need to omit a dummy to avoid a dummy trap, but which one do I omit? Do I just go with the one that is automatically omitted by STATA, or do I omit the one with almost no observations? Thanks in advance!",statistics
nqk5mz,1622635214.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
nqbgy0,1622601942.0,[Question] Is PhD right for me?,"

I've read a bunch of posts here from people asking if a PhD is right for them, and I've found that the circumstances of most posters aren't super relevant to me.

I have a BS in Math with minors in Stats and Information Science from a state university, graduated with a 4.0 gpa. Stats was always my favorite subject, though I also really liked the intro number theory and coding theory classes I took, too. I also competed in some university Hackathons/Datafests and won a few.

For the past 2 years, I've worked as an actuarial consultant in the US. The pay is fantastic, but I'm already feeling burned out from the boring work environment. I thought actuarial work was heavy stats, but in reality the 90% that all clients actually care about is basic accounting. My day to day is something like a baby-level data architect / data engineer / programmer, automating away all the analyst level work and some of the statistical modelling work of different actuarial departments. The real rub is that I'm constantly messing around doing math problems, coding challenges, reading books, doing what I can to feel more stimulated, whereas my job demands more focus on accounting & regulation. I've been applying to some data science jobs but it seems like the only ones available to me with just a BS would be similarly low-level analytics roles, anyway.

I think I chose this job because I was really eager to ""prove myself"" financially, and I wanted stability as fast as possible with a safe, secure job. But now I have plenty of savings and my work just feels hollow. The only part of my work that I really enjoy is a research project into mortality forecasting that we won from a non-profit org -- I think I like ""discovering"" things more than ""building"" things. But anyway, even in this project I can see that typical industry methods of analysis just aren't going to do the job justice. The assumptions we implicitly make are all so clearly off-base, and the more I google, the more I realize we've had better techniques for decades, but nobody in our profession has the depth of education or the awareness/motivation required to innovate.

So from where I'm sitting, learning more statistics and then getting to read new developments in the field, researching to add more to the field, etc. sound like a dream! As far as teaching goes, I actually TA'd a class in undergrad (basically did everything, lectures, website, homework, exams, etc.) and I enjoyed it, so I don't think I would mind that much.

But part of me is also wondering if this interest of mine is just some ""grass is greener on the other side"" bias, or maybe I just feel the need to ""flex"" now that I see some of my friends graduating from grad school. While I really enjoyed writing an undergrad honors thesis, I've never done any actual research before, and some of these papers on the topics I love the most seem a little intimidating.

1. Do you think I'd be doing it for the wrong reasons?
2. Would I even have a shot at a PhD program considering it's been 2 years out of school, I did no research, and I can only be absolutely sure that one prof would remember me and write me a great letter? If it matters at all my GRE practice scores are great, but I don't know if it's enough...
3. I keep thinking about trying out a masters program first, but I see several drawbacks. First, they cost a pretty penny, whereas PhD is usually fully funded with a stipend. Second, if I then get a PhD, would it be faster or just the same time? If the same, that seems like a waste of time. Third, many programs stress that the Masters in Stats is for professionals, not academics, so I worry that I would not be able to try out real research in a masters program.... Do you think all this is accurate?
4. I'm not too worried about money, but whether it's academia or industry, I think I will want a job where I'm actually tasked to ""discover"" things. It seems like Stats PhDs actually do open up some industry doors in terms of quantitative research-related roles... Is that accurate, or would a masters suffice for those roles just as easily?

Thanks! All advice and feedback is appreciated!",statistics
nqaxg1,1622600180.0,[Q] error term in nlme::lme/lme4:lmer function,"

I cant seem to find this info anywhere. What do the different sides of the | in the lme or lmer (in lme4) functions represent?

i.e.,:

    (1|ID) vs (Time|ID)

Essentially, why is the 1 to the left of the | and why is the ID to the right?

Thanks!",statistics
nq9u01,1622596693.0,[D] Help with My A/B Test Loser Score,"I work at a tech company with a large user base that makes many decisions based on A/B testing that affect user experience. I put a [question](https://www.reddit.com/r/AskStatistics/comments/nnulnf/identifying_losers_in_an_ab_test_treatment_group/) to r/AskStatistics about identifying losers in A/B tests which sent me down a rabbit hole investigating conditional average treatment effects. Most papers I found suggested using additional subject data in one way or another (even using [random forests](https://arxiv.org/pdf/1510.04342.pdf) to generate a treatment effect function!). I see how this can be used to segment subjects especially in controlled experimental settings, but in our case there are many potentially relevant dimensions that we can't (or won't, without adequate justification) measure. I realized that if you don't have the data to discriminate a sub-population that is harmed by a treatment, you *can't* in general determine that it happened at all based on the treatment results themselves. For example, one could imagine a treatment that perversely swaps subjects' outcomes about the median, so that the resulting distribution is identical to the control despite half of the subjects being harmed by the treatment (and half helped). However, setting aside swapping, I cooked up a method for summarizing a minimum number of losers in a treatment group:

* For an outcome `o` in control, count the number of subjects, `c`, in the control group scoring below `o`
* Count the number of subjects, `t`, in the treatment group scoring below `o`
* Calculate `t - c` as `losers`
* Compute the maximum `losers` across all outcomes, call this `minimum-losers` (it's a minimum because it can't detect swaps)
* Compute `minimum-losers / sample-size` (assuming control group and test group have the same size). This is the minimum-loser-ratio of the treatment

I ran some simulations with this measure starting with a normal distribution and applying a positive ATE (normally distributed) to a portion of the population and a negative ATE to a portion of the population. The minimum-loser-ratio is consistently zero when there is no negative ATE portion, and increases with the proportion of the population that is negatively affected and the magnitude of the harm. It seems fairly sensitive too. I tried out some different starting distributions as well and they do affect the way minimum-loser-ratio behaves in terms of the CATE of the sub-population.

I'm curious about a couple of things:
* Is this like something else that exists that is probably much better?
* Is there a good way to quantify the confidence of the minimum-loser-ratio? In my simulations I used populations of 100,000 samples and at least visually it seemed like a stable measure. We have millions of unique users per month so we can potentially run fairly large experiments, but we do like to start small.

Currently these tests are not assessed by statisticians; if the ATE is positive and statistically significant as reported by our A/B testing framework then it's generally a go-for-launch. In particular, outcome distributions are not usually examined. I'm hoping this measure might be used as sort of a yellow-light signal that hey maybe you should look at the outcome distribution because it seems likely that x% of users are actually harmed by the treatment (which is relevant for us both for ethical and product reasons; e. g. it may be that the treatment completely breaks the experience for a small subset of users on a particular device). In my simulations it seems like the minimum-loser-ratio helps identify the presence of negatively affected sub-populations even when examining the control/treatment distribution plots doesn't make it obvious.",statistics
nq7wic,1622590773.0,"[D] Depth In Tree Based Algorithms vs Neural Networks (""On the Expressive Power of Deep Architectures"" , 2007, Bengio and Delalleau)","I am reading this paper over here ""On the Expressive Power of Deep Architectures"" (2007, Bengio and Delalleau, http://www.iro.umontreal.ca/~lisa/bib/pub_subject/finance/pointeurs/ALT2011.pdf).

In this paper, they make a statement : ""
One of the characteristics that has spurred much interest and research in
recent years is depth of the architecture. In the case of a multi-layer neural
network, depth corresponds to the number of (hidden and output) layers. A
fixed-kernel Support Vector Machine is considered to have depth 2 (Bengio and
LeCun, 2007a) and boosted decision trees to have depth 3 (Bengio et al., 2010).""

If I understand this correctly, a neural network is said to have the same ""depth"" as the number of layers (e.g. a n-layered decision tree will have a depth of ""n""), whereas boosted decision trees are said to have a fixed depth of 3 - no matter how splits the boosted decision tree is said to have.

Does anyone know why this is? Why does a really deep boosted decision tree still only have a depth of 3?

Thanks",statistics
nq6ic4,1622586677.0,[C] The state of the job market in Bay Area,"I saw the [post](https://www.reddit.com/r/statistics/comments/npt62g/q_those_of_you_msed_out_of_a_statistics_phd/?utm_medium=android_app&utm_source=share) today where a lot of people with MS in stats share their stories, but I can't help but notice that all of those stories are from the people with 2+ years of experience.

What is the situation on the job market rn? I have a feeling that DS positions are flooded by from-zero-to-hero  and CS+l-know-a-bit-of-stats people. Biostats jobs are reserved for biostats people, or am I in a bubble and that's not a case at all?

I have an MS in statistics from San Jose State University and a DS internship in Bay Area. Recruiters automatically assume you are proficient in SQL and Python (I am), and that's all they are interested in. No one asked me a single stats question so far.

Is someone interviewing right now? What are your experiences?",statistics
nq69hx,1622585976.0,[Q] Solve collinearity in a fixed effects model using multi-level regression as well?,"Dear reader,

First and foremost I feel obliged to tell straight that i'm not a statistician or econometrician. When trying to look for solutions, I often find it hard to put into words exactly what I am looking for. I am not looking for someone to solve my homework, I just want to understand this concept. Ill try to keep it as clean as possible and hope that someone can confirm what I want to do is possible, or correct me if there is an easier/more applicable/obvious solution.

* I have panel data from 30 different stores, for 90 days time. The dependent variable is the amount of a certain good sold per store location per day.
* I am currently using a fixed effects model, to differentiate between store specific differences.

&#x200B;

* In my fixed effects model, I use 3 explanatory variables:

the indicator variable day of the week (different weekdays have different amounts of traffic) (i.dayofweek)

dummy var for whether or not there is a sale going on in that particular store that day. The sale is ALWAYS on a friday, but not active for every store location at once. (DiscountDay)

Anticipation variable (object of my study). I want to know if customers buy less on days prior to the sale if they know that there will be a sale later. This takes on the value -4 to 4, where -1 is on the thursday prior to the sale, -2 is on the wednesday prior to the sale etc. This is also an identifier variable. (i.anticipation). for all observations not within four days of a discount day, this value returns blank. This value is not the same at a date for each station, since different stations have discounts on different weeks.

* This leads me to the following fixed effects regression:

the daily sales amount for each station, regressed against the the dayoftheweek, the DiscountDay dummy, and i.anticipation.

As can be expected, there is a lot of collinearity here. The DiscountDay always coincides with a Friday, and each value of i.anticipation can only coincide with one particular day of the week. Still, i need all this information for my model.

* **I have no idea how to solve this, here is what I am currently thinking:**

I am looking to make a fixed effects model that first applies the day of the week to the aforementioned system. So I find regression coefficients for each day of the week under no discounts and no anticipation effects. I want to lock those values, and THEN apply the anticipation values and the dummy. Is this possible using a multi-level model? I am not familiar with this. Is there another solution that is more suited for this problem? I am not that good at econometrics so I prefer to keep it as simple as possible. All I need to find is a good estimate of the anticipation effects per day.

I use STATA, so if you can share a STATA function that is used in your solution then I would also appreciate that a lot.

Whatever the case, any help is much appreciated. I am immensely helpful for anyone willing to put time into this, and will always take the time to reply to you to thank you for your help.

&#x200B;

BHTA",statistics
nq3o9w,1622579148.0,[Q] Normal Distribution Std Deviation % of Occurance,"Hi I was wondering if anyone could help point me in the direction of where the expected occurrence from a std deviation perspective comes from. I am specifically referencing the rule that 1 std deviation is approximately 68% of occurrences, 2 std deviation is 95% and 3 std deviation is 99%.

I have had a google around and cant seem to find anything that specifically explains why these rules are held. They are always just given as rules.

Secondly, I would like to calculate the amount of data occurrences for any given std deviation. For example a 1.34 std deviation. How would I do this?",statistics
npznvc,1622569037.0,[Question] Best statistical test to use for interaction of two independent variables?,"I am doing a study on the effects of obesity and socioeconomic status on patient outcomes. I would like to demonstrate whether socioeconomic status drives the historically poor outcomes in obese patients. So, which statistical test would be best since I am looking at the interaction between two variables and their effect on patient outcomes? My first thought was to use a two-way ANOVA, but I am very new to statistics and would appreciate any help.",statistics
npyos0,1622566611.0,[Q] Why is height on an interval scale but length is on the ratio scale?,"Isn’t length and height the same thing, except height is vertical and length can be in any direction? This is genuinely bothering me.

My book classifies an interval scale as having a consistent difference between units, which separates it from the ratio scale.

But doesn’t time, weight and length have a consistent difference between units? It’s not like how we measure those vary. Sorry if this is a dumb question but it’s been bothering me lol.",statistics
npy0uq,1622564926.0,[D] Hypothesizing the Ideal Conditions for Neural Networks vs Random Forests,"Is it possible to speculate what are the ideal conditions required for a neural network to perform well compared to a random forest?

For instance, when dealing with image recognition tasks, we know that Convolution Neural Networks are generally favorable, seeing as how the ""convolution operation"" is very effective at ""understanding images"" (e.g. recognizing edges).

Now suppose we look at a standard ""binary classification task"". Suppose we have a smaller sized dataset (e.g. 15 columns, 5000 rows).

In general terms, we know that a neural network works by approximating small regions of the target function with a collection of ""mini functions"". This is done by calculating a set of weights : in the future, data is passed through this network of weights, and these weights are used to calculate the probability that a new observation belongs to a certain class is calculated. In theory, we could repeatedly pass similar points through the neural network and monitor how the probability of belonging to a certain class incrementally changes.

A random forest is quite different. Look at the decision tree for a second - the decision tree works by randomly making binary partitions in the data. A binary partition is made for a predictor variable, such that this partition tries its best to cleanly separate the classes of the response variable. When a suitable partition is made for the first predictor variable, we move on to the second variable, then the third variable, etc. So in the end, if we imagine our data as a ""big box"", we create these ""mini boxes"" (i.e. terminal nodes) within the ""big box"" : each of these ""mini boxes"" has an ""address"" (i.e. the different partitions, e.g. if var1>5 and var2<10 then ""mini box 1""). Each of these mini boxes is associated with a response label.

The random forest improves the decision tree by bootstrap aggregation: thousands of randomized and smaller decision trees are combined together for improved predictive power and less overfitting. All the trees in the forest are used to collectively decide which ""mini box"" a new observation should be placed in.

My question: based on this very general understanding on how both these algorithms work - can we try to hypothesize what kind of datasets are more suited for neural networks vs random forests? For example, in the random forest algorithm, by using the gini index criteria, it is relatively straightforward to make ""mini boxes"" for categorial predictor variables. However, a neural network would have to one-hot-encode these categorical predictor variables and as a result, deal with more variables (curse of dimensionality) and as well, these one-hot-encoded variables are likely to contain a greater level of sparsity. Furthermore, it might be easier to make general ""mini boxes"" in sparse data compared to using gradient descent with missing values?

I know this is all speculation (and the ""no free lunch theorems"" say that no machine learning algorithm is universally best) - but could we try to speculate and say that certain machine learning algorithms might be better suited for certain types of datasets? Just as Convolution Neural Networks are better for image recognition and LSTM Networks are better at handling sequential data - could we argue that bagging and boosting algorithms (e.g. random forest, gradient boosting) might have an easier time at handling smaller datasets with mixed categorical-continuous variables?

I would be interested in hearing some opinions and thoughts on this.

Thanks",statistics
npwv7x,1622561942.0,[Question] Modelling of continuous data with lots of 0s,"I'm not a statistician, but I'm having a conversation someone who apparently is. I asked specifically whether data that appears continuous with lots of 0s (e.g. HIV viral concentration in a subsection of population - most will have concentration of 0, some will have some value) could reasonably be modelled with linear regression/MLE rather than negative binomial or zero-inflated models (I have  a very large dataset). The central limit theorem came up in response but I don't see how that might apply. Anyone able to shed some light on whether linear-modelled errors will 'do' in this scenario or do I need to use a better fitting model (and how is the CLT related)?",statistics
npvw2g,1622559347.0,[Q] Estimating class attendance given cumulative registration,"Howdy,

&#x200B;

I am working to estimate attendance for a class in the future. We open up registration up to a year prior, but registrations can occur up to the day of the classes. Not everyone who registers will actually attend. I'm looking to get an estimate each day in the week before the class starts. For example, I might know that:

\- 7 days prior to class, 1000 students are registered

\- 6 days prior to class 1100 students are registered

\- 5 days prior to class, 1150 students are registered (some cancelled)

...

\- 1 day prior to class, 1200 students are registered

\- On day of class, 900 registered students actually attended.

&#x200B;

Additionally, students go through several different ""steps"" in the registration before they are eligible to actually attend (such as gathering requisite materials), which can be seen as a signal of intent to attend. We have the counts at each time step for students who have completed each step.

&#x200B;

I am planning to use a Bayesian approach (with PyMC3), as we know from experience that typically around 30% of registered students don't attend. My current thought for how to approach this is to model like:

Y = P \*  Rₜ

Where Y is the attending count,  Rₜ  is the registration count at t days before the class, and P is an unknown proportion that will actually attend. Then develop a linear model to estimate P.

&#x200B;

I wanted to ask this sub first, though, if this sounds like a problem that already has a general solution or framework to estimate?",statistics
nputzj,1622556400.0,[D] Media Mix Models where retail sales numbers are not available and have only distributor sales numbers,"Has anyone any experience with these situations where as a product owner you want to use media mix models to understand impact of various media on sales(consumer demand) however  retail sales numbers may not be available, only  distributor sales or warehouse stock data is available for a time period(week).",statistics
npum7s,1622555795.0,[Q] Where to download GMHDIF software from?,??,statistics
npuf3d,1622555178.0,[Q] Statistic/ projection about Huawei turnover/ profit in future?,"Hello. Does anyone has a statistic about Huaweis turnover or profit estimated in future? (Best would be for the section 5G) . The projection doesn't have to be that far in future, some years would be totally fine. Thank you very much.",statistics
npu58g,1622554366.0,[Q] Bayesian statistics: how to introduce posterior-probability interpretation in the body an article?,"I'm in the process of writing various Bayesian data analyses, and I feel it is required to **add a quick guide to Bayesian statistics within each article**, to help readers in their interpretation (especially if they have little or no statistical training).

I was wondering if people here know good resources for that. It would be good to have some ready-to-use prose to include in each analysis.

&#x200B;

Ideally, the content I'd add to a data analysis would be something like this:

**A- Below each major posterior-based result (e.g a 99% credible interval), a few sentences to help interpret the 99%.** For instance:

>***How to interpret:*** according to our model and prior assumptions, we have inferred that **with 99% credibility, the Effect Size lies between 1.8 and 7.8 points.** The Effect Size is the treatment's average reduction in perceived pain level compared to a placebo.
>
>**-** The phrase *'with 99% credibility'* may be understood as follows: given the results, a rational person who believes in the model and prior assumptions would be willing to bet 99-to-1 that the Effect Size lies in interval \[1.8, 7.8\]

&#x200B;

B- As an appendix, a brief **motivation of the use of Bayesian statistics** rather than classical frequentist statistics, featuring:

1. Evidence and explanation for frequentist results such as p-values and confidence intervals being commonly misinterpreted (in particular, being interpreted as Bayesian posterior probabilities).
2. Brief explanation / references for grasping the philosophical implications of Bayesian probability (along the lines of: ""you have to be OK with using probability as a measure of subjective uncertainty and beliefs. As we saw above, most people do that intuitively.""), and the related tradeoffs and controversy.
3. References for learning Bayesian statistics at various technical depths.

&#x200B;

If I'm being facetious:

*""Most people should interpret posterior probabilities like they usually interpret p-values. Except that this time they'll be correct.""*",statistics
npu134,1622554026.0,[Q][C]How important is Measure Theoretic Probability for statistics OUTSIDE of research?,"Right know I am making my masters in math and I wanted to take ""mathematical statistics"". For this course it is recommended to know Measure Theoretic Probability. How realistic is it that you would ever need some of this theory when you gonna use statistics in industry-areas for example as a data scientist, machine learning engineer or an actuary. For me it seems that this is overkill if you are not planing to go into research. What are your thoughts about that?",statistics
npt62g,1622551578.0,"[Q] Those of you “M.S-ed” out of a Statistics Ph.D program, or didn’t want to continue after M.S., how did it go after?","Hello, I’m in college right now and have been thinking about applying to PhD statistics programs for a long time. However, Ive been thinking about it often, as to what would be a downside to just a M.S. in statistics vs a PhD. I get it, a phd will open more doors, etc etc, but I’m now wondering, for those of you who only got an M.S. in Statistics instead of going onto get a Ph.D, what made you decide that? How easy was it to get a job after? How was the job itself? Did you get to work on cool modeling? Do you wish you had gone further to get a PhD?

My concern is that I’m afraid spending that much time doing a PhD will not give me any more benefits with regards to the type of job vs if I had an M.S. and incorporate my previous intern experiences. Im still on the fence about a phd in stats so those of you who just got an M.S. I’d like to hear how things are going for you after.",statistics
npqoom,1622542762.0,[Question] Interval estimate for proportional and optimal allocation,"Hi, my assignment is to interval estimate the share of ""SD-voters"" in the parliamentary elections for the region which consist of ""Halland county"", ""Skåne county"" etc.. I get to decide the degree of confidence and precision.

The data I have is the number of people entitled to vote in each county (and its municipalities) and the share of voters voting ""SD-party"" in an ""preliminary examination"" for each county.

How should I by using the data above calculate how big of a sample size I need to interval estimate using proportional and optimal allocation?",statistics
npq4bp,1622540369.0,[Q] Variables in PCA model with same loading,"Hello everyone. I am just wondering if it is possible for a PCA model to have variables (or some of the variables) with similar loading? For example in a model we have variables X1 up to X5 and under PC1, variables X1 to X3 (or all of them) have 0.05 as their value. If it is possible, what causes the variable to have similar loadings? So far I have not encounter this situation, but I'm thinking this kind of situation may come up in exam. Thanks!",statistics
npnr15,1622530118.0,[Q] Favorite classification metric for seeing improvement over imbalanced baseline?,"Q: What is your favorite evaluation statistic/metric/loss, for quickly seeing if a model is doing better than just predicting the majority class, in cases of imbalanced classification data?

&#x200B;

(I lean towards towards roc-auc in general, but it doesn't necessarily give an intuitive ""score >0.5 =\~ model is doing better than predicting all 0"". )

One solution would be to compare the model to the dummy classifier each time, per metric, but ideally i'd like to use something where I can tell at a glance if the model is doing better than majority class guessing, across a wide range of tasks.",statistics
npn3fi,1622527271.0,[Research] Does anyone have any idea on how to tabulate results for a social science paper?,"I apologize if this is not the right place to ask this question; if so, please point me out to the correct place. Most of my statistical analyses include ANOVA and the reviewers are asking me to tabulate the results \[[Screenshot\]](https://imgur.com/a/r2qtqKc). I haven't seen any paper in my field that has tabulated the results so I don't know which way to go. How should a result that mainly consists of ANOVA and subsequent pairwise comparison if the effect was found to be significant be analyzed in the first place? Isn't the norm presenting the statistical results in text? Are there any papers that have tabulated such results? I would really be grateful for any insight.",statistics
npl4g9,1622519751.0,[Q] Mental Preparation for Real Analysis?,"Hello all, I’m a statistics Major whose taking real analysis soon and since I had a whole summer, I was going to start getting a head start on at least trying to get my mind to think in the direction of proofs. Does anyone have any advice on how to tackle such a course or how I should prepare? I feel like jumping into a book right away will be ineffective as I won’t have any prior knowledge on “thinking” to do analysis. Does anyone have any advice on how they prepared for an analysis class, tips, or books I should read before hand? I’m going through Abbots “understanding analysis” book, anything is appreciated. Thanks",statistics
npkmgz,1622517996.0,[E][Q] Is Abstract Algebra or Topology more helpful in preparing for a PhD program in stats,"I want to enrich my mathematical background before beginning a phd program. I have found a couple courses I can take. So far, I have had some exposure to measure theory and have done exhausted the analysis sequence back when I was in undergrad.

I am looking for these things in this priority:
1)  Usefulness in theoretical stats research/phd level stats coursework
2)  Difficulty - the more rigorous and difficult, the better.

Should I take abstract algebra, or topology?",statistics
npjclx,1622513751.0,[Q] how to create your own statistical question and how decide if you need to use a interval or test?,,statistics
npgbcn,1622503962.0,[D] Gaussian Process Regression for More than One Variable,"Has anyone ever come across any source that shows you how to do gaussian process regression (in R) for multivariate data? I found this really good link over here https://www.rpubs.com/cboettig/greta-gp, but it only shows you how to do this for one variable.
I have been trying to extend the results to multiple variables (https://stackoverflow.com/questions/67764577/r-error-in-xi-xj-non-numeric-argument-to-binary-operator ) , but so far I am unsuccessful.
Can someone please recommend some source?
Thanks",statistics
npdlvp,1622495826.0,[Q] Trajectory analysis with Shannon entropy,"I am working on a small project involving the detection of anomalies in aircraft trajectories.

I rely on historical datasets to estimate a PDE of two variables X,Y of a trajectory and then use it to calculate the Shannon entropy of input data as a measure of uncertainty and compare it with a threshold calculated from the initial data (higher entropy means anomaly).

My problem is that a lot of my PDE bins end up giving a probability of 0 for a pair (x,y)
and by convention, the value is ignored. In theory, the entropy of an anomalous trajectory described by a set of datapoints (x1,y1),(x2,y2),...,(xn,yn) could amount to 0 and subsequently fail to be detected by my algorithm.

Is there a way to handle such cases? (mabe there is a better variant of Shannon entropy for this case or a major flaw in my logic)",statistics
npdkvn,1622495747.0,[Q] How to create a score between Twitter sentiment scores (positive/negative/neutral) and performance statistics for athletes.,"Hi! This is my first time posting here so I hope this is the correct space for this question.

I scraped Twitter and analyzed a year's worth of posts for their sentiment. I made a count for each type of sentiment: positive, negative, and neutral. I would like to create a type of index/score when cross-referenced with a player's performance during that same year. The performance will have positive statistics (goals:5 points, assists: 3 points, etc.) and negative statistics (owngoals: -2, yellow cards: -1, etc.)

My goal is to determine which player deserves praise/jeers based on their performance for the given year. Can someone help me out? I've never done statistical analysis before and am not sure where to begin!",statistics
npbk8y,1622490080.0,[Q] How sensitive is inference to model specification? Should test error accompany p values?,"How sensitive is inference to model misspecification? Should out of sample error be reported for inference?

So one of the things about flexible ML models is they are not easily interpretable. But the simple GLM models may not be flexible enough to capture everything in the data, and so even if you get a treatment effect estimate, it could be off.

Is there a way to quantify when you can trust an inference made by a simpler model?

If the predictive accuracy of the simpler but interpretable model is way below that of a flexible nonparametric/ML model, then can one say that the inference should not be trusted since it is likely that the model is misspecified?

And if multiple models are close to the same predictive accuracy, then even if the ML model is slightly better, the inferences from the simpler model will be approximately correct?

Intuitively, even when doing inference, shouldn’t we be caring about out of sample error since the goal is still to generalize our results to data we have not yet collected?

Along with the p-value/CI, should cross validation or test error metrics be reported?

It just seems off to me when there is data where the model gives a low R^2 of 0.05 or something but then people still report p values and something being significant. Especially for observational data.",statistics
npavta,1622488216.0,[Q] Is it possible to cross-correlate rainfall data and flood extent?,"Basically I want to find out whether upstream rainfall affects downstream flood extent.

* Can I do this using cross-correlation? I wanted to use cross-correlation because I think that upstream rainfall will have an impact but after a few days (lag period)
* How should I treat my data before performing cross-correlation?
* Do I have to have the same number of data points in both time-series for cross correlation? (For example, I have rainfall data for 30 days. But I have flood extent data for only 7 days. So do I need to create a third time series comprising of the same days for which I have flood extent data? Or can I perform cross-correlation on the 30 day time series and the 7 day time-series?)

I would also appreciate if anyone could point me toward some resources on cross-correlation. Any help or advice will be HIGHLY appreciated. Kind of walking in the dark right now.",statistics
np9lq6,1622484705.0,[Q] degrees of freedom for nonlinear models,"This question is about the degrees of freedom (complexity) of a nonlinear model.

I know the degrees of freedom can be related to the expected difference between residual sums-of-squares and prediction sums-of-squares, so it's possible to estimate the degrees of freedom for any model by splitting data up into training and testing groups, but I want to verify the results of this simulation with something analytical.

Does anyone know how to calculate the degrees of freedom (or equivalently, the expected difference between residual errors and prediction errors)?

In linear models, this quantity is easily obtained from the hat matrix. But I'm working with a model where there is no way to express predictions using a single projection. Specifically, my model says:

Predicted Y = sum(f(x_i) * x_i) / sum(f(x_i))

So that the predicted Y are a linear combination of (x_1,...,x_n) but the combination weights are proportional to f(x), must sum to 1, and may be negative.

The function f(x) is possibly nonlinear and parameters are what we want to estimate.",statistics
np2exh,1622464569.0,[Q] Help - design of experiment using taguchi method,"I'm doing a process optimization project and I chose to use taguchi method to reduce the number of iterations required for it ( I need around 30mins per iteration). I basically have 4 factors, 3 level each and a cycle time as my response. Upon reducing cycle time, I got different defect phenomenon (total 3 types) which I took as my responses. I have setup my experiment levels in such a way that I get the required cycle time at level 3 each, albeit with increase in defect phenomenon. I suspect that there is a fault in the machine operation for which I'm trying to find some proof through this. Solving this ""fault"" should give me acceptable times, is what I'm going with right now.

Im a complete newbie in this field and have 0 experience setting up such a study. The ""expert"" at the company suggested I go with full factorial and try to study the interaction plots. Another alternative he gave me was to explore RSM. I'm pretty sure that full factorial, will definitely not cut it given the time constraints and I'm unwilling to try RSM for the massive theory that I'd need to understand before. Any alternative solutions to this problem are also welcome😄

The current situation:

I'm currently using the full L9 array (3^4) with 2 repetitions and started facing an issue on how to do it's ANOVA. The DF for residual error comes out to be 0, which doesn't generate any F value in minitab. Although I do have the main effect and SN ratios, most inference I could make from them could be highly situational and probably biased towards this fault. I tried removing factors from the analysis,and I got P values upward of 0.5!!",statistics
nowe82,1622441571.0,[Q] Risk of overfitting in extremely large data sets,"So the risk of overfitting small datasets is obvious, as each individual observation can exert undue influence on our results.  But I have read that as data sets get larger and larger, the risk of overfitting approaches near certainty as we are bound to find spurious relations just due to the sheer quantity of the data.

I am aware of many of the best practices to avoid overfitting on moderately sized data sets.  But I am wondering if there is any guidelines, or literature, on how to know **when a dataset is ""so large"" that the risk of overfitting becomes an increasingly pressing issue**",statistics
nouozs,1622437544.0,"[D] Why does ""survival analysis"" tend to focus on sub-populations instead of focusing on individuals?","Does anyone know why the field of survival analysis tends to focus more on studying survival, hazard and mortality rates of sub-populations within medical studies (e.g. how a certain medical treatment affects males vs females) instead of individual patients?

Many times I see how for instance, the cox proportional hazards model can be used to estimate the survival and cumulative hazard functions for sub-populations in a medical study - and then how to use various parametric and non-parametric tests to evaluate whether there are statistically significant differences between these sub-populations. But rarely do I see survival analysis being used to study individual patients.

Is there a reason for this? Or is it just a practical thing - researchers are generally more interested in extending their research to larger groups of people (e.g. researchers are more interested in knowing if a certain drug will harm a large populations of males instead of just ""Alex"" or ""John"")?

Are survival analysis models ever used to study individual patients?",statistics
nott0y,1622435543.0,"[D] Stupid Question : Why is it called ""deep learning"" instead of ""wide learning""?","Today, my friend was telling me about something called the ""universal approximation theorem"", which apparently contains the mathematical foundation behind neural networks work. After watching a lot of youtube videos on this topic, I think I have some understanding on this topic.

Supposedly, a 2 layer neural network can approximate any function - and the error of this approximation is proportional to the number of neurons within the neural network : the more neurons there are, the better the approximation will be. The only problem with this is, that a 2 layer neural network will likely require a very large number of neurons to produce a decent quality approximation - apparently so many neurons, that the computations will become very inefficient. Conceptually, you can imagine a 2 layer neural network as being very ""wide"" looking.

Supposedly, the solution to the above problem is to create neural networks that are ""deep"" instead of ""wide"". So instead of a 2 layer neural network with a very large number of neurons, it's said that a neural network with fewer neurons and more layers is more computationally effective - and these ""deep"" neural networks also have the ""universal approximation"" property.

The question I have: If ""wide"" neural networks require a very large number of neurons to adequately approximate a function, why don't ""deep"" neural networks require a very large number of layers to approximate a function (at a similar level of accuracy)?

What explains this mismatch between the ""number of layer"" and ""number of neurons"" equivalence? Suppose a ""wide"" neural network with a Relu activation function, 2 layers and 1000 neurons is able to approximate some function with an error of 0.05 - clearly, we believe that a ""deep"" neural network (also with a Relu activation function) with 1000 layers with each layer having 2 neurons, is not necessary. Instead, we believe that the number of layers does not need to be so deep.

What explains this mismatch? Why are ""deep"" neural networks typically able to maintain a relatively low number of neurons and layers, compared to ""wide"" neural networks where only the number of layers can be kept small ?",statistics
nopgnq,1622424980.0,"[Q] Is there a concept of power analysis for Bayesian A/B tests? If not, how do I know when to stop my test?",,statistics
nolppg,1622412034.0,[Q] Heteroskedastic Binary (Probit) Regression Model,"I hope this is the right place for this post. I am currently working on a project where I analyze under which conditions the heteroskedastic probit regression model with an extended link function outperforms the common probit model. This project gives me a lot of headache unfortunately since I am from the finance sector and not a  statistictian.  I now have multiple questions and would be really grateful if you could answer some of them. (I use R for the project.)

I ran both models over my dataset, which consists of about 20, mostly categorial variables and optimized the model. The hetglm model (from the glmx package), with the extended link function however does not really perform better than the common glm model, even though the source of the dataset claims that heteroskedastic is present.

Now to my questions. How do I have to understand heteroskedastic in the framework of a binary choice model? Thats really hard to understand for me and how would I check for it?
I read that I can use the likelihood ratio test to check for het. (Or do I only check if an extended model is a better fit?)
I also read that i can use the LM (score)-test to check for endogeneity, which is often caused by het. is this the case and how would I implement such a test for a probit model in R? [Source](https://core.ac.uk/download/pdf/6494386.pdf)
This [Source](https://www.econstor.eu/bitstream/10419/85235/1/dp99-04.pdf) suggests to use a RESET-test and other sources suggests that there is no point at all to care for het. in this context.
There is not a lot of easy to understand  literature, but a lot of papers which all suggest different things.


Now I thought it might be best to run a simulation study and implement heteroskedasticity of various degress myself to check on when the het. probit model performs better, but also here I am unsure how to control for het and properly run it since again, it's really hard for me to understand het. in this context.


I would be glad if you could help me. I can add additional sources and R-Code if you want.",statistics
noife9,1622402614.0,[Q] Help needed: correlation plant diversity & urbanization degree,"I couldn't find my answer online so I hope someone here on good ol' Reddit can help me out.. At the moment I'm working on my Applied Biology Thesis. The study is about whether there is a difference in plant diversity in same plots (green verges) in different urbanization degrees. 0-20% is extremely low urbanization, 20-40% is low urbanization, 40-60 moderate, 60-80% high ans 80-100% extremely high, this is based on the surroundings.

I want to find out if there is a correlation between the amount of species found in the green verges and the amount of urbanization in the surroundings.

Does anyone know what I can do? A pearson won't do, because I dont have precise percentages of urbanization per area. I divided each location into the 5, %-groups, mentioned above.",statistics
nogaj4,1622396614.0,[D] Technical Analysis,"So I've decided to finally have a vaguely more exciting savings strategy and have decided to start trading some stocks.  As part of it I've started learning about the different indicators and whatnot.  Now there's the obvious stuff like reading a balance sheet etc that I'm all good with, makes sense to me and I understand the value of.

Then there's technical analysis.

You know I have written some pretty mean stuff on this subreddit making fun of six sigma.  And ill do it again.  But Technical Analysis makes six sigma look like some hard-core academics.

It is so god damned absurd.  Its like a six year old son of a stats professor puts on his dads suit and got out his fisher price chalk board and pretended to be him teaching

Which is super cute of course.  But finding out that the stock market trades on this is absolutely fucking bonkers nuts to me.

All of this I would be ok with, to a point, except for one issue.  It is self reinforcing.  The more people *believe* in it the more true it becomes.  People trade on these mickey mouse signals, so they do affect the market.

So I actually have to learn this.  I have to sit down with the 6 year old in the suit and have him explain to me how the EMA crossing the SMA means this, or how the ""fast stochastic bla bla bla"" means this, when its just a fucking average.

And everything has these unnecessary bullshit names.  Fucking ""Bollinger Bands"".  Ffs its an EMA with k sigma bands.  What kind of a twat ""*invents*"" something like that and puts their name on it?   He actually trademarked that shit.  I mean wtf.

Anyways.  Technical analysis is the most mickey mouse bullshit I have ever seen and I have to fucking learn it so now I'm salty.",statistics
noctv7,1622386434.0,[Question] Please help me find the name of this distribution!,"I have been pondering about the name of this specific distribution D (if it has a name):

D is a distribution such that the numbers that are sampled from it are binary and are comprised of n bits such that each bit of a sampled number is actually an independent identically distributed Bernoulli random variable with success probability p.

In other words, D outputs the result of n i.i.d Bernoulli trials with success probability p in n bits.

Note: I know that D would be binomial if I were counting the number of success only. However, this setting involves knowing which trials are successful and which failed. So, I believe I am looking for something else.

Thanks in advance, it has been really bugging me.",statistics
nob3oq,1622380943.0,[Q] contrast estimator for t Student is calculated with standard deviation (S) or with standard quasi deviation (Ŝ)?,"

I'm doing some hypothesis contrast exercises where I have the value of the sample's standard deviation but not the one of the population, so I've read that in these cases I have to do the hypothesis contrast following a t Student distribution. To calculate the t value for the contrast I don't know if I have to use the standard deviation (S) or the standard quasi variation (Ŝ), which is S \* √ ( n / n - 1 ).

So the way to calculate t is:

t = (M - μ ) / (S / √n) ?

where M (sample's mean), μ (population's mean), S (standard deviation), n (sample's size)

or

t = (M - μ ) / ( Ŝ / √n) ?

where M (sample's mean), μ (population's mean), Ŝ (standard quasi deviation), n (sample's size)

Any help is greatly appreciated because I have the global exam next week and I'm so lost.",statistics
noadgo,1622378404.0,"[Q] Times Running Out, which courses do I actually need to qualify?","Hello all, I will be a junior in the fall at my university, and I’m currently majoring in statistics. My goal has been grad school, and even a PhD since I really want to dive deeper into unsupervised Learning methods (clustering, Dimensionality reduction, mixture models) etc.

It had come to my attention from reddit that my major course work will not suffice for qualifying for phd programs. I was also misguided by my advisor as he told me the major they had was intended for phd programs, but now I’m coming to realize this is just a bunch of BS and I’m underprepared.

Currently my major offers a whole host of stats classes, calculus up to multivariable,[ linear algebra (not even upper division)](https://math.osu.edu/sites/default/files/courses/2568_0.pdf), and two proof based math classes, and one of them is a [foundation ]( https://math.osu.edu/sites/default/files/courses/3345_0.pdf ) of proofs, and the other is an [introduction](https://math.osu.edu/sites/default/files/courses/4547.pdf) to analysis.

The links provide syllabi to those courses, and you be the judge of its rigorous enough, but I have absolutely no class which is just real analysis.

I’m at a junior, and at a point where I should be doing gre and such I now have to jam pack my latter two years of school with the requirements my major poorly  fails to include. In fact, didn’t even tell me I needed a math minor when I asked them!

Anyways, this post isn’t about bashing the curriculum it’s about asking what courses do I NEED to take before I graduate. I’m at a point where time is running out and I don’t think I can fit a whole host of classes in my schedule anymore. So I need suggestions on what are math courses I should make a priority of taking for a PhD before graduating.

Please keep this in mind before commenting, if you were in a situation where time is running out, what classes would you recommend taking to qualify for phds.

Thanks",statistics
no4wq3,1622355258.0,"[Career] Please help, Advice Needed!","Hi guys,

First  of all let me apologize if this doesn't belong here or on this sub. I  didn't see any rules saying otherwise. I'm just looking to get some clarity  on ""what I want to do when I grow up"", and then start laying the foundations to do so.

I have a BA in Psychology and fell in love with the Research and Statistics portion of that degree. I was a RA for two years and took all the advanced statistics courses and capstones in that degree. The process of  collecting data, analyzing it, and then coming to a conclusion or lack  thereof is something, I think, I may want to do as a career. Though I don't know what job title that would be or what to look into. I think Data Analyst is the only thing that comes to mind.

My problem is I don't know if that's the only thing out there, and how to start gaining qualifications. I graduated almost 5 years ago now, and definitely need to retouch on statistical analysis/software. Do I go back to school and get a Masters in Stats? Do I take a bootcamp from a university and get a certificate? Or get certificates for individual software like SAS, Excel, & Python? Or perhaps there's an entry level job I don't know about that will teach me these things?

I'm  quite lost, and I figure this would be the community that would have the insight and knowledge to assist me, as I continue to age and start to settle down and look for a career. I'd love to hear your advice.

Thanks so much!",statistics
no1gch,1622340949.0,[D] Why is the beta distribution used to model the number of times a river floods?,"""Let's start with an example problem case. Say we measure two variables that are non-normally distributed and correlated. For example, we look at various rivers and for every river we look at the maximum level of that river over a certain time-period. In addition, we also count how many months each river caused flooding. For the probability distribution of the maximum level of the river we can look to Extreme Value Theory which tells us that maximums are Gumbel distributed. How many times flooding occured will be modeled according to a Beta distribution which just tells us the probability of flooding to occur as a function of how many times flooding vs non-flooding occured.""

Source: https://twiecki.io/blog/2018/05/03/copulas/

Does anyone know why the beta distribution is used here to model the number of times a river floods?

Thanks",statistics
nnz3ga,1622331898.0,[D] Applications of Copulas in Predictive Modelling,"Recently, I came across ""copulas"" in statistics (https://en.wikipedia.org/wiki/Copula_(probability_theory) ). These seem very interesting!

Is the main application of copulas the ability to simulate multivariate correlated data? For instance, suppose I have data collected for 1000 individuals - for each of these individuals, I have their weight, height and age. It is very likely that these 3 variables are correlated with each other.

Thus, just using this data, would it be possible to use copulas to simulate data for new individuals? Would this require to explicitly assume  marginal, joint and conditional distributions for these variables? Or would the copula be able to do this by itself?

How are copulas usually used in statistics and predictive modelling? What are their main applications and advantages? Has anyone here ever used them in their studies or work? I would be very interested to hear about your experiences and results using copulas!",statistics
nny9u3,1622328987.0,"[D] Has anyone heard of ""extreme value theory""?","""Let's start with an example problem case. Say we measure two variables that are non-normally distributed and correlated. For example, we look at various rivers and for every river we look at the maximum level of that river over a certain time-period. In addition, we also count how many months each river caused flooding. For the probability distribution of the maximum level of the river we can look to Extreme Value Theory which tells us that maximums are Gumbel distributed. How many times flooding occured will be modeled according to a Beta distribution which just tells us the probability of flooding to occur as a function of how many times flooding vs non-flooding occured.""

Source: https://twiecki.io/blog/2018/05/03/copulas/

Does anyone know why the maximums are gumble distributed? Shouldn't their distribution depend on the data itself?

Does anyone know why the numher of floods are modelled by a beta distribution? Again, shouldn't their distribution depend on the data itself (e.g. maybe normally distributed)?

Thanks",statistics
nny57e,1622328541.0,[Q] Recommendations for a Bayesian Stats intro textbook meant to rewire my frequentist mind,"This had been asked probably many times in this sub, but I swear this is a special use case. I’m a undergrad stats student who has taken a stat inference course just this past semester, and it was all frequentist. I want an intro Bayesian stats textbook which really is an approach to remove the “brainwashing” of my frequentist classes. Something that really motivates ideas, not a lot of theory., yet does have some math.

For reference, I’ve taken calculus up to multi variable, Probability, and I have some background in linear algebra, but very little as I’m taking linear algebra next semester.

But really, a textbook which just really makes it a point to rewire someone with a frequentist mindset.",statistics
nnwcqo,1622322510.0,[Q] Discord servers for statistics/statistics-related topics,Does anyone know of/can anyone recommend good Discord servers related to statistics and similar topics? Maybe there's one for this subreddit that I can't manage to find for example :) Thank you!,statistics
nnujnv,1622316536.0,"[Q] Two teams are decided by each player flipping a coin. Using a strategy, can you make the chances of being on the same team as a friend greater than 50%?","In ultimate frisbee, teams of 7 are often decided by flipping a frisbee.  Heads is team A, tails is team B.  If one team fills up before the other, the rest of the players don't need to flip because they just go on the other team.

Because of this, is there a strategy where you can increase your odds of being on the same team as another player, if you both use the strategy?  The rules are that you can decide to flip whenever you want.

So to give one example, if 6 players have flipped and they all landed heads, it would obviously be beneficial for you and your friend to not flip since you're most likely just going to be defaulted to the tails team.

Since ay any moment you can decide to flip, your worst case chance is 50%  But by waiting and seeing how the flips go, can this be increased.",statistics
nnuhbj,1622316324.0,[Question] DeLong Test if I only have AUC and standard errors/confidence intervals,"

Is  there a way to perform DeLong comparison between two ROC curves without  having the raw data? I only have AUCs and standard error/confidence  interval.  Moreover, is there a calculator or a simple way to do it in  SPSS or medcalc?

It would help me a lot, thank you in advance!",statistics
nnsyzv,1622311652.0,[Q] Is there a noise-resistant method for testing correlations of proportions?,"I have a friend who is trying to analyse a large Sanskrit corpus with many verbs in. Verbs can occur in the active or the passive, and they can occur in the past tense or the present tense. She wants to run a statistical test to see whether verbs which occur more often in the active (than the passive) in the present tense also occur more often in the active in the past tense. Here is (made up) data to illustrate:

|Present-Active|Present-Passive|Past-Active|Past-Passive|
|:-|:-|:-|:-|
|run|102|50|130|
|seize|40|84|59|
|rebel|1|2|3|

One method would be to compute %active stats for a) present tense and b) past tense and then look at the correlations between these two.

|Present %Active|Past %Active|
|:-|:-|
|run|67%|
|seize|32%|
|rebel|33%|

\[Here for 'run' 102/(102+50) = 67%, and so on.\]

This method is not ideal because some verbs are very rarely attested, like rebel above, and those will introduce a lot of noise into the system. Could anyone point us at a better method? I feel like we need some hybrid of correlation and a chi-squared test...",statistics
nns9qo,1622309568.0,[Q] Would there be any reason to take a ratio stat and convert it to “by capita”?,"I understand that for one variable stats, dividing by the population can be critical in providing context, but when a stat is in a ratio I don’t understand why anyone would divide by the population.

For example, let’s say we want to know about eye color over time. If we have historical data on the ratio of brown eye people to blue eye people (for example,  2:1 this year and 1.5:1 ten years ago) what is the benefit of dividing all data points by the population?

What would dividing a ratio by the population even do? Isn’t the issue of relativity already accounted for because it’s a ratio?",statistics
nnr5m2,1622306182.0,"[Q] metrics for quantifying the ""diversity"" of a partition of data","As the title suggests, I am looking for metrics that quantify a partition's ""diversity"".

Consider a set of observations y={y1, y2, ... yN}, and a partition of pi of y, for example, pi = {A1, A2, ..., AM} for M <= N.

I am looking for metrics f that map from Pi, the set of all pis, into (0,1) such that f(y)=1 (ie, the trivial partition) , and f(singleton(y)) minimizes f. I ue singleton(y) to denote the singleton partition of y.",statistics
nnqrdk,1622305014.0,"[D] Dangers of ""parametric"" models","After doing a lot of thinking, I think I am starting to better understand some of the basic concepts behind parametric models vs non-parametric models.

Historically, it was thought that parametric (statistical) models with too many parameters (e.g. regression coefficients, neural networks with too many weights) were said to be prone to overfit training data and generalize poorly to unseen data. Thus, lots of emphasis was placed on methods like regularization : how to simplify parametric models with too many parameters. This includes approaches like L1 regularization (pushes some parameters heavily towards 0), L2 regularization (generally pushes all parameters towards 0) and drop out (randomly cancelling some of the weights within the neural network).

Apparently, these problems contributed to the popularity of non-parametric models. Non-parametric models, e.g. kernel based models such as SVM (support vector machines) and Gaussian Processes (e.g. gaussian process regression) - these models do not have parameters per say. For instance, gaussian process regression directly estimates the response variable by (repeated simulation) using conditional expectation formulas. If you look at the estimation formula used in gaussian process regression, there are no beta coefficients (unlike standard regression). Somehow, this absence of model parameters are desirable for statistical modelling, seeing as this somehow mitigates potential overfitting and poor generalization.

All this is supposedly implied in the famous bias-variance tradeoff: simple models are said to be stable but are too simple to sufficiently capture complexity within the data, complex models are able to capture complexity within the data but are said to be unstable (poorly generalize). Machine Learning is apparently about trying to make these complex models more stable and generalize better.

Here is my question: what initially lead researchers to believe parametric models with too many parameters are prone to overfit? Is there some mathematical formula that showed some relationship between the number of regression coefficients and error or variance? Or some formula showing the relationship between the number of weights in a neural network and the error or variance?

Or was this all empircally observed? I am curious to see the initial justifications and math formulas that first started to warn researchers about the ""dangers"" of having models with too many parameters?

Note: I am aware that models with too many parameters aren't necessarily ""doomed"" to generalize poorly. Apparently models like ""gpt-3"" (famous natural language model developped by ai researchers) are said to have ""millions of parameters"" (neural network weights) and perform incredibly well in the real world. However, I am more interested in the general idea and mathematical justification relating to ""potential poor model performance linked to overparametrized models"".

Why were overparametrized models said to be more prone to overfitting? Is this really why non-parametric models became popular, because the absence of parameters made them more flexible and less prone to overfit? Is this all empirical, or is there math behind it?

Thanks",statistics
nnqn2g,1622304664.0,[Q] Which statistical test should I run?,"Hi all,

I'm working with an awkward set of data and I'd appreciate some advice. The study (between-subjects design) uses a task that measures mean reaction times and scores of correct/incorrect responses to number prompts. There is one independent variable and the two dependent variables of reaction time/score. There were 16 usable sets of data split into 3 groups corresponding to the 3 categorical levels of the independent variable. One group has 9 sets of data, the second has 5, and the third has 2.

For each of the data sets, reaction time is measured in milliseconds and correct/incorrect responses are measured in whole numbers. I originally planned to use MANOVA, but the sample is smaller than anticipated and the 3 groups are extremely unequal. I'm not sure how to proceed with this analysis without running into issues with statistical power and error. Would it be better to conduct t-tests between the three groups (9 with 5, 5 with 2, and 9 with 2) or a multivariate regression instead?

I'm lost.",statistics
nnphit,1622301207.0,"[D] Has anyone ever used the ""drwhy"" package in R for ""explainable ai""?","https://github.com/ModelOriented/DrWhy

Has anyone ever used this package in R before for trying to ""explain blackbox machine learning models""?  This package (""drwhy"") seems like a comprehensive collection of different algorithms (e.g. lime, shap) meant for explaining blackbox models (e.g. neural networks).

Has anyone ever used this package before? How have your experiences been? Did it prove to be useful? Were the results reliable?",statistics
nnp37u,1622300001.0,[Q] Post-hoc testing for two-way Anova with many group levels in R- how to do it?,"I'm currently working on a statistics project where I'm performing a two-way anova on a dataset with two categorical independent variables (one continuous dependent variable). The dependent variable is a relative growth rate measurement, and the independent ones are a temperature condition (2 levels) and a bacterial strain condition (49 levels).

I think you can see the complication here. The assumptions are met, and the analysis on a full linear model (growth ~ strain + temperature + strain:temperature) returns a significant interaction variable. This is good news, because it confirms our general expectations, however, things get messy when we want to do some post-hoc testing to, for instance, assess whether growth is significantly different between temperatures *for each bacterial strain condition*. I've not been able to find a way to do this that doesn't bury me in a thousands of entries long pairwise tests table that compares every combination of strain and temperature with every other combination of these two.

Does anyone know what methods might be useful to assess such data in R? Thanks in advance.",statistics
nnk13r,1622281571.0,[Q] Is this a bilateral or a unilateral hypothesis contrast?,"So I have to do this exercise and I don't know if it is a bilateral or an unilateral hypothesis contrast:

Calcium is normally present in the blood of mammals at concentrations of about 6 mg / dL of the total blood. A series of 9 tests on a patient revealed a sample mean of 6.2 mg / dL with a standard deviation of 2 mg / 100 ml. Is there any evidence for a level α = 0.05 that is the patient's mean calcium level higher than normal?

If it is unilateral:

H0:  μ  ≤  6

H1:  μ  >  6

If it is bilateral:

H0:   μ  =  6

H1:   μ  ≠  6

So it would be bilateral wouldn't it?",statistics
nnh07p,1622268455.0,[Q] Dividing each observation by series mean,"Hello folks,
A time series data has n observations.
Is there a special name for a series where each observation is divided by the original series mean?
Thanks",statistics
nn7om7,1622236029.0,"[Q] The earliest mention of the ""target illustration""?","Hello, my friends!

A couple of days ago, my ~~terrific~~ girlfriend and I had a bet on the earliest mention of the famous ""illustration with targets"" about similar things. [PIC](https://i.imgur.com/1ZfCwoE.jpeg)

I bet that I would find the earliest mention in psychology or sociology with ""validity"" and ""reliability"" terms used. She bet on statistics and econometrics with ""bias"" and ""variance"" terms used.

Currently, I am winning with the image link to which I posted above, this is ""Babbie E. The practice of social research. 1995 pp. 128"", but one article cited this image with an edition from 1985.

I am not really convinced that this image, which uses targets for an illustration originated only in 1985,  moreover, the book of Babbie cites an ""anonymous reviewer"" as a source, so asking you for any help on discovering the nature of this illustration.

Thanks in advance!",statistics
nn5ru1,1622230709.0,[Q][C][D] Is the 16PF test correlated to any work place attributes?,"I don't know if this is a good place to post this or not, if not, sorry. I wanted to know if the 16PF test was correlated with anything, specifically work productivity or satisfaction.  Are any personality test results well correlated with anything at all?",statistics
nn4tia,1622228028.0,[Q] Should I omit an unreliable dimension from an EFA?,"I have 25 dimensions that were rated by 85 participants. I've computed the ICCs on each dimension and they are all good (> .75) except one dimension which is moderate (.69) and one that is bad (.39).

Should I omit the bad dimension from my EFA? What about the dimension with a moderate ICC?",statistics
nn1y5j,1622220208.0,[Q] Could I use reweighting to turn a cross-sectional dataset spanning multiple cohorts into a simulated lifetime earnings model for a single cohort?," Say, I have a cross-sectional survey with demographic characteristics and wages of people across different cohorts. Could I group people by cohort, and reweight the relevant demographic variables towards cohort A to create a simulated lifetime earnings model for this cohort?",statistics
nn1wvg,1622220107.0,[Q] Is 'age' considered as a numerical or categorical value?,"Hello everyone,

Should I apply Pearson's Correlation Coefficient for trying to find the force of the relationship between 'age' and 'fee' of a soccer player?

In other words, is age really to be considered a numeric value in this case? Or is age more categorical?
My model does show a non-existing correlation (see below), when using Pearson. But I feel like perhaps I shouldn't be using Pearson for this.

Link of graph: https://prnt.sc/13iq1rn",statistics
nn1uxy,1622219965.0,[Question] Can someone explain the finer details of Central Limit Theorem to me?,"So according to the Central Limit Theorem taking n number of random samples from a population means for many iterations and then plotting the mean of those n samples in another distribution we have a distribution where the mean of the Sample mean's is roughly equal to the population mean, but the standard deviation has reduced by a factor of 1/root(n) where n is the number of samples.

* So my question is that the standard deviation of the mean of samples is representing the variability of the mean of the population rather than the whole process as in the population distribution. As in getting a 90 percent confidence range in the sample mean distribution is the measure of the mean estimation being 90 percent accurate compared to the Population mean, which is the absolute mean that we are trying to estimate using the sample.

Hence The population standard Deviation is a measure of the variability of the process across thePopulation distribution, whereas the standard deviation for the sample mean distribution is toshow the variability of the estimated mean. (This is my understanding of it, and need confirmationon it).

* ~~Extending upon the above, Consider that I want to build a confidence range of involving say 95% of all processes(roughly 2σ), Will I will have to do it using the population standard Deviation instead of The sample standard deviation. Since only the Population standard Deviation is indicative of all the process outcomes and the correct range?~~",statistics
nmz4wk,1622212375.0,"[Q] Hypothesis contrast, simple doubt about what standard deviation type to use (sample's one or population's)","

Hi, I'm doing some exercises about bilateral and unilateral hypothesis contrast and sometimes they give us the sample's standard deviation and other times the population's one. So I was wondering which one do I really need to use in the formula to get the contrast statistic:

z = (x - M) / (S / √ n)

where

x is the sample's mean

M is the population's mean

S is the standard deviation (I don't know if the sample's or the population's)

n is the number of tests

Any help is greatly appreciated!",statistics
nmyo9s,1622211027.0,[Q] Logistic Regression and Fisher Information Matrix,"Hello. Recently I've been working on (binary) logistic regression and I came up to a problem. I want to compute standard error of two estimators (B1 and B2) manualy. As far as I understand I have to  compute Fisher information matrix and do an inverse. By definition square root of diagonal of the inverse should be what am I looking for, i.e. standard error of estimators. However when I try to make an inverse it seeems like my matrix is singular. I don't know what am I doing wrong.

Do you guys perhaps have somewhere a general form of Fisher information matrix for logistic regression? That would help a lot. Ty.",statistics
nmsztw,1622189790.0,"[Q] Looking for ""standard"" statistics/probability Bayesian book.","Hey

I am taking a course in Bayesian stats now and the book [Bayesian Data Analysis 3](http://www.stat.columbia.edu/~gelman/book/) we are using is really good, but it is very text heavy. I am wondering if there is any statistics book with the format ""Definition -> Theorem -> Proof -> Example"" that focuses on Bayesian statistics, or at least that it cover Bayesian methods as much as it would cover standard frequentist statistics.

I seen a lot of recommendations for the book Statistical Rethinking, but it seems to be very text heavy as well...",statistics
nmonm3,1622172340.0,[D] can someone please show me how the expected value of f(x) is calculated here?,"https://notes.quantecon.org/submission/5b53cbcd17fb4900153deafb

This is an article on gaussian process regression.

In the ""interpolation"" section, they show how to use gaussian process regression for prediction (I assume you can use this formula for extrapolation as well):

F(x) = m(x) + sum(from i to n) of {k(x, x_i) * alpha_i)}

At the start of this article, m(x) is defined as:

m(x) = E[f(x)] .. where ""E"" is the expected value and ""f(x)"" is the true function you are trying to estimate.

Does anyone know how E[f(x)] is calculated? I understand that you assume a kernel function and a bandwidth value - but how is m(x) calculated? i.e. E[f(x)]

Also: is the only assumption of gaussian process regression, that the data in real life is generated using the specific kernel you selected? In general, does gaussian process regression make fewer assumptions about the data compared to standard linear regression?",statistics
nmo4nj,1622170379.0,[Discussion] Decision Theoretic Reasons for Cluster Analysis?,"Cluster analysis seems to be relatively popular for purposes such as separating out different market segments to aim for with different strategies. However, I have found it a bit difficult to find a reason in decision theory / economic logic that this makes sense. I was wondering if anyone could precisely articulate logic where this would be the analysis that really tells you what you want to know, even under limited circumstances.

Going back to the example of market segmentation, one thing that would maybe make a bit of sense to me is if the clusters were actually the result of some latent categorical variable that you can't measure directly, and you had a reason to expect due to other research that people with different values on this latent variable would respond optimally to different messages. In this case, maybe you would perform a cluster analysis on predictor variables to decide the cutoff for using different messaging strategies. It seems like maybe this would be something close to optimal if your cluster analysis was based on sound assumptions about the distribution of the latent variable and how it relates to your observed predictor... maybe. On the other hand it seems like classification would be more useful than clustering in this situation, at least if you had the right data to make a classification model.

Alternatively, without the assumption of some latent categorical variable, maybe the point of the cluster analysis would be to find the coordinates of the center of the cluster. The idea here is that people with similar characteristics on your predictor variables would respond similarly to messaging, and a message optimized for the archetypical member of the cluster would perform pretty well for a lot a people, since after all there is a cluster of people centered around that point.

I'm not fully sure of my reasoning on either of these examples. Does someone have a better example? Is there a more logical statistical analysis to use for basically the same purpose?",statistics
nmo275,1622170121.0,"[Q] Case Numbers Are Aggregated, Why Isn't The Population?","when it's reported to be 50 cases a day for a week (350) out of 1.4 million population

why isn't the 1.4 million aggregated to it's 7 day total of 9.8 million population like the 50 cases a day are?

is it not algebraic?



disclaimer: outside of deal making, i am not a math guy

thanks in advance",statistics
nmjdrn,1622154491.0,"Calculating if something falls within the standard deviation, word of mouth story. [Question] [Discussion]","Hey, so I took first-year statistics 12 years ago and I'm rusty. This is the problem: a friend heard from a friend who manages a company of 5000 people in Texas (ages from 18-80), 100's of employees had covid, but only 1 died. The friend of the friend spoke to a doctor he knew who says he treated 8000 patients with covid and none of them died. The conclusion my friend is making from this word-of-mouth story is confirmation of his idea that covid isn't as bad as claimed and there's a conspiracy. I disagree, I know it's generally bad to base important decisions on word-of-mouth or small sample sizes so I'm trying to see if there's a way to test this story mathematically.

Now I know that the smaller the sample population the more the reality can deviate from the true percentage, but I vaguely remember that there might be some way to calculate standard deviation based on the sample size. We know the death rate is around 1.9% in general and varies by age [(Case Fatality by age graphic)](https://ourworldindata.org/uploads/2020/03/COVID-CFR-by-age-768x595.png) and it varies depending on how healthy the population is ([case fatality by underlying conditions graphic](https://ourworldindata.org/uploads/2020/03/Coronavirus-CFR-by-health-condition-in-China.png)), but assuming his friend meant around 300 cases, you would expect based on a 2% death rate around 6 deaths, or if you assumed most of them were under 60 expect closer to a 1% death rate with 3 dead.


Ultimately I understand it's difficult to give a fair answer to this question without knowing what 100's mean or without having an idea of the age distribution of the people who actually caught the illness, but roughly how would you go about evaluating this word-of-mouth event statistically?",statistics
nmj3na,1622153657.0,[Question] What analogies have helped you understand statistical concepts?,"I was confused about multilevel/hierarchical modeling until I read the following analogy in Statistical Rethinking:

"" Suppose we program a robot to visit two cafés, order coffee, and
estimate the waiting times at each. The robot begins with a vague prior for the waiting times,
say with a mean of 5 minutes and a standard deviation of 1. After ordering a cup of coffee
at the first café, the robot observes a waiting time of 4 minutes. It updates its prior, using
Bayes’ theorem of course, with this information. This gives it a posterior distribution for the
waiting time at the first café.
Now the robot moves on to a second café. When this robot arrives at the next café, what
is its prior? It could just use the posterior distribution from the first café as its prior for the
second café. But that implicitly assumes that the two cafés have the same average waiting
time. Cafés are all pretty much the same, but they aren’t identical. Likewise, it doesn’t make
much sense to ignore the observation from the first café. That would be anterograde amnesia.
So how can the coffee robot do better? It needs to represent the population of cafés and
learn about that population. The distribution of waiting times in the population becomes
the prior for each café. But unlike priors in previous chapters, this prior is actually learned
from the data. This means the robot tracks a parameter for each café as well as at least two
parameters to describe the population of cafés: an average and a standard deviation. As the
robot observes waiting times, it updates everything: the estimates for each café as well as the
estimates for the population. If the population seems highly variable, then the prior is flat
and uninformative and, as a consequence, the observations at any one café do very little to
the estimate at another. If instead the population seems to contain little variation, then the
prior is narrow and highly informative. An observation at any one café will have a big impact
on estimates at any other café.In this chapter, you’ll see the formal version of this argument and how it leads us to multilevel models. ""

This helped me a lot and the whole thing clicked for me. So, I wonder what other analogies you've encountered that helped you understand what's going on underneath a statistical concept.",statistics
nmg44i,1622145544.0,[Q] Expected value of throwing 3 Heads in a row,"I know a solution to this problem is as follows:

A = {T}, B = {HT}, C = {HHT}, D = {HHH} and then you just say E(X) where x is 3 heads = E(X|A)*P(A)...E(X|D)*P(D)

My issue is not understanding why we choose those events. Could someone please assist me with a detailed and nice explanation. I know we need independent events that are exhaustive but I would never think to use those.

Thank you.",statistics
nmdh12,1622138623.0,[Q] Can anyone help me interpret and create an F statistic for a joint hypothesis test,[removed],statistics
nmda67,1622138129.0,Bayesian Statistics [Question],"Hi guys, I’m conducting an independent study and was wondering if anyone could help me get a general grasp on it.  I’m doing research on cancer rates and pollution levels in the US (particularly along the Mississippi River Delta and Basin). My professor wants me to conduct some tests using Bayesian statistics. I know that a lot of statistical tests have certain parameters and assumptions that must be met —> i.e. the t-test needs relatively equivalent sample sizes between the two groups, as well as a uniform bell-curve distribution in order to work to its fullest extent.
- What are the most basic assumptions for Bayesian statistics?
- is it possible in Bayesian state, like with an ANOVA test, to test conflicting or compounding variables (I.e. variables that work together to overall amplify the risk of the development of cancer)?",statistics
nmcfks,1622135898.0,[EDUCATION] Signal vs. Noise in Statistics | Are we in a record NO-HITTER Season in the MLB?,http://jeffgalak.com/datademystified/index.php/2021/05/27/are-we-in-a-record-no-hitter-season-in-the-mlb-signal-vs-noise/,statistics
nmbeqd,1622133194.0,[E] Any good survey creation tools to show undergrad stat majors?,"I'm looking to do a tech demo of survey creation for an undergrad class or stat majors in about a month. They won't be any big project around it, but I want them to have familiarity with one survey creation tool for future work.

Ideally, I want a system that is

- Free or cheap for small-time users. (Or has a community edition)
- Lightweight enough that the basics of it can be demonstrated in less than 2 hours of lecture.
- Capable of producing a .csv or something similar for analysis.
- Capable of some rudimentary skip or display logic.
- Available in places like China and Iran that have had past difficulties accessing American software services.

Is there anything you know that ticks all these boxes?

Thanks in advance!",statistics
nm7zp0,1622123702.0,[Q] factor analysis,"Hey I need to perform a factor analysis via SPSS for a Student project assignment to look at whether the items of my questionnaire measure the same construct.
I collected data from participants that needed to answer the same questionnaire consisting of 15 items after each task (10 tasks for each participant, therefore 10 times the questionnaire). I see in my data set every item 10 times now.
It seems to me a bit messy that is why my question is how can I make my data set more readable? Should I take the average for each item or should I perform 10 individual factor analyses ?",statistics
nm783b,1622121392.0,[D] Equivalence between traditional state space models and recurrent neural networks,"Can anyone recommend a source that explains the relationship between recurrent neural networks and state space models? I often see recurrent neural networks being explained just in terms of ""neural network"" vocabulary. Can anyone recommend a website/book/video in which the ""hidden state"" aspect of recurrent neural networks are discussed?

Thanks",statistics
nm4xf5,1622113382.0,[Q] Significance Test for a comparison of a group that is part of another,"Haven't explained well in the title, but I'm basically comparing sales in a single office vs the regional sales vs national sales to see if it's performing statistically better/worse and not sure what test to use.

The office is part of the region, which is part of the national data set.

I only have access to the grouped data that looks like so:

Group | Customers | Sales | Sales Percentage
:--|:--:|:--:|:--:
Office | 15250 | 650 | 4.1%
Region | 84000 | 5600 | 6.3%
National | 950000 | 76000 | 7.4%


Thanks",statistics
nm07k7,1622092491.0,[Software] How do I open an SPSS file in Graphpad Prism?,"Hi, I really need some help with this.

I have a large data file in the SPSS format, which was painstakingly typed. Now my PI wants me to use Graphpad Prism instead as the graphs look better. Is there any common format that can be used to transfer my data from SPSS to graphpad? Or can the SPSS file be opened directly on Graphpad?",statistics
nlwtfq,1622079655.0,[E] A neat way to visualize standard error,"A group of samples can be used to generate a normal distribution that approximates the population distribution (central limit theorem). Repeating this process many times generates a cloud of curves whose spread is a representation of their standard error. For example,

[n = 10](https://preview.redd.it/zkidd03k9k171.jpg?width=3371&format=pjpg&auto=webp&s=bfd31b200dc3df590b1845ebe935a30387e702e2)

Transparency was applied to the curves so that their density at any point is represented by its brightness. Increasing the number of samples looks like focusing a camera:

[n = 30](https://preview.redd.it/o5rkj03k9k171.jpg?width=3371&format=pjpg&auto=webp&s=49322956551aa20c80a9cba89f39ae863d594517)

The mean and standard deviation used to generate each curve all bounce around the same value as in the previous graph but with less error. This effect is exaggerated by increasing the number of samples again:

[n = 100](https://preview.redd.it/1e8nzz2k9k171.jpg?width=3371&format=pjpg&auto=webp&s=dbd37e7b17b891efdf5ea29d942374faad860476)

These curves were generated through simulated dice rolls, so they can be compared to the true population distribution, marked by a red curve here:

[true value comparison](https://preview.redd.it/xge8f03k9k171.jpg?width=3371&format=pjpg&auto=webp&s=4e6795f8264a2dd5759631d770c4c6aa877be986)

It's not a great way to visualize standard error, but it's a cool way to explain the concept.",statistics
nlvial,1622075189.0,[Q] major brain fart,"I can't remember how to do this. Working on a personal research project. If I have a population with a standard deviation of x, how would i find the average standard deviation of a random sample of 15 pulled from that population? I tried googling it, couldn't find what I was looking for",statistics
nlunr2,1622072462.0,[Q] How to appropriately deal with a single outlier than can't be deleted (normal distribution),"Hello everyone,

I am currently writing my thesis and have encountered the following problem:

I have sample of 150 countries with their respective scores. For further tests and Z-score calculation, I'll need to check whether the data is normal distributed.

The problem is that North Korea's score is an outlier which leads to an excessive kurtosis.

How do I deal with this appropriately? I have no legitimate argument for excluding the data point from the sample.

Do I transform my entire dataset via log transformation?
Or what is the usual approach here?

Any help or advice appreciated!
Thanks in advance!",statistics
nltls7,1622069252.0,[Q] RKHS and regression," So, in regression context, given N observations of your partially known function F, you want to obtain a prediction of F at new point x*. In RKHS framework by denoting K the kernel associated with the RKHS H, without noise, you are looking for the function which minimises the norm ||f||_H with respect to f(X_i) = Y_i for i=1,...,N.

My question is quite simple: Why is the function with the minimal norm a good choice? What does it mean that the norm is minimal for the function?

Thank you",statistics
nltjr7,1622069082.0,[Question] Prediction based on multivariate explanation,"Hi,

I have a set of variables that when summed, make up an aggregate variable. When I regress the aggregate onto a non-specified timeseries, I get an insignificant result. The same happens when I regress the timeseries onto the regressors individually. That is (in my understanding) because the individual variables capture primarily the variability of the aggregate variable.

However when I use a multivariate regression where I include all ""fractional variables"" at the same time, some of them yield significant results (which also make sense interpretation-wise).

The goal of this endeavor is to use those significant ""fractional variables"" as predictors for the dependent timeseries, I am however unsure how to go about it.
Specifically, I do not understand how to employ the explicative power of those ""fractional"" variables as predictors the same way that I determined it (ie through multivariate regressions).

I'm not entirely sure how ""explanation"" and ""prediction"" connect in this case on a theoretical level, because that really goes beyond what I learned in my stats classes.

Greatly appreciate every comment!",statistics
nlsx88,1622067270.0,[Question] What statistical test should I use?,I have recorded the abundance of an invertebrate species in 10 quadrats for both two separate streams. I am interested in seeing if there is a difference between their abundance between the streams. What would be a good test for this data? Thank you in advance.,statistics
nlqxvj,1622061626.0,[Q] Principal Component EFA and Max Likelihood CFA,Is there any particular methodological issue with doing a Principal Component Analysis with a Varimax rotation to tease out variables from a scale and then to confirm that model with a maximum likelihood confirmatory factor analysis? Versus say using Maximum Likelihood from start to finish?,statistics
nlppmy,1622058368.0,"[D] [R] In a regression discontinuity design, why can't you just make two least squared regression lines centered around the cutoff point and subtract their y intercepts?","I am trying to understand regression discontinuities for a project I am working on, and when reading papers of others doing the same test, they always define some binary variable for when the x values are above/below the point. Why can't you just take two data sets centered around the cutoff point, find a regression line for each set, and subtract their cutoff points? Whenever I do that simple subtraction method like in excel, I get a different number from when I do the analysis in a programming language. I hope this question makes sense and thank you to anyone that responds.",statistics
nlp2fk,1622056686.0,[Q] Indipendent Pathways Model and Initial Path Model understanding problem,"I am a clinical psychology student that is writing his work for the degree discussion, and i know the logical meanings and implications of those models, however, the commission want me to explain how did they calculate those results, what's the interpretation of those numbers and so on.

My problem is about the two models that i mentioned in the title, i know that for the calculation of those numbers the analysis of correlation and the multiple regession are involved, but i don't know how exactly.

Just discovered that tomorrow i have a demonstration to make of what my discussion will be, and i don't have sccess to my statistics books.

Any insights?",statistics
nlmdlk,1622049739.0,[Question] Shouldn't people use the right terminology when they say 'Normalization' or 'standardization' ?,"I often note that people in the machine learning domain (often with no statistics background) define Normalization and standardization such as below

>The two most discussed scaling methods are Normalization and Standardization. ***Normalization*** typically means rescales the values into a range of \[0,1\]. ***Standardization*** typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance)

I believe they are etymologically wrong in using the two terms alternatively. Here is my rationale:

A. Normalization : In classical statistical sense, Normalization means (x- mu)/sd. When statisticians says “normalize” they mean to say a distribution having mean =0 and variance =1. This is also known as standard normal distribution. Any normal random variable X can be transformed into a standard score or z score via the equation (x- mu)/sd. If one thinks Etymologically , it makes sense to call the above process **‘normalization’** since normal here refers to the ‘standard normal’.

B. Min Max scaling (informally referred as normalization by people in machine learning, but I would call it ‘standardizing’) X= X-X(min) / X(max) — X(min) The formula helps in scaling the values in the range of \[0,1\] and in a true sense **‘standardizes’** the values. Come to think of it, how is scaling the values between \[0,1\] normal or Normalization? It simply does not stick or make sense. I would hence rather call this process ‘standardizing’ as things are standardized in the value range \[0,1\].

May be I am thinking from a pure statistical perspective. I would like to know what the statisticians or people with statistical training here think ?",statistics
nlki1y,1622044930.0,[Question] Canonical correlation analysis: how do we get two separate matrices from the cross covariance matrix?,"Usually I see the cross covariance matrix defined to be the matrix whose (i,j)-th entry is the covariance between the i-th element of X and the j-th element of Y, for two vectors X and Y.

But this cross covariance matrix needs to be factored into two matrices, because canonical correlation analysis wants to find pairs of vectors (a, b) that maximize the correlation between a^T * X and b^T * Y.

The wikipedia page does a good job of explaining this more clearly, https://en.wikipedia.org/wiki/Canonical_correlation#Definition

What I don't understand is how we go from the cross covariance matrix (which is just one matrix, whose elements are determined from a specific formula) to two matrices X and Y that can be used in the canonical correlation analysis. There are many ways to factor a matrix so I'm not sure which to use, or if that is even the correct approach.",statistics
nlgtpk,1622035078.0,[Q] Is there some general relation between Bayes tests and (U)MP tests?,"The Neyman-Pearson Lemma (in Bickel and Docksum's Mathematical Statistics I) first constructs the Bayes optimal test for the simple testing problem,  and then proves the Bayes optimal test procedure    is and is the only the most powerful (MP) test at the level of its size.

Is that Bayes test being MP only a coincidence?
Is there some more general relation between Bayes tests and (U)MP tests (or other tests)?
(If I am correct, Likelihood ratio tests for general testing problems are not Bayes tests.)

Thanks.",statistics
nlgsbz,1622034978.0,[Q] What statistical tests to perform when I have low sample size (n=16) and all binary categorical variables?,"n=16

I have binary variable diseased/non-diseased and several binary variables like particular mutation present/non-present. I know that I can do simple frequencies of mutations for diseased/non-diseased. Is there any other particular statistical tests that I can perform with this sample?

Also, any particular plots that can be useful here to present data?",statistics
nlf8v9,1622030417.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
nle8su,1622027048.0,[Q] I need help with a question for my graduation project about ordinal data,"

For my graduation project, I am working on the impact of social media influencers on consumer purchase intention. I collected data through a survey, the data is mainly nominal ordinal and 80% of it is Likert scale. The problem is my supervisor told me that we will consider the Likert scale as ordinal ( unlike my previous marketing professor where we considered it interval) so basically, I want to know what analysis can I do with ordinal data? He suggested working on correlations and said he will accept PCA but won't accept any hypothesis testing, regression, or ANOVA because they can't be conducted on ordinal data... I really need help because I only have 10 days left. For now, I am planning on doing PCA and chi-square.

Anyone can help?",statistics
nlaeae,1622011598.0,"[Q] Can someone explain ""effect size"" in a practical sense?","Hi all,

I feel like I understood the concept, but after doing some googling I am not so sure anymore...

Suppose I fit a linear model:

`Y = a + b1*x1 + b2*x2 + e`

And my null hypothesis is `H0: b1 = 0`.

&nbsp;

I had thought that my effect size in this example would be the estimated `b1`. But when I did some googling around this subject. Most explanation says the effect size for a linear regression is `f2`, where `f2 = R2 / (1-R2)`.

If I am only interested in the effect of `x1` wouldn't it make more sense that the effect size is `b1`?

&nbsp;

(not sure if it matters, but this question stem from a power calculation which I am trying to perform)

Thanks",statistics
nl66m9,1621995929.0,"[D] Why is ""convolution"" a meaningful mathematical operation?","I was watching an introductory video on convolutional neural networks, and the ""convolution"" operation itself seems so interesting. It seems that convolutional neural networks take a picture, and via convolutional layers, repeatedly shrink the original picture to a small matrix of numbers. This small matrix of number is associated with a ""label"" (e.g. ""dog"" or ""cat""), and then the neural network can learn to recognize similar pictures.

I had the following questions:

Question 1: Why is the ""convolution process"" a meaningful operation? How are convolutions able to capture and filter meaningful information from pictures? I know I am wrong, but from a layman's perspective, the convolution process (i.e. taking the algebraic dot product between filter weights and the pixel values of a picture) seems somewhat ""arbitrary"". I just find it very interesting that the dot product between these two entities is able to capture and filter meaningful information about the pictures. Just a guess : does this have to do with the ""universal approximation theorem""? i.e. the universal approximation theorem also applies to cnn's.

Question 2: I have often heard claims about neural network based approaches being intended for ""non-tabular"" data, such as pictures. The argument being, neural networks work better when there is a higher level of ""richness"" within the data, e.g. pictures containing 786 pixels and each of these pixels usually being non-empty. This is usually contrasted with ""tabular data"" such as data that can be easily placed into Excel spreadsheets (e.g. typical of finance data). Apparently, tabular data is more prone to containing less informative data compared to pictures, potentially making the performance of neural networks worse. When dealing with tabular data, it is said that boosting and bagging based techniques (e.g. random forest) are more likely to yield stronger results.

I was just wondering: Why aren't pictures normally considered as tabular data? Couldn't you just take the individual pixel values and collectively store them into matrices (i.e. tabular form)?",statistics
nl1teb,1621981844.0,Real-world problem [Q],"Hi. Thanks for reading this and helping me think it through. I'm an EE who doesn't do a ton of stats. This experiment is the way it is for ~reasons~ I can't control.

The problem: I have experimental data from two models of a device in several changing environments that are out of my control. Not every environment has both devices, but some do. The environments are dynamic in terms of magnetic and electrical fields present. I can process data from each device and get total Vrms noise over a bandwidth I care about per five-second chunk of data. I want to determine if one device is better than the other at shielding against that radiated noise. A meaningful difference would be an order of magnitude or more.

The experiment run (sometimes multiple times) with each device/environment:

* four minutes of ambient environment noise data.

* four minutes of data taken near a noise source that should be greater than the ambient environment, but may not be. The idea is that they'll add root sum squares-style and the new noise will swamp the ambient contribution.


questions / assumptions:

* averaging the five-second chunks' FFTs and then taking the area under the curve gives me total average noise.

* plotting the average noise vs. how often that amount of noise appears, grouped by device and binned in some sensible way, should give a normal distribution per device that I can then compare using a 2-sample t-test.

* I'd like to use the delta between the noises in both parts of the experiment, but it seems like that would be measuring the environment and not the performance of the device. Or maybe that's where a paired t-test would be useful? Guidance here is welcome.

* Some experiments will be run incorrectly, introducing conducted noise, but I only have the data, no observation of it being taken. Can I throw out data that shows 'very large' noise?

* The null hypothesis: the shields are equally performant in defending against radiated noise.

* alternative hypothesis: the shields' performance differs.

This is akin to an epidemiological study where everyone is vaccinated with one of two vaccines and they're in unknown environments, but one environment probably has _more_ of the disease, and we want to know which is better and roughly how much better.

thanks!",statistics
nl0v60,1621979096.0,[Q] Experimental design for simulations,"Hi all, I'm looking for resources about designing experiments for simulated data. As background, I'm a MechEng/BioEng grad student doing fluid simulations, and I'm planning on assembling a dataset to investigate the relation between a geometric measure of a set of related fluid domains (eg, diameter of an orifice in a set of varying, irregular pipes) and a measure of the resulting simulated flow (eg, shear stress on each pipe's wall). I also want to run each domain using multiple flow rates, where a mean and standard deviation flow rate is known (and it is known that flow rate and wall shear stress will be correlated).

I don't have much experience in experimental design, and want to know if there's a ""smarter"" way than brute-force running each domain at, say, 5 different flow rates centred around the mean, or if there are any significant downsides to creating the dataset this way. I assume that randomly sampling the inlet flow rates from our known distribution would help reduce confounding factors, but I just don't know enough and would like to find some canonical sources for this type of experiment. For my purposes, my supervisor is fine running each domain at 5 flow rates, but he's also more of a fluids/numerical methods expert than an experimentalist. I know I'm in the realm of UQ, so any advice from that perspective would be greatly valued as well.",statistics
nkzgoa,1621975279.0,[Q] Level of agreement/ Finding a way to justify why only a certain level of mean was analyzed,"Hey people!

I'm currently writing my first-ever thesis and I'm a bit overwhelmed by the statistical part. In my research, I asked students to fill out a survey in which they had to indicate how important 34 different attributes were to them based on a 5 point Likert scale.

I did descriptive statistics in SPSS to see the mean and std. deviation of all 34 attributes. The outcome was a table that included all 34 attributes and I was able to sort them from highest to lowest based on the mean.

My problem is now that I don't wanna analyze all 34 attributes, but I have no idea how can I justify that I only focused, for example, on the ten most important attributes or on the 5 most important attributes. My question is now if there is some way to calculate some sort of ""highest level of agreement"" that I can use to justify that I only looked at a certain amount of attributes? For example, saying that 12 attributes are the most important ones (M > 4.10)?",statistics
nkywcy,1621973522.0,"[Q] Choosing what prediction interval to use, is that purely based on the business problem?","Hello!

While working on a project and finding prediction interval,
I was wondering if business problem allows, instead of 95% prediction interval, can we use 80% prediction interval?
If I'm getting it right, it will just mean that instead of 95, we are only 80% sure that the prediction will lie in this range?

Thanks!",statistics
nkxmch,1621970088.0,[C] how to get into career in data analysis?,"I’ve become more and more interested in learning statistical and data analysis skills. I worked in psych research so I have a bit of a background, but I’ve found myself leaning towards policy analysis and research positions. I worry that I don’t have the skills necessary for these fields and I’m wondering what I could do to gain more experience now. Any thoughts are welcome :) thanks!",statistics
nkv5zy,1621963606.0,[Q] Is Ward's Method Inappropriate For Dissimilarity Metric Data?,"I'm assessing the results from Hierarchical Clustering using different linkages (single, average, and ward).

[I came across this post made in StackExchange](https://stats.stackexchange.com/questions/195446/choosing-the-right-linkage-method-for-hierarchical-clustering) and it stated the following:

>Last 6 methods require distances; and fully correct will be to use only *squared euclidean distances* with them, because these methods compute centroids in euclidean space

The data I am working with is dissimilarity metrics regarding single-nucleotide polymorphisms (SNPs) and other genetic distance dissimilarities. As such, based on my understanding, it would not be appropriate for me to use ward linkage on this data.

This is my first time discovering this, my previous coursework didn't mention this nuance but I suppose I may have learned about this upon review ISLR.",statistics
nkuhyf,1621961882.0,[Q] Survey tool with a time limit?,"First and foremost, I'm sorry if this isn't the right subreddit for my enquire, but a similar post got auto-deleted from Academic psychology and I couldn't find a sub dealing with methodological issues explicitly.

So, as the title states I need your help in finding a survey tool, as for a class we have the task of conducting a basic scientific research. Long story short, I need a tool that can split the whole survey into three different parts with one of it having a time limit of 25 minutes. I would've usually done it in Google Forms, but I think the time limit eliminates it as an option. So if anyone has any recommendations, I'd be really thankful.",statistics
nktnn8,1621959712.0,[Q] Need help choosing best tests to do,"So i have 2 questions. I'm doing my master's thesis which involves ct (computed tomography) head exams and i don't know/not sure what tests to do. I'm studying dental disease in rabbits and i grade (1 to 5 - ordered) them in quadrants. I also identify lesions that are present (binomial variable yes or no).

First question i want to see if there's agreement in grades between mandible vs maxillary and left vs right. The test i think i need to do is cohen's kappa but not sure if that's right.

Second question is to relate a lesion with the grades (e.g. One of the variables is abcesses and i want to know if as the grades increases/ so does increase (or decreases) the chance to identify them).",statistics
nks295,1621955561.0,"[Q] Is a ""Most Powerful Invariant Test"" UMP over all level-alpha invariant tests?","Given a testing problem,

- When talking about a UMP test, is it correct the test is UMP over all **level-alpha** tests, for some specific alpha?

- When talking about a ""Most Powerful Invariant Test"" as in Sec 6.3 in Lehmann's TSP, is   the test UMP over all **level-alpha** invariant tests? or just UMP over all invariant tests, without requirement to meet a level?

Note that a UMP unbiased test is UMP over all **level-alpha** unbiased tests. So I was wondering if a ""Most Powerful Invariant Test""  is also similar.

Thanks.",statistics
nkrfcb,1621953904.0,[Question] Should we not be careful in our usage of the terms 'errors' and 'residuals' especially in context of Linear regression assumptions ?,"As far as I know, **Errors** pertain to the true data generating process .**Residuals** are something that happens because of us 'fitting a model' , basically the difference between observed and predicted values.

However, I have seen many statisticians / Data Scientists use the terms synonymously. They often use it in the context of assumptions of Linear Regression. I have seen many use the wording ""The errors must be normally distributed"".

I think it actually should be 'The residuals must be normally distributed'. Since there is no way one could know for sure about the Errors and whether they follow normal distribution or not.

So which is the correct terminology ' Errors must be normally distributed' or 'Residuals must be normally distributed' ?",statistics
nkpqld,1621949212.0,"[Q] Is error in linear model a statistic, parameter or something else?","In linear model for regression,

- both error and residual depend on sample. So are both statistics? (A statistic is a function of sample, correct?)

- error also depends on the mean of the true distribution. Is error a parameter? (A parameter is a function of the true distribution, correct? See Bickel and Docksum's Mathematical Statistics Vol I.)

- Is error not a parameter because it depends on sample? (Does a parameter necessarily not depend on sample?)

- Is error not a statistic because it depends on true distribution? (Does a statistic necessarily not depend on true distribution?)

- If error is neither a parameter or statistic, what does it belong to?

Thanks.",statistics
nkokmq,1621945777.0,[D] What areas in statistics are the following topics in machine learning closest to?,"What areas in statistics are the following topics in machine learning closest to?

- supervised learning? (linear/nonlinear random-effect model for regression? Hypothesis testing and categorical data analysis for classification?)

- unsupervised learning? (multivariate statistics?)


- reinforcement learning? ( Does statistics have areas for or close to that?)

- deep learning and neural networks?

Thanks.",statistics
nkml56,1621938918.0,[Q] How can I find a research topic?,"
Hello all, I’m a rising junior at my university who is majoring in statistics at the moment.

My goal is to do a phd in the field of statistical machine learning, specifically with unsupervised learning. I don’t know what but one day I want my thesis to be centered around clustering or dimensionality reduction. Problem is, I don’t know what math I need for that or what is even already out there for me to come up up with an idea as a contribution to the field. Is the field of ML too advanced that by the time I get there I will run out of ideas?

Does anyone think it makes sense or it’s possible for my to eventually do a thesis in that later on? I’ve been trying to learn the basics of unsupervised methods right now.


I know I’m getting ahead of myself here, but I have so much time right now on my hands that I’d rather dig into it a little bit if it’s a topic of interest to me.",statistics
nkjux6,1621927624.0,[D] Planning to apply for master in stats. I failed econ class twice. Would it matter?,"I took this intro macroecon class twice but failed both. The class itself wasn’t difficult but I just could not get the concept of macro, so I just did not even have desire to study. Would it matter when I apply for stats master’s program if I failed it twice? Im curious since there are lots of folks in stats grad who are coming from econ background and stats&econ are pretty famous combo so Im worried that admission center will care :((",statistics
nkjtrt,1621927485.0,[Q] How to calculate sample size in example scenario?," I want to calculate how large my sample should be in the following example scenario:


There are 100 bathrooms being renovated. According to the client, they are all the same size so only one drawing is needed for all the bathrooms. There will be n number of bathrooms 3D scanned in advance with a laser scanner for accurate dimensions. From this n number, the average of each dimension is taken to get the dimensions for the main construction drawing. On these dimensions there is a tolerance of 10 mm(-5, +5) in which the bathrooms can always be renovated neatly.


How big must n be to be able to say that at the average of n with -5, +5 mm tolerances, 95% or 99% of the 100 bathrooms are within said tolerances?",statistics
nkg2wk,1621913443.0,[Q] Re-running A/B test,I'm a data scientist and we ran a few A/B test and 3 of the 17 features  tested came out stat sig. We really want to be right that these features  are good for the product so there was discussion of running A/B tests  again but only for the 3 stat sig features. On an academic level is this a good idea? I'm having trouble thinking about what happens to type 1 and type 2 error in this case. Can anyone help clarify this for me?,statistics
nkfgn7,1621911435.0,"[Q] Is using a rate per 100,000 people bad practice when your population set includes populations under 100,000?","I'm looking at various Covid statistics, and something like 0.00105 deaths per capita isn't a very user friendly number. 105 people per 100,000 is easier to conceptualize.

If I want to be able to compare all of Europe, I have to apply that per 100,000 to Germany, but also San Marino and Liechtenstein.

Is this fine, or is it exaggerating the small countries' statistics?",statistics
nkf95k,1621910765.0,"[D] Do successful models defy the ""bias-variance tradeoff""?","In statistics, we are always warned about the ""bias-variance tradeoff"":  simple statistical models are reliable, but are generally unable to sufficiently capture the complexity within the data (i.e. high bias, low variance) ; complex statistical models are able to capture complexity within the data, but are generally not as reliable when generalizing to new data (i.e. high variance, low bias).

This leads me to my questions:

1) Are successful statistical models able to defy the ""bias-variance tradeoff""? As a simple example, consider the famous ""iris dataset"".  Kaggle competitions have shown us that statistical models can be made that perform well on both the training data as well as the test data. Are these statistical models defying the ""bias-variance tradeoff""? Now, let's imagine a far more complicated problem and dataset - but suppose that we are still able to create a statistical model that performs well on both the training data as well as the test data : are we again defying the ""bias-variance tradeoff""?

2) I have seen proofs that show how the MSE (mean squared error) can be decomposed into a ""bias term"" and a ""variance term"". Thus, for a given statistical model : for a fixed value of this model's MSE, if the variance is high then the bias must be low in order to compensate (and vice versa).

My question relates to the following : when people discuss the variance in the ""bias-variance tradeoff"", they are generally interested in the variance of a statistical model's performance when dealing with unseen data. Since this unseen data might not even exist at the moment, how is the ""bias-variance tradeoff"" able to make claims about unseen data? Is the ""bias-variance tradeoff"" a general idea with some theoretical foundations? Or is it mainly empirical?

3) Finally, how does the ""bias-variance tradeoff"" apply to real world models such as the ""self driving car"" , ""alpha go"" and computers playing tetris? Or in the case of reinforcement learning models, the ""bias-variance tradeoff"" does not apply the same way it does in supervised learning models?

Thanks",statistics
nkeu7m,1621909441.0,"[D] Does the ""memoryless"" property actually apply to grocery store lineups?","https://imgur.com/a/rvooTXN

I was reading about the famous ""memoryless"" property of the exponential distribution, which can be used to approximate the amount of time you need to wait before being served at a grocery store.

For instance, if you have already waited for ""s"" minutes and you want to know the probability that you will get served after waiting ""t"" more minutes :

Probability (getting served at ""s plus t"" minutes; having already waiting ""s"" minutes) = Probability (getting served after waiting ""t"" minutes)

My question: Does this formula actually work in real life? Just using logic and subject matter knowledge, can this formula really be applied to estimate waiting times at grocery stores? Suppose ""s = 50 minutes"" and ""t = 30 minutes"" : it just seems unrealistic to me that the probability of getting served after waiting 80 minutes (after already waiting 50 minutes) can be the same as the probability of being served after waiting 30 minutes.

Can this ever happen in real life?

Thanks",statistics
nkemwx,1621908808.0,[Q] [E] [C] Getting a MS in Stat after Failing to find job as an actuary,I am currently interested in majoring in mathematics and taking the actuarial exams while still in school. I have heard that the job market for entry-level actuaries are really competitive right now and will become more so. I am worried that I will not be able to find a good actuarial job after graduating with a bs in math so I'm wondering if it would be possible for me to then go back to school to get a ms in stat and became a statistician afterwards if my job hunt to become an actuary fails. I would appreciate it if anyone could also point out any other flaws that they see with my plan. For further clarification I want to major in math and minor in cs.,statistics
nke1du,1621906948.0,[Q] Statistically coherent method to detect time to steady state,"Hi everybody, have a question on a piece of research I am conducting.

I have currently a number of minute by minute time series of hardware temperature. And my goal is to find a statistical method that would allow me to determine how long on average the equipment takes to achieve its steady state temperature.

The temperatures would start at 18 degrees, then increase at a faster rate to reach 70 degrees (steady state), then it could either fluctuate around 70 or it could drift slowly upwards until about 100 degrees. The issue is that different equipments have different steady state temperatures, and I need to calculate the duration to steady state on average across all equipments. I have unfortunately only excel at the moment to run the analysis Would you have any advice on how I can estimate this duration?

Thank you.",statistics
nkd7ji,1621904381.0,[Q] Undergraduate Course Load Advice,"Hi everyone,

I’m currently an undergraduate seeking for some advice on picking courses for my upcoming term (I’m not sure where else to ask about this so I apologize if this is not very relevant).

The course load in my upcoming term, which consists of 5 courses, will be very heavy. I will be taking abstract measure theory, functional analysis, continuous stochastic process, and measure theoretic probability. And for my fifth course, I’m debating between advanced regression and analytic number theory. As someone who is interested in aiming for top Stats PhD programs in the future and doing research in probability theory, do you think I should take more math or more statistics? The most common advice that I’ve heard is that Stats PhD programs prefer pure math major and that Stats courses for undergrad are not very beneficial so this is the reason why I’m asking.

Thank you in advance!",statistics
nkc7do,1621901246.0,[Q] Does it at all make sense to ask whether a factor analysis vs a network analysis better explains a dataset?,"I've read that these are philosophically different approaches in that a network analysis doesn't assume the existence of latent variables. Is it possible to submit the same dataset to both, and then ask which one is a better fit (i.e., whether latent variables are necessary to explain the data)?",statistics
nk3hfp,1621877678.0,Job market? [C] [Q],"Nearing the end of my degree in math and stats, I found myslef wondering what kind of job opportunities exist. While I know that stats can be applied to virtually any field, I do not really know what job titles to look for.

I am aware of biostatisticians, but it is not a career I want to pursue. I haven't seen a lot of ""statistician"" job offering and hardly any statistics internships per say.

On the more lucrative side, I am aware of quantitative finance and data science, however these are very hot and hard to get into.

What job titles should I look for?",statistics
nk145b,1621871537.0,"Arizon election ""fraud"" statistics crank [D]","Found this link since someone told me it was “mathematical evidence” that the election was rigged in the state of Arizona 2020. I started watching it hoping to follow along with this guys analysis and I just don’t understand what he is talking about when he talks about “correlations between 1 vs 2 [hardline republican vs slightly red] 1 vs 3 [hardline republican vs moderate]... 1 vs 5” “and the average correlations are 63% for men.” I don’t know what he means by correlation or what he is measuring between groups. His “tedious analysis” seems like it would be at most 5 lines in R to accomplish, separating and summing into a bin for age, gender, and voter type. I was wondering if anyone else might be able to share some insight on this guys “analysis” since I can’t understand it?

https://www.realclearpolitics.com/video/2020/12/01/data_expert_up_to_300000_fake_people_voted_in_arizona_election_.html#",statistics
njx52g,1621860369.0,[Q] Hypothesis testing on ordinal data,"Hi!
Let's say there's ordinal data (1 (low) - 5(high)) about the importance of X in doing something. Eg ""rate how important food is with regards to relationship length""

This is clearly ordinal in nature. Then someone puts forth a hypothesis ""Food leads to longer relationships"".

So my question is, are there any statistical tests that are applicable here. All my searches have led to two sample non parametric tests eg Mann-Whitney test. But this is one sample, and according to the researcher there isn't a interest in different groupings (eg we have male/female- so they don't necessarily want to see if there's a difference between males and females)

The second question would be is this enough data for any meaningful analysis? Because it seems to me some thing is missing, but this area of statistics not being my area of expertise I cannot tell if that's correct.

Any resources are welcome. Thanks!",statistics
njvssv,1621855861.0,[Question] Are Generalized linear models (GLMs) linear ?,"I understand the difference between linear models (Linear Regression) and GLMs (logistic, Poisson, Bernoulli and Gamma regression). I have always thought of GLMs as non linear models.

However I stumbled upon an online resource which states that the discoverers of GLMs consider it to be linear !

Here is quote from ([https://online.stat.psu.edu/stat504/lesson/6/6.1#:\~:text=The%20term%20general%20linear%20model,(with%20fixed%20effects%20only](https://online.stat.psu.edu/stat504/lesson/6/6.1#:~:text=The%20term%20general%20linear%20model,(with%20fixed%20effects%20only)).

> The term ***generalized linear model*** (GLIM or GLM) refers to a larger class of models popularized by McCullagh and Nelder (1982, 2nd edition 1989). In these models, the response variable yi is assumed to follow an exponential family distribution with mean μi, which is assumed to be some (often nonlinear) function of xiTβ. Some would call these “nonlinear” because μi is often a nonlinear function of the covariates, but McCullagh and Nelder consider them to be linear, because the covariates affect the distribution of yi only through the linear combination xiTβ.

Given this background, my question is, can Generalized linear models be considered non-linear models or not ?",statistics
njudyr,1621850637.0,[Q] How do I create this kind of scatter-plots graphics in RStudio?,"Hello, as the title says, I'm looking to create data visual representation that looks like [this](https://imgur.com/3QEt6fP). I'm comparing the TI Corruption Perception Index, which dataset I found [here](https://www.transparency.org/en/cpi/2019/index/nzl) with the three subindizes of the Human Development Index that I found [here](http://hdr.undp.org/en/composite/HDI), the subindizes that I want to measure for are the life expectancy, education and GNI indexes.


Both datasets are in excel, I already could open them in RStudio, but when trying to create a scatter-plot I get multiple errors. It is less to say that I am still new at using R.


Ideally I would have three different scatter-plots, where on the x-axis I have the TI Corruption perception Index on all of them and on the y-axis the different indicators accordingly, namely life expectancy, education and GNI.


Any help or tips are very appreciated, thanks.",statistics
njsj7w,1621842897.0,[Career] Can I become a statistician studying at home?,"**Some context:** I'm a pure mathematician with a master degree. The career prospects for PHD's in my field of study is not promising anymore and I made a decision to change my career towards Data Science. I'm working as a private teacher and I'm using all my free time (I have plenty) to study stats/programming.

The problem is I fall in love with statistics, I've learned more in the last year than CS related subjects The last stats subjects I've been learning with a strong enthusiasm and rigor (doing the exercises included): Time Series, Bayesian Statistics and Design of Experiments. Of course, I've already learned the more fundamental subjects such as Probability Theory, modelling and Inference.

**If I make relevant projects can I apply for jobs as a statistician?** or is it better to only focus to Data Science jobs more CS related? maybe it depends on the field? are there easier fields without a bachelor degree in Statistics I can apply for? I've see some posts here people having problems to get a job without a PHD, so maybe I'm to naive thinking I can get a pure stats job without a degree in stats.",statistics
njrud1,1621839829.0,[E] Updated Article on Data Types in R,"I posted an article on the data types in R yesterday and it's been edited after all the suggestions that I received. Check it out [here](https://spardha13.medium.com/the-ultimate-beginners-guide-to-data-types-in-r-ac4358985150)! Hope this helps any beginners! I've verified what I've written from multiple resources before posting it. (I can link those resources in case anyone is interested to know more). Hopefully, it gives you clarity on \[ \] vs \[\[ \]\] and NA, NULL, NaN. If you found the article useful, give it a  👏 , thanks!",statistics
njripn,1621838471.0,[Q]Risk Theory- How to find the distribution of the insurer's claim payment per loss event via CDFs,"

So the payment for this insurer is that he pays for anything above D and he also has a reinsurer that covers him for anything above M

So his payment per loss event is denoted as such:

0 X<=D

X=X-D D<X<=M

M-D X>M",statistics
njkmzc,1621813998.0,[E] Spatial Statistics vs Network Models,"If an undergraduate student in applied statistics had to take a course in either Spatial Statistics or in Network Models, which do you think is the most useful (in industry, research, grad school, etc.)? Obviously, both are useful, but is there one that stands out on your experience?",statistics
njihgs,1621807362.0,"[Q] How to understand taking a simple sample to compute the confidence value and confidence interval, using CLT?","Suppose there is a population distribution having mean M and standard deviation SD. We want to estimate the Confidence Interval by using a single sample using CLT. We take a sample and compute it's mean(say SM) and standard deviation(say SSD). The distribution of Sample Means is normally distributed with a standard deviation close to SD/sqrt(n) where n is the sample size, and mean(say MSM) close to M.

We can understand this process in two ways:

   1.) That what we are trying to compute is the range MSM +/- 2SD/sqrt(n). This is what our Confidence Interval is.

      Now:

 * We approximate(replace) MSM with SM.

 * SD and SSD are quite close, so SD/sqrt(n) can be written as SSD/sqrt(n).


 Now, we can compute the Confidence Interval(MSM +/- 2SD/sqrt(n)), using the
   sample mean and sample standard deviation.

 But the problem with this understanding is that as a result of our process using CLT and a single sample, we can end up taking a sample having an exact mean of MSM + 2SD/sqrt(n) or MSM - 2SD/sqrt(n), with a 95% probability. In such cases, the Confidence Interval we will be computing are: MSM to MSM + 4SD/sqrt(n) or MSM - 4SD/sqrt(n) to MSM, which will be 50% off the confidence interval we were meant to calculate. So, how one solves this contradiction? The second way might have the answer.

2.) That we assume MSM is actually quite close or same as M (Population Mean). Then we say that we have a 95% chance of taking out a single sample which has it's mean within range MSM +/- 2SD/sqrt(n), in which case it will be 100% certain that our MSM(or Population Mean) is within 2SD/sqrt(n) of the SM (Sample Mean). So, that is how it comes out to be our Confidence Interval.

But if the second approach is indeed correct, that would mean forgoing the idea that the distribution of Sample Means provides a Confidence Interval of the Population Mean(M) around it's mean(MSM). And will that be correct?

Thanks",statistics
njgf6b,1621801717.0,"[D] difference between a ""distribution"" and a ""process""","I can understand what a gaussian distribution or a poisson distribution is, but what is their relationship to a gaussian distribution and a poisson distribution? Is a gaussian process basically a series of gaussian distributed variables?

Suppose you want to model some data using a gaussian process or a poisson process: how do you determine if the data is well suited for using a gaussian process or a poisson process?

It's relatively straightforward to determine if an individual variable has a gaussian distribution, e.g. a 100 height measurements of basketball players -  you can see if this height variable follows a gaussian distribution with a specific mean and a specific standard deviation (e.g. kolmogorov-smirnov test).

But how would you check if this variable follows a gaussian process?",statistics
njfmha,1621799532.0,[D] how important are the statistical assumptions in this question?,"https://m.imgur.com/a/Ct5PqnI

In this question, they assume that people arrive according to a ""poisson process"".

1) if you have real data (e.g. a list of times at which each customer arrives), how would you check to verify that your real data follows a poisson process?

2) suppose your data does not follow a poisson process - does the formula in this question still apply? Is there a ""non parametric"" form of this equation that does not depend on the poisson process?",statistics
njepzn,1621797019.0,"[Q] ANOVA results reported, df2 is decimal value","My google-foo is not helping me here. The paper I’m reading has ANOVA results reported throughout that are like:

F(2,.174)=12.9, p<0.001

Statcheck.io says each is a Decision Inconsistency, and recalculates p=0.64694.

I thought df2 = num_subjects - df1

Some of the df2s have leading zeros (I.e. .086), so I don’t think they are typos.

Thanks for any pointers.",statistics
njdzdx,1621794963.0,"[Q] Method for linear regression analysis of 1 relation between 2 variables, but based on data of different samples with different strengths.","Had trouble formulating the title, but I hope my explanation here will do.

For  research I will be analyzing the relationship between precipitation and  mass of deer antlers. Naturally, I would use a linear regression  analysis. But I have a limited amount of data available. I know the mass  of antlers over \~10 years for multiple deer. So to illustrate:

For  Deer A-H I know the antler mass from 2011-2020.  And of course I also  know precipitation in those years. And since genetics and body mass of  the different stags matter, I cannot just treat my data as 1 sample, but  I have to make data sets of 10 values for each stag.

That  would then yield multiple (possibly) linear entries for my analysis  with varying strength, but in essence I want to know how strong the  relationship **in general** is between antler mass and precipitation.

So  I am wondering whether there is a method in which I can do an analysis  for this 1 relation, based on these different individual datasets.

I hope this is clear enough, would really appreciate some help!",statistics
nj9nhh,1621782605.0,[Q] What regression methods are similar with Nadaraya-Watson Kernel?,,statistics
nj9n4n,1621782573.0,[Q] Parametric unpaired t-test or non-parametric Wilcoxon rank sum test for relative values?,"I have to groups (n1=13, n2=9), each having a set of values for cell sizes. Unfortunately, the calculation to get absolute values didn't work (probably due to an uncalibrated flow cytometer, which I used for measuring sizes). My supervisors and I agreed that we'd still use the relative values to test for differences between the groups.

Both groups are normally distributed, and both t-test and wilcoxon rank sum give non-significant differences in mean/median, respectively. So the results are actually quite clear, i just want to be sure i'm using the right test.

So the question is what is theoratically correct; I know the t-test checks for differences in means, but could the relative values affect the results? From my understanding the wilcoxon test modifies the data to pure ranks anyway, and i imagine this will be completely robust for relative vs. absolute values.

Greatly appreciate any tips!",statistics
nj8kvc,1621779237.0,[Q] Creating correlation matrix for multiple combinations of variables,"I hope this is the right Reddit for this.

I have a csv file with 10 columns and I've used Python to output a correlation heat map. Simple to do, but what I want next is to identify correlations using combinations of columns.

For example, a simple correlation matrix would compare: A to A | A to B | A to C | A to D etc

But I want to combine columns, in every conceivable way, such as:

A & B to A | A & B to B | A & B to C etc | A & B & C to A | A & B & C to B etc

And be able to highlight any noticeable correlations between certain combinations.

Is this possible at all? Are there proprietary applications that can do this? Or does anyone know how to do it in python?

Thanks",statistics
nj8d5p,1621778539.0,[Q] What kind of t-test to use when comparing mean price of ONE stock in two points in time?,"Hello, I would like to ask you the question from the topic.

I am writing a bachelor thesis on stocks and want to compare 30-day mean stock price in two points in time. I was suggested to use a unpaired two-sample t-test and then a beta coefficient t-test to compare the sensitivity (the beta coefficient in the financial meaning) of the stocks.

However, I think that when comparing 2 mean values of the same stock in different points in time, a single sample t-test would be better, as these two means come from dependent samples. (Just like e.g. grades before a test and after a test from one student) In that case, the beta coefficient t-test would not be performed (as it requires the betas to come from independent samples).

Which approach is right in this situation? Thank you for the answers.",statistics
nj6tkl,1621773061.0,[Q] Appropriate way to present statistics for age collected in ranges?,"Hello, I performed an audit which involved recording audited individuals age into discrete age ranges (<19, 20-29, 30-39 etc..). What would be the appropriate method of displaying the statistics of this age range?

Is it appropriate to calculate the mean Age Range of the study and the IQR? Sorry for such a basic question its been many years since my undergrad stats course!

Thanks for your help.",statistics
nj0khg,1621746412.0,coefficients in logistic regression and odds ratio [Q],"this seems really simple as no books or example sites are explaining this, but I am wondering how to interpret the log odds and odds ratio of coeffecients in logistic regression models. Most examples I have seen have easily interpretable coefficients, such as in this one example: https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/

>    ...exp(.1563404) = 1.1692241.

>So we can say for a one-unit increase in math score, we expect to see about 17% increase in the odds of being in an honors class.  This 17% of increase does not depend on the value that math is held at.

Obviously this 17% comes from the .169 at the end of the 1. But in my logistic regression model I made with the GLM function in R, one of my coefficients is 4.9996, which exp(4.9996) = 148.354, So I don't know how to turn that into a percentage. In other words, what is the formula for turning the odds ratio into a percent change per unit increase? Is it 1 - the number? for instance 1 - 1.169 = .169 after rounding is .17 = 17% like in the example? Is the percent increase per unit change for my coeffecient 1-148=147 = 14,700% increase?",statistics
nizujp,1621743630.0,[D] has anyone heard of the Stein Paradox in statistics?,"There is a famous statistical paradox discovered by the researcher Stein, which is said to describe a very paradoxical phenomenon:

 ""Popular articles have appeared hailing the James-Stein estimator a paradox; one should use the price of tea in China to obtain a better estimate of the chance of rain in Melbourne!""

Is this really true? Can you really use ""anything to estimate anything""? Does this work for quantities with completely different units? E.g. years vs micrograms?

And the more important question: if the Stein paradox is true, why don't weathermen in Melbourne use the price of tea to predict the weather? As far as I know, they only use meteorological satellites.

Thanks

Sources :
https://jmanton.wordpress.com/2010/06/05/comments-on-james-stein-estimation-theory/

https://en.m.wikipedia.org/wiki/James%E2%80%93Stein_estimator

https://en.m.wikipedia.org/wiki/Stein%27s_example",statistics
niwzi2,1621733071.0,[Q] Which statistical test to use for a comparative study that uses a likert scale?," I am a student who is currently doing an investigatory project wherein I made bio-based utensils to compare to the conventional plastic cutlery in terms of comfortability and other variables which is why I utilized survey questionnaires.

With that said, what statistical test is best for the data I have gathered? Thank you! Any help or comment is appreciated.",statistics
niq1z4,1621711537.0,"[Q] If there is a 1/56 chance for an event to be occurred, how likely it is for it to happen after the 56th attempt? (context in the post)","Before I start, I'd like to excuse any misuse of terms or mathematical symbols since I am not studying anything related to statistics or mathematics. What I am doing here is for my own curiosity.

I've been playing a game recently and I want a specific item. However, it has an extremely low chance of it dropping (0.0005%) and, if you make the calculations, you would need to kill around 200,000 monsters to get it, which takes around 56 hours. I imagine that it is safe to assume that the chance of the item dropping in each hour is 1/56.

I am curious to see what the chances are of me getting the item only after the 56th hour.

Thank you!",statistics
nijz99,1621694209.0,[Q] Do principles of sufficiency and likelihood mean functional dependency?,"Casella and Berger's Statistical Inference lists:

> Formal sufficiency principle. Consider experiment E  =  (X, theta , {f(xltheta)}) and suppose T(X) is a sufficient statistic for theta. If x and y are sample points satisfying T(x)  =  T(y), then Ev(E, x)  =  Ev(E, y).

Does it mean that Ev(E, x) = h(E, T(x)) for any x, for some function h?

> FORMAL LIKELIHOOD PRINCIPLE:  Suppose that we have two experiments, E1  =  (X1, theta , {f1(x1 | theta)}) and E2  =  (X2
, theta , {f2(x2 | theta )}), where the unknown parameter
theta  is the same in both experiments. Suppose x1 and x2 are sample points from E1 and E2, respectively, such that
L(theta | x1)  =  C L(theta  | x2)
for all theta and for some constant C that may depend on x1 and x2 but not theta. Then  Ev(E1, x1) = Ev(E2, x2).

Does it mean that Ev(E, x) = g(E, L( | x)) for any x, for some function g?",statistics
nijp9a,1621693392.0,[D] is there any relationship between this graph and this picture?,"Here is a picture of the famous bias-variance tradeoff: https://www.ncbi.nlm.nih.gov/books/NBK543534/figure/ch8.Fig3/

I am trying to understand what is responsible for the shapes of the ""orange"" curve and the ""blue"" curve. I understand that this bias-variance tradeoff often occurs in real life, but I am trying to understand if it will always (mathematically prove) occur.

For instance, if you look at the decomposition of the MSE into bias and error:
https://i.stack.imgur.com/3Mydo.jpg

Where exactly is the tradeoff? In this mathematical formula, is there something which physically (or probabilistically) stops both the variance and the bias from moving towards 0? Or is this just a general idea that has been empirically observed?

In this picture (https://www.ncbi.nlm.nih.gov/books/NBK543534/figure/ch8.Fig3/), why have the bias and the error been depicted as ""curves"" (instead of straight lines, very squiggly lines, etc)? Are they always going to have this shape? Is there some mathematical logic behind this, or is this just an artistic depiction of what is to be commonly expected?

Also in this picture (https://www.ncbi.nlm.nih.gov/books/NBK543534/figure/ch8.Fig3/),  why do the orange and the blue curve intersect? Mathematically, will they always intersect? Or again, is this just an artistic depiction of what is to be commonly expected?",statistics
nih8uy,1621685368.0,[Q] Grateful for help with a tricky mathematical problem,"Hi guys!

I've been very impressed with some of the answers i've seen on the sub and was wondering if someone could help with my mathematical problem or at least signpost me in the right direction. I did statistics at school about twenty years ago so my skills are extremely rusty.

The problem is as follows:-

I have inherited a hundred classic watches that I want to trade, eventually leaving me with no watches, for the maximum profit available.

I strongly anticipate that there is going to be a spike in the value of the watch market however I don't know when the spike will be, how long it will last or how high it will go. It is also not clear whether or not I will be able to rebuy the watches once they are sold.

My problem is therefore to work out a formula that will give me the highest rate of return by selling the bulk of the watches as close to the ""peak"" of the spike as possible.

What i THINK I need to do is construct two models:-

Model A: in which I can only sell and not rebuy watches. I try and work out the optimal size of batches that I could sell watches for (eg 10 watches in a batch) and run a Monte Carlo simulation that takes account of the local volatility of the spike in price, the peak and variance of the price movement.

&#x200B;

Model B: in which I could re-buy the watches so that (for instance) if the watch price goes to $100 each I could sell (say) ten watches and rebuy them if the price drops to (say) $50 each in the anticipation that price would rebound above $100 (or to sell them at a lower cost if the price continued to fall). Again i am assuming a Monte Carlo simulation would yield the best results?

&#x200B;

So, how would I solve this issue? Is this a statistical problem or something more suited to computer programming?

&#x200B;

Thankyou in advance for your considered opinion - it's driving me mad!",statistics
nig6xj,1621681370.0,[Q] How is the standard error / CI of multiple data sets while doing operations on their differences calculated?,"Hello, I'll try using the proper vocabulary but don't hesitate to correct me if I seem to use the wrong words. I'm having an issue with interpreting statistics of data sets, maybe I'm overthinking the thing and it might be pretty straight forward :

**P :** I have 3 sets of unskewed normally distributed data, A B C, from which I calculated their mean average with a 95% CI and a sample size N high enough for a 0.05% standard error (N≃40000 per data set). Their mean CIs are : `A=1574.0±0.8` ; `B=1616.4±0.8` ; `C=1595.9±0.8`. We can safely assume their variance are equal.

My main goal is comparing the difference between the data sets, to see the effect of variables applied to A (1 variable was applied to B, another 1 to C) and end up with a *ratio of effectiveness* by comparing data sets between them (B's variable is x times as effective as C).

**Q1 :** I think we can safely say the average difference between A and B is `1616.4-1574.0=42.4`, but what can we say about the standard error of this value? Is it `42.4±0.8` as we keep the CIs range of initial data, meaning its error is about `0.8/42.4=1.89%`?

**Q2 :** What can we say about the relative effect of B's variable compared to C's? C average difference being `1595.9-1574.0=21.9`, it seems safe to say B variable is about `42.4/21.9=1.94` times as effective as C's (the *""effectiveness ratio""*), but what's the error range of this value? Experimentally, it's been varying quite a bit (by repeating the whole process), I'd say as high as `±0.4` but have no idea how to properly calculate that.

Thanks to anyone willing to help :)",statistics
nie3j6,1621672376.0,[Q] Hedging against criticism and misunderstandings when presenting statistical work to non-technical or ill-informed audiences.,"So I just had a work-related thought. For technical analysts, it is quite often that the work is presented towards an audience that has a non-technical background. Or even worse, an audience with some technical knowledge but still has misunderstood essential ideas and concepts. In such settings, it could be quite challenging to present and defend the work you have done if you do not have the respect of the audience.

Take this hypothetical scenario as an example; a statistician or economist presents a forecast from a model where the forecast is later shown to be off the realized target to some degree. From a statistical perspective, it is natural that a prediction will be off, given that it is unreasonable to expect a model to be entirely deterministic due to the stochastic nature of the problem. However, a non-technical audience might interpret such a scenario as the forecast being bad due to a flawed model and might then assume you do not know what you are doing.

How would you position yourself to avoid this in a practical context? I think it might be reasonable to present prediction intervals and a benchmark that the audience can understand to hedge against this problem. Then you could intuitively present uncertainty while showing that the model outperforms something that the audience might be thinking of using. I am curious if anyone else has given this scenario a thought or possible have relevant experience?",statistics
ni8050,1621647782.0,"[Q] How would you visualise a patient's psychiatric information? Sleep amount, sleep start and end times, medication periods, evolving medication effects, underlying symptoms and their progression, key events, etc, over many years. Parallel information about other medical conditions too.","I rely heavily on notes and struggle to keep doctors informed. I'd also like to maintain my own records more clearly. I have a huge amount of disorganised information.

I'd like to be comprehensive with it but also allow a doctor to pickup key trends quickly.

Any suggestions would be appreciated.",statistics
ni7wzz,1621647456.0,[Q] Trying to understand what best predicts employee working hours?,"Hi guys,

I am really no statistics expert so I hope this is clear, if you need clarification please let me know.

Background: we have a casual workforce where there is no measure of ‘efficiency’ - we don’t allocate a specific amount of hours for a shift the employee just works until it’s done.

Assumption: in the business there is an assumption that employees work longer in summer than winter because our carton size is larger in summer. Although it doesn’t appear that hours change that much.

Problem: trying to understand what variable contributes the most to employee shift hours and what statistical test to use.

Data available: age, start date, cartons, by shift, gender, weather, season, location, pay rate, day of the week.

Thank you!",statistics
ni7t7i,1621647064.0,[Q] What test would I use to compare means of answers from two different groups on a survey?,"Hey all,

I’m doing a survey for a class where I’m trying to compare answers for four questions based on whether or not people listen to a certain type of music for x amount of time. What test would I use to compare the means of the answers for both of the groups? It’s been a while since I took stats, but I think the correct test would be a paired sample t test but I’m not sure. I’m familiar with using SPSS. Thanks!",statistics
ni7qhk,1621646777.0,[Q] Is a likelihood function a sufficient statistic?,"In Casella and Berger's Statistical inference, there are two principles very similar to each other: the sufficiency principle (p293 and 272) and the likelihood principle (p293, 294 and 290).

A likelihood function can be viewed as a function-valued statistic.
Is  a likelihood function a sufficient statistic? (So that the likelihood principle is a special case of the sufficiency principle.)",statistics
ni2wnq,1621631193.0,"[D] how ""interpertable"" are regression models?","I was recently reading some articles on the importance of ""interpertability"" when dealing with ""blackbox"" models. ""Blackbox"" models like neural networks are said to have a very low level of interpertability, because they don't allow the analyst to understand why the model is making a certain predictions for an individual observation.

On the other hand, models like decision trees and regression models are said to have much higher levels of interpertability. In a general sense, I can understand why models like decision trees are interpretable, because they literally provide the analyst with a set of fixed rules that explain how to classify an individual observation.

If you look at a regression model,

e.g. salary = 5.3 * height  + 2 * weight  - 15.8 * age

A regression model can allow the analyst to understand how much each variable contributes to the prediction (e.g. in this example, age contributes more to the prediction by a factor of almost 8 times), and you can also find out how statistically significant each variable is (e.g. indivudal p-value of each regression coefficient).

Is this what is meant by the ""interpertability of a regression model""?

Thanks",statistics
ni0z2f,1621625937.0,[Q] When do I reject my directional hypothesis when using a t-test?,"So, Let's say that I have two groups that undertook an English test, one's and experimental group (EG) and the other's the control group (CG). In my directional hypothesis, I stated that EG will perform worse than CG. The alpha level is p<0.10 since it's a directional hypothesis. My degree of freedom (df) is 37. Because I don't have 37 in my t-table, I chose the closest that is 40. The t critical in this case is -1.68 (left-tailed since my hypothesis stated that EG will perform worse). I calculated the t observed and I got -1.36.  In this case, do I reject the directional hypothesis or not?

I argued with my colleagues about it for god knows how long. I think it should be rejected since there's no statistical difference between the two group so we can't say for sure whether EG performed meaningfully worse than CG, if that makes sense. Am I wrong? I looked all over the net, but I couldn't find a satisfactory answer, so I'm giving you this specific example to clarify things once and for all.",statistics
nhzqnm,1621622655.0,[Q] Is there a way to properly average bootstrap confidence intervals from different samples?,"I have a deep learning classification pipeline in which I had created 10 independent train/val/test splits. The pipeline uses large images which must be broken up into ""tiles"" which are assigned the label of the original image. I have a script which gives me the AUC and 95% boostrapped confidence interval on a given test set. After running on all 10 splits, I have 10 AUCs and 10 CIs. I was wondering if there was a proper way to aggregate these and generate 1 single statistic AUC and CI.

Intuitively I would think to get the mean AUC, the mean lower bound CI and mean upper bound CI, but I am not sure if that is correct and what to call that if it is correct.",statistics
nhydad,1621618966.0,[E] How important is taking a course on sampling during a masters program?,"I am currently in a M.S. in Statistics program, and have a scheduling dilemma. I am most interested in the biostatistics and machine learning/data science electives, but unfortunately I need to get certain prereqs out of the way before I can enroll in them. So, I am having to decide whether or not to take a foundational course along with the sampling elective, or to only take the foundational course and potentially be in the program for an extra term in an effort to take one of those previously stated electives.

If I choose to not take sampling and stay longer it is going to have a pretty significant impact on my ROI for the program, but I want to make sure I get the most out of the education because I really do love the subject. It is a top 20 program globally, so I want to soak up as much knowledge as possible. Career wise, I am most interested in using statistics and machine learning to help people through the world of medicine, as my dream would be to work as a data scientist for a health tech company where I can make a real impact on peoples' lives. My intuition tells me that having a strong foundation in sampling theory would be beneficial for any medical trials I may be working on. Still, any input is very much welcomed.",statistics
nhxpfl,1621617243.0,[Q] bio stats phds,"I have been hearing that a lot of bio stats jobs do way less real and interesting works than data science roles. I was wondering if this was still the case for people with phds. I am interested in bio stats because of the ability it gives to help the world such as work related to pandemics, but don’t want to just be trying to get drugs past the FDA. Also is a bio stats PhD just as rigorous and respected as a normal stats PhD when applying to industry or academic roles? Thank you",statistics
nhxiun,1621616788.0,[Q] Can any give a non-technical explanation of the different between the survival and hazard function on a kaplan meier graph?,,statistics
nhwp6j,1621614681.0,[Question] Regarding an example of Texas Sharpshooter Fallacy.,"Hi,

Consider the below example explaining the Texas Sharpshooter Fallacy:

There are a certain number of cancer cases in a region/area(say 36000) every year, and we divide all the area into 1000 sub-areas/parts for analysis of 'cancer clusters'. We notice that the highest no. of cases is 48 in a year, belonging to a particular sub-area, so to analyse we run a simulation(may be 1000 times) and try to find the probability of that particular sub-area getting more than 48 cases in a year.

Now, as per Texas Sharpshooter Fallacy, we should be checking for the probability of the 'highest' no. of cases exceeding 48 in all of the area/region in totality and not just that particular sub-area.

My question is this: In what scenario, we should be checking that particular sub-area only, then? and how? I could possibly think of a scenario where we are looking for the historical record of that particular sub-area; making a distribution out of that data and then checking whether 48 is an exceptional value or not? But I think that we will reach the same conclusion as we reached above, so where am I wrong? In the framing of my scenario or something else?

Thanks",statistics
nhsopj,1621604128.0,[Q] Do resampling and exact tests control/ for false positives in multiple comparisons?,"I was reading the following article, when I encountered this:

>\[...\] There are other methods for controlling the probability of false results when doing multiple comparisons, including familywise error rate methods (e.g., Holland and Copenhaver, 1987), false discovery rate methods (e.g., Benjamini and Hochberg, 1995), resampling methods (jackknifing, bootstrapping— e.g., Efron, 1981), and permutation tests (i.e., exact tests—e.g., Gill, 2007).

[https://dx.doi.org/10.3389/fpsyg.2015.00223](https://dx.doi.org/10.3389/fpsyg.2015.00223) page 3 (box note).

I never heard of using the aforementioned procedures for controlling false results in the multiple comparisons situation. I do know that sometimes we do control the FDR, FWER (Bonferroni, Holm), and use specific tests, like Scheffé, Dunnet, etc.

How can these procedures control de false positive rate in multiple comparisons? If they do, of course.

Thanks",statistics
nhrts1,1621601708.0,[Q] What sports postseason has the most unpredictable results?,"Edit: I’m talking about the big 4 USA sports leagues. NHL,NBA, MLB, and NFL

What would be the most random sports postseason?

What playoffs do lower seeds constantly beat higher seeds? We know in tournaments typically the higher the difference between the seeds between two team gets, the better chance the high seed has to beat their matchup. While this is true, I feel like in the NHL it just about does not matter.

Many times the best team in the league bows out in the first round or second round sometimes. Rarely ever can you predict an NHL playoff going according to the regular season. Good teams can get worse and bad teams can get good. More years than not the team that wins the cup is kind of unexpected. Good teams no doubt win but it’s like they changed when the playoffs started.

If anyone could get an answer to this thatd be great!  I love the NHL and all sports in general but it seems like NHL playoffs just about have no way of predicting the winner.

Just a random note: during the regular season for NHL teams the best team in the league in the last 30 years has only won the Stanley cup 8 times",statistics
nhq1jx,1621595883.0,[Q] How does one compute the log probability of arbitrary models?,"I'm wondering whether there is a method of computing the log probability of observing a value from an arbitrary model. (Apologies in advance, I don't have a good background in statistics, but rather a background in probabilistic programming and programming languages. The wording I'm using and questions I'm asking may therefore be silly).


To elaborate - it's relatively easy to compute the log probability of observing a given value from a primitive distribution. In probabilistic programming languages, there exist functions for doing so, for example:

    normal(0.0, 1.0).pdf(x)

In more complex hierarchical models, we may sample from many distributions, and the output data of our model will not result from a primitive distribution. For example, where we sample from two normal distributions and add these samples together:


    def model():
      x ~ normal 0.0 1.0
      y ~ normal 3.0 1.0
      return (x + y)

In the situation where we want to condition some data against the result of this model, is it possible to compute the log probability of this somehow?",statistics
nhooh6,1621590551.0,[E] Is Introduction to Mathematical Statistics (Hogg/Craig) supposed to be hard?,"Hi all,

I am self-learning using the Hogg/Craig mathematical statistics textbook. It's challenging, but I'm understanding 98% of the subject material, and I can get most of the questions right.

One of my worries is that I find the practice questions quite challenging, and I often have to look at the answers - I can get most of the ""application"" questions right, but often regarding the proof-esque questions I get stuck, and give up after 45+ minutes of trying. I understand the answers to the questions, and often have ""why didn't I think of that??!"" moments, but sometimes the answers are stuff that I think I might never would have come up with.

I'm also in grade 10. I know calculus, important parts of multivariable calculus, and linear algebra. What I'm wondering is - *is this textbook supposed to be that hard for someone using it for a statistics course in university? Or does most of my difficulty come from the fact that I may not have formal training in these subject matters?*

Also, a follow up, because I'm getting a ton of imposter syndrome from trying this textbook - does the fact that I'm struggling with the questions this much mean my learning is ""shallow""?

Thanks a bunch!

A",statistics
nho4jb,1621588224.0,[Q] Advice for building a strong profile as a Statistics grad student,"I will be starting my M.S. in Statistics this fall and plan to start applying for internship positions by the end of the year. I wanted to utilise my time before grad school to work on my profile.
What kind of and how many skills/projects/papers should I include in my profile to be a strong candidate for internships as an analyst in health, finance or chemical industry?",statistics
nhgg23,1621559297.0,[Q] PhD programs which lean more towards modern/applied methods vs theory heavy?,"Hello all, I’m currently a rising junior statistics Major at my university. I have really come to love my stats classes, and have really liked getting the classical foundation of probability, inference, and regression. I’m also looking forward to my Bayesian stats and time series courses. And enjoyed math in general as i like math.

While I do like the classical stats, I want to go more into the data science side, as this is my interest for the future. While I’ve enjoyed classical regression analysis, and see it as a great foundation for me, I’ve really seen myself get interested in statistical learning, and more into predictive modeling with modern methods, ie machine learning. (ISLR has also been a fascinating read thus far)

Aside from my classes, I’ve been fortunate enough to have professors have trust in me to work alongside them in research, and have been on two projects in the text analytics space doing sentiment analyses and LDA topic modeling. In my research I’ve realized I really like working with unstructured text, and use statistical learning methods to make sense of unstructured data and to quantify text. I like unsupervised learning a lot as well.

Through research I’ve realized I want to pursue graduate school, and maybe even a PhD, but I keep reading how theory based some of these stats phd programs are.

Are there phd programs in stats which lean more on the data science, applied stats side? Where I could do work with nlp? Or is every stats phd program tons of theory and working on super abstract mathematical topics like likelihood theory etc.

I don’t want to do a data science program, because I’ve heard many data science grad programs can be just titles and have watered down courses. I want to do a stats phd, or MS at least, but don’t want to delve too much into theory.

Any suggestions?",statistics
nhfai0,1621555551.0,[Q] Interrupted Time Series analysis with 2 constant Variable,"Hello Statisticians!

I am currently working on a study where I am analyzing Time series data for 2 groups of people before and after covid (Using the date Cali started lockdowns as the specific date). I am wondering if anyone had a statistical test where I could compare these two groups change before and after covid. I currently have them graphed on the same graph which hints that there may be a difference, but do not know what test to use to definitively say. I have tried to use an Interrupted time series  with the standard equation: Yt=β0 +β1T+β2Xt + β3TXt  , but am unsure how to manipulate it to add the two groups as constant variables. Any help would be amazing thank you!!",statistics
nhdam3,1621549505.0,[Q] How do I interpret these results?,"Spearmans rho = -0.107
P-value= 0.378

what do they show about the correlation between the two variables? I need to interpret these for an academic report.",statistics
nh9j2a,1621539783.0,[Q] What does it mean when the prediction interval is too wide to the point it's useless?,"Hello!

I am using quantile random forest to get the mean prediction and 95% prediction interval. I used quantile 0.025 and 0.975 to get the lower and upper prediction interval.
The mean prediction that can be like a point estimation is close to accurate but the prediction interval, especially the upper limit is way too high, to the point that it's useless.
If I just get the 0.5 quantile, the model seems like it's performing well but for my project, I need prediction interval as well.

Can you please tell me what can cause such a wide prediction interval and is there a way to fix that?

Thanks!",statistics
nh8osn,1621537671.0,[E] What do you guys think of this curriculum from an undergrad degree in Statistics?,"Hello! I'm thinking about getting a Bachelor's degree in Statistics, and I'm wondering if the curriculum below will be enough to give me a good knowledge of the field.

I'm not in the US, so I translated the names listed from my country's language. If any name seems weird, please let me know.

Here it is:

* Calculus I
* Analytic Geometry and Vectors
* Calculus II
* Calculus III
* Linear Algebra
* Computer Algorithms and Programming
* Notions of Statistics
* Statistics Laboratory
* R
* Probability I
* Probability II
* Database Manipulation
* Inference
* Scientific Method and Research Techniques
* Sampling Techniques
* Stochastic Processes
* Computing Applied to Statistics
* Time Series
* Regression Analysis
* Planning and Research
* Bayesian Inference
* Statistical Consulting I
* Discrete Data Analysis
* Methods in Multivariate Analysis
* Statistical Consulting II
* Suplementary Math
* Numerical Methods
* Numerical Analysis I

Beyond that there is a bunch of electives to be chosen among subjects like computer science, biology, engineering, data science, math...

What do you guys think?

edit: so I really thought I would hear I would need more CS, but it seems like what is really lacking is math. That was a huge insight. Also, a degree is probably not enough. I appreciate all the answers!",statistics
nh7iam,1621534751.0,[D] miscellaneous theorems used in machine learning,"I am trying to learn more about the background of machine learning and came across the following theorems:

1) the universal consistency theorem (i have heard of the universal aproximation theorem, but not of the universal consistency theorem)

2) the cover-heart theorem (i have heard of something called ""cover's effect"", which talks about how non-linearly sepperable patterns tend to become linearly sepperable when projected into higher dimensions ... is the cover-heart theorem related?)

3) stone's theorem (i have heard of something called the weistrass-stone theorem, which talks about how polynomials can be used to aproximate almost any function, is the weistrass-stone theorem related to this?)

Can someone please help me better understand these?

Thanks",statistics
nh6wc2,1621533322.0,[Q] What’s gone wrong with my Linear Discriminant Analysis (LDA)?,"So I have 4 groups, each with 3 dependent variables (vectors), and different sample sizes in each group.

I firstly performed a MANOVA, which involved calculating the matrices for the sum of squares between (E) and within (H), and found an F value more than the critical value, so I know there’s a significance difference in the variables across my groups. What I want to be able to explore is which variables seem to be the main differences between groups.

So, my next step was trying to do LDA. I already had the matrices so just needed to calculate the eigenvalues of the matrix (E^-1 H).

This gave me 3 eigenvalues and eigenvectors, which is fine, and I chose to keep the first 2.

The strange thing is, my eigenvectors were:

v1=(0.999, 0.001, 0.002) and v2=(-0.999, 0.001, 0.001)

So the “x component” of the eigenvectors seems to dominate.

When I then project my original data in terms of the first two Linear Discriminants (v1 and v2), and plot LD 1 vs LD 2, all the data lies on a line. I expected the groups to break out into different areas of the plot, but instead they all lie together. It’s almost like it’s plotted in 1D even though I’m making a 2D plot. Any ideas what’s gone wrong here?",statistics
nh2pu0,1621523358.0,[D] Trying to be a Millionaire,"So out of boredom I started doing a statistical breakdown of the drawn mega millions numbers since they last changed their drawing matrix. I found great information on frequencies of drawn numbers during all drawings but what I'd be really interested in seeing is the frequency with which the numbers between 1-66 were the first number, the numbers 2-67 were the second number, 3-68 were the third number, 4-69 were the fourth, and 5-70 were the fifth. I could sift through all the drawn number combinations since Oct 2017 (371 drawings) and I know I said I was bored but I'M NOT THAT BORED.  Does anyone have this info or know where it can be found? The mega millions websites don't break it down that way and I can't find any other website that has that info.",statistics
nh2mn8,1621523151.0,[EDUCATION] CMU Professor (me) INTUITIVELY explains Type 1 vs Type 2 Errors in Statistics (False Positives and False Negatives),http://jeffgalak.com/datademystified/index.php/2021/05/20/type-1-and-type-2-error-explained-false-positives-vs-false-netagtives/,statistics
nh2da6,1621522568.0,[Q] Correlation in non independent data setting (longitudinal study),"Is the second time I have been asked to compute correlation between two variables in a correlated data setting. So is time to solve this out. Let us assume that we want to calculate “correlation” between variables X and Y where we have repeated measures of both variables for each subject in the study, and there are several subjects in the study (more than 10). The number of repeated measures is not constant but can vary from 2 to 10.

I have been thinking on how a mixed effect model can be used to address this. Something like

`y~x|time/subject`

could be a possibility but not sure",statistics
nh26ee,1621522115.0,[Q] Cross-validation for mediation models estimated with bootstrapping?,"Does it make sense to perform cross-validation on mediation models that were estimated using bootstrapping (with Hayes' Process macro)?

I know that the two techniques have a different purpose, but when I look online, I find many articles/posts comparing their performance and how one may perform better than the other.

Since bootstrapping already uses resampling, will performing cross-validation add any value?

Additionally, since direct effects are not (by default) estimated using bootstrapping in Hayes' Process macro, should I use bootstrapping for all coefficient estimates?

Thanks in advance!",statistics
nh19ed,1621519868.0,[D] Accumulated Local Effects,"I recently came across a newer technique called ""accumulated local effects"", that attempts to explain the effect of predictor variables on the response variable :

https://docs.seldon.io/projects/alibi/en/stable/methods/ALE.html

Has anyone tried using this method on real data? Did you find it useful? Any stories/anecdotes/experiences/comments/reviews you would be willing to share regaeding this method?",statistics
ngz434,1621514368.0,"[Question] [Research] Can I explain 3 variables PSM as ""predictive""?","Background: clinical research chart reviews looking back at preoperative variables, intraoperative interventions (Blood pressure, drug dosages) and post-operative outcomes. Stratified by 2 groups (conscious vs general anesthesia). Biostats analysis done by our statistician who recently left. He did a 2:1 propensity score match for the 2 types of anesthesia and using preop variables.

Results: Significant differences found for blood pressure and 1 drug between 2 anesthesia groups. Significant differences found for hospital length of stay and blood transfusions between 2 anesthesia groups.

Question: Is there a way for me to connect Changes in BP/drugs to outcomes? eg, Conscious anesthesia is more likely to have longer hospital length of stay and this may be explained by higher blood pressure during surgery.",statistics
ngwjyr,1621506342.0,[Q] How can I determine the required sample size for a qualitative interview?,I read only that there is not a lot of consensus with regards to the required sample size for interviews. How can I figure out how large my sample should be and what kind of power analysis could I do for qualitative data?,statistics
ngw9ah,1621505272.0,[Q] Masters with low undergrad gpa?,"I graduated from FSU with a bs in statistics in december, I immediately got a pretty well paying job out of sheer luck I feel (around 85k after bonuses).

The company offered to pay for me to do a part time masters starting next spring, the issue is that my undergrad gpa is incredibly low at 2.6. I did have some serious health issues throughout college since I have Crohn's and did not have insurance for about a 5 year period, I just kinda marched through the pain and constant bathroom use for those years, which was incrediblly difficult for me, but I'm not sure if any college would even care.

I really do believe I can finish coursework now since I have my disease under control and I'm fully in remission. What are my chances of getting into a masters program with 1 year of work experience? Is there anything I can do to help my case when talking to graduate admissions in the mean time?",statistics
nglvl2,1621470728.0,"[Q] Does ""If a minimal sufficient statistic exists, then any complete statistic is also a minimal sufficient statistic"" mean to say ""any complete sufficient statistic"" instead?","p42 in Lehmann and Casella's TPE says

> Since complete sufﬁcient statistics are particularly effective in reducing the data, it is not surprising that a **complete sufﬁcient** statistic is always minimal. Proofs are
given in Lehmann and Scheff´e (1950), Bahadur (1957), and Schervish (1995); see
also Problem 6.29.

p289 In Casella and Berger's Statistical Inference says

> Theorem 6.2.28  If a minimal sufficient statistic exists, then any **complete** statistic is also  a minimal sufficient statistic.

Does the theorem in the second book mean to say ""any complete **sufficient** statistic is also  a minimal sufficient statistic"" instead?

Thanks.",statistics
ngk1gg,1621465619.0,[Q] Question about determining statistical significance,"In my free time lately I've been messing around with the idea of algotrading, basically using an algorithm to find an investing strategy. With that being said, establishing statistical significance for a given strategy is paramount to ensure that your strategy is actually legit and not merely due to chance, especially when you are running hundreds of different trials on various parameters.

So my question is as follows: If a stock over the last year has increased in price say 195 days out of 365 and I have found a potential strategy that says after some indicators have been reached, the stock in the past year has increased 36 days out of a total of 60 days where these indicators were met. How would I go about determining whether this would be statistically significant or not? I've been researching the p-value and the Bonferroni correction which I know I need to make use of, but I am struggling to find the exact method by which I should calculate these things, especially when my desired results are binary (price increases/price does not increase)

Thanks!",statistics
ngjaa6,1621463639.0,[E] Will Do R Coding Free For Practice,"Hi,

I'm a rising Sophomore in college who wants to major in Statistics. I'm looking to gain more real-world experience in using R after taking a few R classes in my first year. I think I have the skills necessary to accomplish most basic tasks, and want to learn more (using various online sources) to complete more difficult tasks. If anyone has some coding they need done in R, you can message me and I'd love to work on it for you to gain some experience. Obviously, I would do this for free as the goal is to improve my skills.

Thanks!",statistics
ngfl65,1621454690.0,[Q] Help in understanding the difference between PCA and EFA...,"I'm a grad student of psych trying to grasp how Principle Component Analysis (PCA) and Exploratory Factor Analysis (EFA) are different and having a hard time. I've read definitions online and watched videos of people explaining it but am still struggling.

I know both are used to identify variables that cluster together in a data set, but don't see how to are distinct from there. I would greatly appreciate help with this.",statistics
ngfbdp,1621454013.0,[Q] Is comparing the prevalence of something to the size of a sub population useful?,"My apologies if this isn’t the right space to ask this question and that it is likely very basic.

I’ll start with an example first as I don’t have the exact language to clearly state my question.

Example: 30% of traffic stops were of black residents despite only representing 19% of the population.

Question: Is this a useful comparison? The comparison seems to say that, because blacks represent 19% of a population and they represent 30% of the traffic stops, the traffic stops should be lower than 30%. So does that mean 19% would be acceptable? Less than 19%? Why does the percentage a sub population holds within the whole indicate whether something is acceptable or not? What’s the relationship that I’m missing?

Thanks for your help.

Edit: Thanks all for your help with this! And noted, I’ll be more careful with my language next time.",statistics
nge69a,1621451163.0,[Q] Which of these statistical tests is the most powerful?,"Matched pairs t-test
Independent samples t-test
ANOVA
Regression
Mann-Whitney U test
Kolmogorov Smirnoff test

It is going to be the one that has each individual serve as their own control, so would it be the matched pairs t-test?",statistics
ngd37x,1621448498.0,[Q] [E] What range of schools are realistic for a PhD program in statistics,"Long story short, I wasn't a really serious student until later in my undergraduate career, and I found math my Senior year. I'm currently in a MSc. program in a top 100 math program, and am finding myself intrigued in Statistics (and Applied Math) and wish to pursue further in a PhD setting. What range of PhD programs would be accessible? Also, is it necessary to take the Math GRE?

Below is a break down of my profile.

&#x200B;

**Student Type:** Domestic student

**Applying for:** Statistics PHD Fall 2022

**Undergrad:** Relatively Unknown Liberal Arts

**Major:** Biochemistry and Economics, **Minor:** Mathematics

**GPA:** 3.7 (Biochemistry 3.8, Economics 3.85)

**Master's**: Mathematics

**GPA:** 3.99 (Over 11 Courses for the Past School Year/Summer)

**Undergrad Math Courses:** Calc 2/3 (A-/A-), Linear Algebra (A), Intro Statistics (A), Intro to Proof (A-), Abstract Algebra 1 (A), Complex Analysis (A), Abstract Linear Algebra (A-), Real Analysis 1 (A), Real Analysis 2 (A), Topology (A-), Numerical Analysis (A), Numerical Linear Algebra (A+), Probability Theory (A+), Mathematical Statistics (A+), Differential Geometry (A), Mathematics of Data Science (A), Topological Data Analysis (A).

**Graduate Math Courses:** Abstract Algebra 1 (A-), Measure Theory (A-), Graduate Complex Analysis (A+), Uncertainty Quantification (A), Markov Chains and Mixing Times (A).

***Remark:*** The A+ are quirks of my current institution, they do not impact GPA, but serve as indicators of maintaining above a 98%/strength in coursework

**Taking in Summer:** Algorithms, Intro to ML

**Taking in Fall:** Graduate Algorithms, Graduate Numerical Linear Algebra, Graduate Numerical PDE, PDE 1

**Research:** Starting this summer, part of Master's Thesis. Focused on differential equations on Fractals.

**GRE:** 170Q, 164V, 6W

&#x200B;

**Interests:** Use of Harmonic Analysis for nonparameteric estimation techniques, Machine Learning on Manifolds, General Stochastic Processes (I'm very interested on the theory side in general)",statistics
ngcni9,1621447403.0,"[Q] what's the difference between a ""confidence level"" and a ""tolerance rate""?","here's what I read about tolerance level but doesn't make complete sense to me: ""The tolerance rate is the rate of exceptions that examiners would like to demonstrate is not exceeded in the population. Examiners should select a tolerance rate at the outset of sampling, after defining the population. Tolerance rates are typically less than 10 percent. For a given confidence level, a lower tolerance rate results in larger sample sizes.""

i don't get how tolerance rate is different from confidence level?

Thanks in advance for any help",statistics
ngcm8e,1621447317.0,[Q] How to select appropriate linear regression equation transformation in case of violation of linearity assumption?,"Looking at  the Residuals vs Predicted plots of my models, it becomes apparent that the models do not fulfill the assumption of linearity. Most articles  I found recommend applying some sort of transformation to the model, adding a polynomial, interaction or logarithmic term to independent variable, or transforming the dependent variable. But I am having real trouble understanding which transformation is appropriate for which type of relationship observed on Residuals vs Predicted plots, and to which variables should I apply these transformations ( I have about 15 independent variables). One of the models resemble a line with negative slope, other starts out as a line with a slope of zero but has two humps above y=0 in the middle and then turns into a line with negative slope. Another model once again starts out as a line then exhibits a hump below y=0 but ends as something which looks like cube root function.",statistics
ngc8y0,1621446397.0,[Q] What test should I use if the sample standard deviation is known and the sample is small (<20)?,"I know that z-tests are used if the sample standard deviation is known and that t-tests are used if the sample is small, but what if both the sample is small and the standard deviation is known, which test would I use then?",statistics
ng9s3h,1621440358.0,[D] life table vs survival analysis,"https://en.m.wikipedia.org/wiki/Life_table

I was looking at this article on how actuaries use life tables - is this not closely related to the kaplan meier method from survival analysis?",statistics
ng9lkc,1621439930.0,[Question] What are the best/most up-to-date methods of causal analysis with time series data?,"Hello! This might not be a very 'correct' question given that much depends on the nature of the data, but what are the best/most up-to-date methods of causal analysis with time series data?

I've only had an introduction to econometrics and therefore have only been exposed to Granger causality but since the method seems quite old, I am wondering if there are any newer and potentially better methods of inferring causality. I would be grateful if anybody could just point me to the method itself or some papers using it - I can figure out the rest.

Regarding my RQ, I am particularly interested in analysing economic growth, mostly GDP per capita and other similar variables as the dependents, using varying lengths of time series.

Apologies if anything is not clear enough and thank you in advance!",statistics
ng8i64,1621437288.0,"[Q] I have a dataset of some groups which answered questions, what statistic should I use?","Thank you for reading.

I have a dataset where some people answered 10 questions, with a value from 1 to 6  (integer) depending on the agreement of the statement. Each person has 4 categories: gender, age range, profession and years of experience.

I want to check for each question, if there are substantial differences between each group, the thing is that there are many combinations possible since each person belongs to 4 categories.

What statistical test should I use?

I have done T-tests between each group of each category, pair by pair. Is this correct? Should I perform other kind of test like ANOVA?

&#x200B;

Thank you so much!",statistics
ng86zs,1621436558.0,[D] inductive biases in machine learning,"Can someone please try to explain the concept and role of ""inductive biases"" in machine learning? Are inductive biases very basic and general assumptions  required for machine learning algorithms to work?

E.g. birds of the same flock fly together = unseen data can be predicted based on how similar it is compared to seen data?",statistics
ng7rk9,1621435524.0,[D] is the following statement about statstics correct?,"A friend told me that all analysis in statistics (including machine learning algorithms (supervised learning, unsupervised learning, reinforcement learning) , hypothesis testing, bayesian methods, regression models, survey sampling, time series, clustering, etc) can either be considered as causal analysis and counterfactual analysis.

Is this statement somewhat correct?",statistics
ng7fyp,1621434765.0,[Q] How to calculate effect size,"I am trying to calculate the effect size of exercise on depression. So I have 2 groups (control and intervention) in an RCT setting. I have both mean values and standard deviation of groups at T0 (baseline) and Tf (final). The number of participants in each group is different due to dropouts etc., hence the variations.

My question is how should I calculate an effect size out of this setting? Intuitively, I feel like I need to standardize every mean value first, calculate SMD (standardized mean difference) between Tf and T0 for each group, and compare (take SMD again), this time for the difference between groups. However, I am not sure how should I take the variance into account. Should I just use the variance to standardized each value of the group? But, how I am going to estimate the variance of the effect size?",statistics
ng7dmq,1621434612.0,[Q] How to explain the change in significance due to the addition of an interaction variable?,"I am currently working on my dissertation for my Master in Finance. Put simply, I am running panel data regressions to analyze the relationship between a firm's valuation and their ESG score (environmental, social, governance score) in Stata.

The simple regression form without an interaction variable looks like this:
Value = b1\*ESG + controls, using country and year fixed effects, clustering for firm standard errors.

The ESG coefficient seems to be strongly insignificant.

When I add an interaction effect with a dummy variable (of a control variable) that represents a specific industry, my regression looks as follow:
Value = b1\*ESG + industry\_x\*ESG + controls, using the same country/year fixed effects and clustering.

The results indicate that both the ESG variable (p=0.016) and the interaction variable (p=0.004) turn out to be significant. How can it be explained that without this interaction, the ESG variable seems to be insignificant, while the ESG variable becomes significant with the addition of the interaction variable?

Thank you in advance!",statistics
ng6eq9,1621432268.0,[Q] Missing Subject Index in Mathematical Statistics Vol II by Bickel and Doksum,"The ebook for the following book that I read misses the entire Subject Index and Author Index from p443 to p465

> Mathematical Statistics Volume II, By Peter J. Bickel, Kjell A. Doksum 2016 ISBN 9781498722681

I was wondering if someone by chance could scan the following four pages in Subject Index:

- https://books.google.com/books?id=MgXeDwAAQBAJ&pg=PA444  for subject index from C to E
- https://books.google.com/books?id=MgXeDwAAQBAJ&pg=PA446  for subject index from G to ...
- https://books.google.com/books?id=MgXeDwAAQBAJ&pg=PA447  for subject index from ... to L
- https://books.google.com/books?id=MgXeDwAAQBAJ&pg=PA450  for subject index from N to R

?

I have tried to find out if the index parts are freely available by the publisher or the author websites.

Thank you so much in advance!",statistics
ng4qmw,1621428064.0,[Q] is there any reason to use Phi over proportion tests?,"Hello all, I am currently learning about different tests of association and ran across Phi for testing two nominal dichotomous variables. I was curious however in what sense this might be applicable. Given that a proportion test seems more readily interpretable when it comes to  reporting about two dichotomous variables (e.g., testing the proportion of males who smoke to women who smoke) and that outcomes in the statistical significance do not differ between these two tests (when you use Chi-Square to test for significance with Phi), when would one favor using Phi in a practical context?",statistics
ng46of,1621426508.0,[Q] Are Linear Regression assumptions ever satisfied? And what do you do if they aren't?,"I've read that linear regression requires meeting a number of assumptions (I think 4 or 5 depending on where you look). Do most researchers ever satisfy these and, if not, does that make their results and p values misleading? Because, in my experience, these are rarely ever completely satisfied. And transformations to try and satisfy them makes the results harder to interpret (for example, if you are doing a log transformation, what does it mean that this independent variable is significant with respect to the log of the dependent variable?). So what would be the best way to do this?

Here is a link to the assumptions I'm talking about: [https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R5\_Correlation-Regression/R5\_Correlation-Regression4.html](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R5_Correlation-Regression/R5_Correlation-Regression4.html)",statistics
ng432e,1621426215.0,"[Q] Interrater agreement (ICC(2,1)) on a set of (more or less) correlated items?","Hi,
I'm trying to test, whether my subject participants (the raters) rate the personality of a fictional character similarly - think of a personality profile - , on a variety of items (the cases). I am using an ICC(2,1), absolute agreement, as I would like to generalize to other raters from the same population (i.e., the general population).


In my analysis, I noticed that the ICC always decreased wenn less items are rated.

Lets say my 50 raters first rated the character on how important 10 social values are to them -- the ICC was quite good!


But when the 50 raters rated the assumed health of the character on 2 items (mental health and physica health), the ICC was close to zero.

In the latter case, both variables were highly correlated, which might habe to do with it.

So, my questions are:

1. Is it correct that a lower number of cases (or a too low number) is detrimental to the ICC.

2. Is it correct that a high intercorrelation between items (cases) has negative effects on the ICC

3. If that is the case, would it make sense to create mean scores of highly correlated variables and then use an ICC(2,k)? (though, in my example, this would not work as it would leave me with a single item (case), which the ICC does not compute for.

Thanks for your help!",statistics
ng3ved,1621425616.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
ng3cju,1621423960.0,[Q] Strict stationarity with dependent random variables,"Strict stationarity means that the joint distribution of any subset of random variables within a time-series is time-invariant.
Can you think of any practical (or real-life) example where this applies when the random variables are dependent ?",statistics
ng37p4,1621423525.0,"[Q] I want to do a cluster anlysis on sets of numbers, while taking into account fluctuations within those sets. Is there something more advanced than using variability?","I have sets of numbers, the sets will be clustered, not the numbers.

If I have for example four sets:

4 4 4 4; 7 3 4 8; 6 2 2 6; 6 6 5 5;

(the real sets are much larger in size and number, and range 1-10, with one decimal.)

Now likely the first and third set would be put together, and the second and last set. This is based off their means, they are the same for 1 and 3, and 2 and 4.

However, and this is my question, I'd also like to take into account the fluctuations that occur within the sets, in addition to the means. In that case sets 2 and 3 will be put close together in the analysis, since they both have the same drop from the first to the second number, and the same rise from the third to fourth number, making a U shape, and their means are somewhat close to each other.

Taking something like variablity to do this works somewhat, but different trends in the sets of numbers could lead to the same variability. For example another set, 2, 6, 6, 2; would still be in the same cluster as 6, 2, 2, 6; this is because their means and variability are the same, even though the sets are the exact opposite of each other. So by using variablity there is too much loss of information. A lot more interesting interpretation of the results could be done if similar fluctuations at similar points in the dataset are grouped together.

So, is there any way to do this?",statistics
ng2fm2,1621421109.0,[Q] Does Basu's Theorem require sufficiency or minimal sufficiency?,"p287 In Casella and Berger's Statistical Inference says

> Theorem 6.2.24  (Basu's Theorem)  If  T(X) is a complete and minimal suffi­cient statistic, then T(X) is independent of every  ancillary  statistic.

P42 in Lehmann and Casella's TPE says

> Theorem 6.21 (Basu’s Theorem) If T is a complete sufﬁcient statistic for the family P = {P_θ , θ ∈ Omega } , then any ancillary statistic V is independent of T .

Is ""minimal"" required? Thanks.",statistics
nftcwu,1621390905.0,Glmer and convergence [Q],"Would there be any problems with running a glmer model with logRT instead of just RT, i.e. glmer(logRT \~ )?

I tried to use just RT but it basically gave me convergence issues for all models, even the simpler ones. logRT, on the other hand, produced working models that pass allfit and all. Is it just a problem for interpretability or is there any reason why one would be very cautious about doing this?",statistics
nfsxs4,1621389741.0,[Question] Why is qualitative research not always considered as statistics?,"I was in an argument with my sister where she was telling me that qualitative research is not statistics. She was saying that statistics requires quantitative data. Now I am a statistics graduate and I know that you can perform statistical analysis on qualitative data so that isn't exactly true. But to my surprise from some research, there is something called qualitative research that may use no numbers and ""is not part of statistical analysis.""

I thought the definition of statistics was the analyzation of data, so therefore this should be considered statistics in a way. But my sister insists it isn't, and I have found multiple things on the web saying it isn't considered statistical analysis. Further research also told me that this form of ""qualitative research"" can't be generalized to a population, but only be used to explain things about the sample. So I have a couple questions.

1. Why isn't this considered statistics?
2. If it can't be used to generalize to a population, what questions could it possibly answer?
3. How do they analyze data with this method without using numbers or statistics?",statistics
nfr0s5,1621384364.0,[Q] Inferring CV (or even just a meaningful analysis) of an unknown variable by comparing component CVs.,"Hi, I am working on a project where I am attempting to figure out some QC criteria for an end product where in the process I can measure 3 out of 4 variables during manufacture. The variable I am attempting to analyze is the most crucial for final consistency but it is only 2.3% of the total mass so even with a low variance in the other components it's actual consistency isn't that apparent from the final measurements.

I only took a single statistics course in college and honestly don't remember much so if anyone has insight into how to combine component CVs/final result to infer/analyze an unknown component it would be much appreciated. Thanks!",statistics
nfozil,1621378797.0,[Q] How to find statistical significance of more than two variables in a/b/b tests?," I am looking for some advice on how to calculate statistical significance of more than two values - it will basically be an a/b test but more like a/b/b or a/b/b/b etc. So, the control will be compared against multiple versions to find which creates the most of a ""desired"" result.

I came across this repo on one-way and two-way anova, but I don't know if it is the correct way to get my desired result: [https://github.com/mljs/anova](https://github.com/mljs/anova)

Any advice would be appreciated.",statistics
nfkwdw,1621368727.0,[Q] Promax/Varimax Rotation w/ML FA,"Is there a minimum threshold of item correlation at which I should use Promax rotation? I've been reading every piece of literature I can find on this topic today, and I still don't have a citeable justification either way. I'm doing a confirmatory factor analysis using Max Likelihood (and a couple of others) on data that is moderately correlated (.50-ish) inter-item.",statistics
nfjzsj,1621366590.0,[C] MA in Statistics Job Prospects,"I'm considering doing a 4+1 degree (Mathematics BS + Statistics MA) at my school, Binghamton university. I have almost a 4.0 GPA (3.98 right now) and am really far ahead in the curriculum, I'm taking Grad level math classes in my junior year. I'm wondering how good my chances are of landing a job after graduating with the MA. Do you think a job is ""guaranteed"" for me after graduating with degree and a high GPA? Also I will likely do a few interships before I graduate. Also for reference I live in the northeast.

I guess my main question is: how valuable is this degree and skillset? Is the job market saturated? I know stats is predicted to grow a tooooon by the BLS, so that makes me think I'd be ""guaranteed"" a job. Is this an accurate impression?",statistics
nffkel,1621356312.0,[Q] How To Choose K for Hierarchical Clustering?,"I'm beginning working on my M.S. Thesis for a lab, currently I am conducting a preliminary HClust in order to replicate what this lab has already done in regards to their data.

From what I learned in my coursework, to determine where to cut the dendrogram requires estimating K and there are many ways to do so,  in particular I chose to use summary indexes (CH, Hartigan, KL, and Silhouette) as well as Gap Statistics.

However these best estimates for K vary by a bit, CH and Hartigan estimated K = 20 while KL and Silhouette estimated K = 2. The Gap Statistics method estimated K = 5.

**Any recommendations on how to choose K?**

The lab performed an HClust using distance matrices generated from WGS results of antimicrobial-resistant bacterial strains. I have already sent emails asking them about how they came upon the number of clusters that they did, but their explanation didn't make much sense to me as they explained they clustered any isolates with at most 15 SNPs of dissimilarity.

Knowing that I want to select K = 20, but I realize that decision comes from bias and isn't methodical or objective in anyway. In fact I wonder whether or not they misunderstood what they were doing and selected K = 15 thinking that means HClust would cluster together isolates with a dissimilarity of <= 15.",statistics
nfbvjv,1621347499.0,[Q]How to compare two datasets in R,"Very basic question, but I'm very new to R programming.

I'm writing my thesis and need to compare datasets with one another. I will for example use the dataset of Transparency International (TI) called Corruption Perception Index (CPI) and compare it with the dataset Human Development Index (HDI) from United Nations Development Programm (UNDP). I also need to compare other indexes the other hypothesis. All of them will be compared with the Corruption Perception Index from Transparency International.

I am very lost with this statistics programm so any tips about how to even start with this would be greatly apreciated. Thanks !",statistics
nf9g9r,1621340982.0,"[E] I need recommendations for books on statistics and probability. I can purchase a maximum of two books. I'm opting for a PhD in Machine Learning, and need to brush my abilities in Stats and Probability.","I've studied these before at undergrad, but seem to have forgotten some of it over the last 6 years.

The book which I'd prefer is which would provide me should conceptual understanding first before diving into the notation and mathematics.

Due to financial constraints I can purchase a maximum of two books only. I have understanding of Machine Learning, but I'll need books that'll help me understand research papers, and be able to write my own. I'd prefer the book which uses the most common notations, particularly for Bayesian probability.

PS: I'm opting for a PhD in Machine Learning. I did my masters way back, haven't been actively involved in ML, and I need to brush up things. I prefer reading over watching tutorials/lectures.",statistics
nf7dsg,1621334529.0,[E] The Book of statistical proofs,"Hi all, I just stumbled upon this [incredible book](https://statproofbook.github.io/) which holds a very large number of proofs and definitions. I thought that was interesting and potentially useful.

Cheers",statistics
nf42a6,1621322239.0,Include intercept or not in Bayesian Linear Regression? [Question],"I'm running a very simple Bayesian linear model with categorical predictors as follows:

y \~ dnorm(mu, sigma)

mu \~ a + bx\_\[i\]

a \~ dnorm(0,10)

bx\_\[i\] \~ dnorm(2,1)

sigma \~ dexp(1)

Where x is a categorical variable with 4 categories, which I indexed 1 through 4 in the model. There is one b parameter for each category, if that was not clear from above. I'm debating whether to include the intercept a or not in this model; when I do I get standard deviation values for each b parameter which are quite larger than when I do not include the intercept. To be honest I'm also a little confused about the meaning of the intercept in this case with the categorical variables, and I know with these models some people use an intercept while some also don't (see last couple models [https://www.samples-of-thoughts.com/projects/statistical-rethinking/chapter\_5/chp5-part-three/](https://www.samples-of-thoughts.com/projects/statistical-rethinking/chapter_5/chp5-part-three/)). I would appreciate if maybe someone could help me out, thanks!",statistics
nf0omy,1621310625.0,[D] Does anyone here study Game Theory?,"I have always been curious about game theory, but have been to intimidated to try to learn it. This week, I have decided to try and shake my fear and begin to learn about some basic principles in game theory:

&#x200B;

I am looking at this basic problem in game theory that asks how should the owner of a company split the profits between her and her workers:

&#x200B;

[https://imgur.com/a/aDa5jiE](https://imgur.com/a/aDa5jiE)

&#x200B;

I am having some difficulty in understanding the notations:

&#x200B;

1) "" Formally, a coalitional game is defined as: There is a set N (of n players) and a function and a function v that maps subsets of players to the real numbers: v : 2\^N -> R , where v(""empty set"") = 0""

&#x200B;

a ) Why does "" v : 2\^N ""? Is the point of this expression to show all the possible interactions that can exist between any groups of players?

&#x200B;

b) When considering the ""value function"" (i.e. ""v"") , why does v (""empty set"") = 0? I guess this is an obvious statement, but is it supposed to mean that the potential value of the interaction between ""no players"" (i.e. the empty set) is ""0""?

&#x200B;

2) Now, the problem where the owner of a company split the profits between her and her workers:

&#x200B;

\- The owner is represented by the symbol ""o""

\- There are ""m"" number of workers (w1, w2, w3 ... wm)

\- Each worker contributes an amount ""p"" to the profit

&#x200B;

I am having difficulty understanding how the ""value function"" for this problem is determined:

&#x200B;

The value function for the coalition of players (the coalition is denoted by ""S"") is:

&#x200B;

\- v(S) = mp, if the owner is included in the coalition

\- v(S) = 0, if the owner is not included in the coalition

&#x200B;

My question: How are v(S) = mp and v(S) = 0 initially determined? Or are these values assumed?

&#x200B;

3) In this question, ""m"" is defined both as ""the number of workers"" as well as the cardinality of : S / {o} .

&#x200B;

I have generally heard ""cardinality"" referred to as the ""size of a set"". What exactly does cardinality mean in this question? Are you supposed to be able to compute "" S / {o} ""? Why does ""S / {o}"" = m?

&#x200B;

4) Can someone please walk me through the calculations? Why according to the Shapley values, should the profit be distributed such that: the owner receive ""mp/2"" and each worker receive ""p/2""?

&#x200B;

5) Lastly : Why is this question important? Is the point of this question to show ""the fairest distribution of profits according to contributions""?

&#x200B;

Thanks

&#x200B;

&#x200B;

Source: [https://en.wikipedia.org/wiki/Shapley\_value](https://en.wikipedia.org/wiki/Shapley_value)",statistics
nejiy3,1621266003.0,[Question] Who prefers Bayesian Stats over Frequentist Stats? And Why?," I  just ""found"" Bayesian stats, but dont fully understand the idea yet. I  understood the basics what they are doing and what´s the difference.

Why would you prefer either bayesian or frequentists?

Do you know any good technical textbooks on bayes? (the more math the better :)",statistics
neinkb,1621263923.0,[Q] Stochastic Processes vs Statistical Inference,"I'm considering pursuing a major in statistics and so I need to complete either a course on stochastic processes or statistical inference (using Casella and Berger). Is either one of these courses obviously more useful than the other if my goal is to become a machine learning engineer or data scientist?

The stochastic processes course uses the book 'Introduction to Probability Models' by Sheldon Ross.

Would one of these books be much more difficult/time consuming than the other?",statistics
necq8t,1621247675.0,[q] why calculating quartiles gives different answer depending on the application used?,"So when calculating the third quartile the method I use is (n/4)*3, where n is the amount of data points. If the answer is an integer, I take the mean of that positions data point and the value above.
If its a decimal, I always round up and find that value.

However I'm getting conflicting answers..

My data set is :
37, 43, 43, 44, 44, 46, 46, 47, 47, 47, 47, 48, 51, 52, 53, 53, 54


Doing it with the method above gives 51 as the third quartile. Typing =quartile() on excel gives the answer as 51.
If I type it into my graphical calculator, the answer I get is 51.5?


What's going wrong here??


If I use median and median again, I get 51.5..",statistics
nec16j,1621245269.0,[Q] PCA applicability,"Hello!

 (I posted this in [r/bioinformatics](https://www.reddit.com/r/bioinformatics/) originally - also posting here to get a breadth of opinions. I tried to cross post but the tags weren't compatible :( )

I've got an idea that is centered on using PCA to group genomes based on the frequency of specific genetic features.

I am a complete stats noob, but am aware that the applicability of different techniques is generally dependent on the data set your analysing. With that in mind, are there any things that I should be aware of for general applications of PCA?

For example, from my understanding PCA is commonly used in transcriptomic data analysis to look at differential gene expression, where the dimensions being reduced are the transcript counts for each gene (fyi my use-case isn't transcriptomic, it's just an example). So for this you might have 1000's of genes/features describing perhaps 2-4 samples. Would trying to apply PCA to a set of samples with far fewer features (e.g. 20) be a fundamentally bad idea? Would any issues be easily diagnosable with (e.g.) a scree plot? How many features per sample is the minimum, in your opinion?

In general, are there other things that need to be considered?

Cheers,

Your friendly bioinformatics padawan",statistics
ndy0pi,1621199289.0,[E] Evil Geniuses Presents: Data Analytics and Tech in Esports,"Hey everyone, my name is Sean and I’m an intern at Evil Geniuses (Tier 1 Esports Organization) working with the data and tech team. We will be hosting a workshop this week (5/19 at 11 AM PT / 2 PM ET) focused on the use of data in esports. The two panelists who will be running the workshop are **Soham “valens” Chowdhury** (Head of Data Science) and **Zach Kamran** (Head of Tech and Analytics).

&#x200B;

I've copied the Eventbrite link below; the event is **completely free!** If you have any questions, please don't hesitate to reach out to me via Reddit DM or on Discord (info on the Eventbrite page).

&#x200B;

Eventbrite: [https://www.eventbrite.com/e/data-and-tech-innovation-in-esports-tickets-154295117851](https://www.eventbrite.com/e/data-and-tech-innovation-in-esports-tickets-154295117851)",statistics
ndxw11,1621198923.0,[Q] What tips do you have for successfully making the most of graduate school in statistics?,,statistics
ndvk4b,1621192484.0,"[D] Understanding the relevance and the importance of the ""representor theorem""","I have often seen the ""representor theorem"" mentioned in machine learning, but I have never been able to fully understand the application and relevance of this theorem in machine learning:

https://en.wikipedia.org/wiki/Representer_theorem

https://analyticsindiamag.com/what-is-representer-theorem-in-machine-learning/

Can someone please try to explain this in a simpler way? How is it different from mercer's theorem?

Thanks",statistics
ndrs4p,1621181935.0,[Q] How do you take notes while reading a statistics book?,"Hi!

It's been a year since I finished grad school and it feels like I need a refresher on the concepts. I started reading ISLR and I felt like I need to take notes so that next time I need to refresh on the concepts I can just go through the notes instead of reading the entire book.
The note taking is primarily because of potential future interviews.

Do you guys just do it old school by taking notes in a notebook or do it differently now?
Also, is there anything else I should do in order to prepare notes for interview prep?

Any other advice is welcome.

Thanks!",statistics
ndq8jt,1621177468.0,[Q] ANOVA or Kendall tau-B correlation when reporting on datasets,"I've done a survey, where I've divided participants in age groups and measured their loneliness scores. When analysing the data the ANOVA comes out insignificant, however if I do a Kendall tau-B correlation, between age and score, it is significant. Therefore I'm not sure which one to report and rely on. What to do ?",statistics
ndq1gs,1621176907.0,[Meta] Looking for a quick-reference text.,"I need to put a stats textbook on my  desk that I can pick up and quickly look up fairly general statistics problems. Things like, say, how to do a  chi-squared association test, or a t-test, or what a binomial/beta  distribution looks like, etc. --just  the standard set of foundational problems most people learn in their undergrad (but then forget later) with some examples and enough background to see the main points of the  theory.

A small pocketbook would be ideal; a lean textbook would work. Does anyone out there have a favorite book they'd recommend?

**E:** thanks for the suggestions, but yes, I know about the internet; I'm looking for a reference text. A physical document I can hold in my hands written by a reputable expert.

**E2:** Favourite so far: [https://leanpub.com/openintro-statistics](https://leanpub.com/openintro-statistics)",statistics
ndotf4,1621173226.0,[Q] Changing a tyre turned into a stats problem on my head,"Okay so I have to change a tyre on my car and I realised there's kind of a hidden stats problem here.

For the sake of the stats problem, I must change my tyre within 48 hours and every hour on the hour the weather changes at random and stays that way for an hour. Based on observing the weather I can give it a rating between 0 (very bad) and 10 (very good) and my goal is to have the highest possible chance of changing the tyre in the best possible weather.

For the sake of simplicity, changing the tyre will take exactly one hour, weather forecasts do not exist, and nothing will cause me to become unavailable to change the tyre.

Which stats problem have I stumbled upon? What is the algorithm I should follow? How does the algorithm vary depending on how long I have to change the tyre?

(I know this is overthinking it, I just changed the tyre now but was still interested in the problem I thought up).",statistics
ndoe38,1621171858.0,"[Q] What does ""depend on"" in the likelihood principle corollary mean mathematically?","In Casella's *Statistical Inference*, *6.3.2  The Formal Likelihood Principle* on p294 says

> LIKELIHOOD PRINCIPLE COROLLARY: If E(X, theta, {I (x | theta)} ) is an experiment,
then Ev(E,x) should **depend on** E and x only through L(thetalx).


What does ""depend on"" in the likelihood principle corollary mean mathematically?

Does ""depend on"" mean exactly The  Formal Likelihood Principle on p293 and p294? (if yes, why bother to have the corollary?)

Thanks.",statistics
ndmusu,1621166482.0,[Q] Resources for Multivariable Calculus and Linear Algebra,"I’ll be starting my Master in Statistics this Fall and an understanding of Multivariable Calculus and Matrix Algebra are a crux to many of my first semester courses. Although I have a background in Mathematics and have studied Linear Algebra and Differential Calculus in my undergrad which was approximately two years back. I am looking for a MOOC or quick course that will help me with enough material walkthrough that would be required to grasp the Statistical concepts. The reason I’m asking for an online resource and not a textbook is because I have a full-time job right now and going through an entire textbook that is not an easy read would be arduous.

Thank you for the help!",statistics
ndlyod,1621163026.0,[E] That troublesome coin toss,"I understand that the toss of a coin is a good example of probability.
But it bothers me that there is some chance of the coin landing on edge, and I’ve never seen that mentioned.
I’ve just discovered a [paper](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.48.2547) where a simulation determined the probability of a US nickel (which has a flat edge) landing on edge is 1 in 6000, or 0.0167%.
So perhaps all the examples that are careful to point out a ""fair coin"" should say ""a fair coin with a rounded edge."" 🙂",statistics
ndh7jc,1621142414.0,[Q] How exactly is domain knowledge used when model building?,"Outside of well defined problems in engineering, physics and chemistry, we don’t have a functional form for things. So how is domain knowledge used in more complex situation either in those fields or other fields?

If we have like 1000 genes and are trying to do some prediction or inference, and given that some of these genes there may be little to nothing known about them, how do you even add priors or regularization terms?",statistics
nda83g,1621117955.0,[Q] Probability of choosing an expired pill,"I have n pills in a bottle. The pills expire after t days where n is less than t. I get a new bottle of n pills at some number of days that is less than n, which is a proportion of n, called p. When I get the new bottle of n pills, I fill that bottle with the p*n pills from the last bottle. What is the probability that I pick an expired pill from the new bottle? How does that probability change if I repeat the process (assume the bottles are infinite size)? What if p is variable over time? I'm most interested in how you approached this problem, so please share your thought process as well as any solutions.",statistics
nd80ve,1621111394.0,[D] Confidence Intervals for Classification Models,"The idea of creating confidence intervals in regression models is quite straightforward.

For example :
https://www.researchgate.net/profile/Folorunso-Oludayo-Fasina/publication/284729754/figure/fig2/AS:300625800777756@1448686184816/Scatter-plot-with-linear-regression-fit-and-a-95-confidence-interval-for-reported.png

But do confidence intervals carry over to classification models?

1) For example, in this picture here (confidence interval for an ROC curve corresponding to a classification model ) https://i.stack.imgur.com/Y7KSNm.png - can the lower limit of the confidence interval from this ROC curve be used to gauge how well this model might generalize to new data?

2) For a classification model, can we make a confidence interval for the prediction of an individual observation? For instance, I wrote some R code (you can directly copy/paste the code) for a particular example where a random forest (i.e. classification model) is used to predict whether if an observation will be ""approved"" or ""rejected"" (see here for the code: https://shrib.com/#Madelyn_NMjYE8) .

Thus, for each observation, the classification model predicts the probability that this observation will be ""approved"" or ""rejected"". Whichever probability is higher, the model selects that outcome for the given observation.

Also, the higher one of these probabilities are, this means the classification model is more confident with its prediction (e.g. for two observations, the ratio of approved:rejected 0.9:0.1 vs 0.6:0.4 . The model is more confident about the first prediction)

Thus, is there anyway to apply the notion of confidence intervals to the probabilities for individual predictions?

Thanks",statistics
nd7wyw,1621111055.0,[Q] How can I do regression with repeated measurements?,"I have a list of hospital admissions of 396 patients, and each patient has gone into hospital more than once. I have also got the deprivation index of the area they live in. Is there a way to model the relationship between number of admissions and deprivation index?",statistics
nd7hmo,1621109759.0,[Q] Help with choosing test?,"I am comparing average algae heights (cm) under a factorial treatment design (2 levels of herbivory, 2 levels of nutrients) over 4 months at 3 different sites. I believe my treatments are the between-subjects variables because I am looking for the differences between the subjects used for each level. I also think my sites are between-subject variables because I am not measuring the same algae plots at each site (because they are in different locations, I am not moving them). [Would the three sites be three different levels?]
Then I believe ""month"" would be my within-subjects variable because I am testing the same subjects every month (for 4 consecutive months).",statistics
nd6zrn,1621108230.0,[E] Can you do a PhD part-time?,"I wanna start working after my bachelors and pursue a master part time, which I know is very common. However, I really wanna take it a step further get a PhD, too. Is it possible to do so while still working?
Perhaps I could do it part time and then switch to full time for the final year?
Also, I heard most PhD programs don’t allow you to work at all. Is that just conditional to when you’re getting financial aid from them?
I would appreciate any help! In case its relevant, I would wanna pursue statistics or data science. Thanks!",statistics
nd6lj8,1621107049.0,[Q] How do you get the z score out of ONLY a percentage?," Let's say we're planning on constructing a confidence interval. We haven't done any research yet, so we don't have the mean, the standard deviation, anything. We want to set the confidence level at 95%, 2.5% tail probabilities. Without the use of a calculator or a z score chart, how would we get the z score out of 95%? I'm guessing there's an equation for this, if so, what is that equation?

A solution I see is rearranging the equation for the bell curve to isolate x, but I don't see how I could do it since I'm not good enough at math to do that.

I'm sorry if somebody has posted this question before, but I can't find anything on this anywhere on the internet.",statistics
nd5if4,1621103994.0,[D] Why are there so many variations on stochastic gradient descent?,"I have been reading about variations on the stochastic gradient descent algorithm such as ""ADAGRAD"" ""RMSPROP"" and ""ADAM"".  I am trying to understand the motivations behind the need to develop these extensions.

Just by reading online, it seems that these variations have an ""adaptive learning rate"", which can assist the neural network by optimizing the cost function.

2 questions I had about this:

1)  How exactly does having an ""adaptive learning rate"" help to in trying to find the optimum of the cost function? People wrote online that incrementally reducing the ""step size"" prevents from ""overshooting"" the optimum point - but is there a more mathematical explanation as to why the basic stochastic gradient descent algorithm tends to overshoot the optimum point? Or is this just an empirical observation? (i.e. there is no real reason, but it has been observed many times)

2) I am trying to understand the relationship between gradient descent and regularization. Perhaps I am this incorrectly: It seems that the neural network is trying so hard to find the optimum point of the cost function, and so much research is being done/has been done in trying to find this optimum point - but as it turns out, this optimum point has often been observed to produce a set of weights that result in overfitting. This is where regularization comes into play and ""nudges"" the algorithm away from this optimum point, in hopes that the new point (obtained from the regularization) will not overfit.

Isn't this kind of ironic? There is a possibility that the true optimum of the cost function will likely result in an overfitted model?

&#x200B;

Thanks",statistics
nd4osu,1621101679.0,[Q] Measuring the influence of three factors within a larger construct.,"I am currently conducting a research dissertation into a given area. Much of my progress has went very smoothly and I have reddit to thank for such support. I may use incorrect jargon, so I will explain everything in full.

I have three scales which together form construct X. i.e these three scales measure different aspects of the same concept. Now what I want to find out is *which* of these three scales is of most importance - or which of the scales has the most influence over the overall construct.

Lets take the basic idea of anxiety (I'm spit balling here). You measure stress, sadness and loneliness on three separate scales. Together they form the construct anxiety. Is there a test which will display *which* of these variables is of most influence.

The data I have are on 10 point scales. So the three scales which make up the construct each are on a 1-10 scale. Where 1 is low and 10 is high. My N is small as this is student run research. N=220.

I have tried PCA, EFA and a few other techniques. I am either misreading the results, or I am correct in assuming these only reduce constructs to core values. Not tell you which of the core values are most influential.",statistics
nd1zkp,1621094176.0,[Q] likelihood of spurious correlation,"\[Q\] What is the likelihood of spurious correlation that exists between two random variables? This guy ([https://www.youtube.com/watch?v=fb921ZrM6h0](https://www.youtube.com/watch?v=fb921ZrM6h0)) takes sets of 18 samples and shows correlations of up to 0.5 even though the correlation should be zero.

(I have an engineering background. I sometimes need to troubleshoot which of several inputs might be causing some output)",statistics
ncuisq,1621069246.0,[Q] Question about Testing,"I have three distributions of variables that are more or less normal. These variables measure whether I think someone is cheating at a video game. For var1 and var2, the lower the value, the more likely I think you are to be a cheater. For var3, the higher the value, the more likely I think you are to be a cheater. No measure alone is evidence, but if you do really poorly on either both var1 and var2 or on all three metrics, I think that person's probably a cheater.

 I want some sort of statistical test using the three of them to identify the cheaters with some degree of confidence. Like if I can say ""5% of the population is cheating, with 95% confidence"" or ""these 10 players we are 99% sure are cheaters,"" that would be amazing. Does anyone have a good idea about how to approach this??


Is there a way to say like “this person is 2 standard deviations below on all three metrics and there’s only a 5% chance that’s a statistical coincidence” or something like that?

If this is relevant, I have var1 and var3 data for all players, but only var2 data for about 1/3 or 1/2 of the players.",statistics
ncpv2f,1621049385.0,[D] Xavier and He weight initialization in neural networks,"I was reading this article here on Xavier weight initializations in neural networks (e.g. https://www.deeplearning.ai/ai-notes/initialization/ ).

Is this now the default for python libraries (e.g. tensorflow/keras) when initializing weights in neural networks?",statistics
ncl5dh,1621032633.0,[E] M.S. in Statistics at SDSU vs SJSU,"I have some insight into the program at SJSU since I've taken a class there, and it seems like a solid program - I like a few of the profs. I'm wondering, has anyone done the MS program at SDSU? Or if there are math/stats undergrads at SDSU as well. What is/was your experience like? How good are the professors and how challenging is the program?

I'm currently living in San Diego but trying to decide if I should pursue one program over another. Thanks in advance.",statistics
ncjnnt,1621028143.0,[Q]ELI5 Pearson and Spearman correlation,I want to know if there is a relationship between my two variables but it has to be in terms of increase or decrease. Should I apply Pearson or Spearman correlation?,statistics
ncjc87,1621027246.0,[Career] What's the point of actuarian exams?," So basically my question is, why does this exam system exist instead of university courses if you want to work as an actuarian? And I guess it does not replace a uni degree, so you need both. Why? Or do you even need them to work as one? It's just a bit of a weird concept imo",statistics
nch85o,1621021579.0,"[Q] What are the odds of rolling 6 dice and getting a 6 on all of them, you get 2 re-rolls and you can save dice","Basically, Yahtzee rules but with 6 dice. First post so I hope this follows rules, I just don't know how to calculate it.",statistics
ncc9lk,1621008585.0,[Q] Why is mean considered better average than median?,Why is it the case that we consider mean better average than median when we are aware of the fact that mean is affected by outliers and also it's not something we can locate by inspection on a graph.,statistics
nca0df,1621002743.0,[E] Introduction to Computational Statistics using PyMC3 by Srijith Rajamohan,">The purpose of this series of courses is to teach the basics of Computational Statistics for the purpose of performing inference to aspiring or new Data Scientists ... Learn the basics of PyMC3 for various Bayesian modeling including Linear Regression, Hierarchical Regression, Classification, Robust models and assessing the quality of models.

Source: [https://www.coursera.org/specializations/compstats](https://www.coursera.org/specializations/compstats)

The enrollment is free.",statistics
nc98qb,1621000710.0,[Q] Can you use Principal component analysis to compare data sets?,"I am working with spacecraft data, where I’ve split my data into 4 subsets/categories.

Within each category, there are a number of data points (flow “events”), and each flow event has a number of measurable parameters. An analogy might be that you have 200 cars, split into 4 sets of 50 based on manufacturer, and each car has parameters that you measure like engine power, wheelsize etc.

What I’m trying to do is use PCA on each subset (including all my parameters), to understand/find out if there are true distinguishable differences between my different “subsets” of flows.

I have written the code to do this, but I am having real trouble interpreting the results. I have plotted principal component vs % variance for each subset and they are all very similar. Is this telling me that, based on my chosen parameters alone, there is little distinguishable differences between the datasets?

In each subset, the first principal component only contains around 20% of the variance. What does this mean physically?

What I want to be able to say is “ah so statistically that is why this flow falls into category X, because it has a high Y parameter value”.

Thanks!",statistics
nc7ld4,1620995803.0,[E] Introduction to bootstrapping book (giveaway),"Dear all,
a new book about statistical bootstrapping has been published. Aimed at students, practitioners, and researchers, the book provides an introduction to the technique. Besides the theoretical foundations, practical examples are given in Python and Stata. This book was written for very beginners and only the very basics (Stats I, maybe II) are required to understand the content.  I am happy give away a few digital copies (PDF). I would very much appreciate a short review online (personal blog, website, webshop, etc).
[Bootstrapping: An Integrated Approach with Python and Stata](https://www.degruyter.com/document/doi/10.1515/9783110693348/html)
ISBN: 978-3110694406
Please PM me with your email and a very short summary of your status (student, researcher, etc...). Many thanks.


EDIT: Due to the large interest I will send out the book about Saturday evening (European time). Thanks for the interest.
EDIT2: Done! If you PMed me but did not receive an email (please check your spam folder as well), message me again (and please make sure to include your email!). Thanks a lot!
EDIT3: I just realized many people contacted my in the messenger in Reddit. I did not see this until now. My apologies.",statistics
nc6c1c,1620991583.0,[Q] How is unbaised estimate S^2 of sigma^2 derived for linear regression?,"In Seber's Linear Regression Analysis, for Y=X*beta + epsilon, where Var(epsilon_i) = sigma^2:

- Section 3.1 and 3.2 are about least square estimate of beta. Does it assume sigma^2 is known?

- Section 3.4 and 3.5 are about MLE of beta and sigma^2.

- [Section 3.3](https://books.google.com/books?id=X2Y6OkXl8ysC&pg=PA44) gives an unbiased estimate of sigma^2 as S^2 (which is defined as RSS/(n-r)). How is the estimate S^2 of sigma^2 derived? Is it derived as LS estimate of sigma^2?

Thanks.",statistics
nc4ahj,1620983632.0,[Q] Predicting distributions instead of single values in regression,"I am curious if there is a good way to give richer predictions in regression in a form of probability density of the target for every observation. I've heard about quantile regression (which requires fitting multiple models and hence is too computationally heavy) and have read [this article](https://medium.com/@qucit/a-simple-technique-to-estimate-prediction-intervals-for-any-regression-model-2dd73f630bcb) (where normality is assumed, so it is unusable in some tasks).

What other methods am I missing? Does the Bayesian approach have anything to offer here?",statistics
nc3co8,1620979635.0,[Question] How differencing a time series leads to stationarity ?,"When we talk about Stationarity of a Time Series, the properties we attribute  are constant mean, constant variance, constant autocorrelation structure and no seasonality.

I came across several articles and books which says differencing makes a series stationary.

The illustration normally begins with taking an AR(1) model as example

  Yt = ɸYt-1 + ɛt

Also it is assumed that the above equation has a unit root i.e., |ɸ| = 1,

Then they difference the series and represent it as below

   **Δ**Yt = Yt - Yt-1 = ɛt

They then claim that the error (ɛt) in AR process is White noise.

White noise by definition has constant mean, finite and Constant variance and no correlation structure.

They then go on to take expected value of the error term and say  E(ɛt) = 0,

Thus implying that mean is constant.

Ok so far we have ticked one of the check boxes to prove it is stationary. The the other check box i.e. to prove constant variance remains unchecked.

The next part is what is very unclear and often left unproved

They say the variance of the error term is  Var(ɛt) = σ2

Then without proving that variance is constant they say differencing has lead to constant mean and variance.

My question is how can one prove that differencing leads to constant variance ? would be grateful for any explanation.",statistics
nc1rb0,1620972568.0,[Q] Any tips on rare event binary classification?,"I have a dataset where only 5% of the samples have a positive value for the outcome variable. I trained logistic regression and some other models, but most of them result in predicting negative about 99.5% of the time. Should I lower the probability threshold for acceptance so that more positives are predicted? How should I decide which threshold to use? Is there some method/model that can deal with rare events?",statistics
nbtuld,1620946563.0,[Q] Is Survival Analysis an appropriate application if I want to study likelihood of community college students graduating in a particular quarter?,"

What I want to do: Determine the likelihood that someone graduates with an associates degree after a particular number of quarters in community college. What is the likelihood they graduate in their 8th quarter at school? what is the probability that someone graduate any time before their 8th quarter?

Data: I have demographic information and graduation quarter of each student going back 20 years.

What I imagine this looking like (correct me if I'm wrong): 1. Correcting for censored data such as drop outs and type 1 censoring. 2. Reference distribution plots to find the appropriate family. 3. Survival analysis summary table and plot.

Am I going about this correctly? Thank you for your help!",statistics
nbtnyw,1620946063.0,[Q] How to tell when a variable doesn't follow a Bernoulli distribution?,"Hi! I am wondering if anyone has helpful resources for figuring out how to understand when response variables follow (or don't) a Bernoulli distribution.

Let's say, for some given year, we are using logistic regression to predict some binary response variable (e.g. company bankrupt or not) based on a predictor (e.g. company income). How would I go about thinking about whether, for a given income level, the bankruptcy status does or does not follow a Bernoulli distribution? (I've looked around online a lot, but don't quite understand the answers, since it seems like there's always going to be some combination of factors that deterministically decides whether or not it's bankrupt? How can it be ""truly"" random?)

Thanks peoples",statistics
nblo29,1620925747.0,[Q] Methodology for estimating expectations by dividing-and-conquering partitioned data,"Suppose I have a set of iid observations y1, y2,..., yN, which are partitioned in M blocks A1, A2, ..., AM, for M << N. My goal is to estimate E[f(Y)].

The most natural thing to do is to take the sample mean 1/n sum_i f(yi) as an estimate. This would be unbiased and converges to the true expectation by law of large numbers.

Alternatively, I could estimate A1's sample mean, i.e., ybar1 = 1/|A1| sum_{j in A1} f(yj), and similarly ybar2 (corresponding to A2), so on and so forth. Then combine these estimates ybar1, ybar2, ..., ybarM via some function h(ybar1, ybar2,...,ybarM) to produce another estimate. h is some arbitrary function, so h could be defined in such a way that it recovers the original sample mean.

Is there a name for this methodology? I'm interested in learning about the construction of h that could reduce variance at the cost of introducing bias.",statistics
nbllyf,1620925606.0,[E] Pursuing PhD with coursework part-time Masters,"I hope you don't mind another PhD question. I'm becoming interested in pursuing higher education and am looking for some opinions.

My current situation:

\- Working full-time as an actuary

\- Studying MSc statistics part-time at the University of Toronto

\- No research experience outside (work + school already consumed most of my time)

\- I've always been interested in genetics & big data, but not biostatistics in general

\- I'd like to work in the industry for a research role (hopefully in biotech) after graduation

I'm hoping to apply to a statistics PhD program in a school with warmer climate (I know it's kind of petty but Toronto is very cold!). My grades are not stellar given that I'm squeezing school + work together, so I'm okay with not shooting for top schools, but I'd still try to apply for reputable places.

Thanks again!",statistics
nbkyoa,1620924009.0,[Q] How to rescale coefficients of lognormal regression to be % change in y for unit increase of X?,"I have fit a lognormal regression model, after scaling and centering the independent variables only. I did this using the brms package in R using the family = lognormal() argument, which fits a model with the following regression structure;

    log(y) ~ alpha + beta * X

To be explicit, I did not scale and center the y variable prior to running the regression. Now, thanks to this [excellent explanation](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/), I understand to interpret the parameters for the model, I need to exponentiate them. If beta = 0.0582, then exp(0.0582) = 1.059, which means I would see a 5.9% change in the value of y for every ***1 standard deviation*** increase in X. But how should I get the % change in y for every ***unit increase*** of X? Do I divide beta by the standard deviation of X (recorded when scaling and centering the variable) and then exponentiate the result, or exponiate beta and then divide that by the standard deviation of the variable? I.e. which of these is correct?

    a) exp(beta) / (std)
    b) exp( beta / std )

Also, is there anything I need to do with the intercept (alpha) other than exponentiate it?",statistics
nbkq61,1620923417.0,[EDUCATION] CMU Professor (me) Explains Confidence Intervals in an Intuitive Way (no formulas!),[http://jeffgalak.com/datademystified/index.php/2021/05/13/confidence-intervals-explained-intuitively/](http://jeffgalak.com/datademystified/index.php/2021/05/13/confidence-intervals-explained-intuitively/),statistics
nbkdj0,1620922550.0,[Question] How can i create a dataset featuring clusters with inhomogeneous internal densities with python?,Do you guys have any idea? Sklearn doenst have a built in library to do that,statistics
nbihwy,1620917688.0,[C] I'm in Six Sigma Training and the course director told us statisticians don't really know stats,"I have my masters degree in statistics and I've noticed that during this training, a lot of the black belts have no idea what they're talking about. While the main course instructor is an amazing engineer, he does tend to say that what I learned in my degree program is incorrect because my uppity stats professors do not understand true stats because they've adapted or changed the ""original"" meaning of things, therefore what they say and what I learned is irrelevant and not true. And I'm not paraphrasing. This is what they said word by word. My argument to this is, why should I believe you? They seem to be looking down at people with a Phd in statistics since they claim they don't understand true stats. I find it hard to believe that an engineer knows stats better than well known statisticians from a top-10 stats program. I find that I am unable to suspend my disbelief and feel like I'm becoming quite resistant to the learning process, even though I would like to keep an open mind. I just find it hard to believe that my professors are all poorly informed and don't know anything, while the engineers understand true stats.

Someone explain this to me please? Is this normal for 6 Sigma? It has honestly really turned me off towards the whole thing. I think I'm struggling because I have a lot of respect and admiration for a lot of my professors--I still speak to my advisor even though I graduated years ago. I have no intentions of continuing my Six Sigma Training after I finish this one. ",statistics
nbh9ka,1620914324.0,[Q] Does Personal Laptop Choice Matter?,"Hey everyone, so I’m heading into my first year of grad school for stats in the fall and planning on getting a new laptop! I just wanted to ask if personal laptop choice really makes a difference in terms of having “laptop A vs laptop B”. I’ve read around here and there that at the end of the day if I need to do any sort of heavy work, it won’t even be through my own personal laptop. Along with grad school I’ll be interning doing data work with Python/R, SAS, and some entry level algorithm stuff if that helps. So does it really matter as long as it does what I need for daily stuff? Ie my school work, basic productivity, etc? Is there anything I should avoid? And does OS matter - I’m only familiar with Windows/Mac so fine with either “mainstream OS”. Thanks for any help!",statistics
nbd0kc,1620899669.0,[D] Panel data and variable domains,"Hi,

In the context of panel data analysis, time domains of variable widths are often a problem in social sciences or biostats. Traditional techniques such as resampling or modelling summary statistics have the disadvantages of information loss and potentially spurious results. Somewhat recently, a [paper by Gellar et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4315944/) for handling variable time domains in regression appeared, and has been [cited 31 times according to Google Scholar](https://scholar.google.com/scholar?cites=16295123835056164766&as_sdt=2005&sciodt=0,5&hl=en).

What is your opinion about that paper? The technique is quite seductive IMO, and it appears worth of promoting more widely among biostatisticians.",statistics
nbbi77,1620893173.0,[Q] Propensity score matching validity,"Hello fellow Statisticians,

I would like to perform a propensity score matching procedure in order to appraise an intervention. For the sake of discussion lets assume this is a government grant.

Robustness-- My series of questions: if I follow the standard procedure of using a pairing algorithm, and then compare the treatment and control groups across their respective observable characteristics, what are the signs that the pairing algorithm has produced a robust comparison frame?

Model Specification-- Does it make sense to include categorical variables in the model specification for the PSM procedure? I also have a variable that scores grant recipients against selection criteria (a continuous variable)--this is an imperfect proxy for treatment, but correlates very well, Should I include this in the specification for the PSM model?

Generalities-- Any general mistakes that newbies often make regarding ""internal validity"", if you will... How can I insure that the procedure is robust?

Your help is greatly appreciated.

Thanks",statistics
nbap2i,1620889665.0,[Q] Weighted Least Squares Parameter Estimation - How to define weighting matrix?,"Hi. I'm a noob at this so I'll try my best to explain my question.

I'm looking to use the weighted least squares formula for a parameter estimation problem.

Basically the the formula consists of sum of the residuals squared, multiplied by a diagonal weighting matrix consisting of the inverse of the variance from measurement data. This is to 'weight' certain values of measurement data and their associated residuals that are more accurate than others (lower variance = more accurate = more weight) (Please correct me if I'm wrong). .

My question is.....why do you have to use the inverse of the variance? Does the formula only work for variance or can the weighting matrix be defined in a different way? For example why not the inverse of the standard deviation? Or the inverse of the range? Because basically we are saying that the greater the variance of a probability distribution, the more inaccurate it is.....so really any term that is a measure of the spread should suffice to define the weighting matrix.

Any thoughts would be much appreciated.",statistics
nb7pm6,1620877633.0,"[Q] Possibly noob question, sorry in advance","So I was thinking, is getting heads on a coin twice in a row *always* 1/4?


If I predetermine ""Ill get tails twice in a row,"" then it's 1/4. But if I get tails once, *then* decide to predetermine ""I'll get tails again,"" is it technically still 1/4 or something else? I think (but I'm probably wrong, hence the post) the chances of getting another tails is just 1/2 at that point.


Another example, lets say there's 100 balls in a bag, each one is labeled with a number from 1 to 100. Basic example. If the first ball I pull is 97, and I put it back in the bag, then predetermine ""Ill get 97 again,"" and I actually do get 97 again, was it really a 1/100,000 chance or just 1/100 by that point?",statistics
nb5lk1,1620870912.0,[Q] How to compare 2 sample means when the samples are highly left-skewed and have outliers?,"Hi friends, I have few questions that I had in my mind for a long time & was hoping someone can help.

1. How to compare 2 sample means when the samples are highly left-skewed and have outliers? (Is non-parametric test the only way?).
2. How to compare 2 sample means when the samples are both approximately normal but with few outliers? (May I simply remove the outliers and compare all data points <= 99th percentile in each sample? I imagine if we were to compare salary of men & women, and I randomly sampled Bill Gates... I can remove him?).
3. What is the application of Central Limit Theorem on this question? My understanding is that CLT will return us a normal distribution after we get the means of the resampling. Let's say I am working on 2 samples that are highly-left skewed & have outliers. After resampling & getting the means, I am left with 2 samples that are normal. May I use the 2-sample t-test now to compare sample means?",statistics
nb42ca,1620866348.0,"[Q] When applying for PhD programs, do I need to explain a ""C"" grade on my transcript in an unrelated class?","So I just finished my MS in Statistics. I got A's in all the statistics courses required for the degree. However, in the last semester I decided to take a java programming course ""for fun"" as I was just curious about more intensive computer science theory and java. The course was not required for my degree, and was unrelated to the field of statistics. I ended up getting a C in that class.

When I apply to PhDs in Statistics/a closely related field like Biostats for example in the future, do I need to ""explain"" the C in that java class, or I can just leave that out and the straight A's in the grad level statistics courses will speak for itself?",statistics
nb3zuq,1620866138.0,[E] Distinguishing Between Principal Components and Factor Analysis,"The below article helps to distinguish and clarify differences between PCA and EFA, and when it is appropriate to use one vs. the other. Moreover, it describes when you may come to the wrong conclusion or may be inappropriately using one vs. the other.

&#x200B;

[https://laura-castro-schilo.medium.com/principal-components-or-factor-analysis-fcc98225b932](https://laura-castro-schilo.medium.com/principal-components-or-factor-analysis-fcc98225b932)",statistics
nb2jjl,1620861975.0,[D] poisson distribution vs poisson process,"Until now, I was familiar with the poisson probability distribution (https://en.m.wikipedia.org/wiki/Poisson_distribution).

 I also learned how to determine if a given variable (e.g. 1000 recorded measurements) follows a poisson distribution. This can be done by simulating different poisson distributions and seeing how closely they match your data. (https://stats.stackexchange.com/questions/78139/how-to-know-if-a-data-follows-a-poisson-distribution-in-r).

Now, I am trying to learn about something called the ""poisson process"" (https://en.m.wikipedia.org/wiki/Poisson_point_process). My question : is there a way to check whether your data follows a poisson process?

I am learning about queueing models. In these problems, you try to represent a queue (people arriving in line, waiting in line and getting served) using statistical models (e.g. the m/m/1 model) that require ""arrival times"" (a common and important variable used in queuing problems) to follow a poisson process.

Suppose i have a list of arrival times : e.g. the first customer arrives 10 minutes after the shop opens, the second customer arrives 7 minutes after the first customer, the third customer arrives 3 minutes after the second customer, etc. This can be expressed as either (10, 7, 3 ...) or (10, 17, 20...).

Is there a way to find out if this variable follows a poisson process? I saw that there are ways to simulate a poisson process (e.g. https://stats.stackexchange.com/questions/148997/poisson-process-in-r-from-exponential-distribution or https://stackoverflow.com/questions/55854071/manually-simulating-poisson-process-in-r). But how can you check if individual measurements follow a poisson process?

Thanks",statistics
nb20bd,1620860465.0,[Q] Survey analysis using chi squared and logistic regression?,"I have survey results assessing interest in a healthcare product. The overall goal of my analysis is to profile respondents to better understand which factors correlate with those who at the end of the survey indicate that they interested in the product vs those who indicate that they are not interested - essentially uncover the differences in these 2 groups.

I've begun by splitting respondents into these 2 distinct groups based on their indicated interest (interested vs not interested).

From there, I have several categorical and ordinal (Likert type) variables which I will use to profile/compare and contrast these 2 distinct groups.

Examples of categorical variables available are:

* gender
* race
* employment status

Examples of Likert scale/ordinal variables available are:

* How often do you exercise? (coded from 1 - never exercise to 5 - daily exercise)
* How likely are you to follow a diet if recommended by your doctor? (coded from 1 - very unlikely to 5 - extremely likely)

I plan to use a Chi-Squared test to identify if there are relationships between each of the categorical variable and the respondent group (interested vs not interested), following up each significant test with further chi-squared tests to identify where the significant differences are between categories (for example - if education level is significant is college vs high school degree attained significant? Is college degree vs masters significant?). My understanding is that this (where tests come back as significant) will allow me to say things such as 'respondents with a masters degree are more likely to be interested in the product than those with a college degree"".

For the Likert scale data, I plan to run a series of simple logistic regression models, a separate model for each likert scale variable, to identify independent relationships. My understanding is that, where relationships turn out to be significant, this will allow me to say thing's such as 'the more often a respondent exercises, the more likely they are to be interested in our product'.

My main question is, does this approach make sense? Is there a better way to approach this? Am I misunderstanding how to interpret any of the outputs described?",statistics
nayg7k,1620851047.0,[Q] What are the differences and relations between these three exogeneity/exogenicity/exogenous assumptions in linear regression?,"On [p413](https://books.google.com/books?id=YK4Qb5x-hoIC&pg=413) in R in a Nutshell by Adler

> Technically,  linear  regression  is  not  always  appropriate.  Ordinary  least  squares
(OLS) regression (implemented through lm) is guaranteed to work only when certain
properties of the training data are true. Here are the key assumptions:
>
> (3). Exogenicity of the predictor variables. The expected value of the error term ε is
0 for all possible values of the predictor variables.
>
> (6). Exogenously generated data. The predictor variables x1, x2, ..., xn are generated
independently of the process that generates the error term ε.

In https://en.wikipedia.org/wiki/Linear_regression#Assumptions

> Weak exogeneity. This essentially means that the predictor variables x can be treated as fixed values, rather than random variables. This means, for example, that the predictor variables are assumed to be error-free—that is, not contaminated with measurement errors. Although this assumption is not realistic in many settings, dropping it leads to significantly more difficult errors-in-variables models.

What do the three assumptions  mean mathematically?  (rephrased in terms of math formulas?)

What are the differences and relations between them?

Is the Weak exogeneity assumption in Wikipedia the same as one of the two assumptions in the book?

Thanks.",statistics
navpyr,1620844033.0,[D] The Rational View episode 50: Statistics 101 with Prof. Jeremy Balka (podcast episode),"https://www.podbean.com/ei/pb-ybp93-102e8d0

It seems that in general humans are not logical. We are poor reasoners and easily fooled. Misconceptions and misunderstandings of statistics are often at the root of society’s problems with communicating and understanding science.

In this episode I welcome a University curling buddy, Prof. Jeremy Balka to discuss how statistics effects us every day. We talk about statistics in science, sports, gambling, and the mind blowing Monte Hall problem.

Prof. Jeremy Balka is a teaching-focused Associate Professor in the Department of the Mathematics and Statistics at the University of Guelph. He has a YouTube channel on statistics with over 100k subscribers, https://www.jbstatistics.com/",statistics
navinl,1620843517.0,[D] How to continue making progress in Statistics and R after getting the first job?,"First of all, thank you! Few months back I made a [post](https://www.reddit.com/r/statistics/comments/hv5v3j) where many of you suggested learning R. Eversince that, I started learning it and a month back, got my first job as Business Analyst. Can't even begin to say how right y'all were, and how awesome this language is!

Anyways, my today's post is about how to keep on progressing on this domain. I want to continue making progress both in Statistics and R.

My problem is I am spending too much time looking at courses and resources and wondering what to do. I don't even know how to classify myself as a R programmer. Whether I am novice or intermediate? This all feels overwhelming.

My plan so far:

1. To do Tidy Tuesdays/ Kaggle notebooks on weekends.
2. Finish the Statistical Learning with R book. (Yes, I haven't finished it yet)
3. Learn Shiny. (It is needed for my work too)


Any help would mean a lot!",statistics
navfav,1620843283.0,[Q] Controlling for year effects using dummy variables,"I am currently reading the master thesis of a friend of mine. The aim of the thesis is to measure the impact of the fund size of a private equity fund on the performance of the fund using a regression analysis. Among other control variables, the year in which a given fund was launched is included. My friend argues that this allows to control for differences between economic conditions, which are related to the specific year. What makes me wonder is the implementation of this control variable: for each year he creates a dummy variable in the following way:

2010: 1 if the fund was launched in 2010 and 0 otherwise

2011: 1 if the fund was launched in 2011 and 0 otherwise

2012: 1 if the fund was launched in 2012 and 0 otherwise

...

My understanding is that the variable year is an interval scaled variable. Is it legitimate to control for year effects in this way? What would be an alternative (better?) way to control for possible effects emanating from the launch year of the fund? I have no experience in panel data regression but I thought that this may be a more appropriate approach to use here.

Thanks",statistics
nasssx,1620836758.0,[Question] Temporal aggregation of random walk,"Hello everyone,

I have this doubt about random walk that I can't seem to find a convincing answer to, hope someone in here could help me?

If I have a daily time series that has all the characteristics of a random walk, and if I have another weekly time series that results from the aggregation of that daily random walk time series. The weekly time series does not have the characteristics of a random walk. Is it safe to say that the weekly time series is NOT a random walk despite being an aggregation of a random walk?

Thank you very much!",statistics
narpxp,1620834084.0,[Q] How many times should I use the nonparametric related Wilcoxon when having many groups and just 2 pre and post?,"My questionnaire is between subjects where everyone answers the same pretest questions then they get randomly assigned to read/view only 1 of the total 4 stimuli, and then everyone answers the same posttest questions. Based on the paper I’m using the likert questions from, they averaged the pre together and the post together (im aware likert is ordinal but all these peer reviewed papers did it) to a total average for the pre and an avg for the post.

I know this warrants a paired test and I was using the Wilcoxon signed rank test bc data is not normal and sizes are a little small

However, here where my question resides, I have many many groups. I wanted to analyze the differences between each of the 4 stimuli and across the 4 stim- there are commonalities for which I wanted to group based on too. So say stimuli number 1 can be combined with stimuli 2 ,3 with 4, 1 with 3, and 2 with 4. So that’s 8? ALSO I was interested in breaking apart the pre and post test questions to look at each one individually (3 questions) to see difference between pre and post.

So even though there’s an absurd amount of groups, I still just have 2 paired measures so I don’t think I need Friedman’s, I just have a shit ton of groups with some overlap. I’m assuming this introduces problems? Or can I run each test for each group and so on?

Also bonus- I’m having trouble understanding Hodges-Lehmann. I always get an estimate of 0.000 and usually the lower and upper bounds are also 0.000 (for some upper was .5)",statistics
naqqj7,1620831602.0,[D] Does anyone know how to make the second graph from the first graph?,"https://imgur.com/a/apbQKXq

In this example here - what are the steps required to convert graph A into graph B? How do you decide the shape and size of the oval contours? How do you decide which points end up in which contours?

Thanks",statistics
naq582,1620830088.0,[Q] Explanation on Normal Probability Plots / P-P / Q-Q plots,"Hello /r/statistics,

I'm doing some classwork that pertains to normal distribution plots, and I'm having a bit of a hard time understanding the meaning of the plot axes. I understand that probability plots indicate how well a set of data matches a normal distribution (or some other distribution), however  `scipy.probplot` labels the axes as `Ordered Values` and `Theoretical quantiles`. See the plot generated from my data set [here](https://i.imgur.com/Naz1lQ8.png).


I've looked into quantiles a bit more, and I don't quite understand what the x-axis and y-axis ranges really mean. I don't quite understand what a `-3` quantile is, nor how I would take a particular data point and map it to these coordinates. Can anyone help shed some light on this? Online descriptions aren't very intuitive to me, but that's probably because I am a bit new to this depth of statistic and this kind of jargon.",statistics
namxz2,1620820813.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
nah95s,1620797163.0,[D] How Do Heatmaps Work?,"I am interested in learning about the mathematical and statistical formulas used in making heatmaps (choropleths) such as the one below (made in R):

[https://imgur.com/a/Su2gBvh](https://imgur.com/a/Su2gBvh)

 Does anyone know if it is possible to understand the exact (math) formulas behind the coloring/shading in this map? I tried consulting the official documentation for the functions used to create this map ([https://cran.r-project.org/web/packages/leaflet.extras/leaflet.extras.pdf](https://cran.r-project.org/web/packages/leaflet.extras/leaflet.extras.pdf)) , but no where does it explain how the colors are finalized. I suspect that this somehow might be related to ""kernel density estimation"". Furthermore, I have a feeling that the ""max"" and the ""blur"" options are actually parameters used in the final coloring of this map.

Does anyone know if it is possible to understand the exact formula used behind the coloring?

Thanks",statistics
naee41,1620786785.0,[Career] [Question] Things I could start to prepare for my future stats service-providing business as an undergraduate math student?,"Hi everyone, I am an undergraduate math student who has decided to pursue a PHD in statistics after my current program. When considering my future career, besides becoming an academic in universities, alternatively I also think about starting my own small service providing business related to statistics, so that I could apply my statistical skills to the real world and hopefully make a living from that. At the moment I know nothing about how to make this idea a reality. I don't know what statistical skills are wanted in the market? How to find clients? As an undergraduate what should I do to prepare for it besides learning my courses well, etc.

I have read some posts related to business in statistics in this sub, but I hope to get more advice and insight directly form those who have gone through the process of building their own business. Some starting things to do and several rough directions will be very helpful for me.

And a little bit more about my background, besides math skills, I could program at a basic level (C++ or Python). I also know how to use matlab and currently I am learning R language.",statistics
nacx00,1620782099.0,[D] Concordance Index (for censored observations),"References:

https://statisticaloddsandends.wordpress.com/2019/10/26/what-is-harrells-c-index/

https://www.statisticshowto.com/c-statistic/

""the C-statistic gives the probability a randomly selected patient who experienced an event (e.g. a disease or condition) had a higher risk score than a patient who had not experienced the event. ""

Just a question: For a given survival model, is the C-index only calculated using the set of patients who experienced the ""event""? For the same survival model, do we not use censored patients for calculating the C-index?

Thanks",statistics
na9wp1,1620772986.0,[Q] how do you explain someone who does not know statistics that sometimes you need to remove the outliers?,After completing data analysis courses.  I was wandering how could i explain someone sometimes we need to remove the outliers inorder to get better result with simple to understand examples?,statistics
na9eym,1620771609.0,[D] Decision Trees and Random Forests for Regression,"Are there any advantages in using Decision Trees and Random Forests for regression compared to standard regression models? It seems to me that there might be certain advantages for Decision Trees and Random Forests for classification problems (e.g. more logical interpretations, easier to combine categorical and continuous variables together) - but are there any advantages for using Decision Trees and Random Forests for regression problems (compared to standard regression approaches such as GLM)?

Thanks",statistics
na946m,1620770787.0,[D] Correct Application of Survival Analysis,"I have been struggling to understand this concept for some time: can you use create a survival analysis model for old patients, and then use this model for prioritization and decision making for new patients?

Imagine this example: you have a historical dataset that shows patients coming into an emergency room (you have covariates associated with each patient such as age, gender, etc.) and the time at which they left the emergency room (call this the ""event"") or the time at which they passed away (call this ""censored""). Suppose you build a survival model for these patients, and you want to use this survival model to ""triage"" new patients so you can decide who to treat first - this model can tell you the probability of surviving past a certain point and the rate at which an instantaneous ""hazard"" can occur for each new patient. Based on the covariates of a new patient and the estimated hazard and survival function of each patient, I want to try and use this information for triage. I know that you could probably use a standard supervised classification model or regression model for this problem, but classification/regression models can only provide a ""point estimate"". I want to do an analysis that shows how ""risks evolve with time"" for each new patient. (this is an example I made up, it might not be very realistic ... but I am trying to illustrate an example where survival models can be used for triage and decision making).

In survival analysis, the ""cox proportional hazards regression model"" is the most common model ... but I want to use a newer approach called ""survival random forest"". Like a standard random forest, the survival random forest is made up of randomized boostrap aggregated (""survival"") decision trees. Each survival tree passes observations through a tree structure and places them in a terminal node. A Kaplan-Meier curve is made for all observations in the same terminal node. Then, the survival random forest performs an ""ensemble voting"" using all trees and produces an individual survival function for each observation (see here for more details: https://arxiv.org/pdf/0811.1645.pdf)

The advantage of the survival random forest is to combat the common problems associated with non-linearity and complex patterns in bigger datasets. Traditional cox proportional hazards regression models would require the analyst to manually consider different potential interaction terms between covariates - these can be potentially infinite. The survival random forest uses bagging theory developed by Leo Breiman to overcome this problem.

Going back to my initial example for using survival analysis for triaging, I tried to illustrate this example using R (code adapted from here: https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/).

In this example, I train a survival model (survival random forest) on a training dataset (the ""lung"" dataset that comes with the ""survival"" library in R), and then use this model to generate the individual survival curves for 3 new patients. This can be seen here:

https://imgur.com/a/A0n8AFl

Based on this analysis (after generating confidence intervals for each survival curve), can we say that the patient associated with the ""red curve"" is expected to survive the longest, therefore we should first begin to treat the patients associated with the blue curve and the green curve?

The formatting on reddit was giving me a hard time, so I attached my R code over here: https://shrib.com/#RoseateCockatoo7ZeV5KA

Can someone please let me know if this general idea makes sense?

Thanks",statistics
na8urx,1620770110.0,[Q] What is the number of cards needed to complete a full pack if I'm randomly picking them off the street?,"How many playing cards would I need to find, to ensure completion of a full deck of cards, assuming I randomly pick up cards off the street?

Some context: Guy on Twitter says he has completed a full deck of cards since the beginning of the pandemic, by picking them up every time he saw them on the streets (!!!!)

By my very poor reckoning, the calculation would go something like this:

First card chances are 52/52 would work for the collection. Second card 51/52 because one would be a duplicate.

Third card 50/52 ...and so on

So, is the probability the product series of n/52, for n = 1 to 52???

Stick that into Wolfram you get an absurdly low number (the exponent is -22)

So the number of cards needed is 1 over this figure? This is probably more than all the playing cards ever printed anywhere.

This silly post has me plugging numbers into wolfram and I need closure, please help, thanks",statistics
na3u8j,1620757544.0,[Q] When to use t* vs z* in confidence intervals?,"AP Stats teacher said the following question would be graded wrong if we wrote z\* instead of t\*. Why is this? I always write z\*.

Question:

Activity trackers are electronic devices that people wear to record physical activity. Researchers want to estimate the mean number of steps taken on a typical workday for people working in New York City who were such trackers. A random sample of 61 people working in New York City who wear an activity tracker was selected. The number of steps taken on a typical workday for each person in the sample was recorded. The mean was 9797 steps and the standard deviation was 2313 steps.

a. Construct and interpret a 99 percent confidence interval for the mean number of steps taken for a typical workday for all people in New York City who wear an activity tracker.

Answer: x-bar ± t\*(s/√n)",statistics
na21qi,1620753125.0,[Q] what is some good outside resources to learn statistics,So my college level statistics class is not cutting it for me. And my professor is the least cooperative as there is. So I need to know some outside resources so I can learn some of this stuff.,statistics
na1c3w,1620751352.0,[QUESTION]How to derive Newton's Forward Interpolation formula from Lagrange's formula?,How to derive Newton's Forward Interpolation formula from Lagrange's formula?,statistics
na075h,1620748413.0,[Question] How do I calculate percentiles given this limited information?,"Hey there,

do you know of a formula to convert the absolute test scores into percentiles if only the following information is given?

|Test Scores|Median (50th percentile)|10th percentile|90th percentile|
|:-|:-|:-|:-|
|2.06|3.22|2.41|3.97|
|4.25|3.50|2.72|4.22|
|4.00|3.63|2.50|4.50|

The minimum value is 1 and maximum is 5.

I now would like to get the absolute test scores (Column 1) as percentiles. How do I calculate that?

Many thanks already in advance.",statistics
na01qz,1620748018.0,[Q] Do I have to report confidence intervals when data is not significant?,"Hello,

Throughout exploring my data I have found no indicators that my independent variable has any causal effect on my dependent variable. After running general and generalised linear models this is still the case. Do I have to report my confidence intervals still?

Thanks",statistics
n9zcex,1620746136.0,"[Q] What does ""model"" mean in ""training a model from a set of training data""?","In statistics, a model is a set of probability distributions. There are parametric, and nonparametric models.

In ""training a model from a set of training data"", does ""model"" still have that meaning? Does ""model"" here mean a probability distribution in a model?

Thanks.",statistics
n9yhsy,1620743937.0,[Q] SPSS Split-file ?," I want to compare learning approach (have 2 scale + 4 sub-scale)  between 2 university. And for each university I want to find the different between their demographic such as gender, academic lvl etc. I wonder if I could use split-file function in spss analyses them as different set of data. Or do you guys have any other-way",statistics
n9y5ph,1620743025.0,[Q] How to compare the success rate in different states,"Hello,

Let's say I have 5 states A,B,C,D and E. Each state has 3 sub-categories (A1,A2,A3 and so on). I performed some kind of tests and it looks like state A and B have a higher success rate than the other 3 states. How can I validate that statistically?

Thanks!",statistics
n9vs6g,1620735786.0,[Q] How do I find crime statistics relative to race relation to proportion of the population?,"I want to find murder statistics by race for a given country relative to the population of that race within the total population of that country. Races can include, white, black, hispanic, asian etc. For example if there was 2500 murders in a given year and 1000 were by white murderers and 1000 were by black murderers I would want that divided by their proportion of the population. For example if the population was 75% white then you would divide 1000 by 0.75 to get roughly 1334. If the population was 10% black you would get 10000. The point of the statistic is to mitigate 'total numbers of crimes' to the relative population of the race of the murderers.",statistics
n9u9c6,1620730405.0,[Q] Taking the median of datasets,"Hi all,

I’m working in the IDL programming language which has a median() function, which I’m using on my data.

Obviously, taking the median of an odd amount of numbers gives you a middle value, whereas taking it of an even amount gives you two in the middle (which I believe you’re supposed to average).

For some reason, in IDL, the *default* option is that doing e.g. median(1,2,3,4) returns 3, median(3,4,5,6) returns 5. I.e. it returns the number just past half way.

You actually have to specify “EVEN” as a keyword so that it averages the middle 2 (returning 2.5 and 4.5 in the above examples).

My question is, is what IDL does with even sets of numbers by default “wrong”? If so, why would it not automatically average the middle two numbers?

I’m trying to work out whether I need to reprocess all my data or not..",statistics
n9omyn,1620706734.0,[Q] Issues in Jamovi. Help?,"I’m trying to input data into Jamovi and it’s not giving me any information. I’m trying to find chi-square for goodness of fit. I’m not sure what I’m doing wrong. It’s not allowing me to put in a ratio for expected counts. If you need me to explain more or think you could help, pls send me a chat!",statistics
n9mx3l,1620700749.0,[Q] Please help with primary data methodology in research proposal.,"So I’ve got a business writing course where I have to do a research proposal with a survey or interview attached. I bit off a little more then I could chew and designed it as a one group pretest post-test intervention study to see what effect a meditative practice called yoga nidra would have on university students in terms of anxiety, depression, and academic performance.

Our professor in the primary data methodology section asked those of us doing surveys to post the number of participants needed for the study to be statistically significant. The method given is to find this out by using a online tool and plugging in a 95% confidence level, confidence interval of 3 ,and total undergraduate student body. I came up with the following in my proposal:

“There are 13,620 current students at the university. Using a confidence level of 95% and a confidence interval of 3 it is determined that 990 students will need to participate in order for the study to be statistically significant”

Because of the nature of my pretest post-test intervention study I’m under the impression that this isn’t sufficient and I’ll need to do more complicated statistics math involving power analysis. I have no idea how to do this as I’ve never taken a statistics course.

Will that be necessary? The teacher I don’t think will be expected something that complicated as this is just a business writing course. Should I just leave it as is and not work this out? If I should how do I even begin?

Thanks! Any help is much appreciated!",statistics
n9jmu4,1620690445.0,[Q] What is Your Opinion On Sports Statistics?,"Hi there!

First off, I apologize if this is the wrong place to post. Considering that I've seen a few posts about an education in stats, I thought that this may be the place to ask for your opinions :)

I'm currently 15 years old, in grade ten, and have been asked in one of my courses to plan for post-secondary school. I have a few questions and would love if you could give me your opinion on it :)

Do you think a career in sports statistics is realistically possible to get into? I know that sounds like a stupid question, but I have been seeing mixed answers when I look online, some saying it is very hard as there are only a few positions available, whereas others are saying that it is in high demand and that a candidate should have a MS in Statistics to have a good chance of getting the job. And if you are someone who has a career in sports statistics and you're willing to share, what tips would you recommend to someone who has an interest in it?

Thank you!",statistics
n9isq4,1620688039.0,[Q] How did distribution tables come about?,"Hey guys, I am confused as the two stat undergrad books I have read do not go into the history of the tables? I mean, how did W.S. Gosset calculate the t-distribution table?

Also, is there a geometric or* algebraic interpretation of a distribution table, please?",statistics
n9hzld,1620685770.0,[Q] Overall Prevalence,"Hi everyone,

Rookie here - if one study has a population of 200 (wherein 35 are sick) and the other has a population of 300 (wherein 40 are sick). What is the overall 'weighted' prevalence of the disease? I am trying to complete this clac in SPSS but i feel like my logic \[(200/500)\*35\]+\[(300/500)\*40\] is very wrong. Please can someone help me understand!",statistics
n9h2c5,1620683271.0,"[D] Difference between ""ensemble models"" and ""stacking models""","I was reading the following tutorial over here: [https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html](https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html)

I am trying to understand the difference between ""ensemble models"" and ""stacking models"". Is my interpretation correct?

Ensemble: Using the majority vote from different models to predict a new observation - e.g. in the case of classification, suppose we have a new observation. ""random forest"" says this observation is class ""1"", ""SVM"" says this observation is class ""1"" and ""K Nearest Neighbor"" says this observation is class ""0"". Since the votes are 2-1 (in favor of class ""1""), we say that this new observation is class ""1"".

Stacking: I am a bit more confused about how stacking works. As far as I understand, it seems like you are taking the probability score produced by the first model, and then treating this probability score produced by the first model as inputs for the second model. E.g. Suppose you are doing supervised binary classification. you have 5 predictor variables. You use a random forest as the first model, and the random forest outputs a probability score that each observation belongs to class ""1"" or class ""0"". Now, you take these 2 variables (the probability score and the original response variable) and treat these as inputs for the 2nd model (e.g KNN).  You can repeat this process for a third model.

Is my understanding correct?",statistics
n9ft6m,1620680066.0,[Q] Does it make sense to calculate d prime for a split plot design?,"Lets say participants study 100 words. The words can either be happy or sad (within subjects variable). The participants either study them while in a hot or a cold room (between subjects variable).

They are they tested on 200 words in a different room of neutral temperature. These 200 words consist of: the original 100, and 100 more. These 100 extra words are half happy, half sad.

Am I right that it wouldn't make sense to calculate d' for both word emotion and encoding temperature? Because it doesn't make sense to calculate false alarms separately for encoding temperature?",statistics
n9fjze,1620679387.0,[D] Interpretation of Kaplan-Meier Curves,"https://felixfan.github.io/figure2016/km2-1.png

In this picture here, it appears that the survival curve for ""male"" patients seems to descend steeper than the survival curve for ""female"" patients. Based on this information, could you argue that in this example, males are at higher risk of experiencing some unfavorable ""event"" (e.g. let's assume that this example is about surviving some medical condition) and therefore should be initially paid more attention to compared to female patients?

Thanks",statistics
n9fehs,1620679000.0,[Q] Does having a higher drop-out rate than what was accounted for cause a threat to your sample size power calculation?,"For example, in the study I am reviewing they calculated a 90% power, w/ alpha = 5%. They had a strict drop-out/non-compliance rate of 15%.

After analysis they had an 18-21% drop out rate. Does this cause a threat to the external validity and make their 90% power calculation negligible?

Thank you.",statistics
n9fa8i,1620678701.0,[E] Sampling methods in Stats in 10mins,"Hi everyone I made a video which explains all the different types of ""Sampling methods used in Statistics"" in 10 mins. Please check it out and share it with anyone who might find it useful.

Here is the link: https://youtu.be/QemLfGIXfUo",statistics
n9ebkt,1620676307.0,[Q] Help with a stat problem,"The question is as follows:

27. To compare the effectiveness of two treatments, researchers conducted a well-designed experiment using a randomized block design in which the subjects were blocked by age-group (under 40 years and 40 years or older). Which of the following must be true about the randomized block design of the experiment?

(A) The number of subjects in each block is different.

(B) Treatments are randomly assigned to subjects within each block.

(C) The design cannot have a control group because subjects are blocked by age-group.

(D) The experiment uses a matched-pairs design, where subjects from one block are paired with subjects from the other block.

E) The subjects in one block receive one treatment, and the subjects in the other block receive the other treatment.

I understand why B is right but why would C not be right also? What would the control group be for this experiment?",statistics
n99od8,1620664963.0,[C] Help with call center work flow,"Forgive me if I am in the wrong place..

I am looking for an analysis on work flow. Please let me know if I can provide more data.

I manage a call center with 8 hour shifts

Given no sales the daily requirements are 150 dials per day or 5 hours of talk time or 18.75 dials or 37.5 minutes talking per hour.

If agents close 3 sales they only need 115 dials or 4 hours 15 mins talk time.

Each call with voicemail is approximately 90 seconds.

I am seeking an analysis of the maximum time that can be spent per call in order to still meet our quotas while still staying at or below the desired work pace of 18.75 dials or 37.5 minutes per hour with no sales.

My assumption is that by taking the time to make the sales agents are asked to work at a higher pace than with no sales.

My hypothesis is somewhere just over 30 mins per sales call will be detrimental to work flow as the pace of dials will exponentially increase as time decays and as people actually answer the phone (unknown how any will answer if any at all)

Say an agent makes 3 sales but each call takes 30 mins. That is 3 dials and 1.5 hours gone and now there are 6 hours 30 mins to make 112 dials or complete the talk time minutes.

I know you statisticians can sum this up...

Thanks for any help. Mods delete if necessary.",statistics
n98y7y,1620663190.0,[Q] High school statistics question. Can anyone help me find the anwser?,"
Suppose a 95% confidence interval constructed from a sample for the mean weight of apples on a farm is (90, 120). (1) What is the average weight of the sample? (2) What is your conclusion to the test that the mean weight of the apple is 103 at the significance level of 0.05? at the significance level of 0.01? still at the significance level of 0.05 but decrease the sample size?


 The weight of the oranges on a farm is subject to a normal distribution with a mean of 40g and a standard deviation of 5g. (1) What is the interval that contains the middle 60% of the orange? (2) What is the probability the average weight of a sample of size 100 is less than 30g?",statistics
n97p4f,1620660606.0,[Q] Datasets,Hello I was wondering if you know some datasets where they compare or can be adjusted for comparing two populations. Sorry if my English is bad it isn’t my native language.,statistics
n957na,1620655493.0,[Q] Question about displaying significance levels in regression tables,"When presenting the results of regression models in a table, do you prefer to display stars for just one significance level (e.g., \*\*p<0.05)? I know some people prefer to present all three (i.e., \*p<0.1; \*\*p<0.05; \*\*\*p<0.01), but I've also heard that it's best to just select one for the sake of presentation. Any thoughts on this?",statistics
n8zt2g,1620636680.0,"[Q] With possibly too few data points post-intervention for an Interrupted Time Series study, should I try a different test?"," Hello! Currently, I am analyzing the change in a trend-line pre- and post- the COVID-19 lockdowns (April 2020). I have two separate datasets, one with monthly data points from 2013 Q4 - 2021 Q3 (dfA), and the other from 2015 Q4 - 2021 Q3 (dfB). On each of these datasets, I have different points plotted on the same graph (EX: Monthly Energy used for the Top 10% vs Bottom 10% of income for dfA). I have plotted both monthly and yearly averages of the data. I want to analyze if there was a change pre-and post-April 2020 between these two groups (if being in the bottom 10% caused this group to use more/less energy compared to the top 10%), but am scared I do not have enough data points to confidently come to a conclusion with the interrupted time series study, especially based on this paper: ""Zhang F, Wagner AK, Ross-Degnan D. Simulation-based power calculation for designing interrupted time series analyses of health policy interventions. J Clin Epidemiol 2011;64:1252-61"" which says you ideally should have close to an even amount of points before and after the intervention. So, my question is, does anyone here possibly have an idea of what other study I could use to analyze this difference, or how I could alter the interrupted time series equation of "" Y=b0+b1T+b2D+b3P+e"" to fit my analysis better? Any help is greatly appreciated, and if anything confuses you on this long-winded explanation I would be happy to delve in further!!! Thank you in advance!!",statistics
n8zajn,1620634545.0,[Q] Example of distributions which are difficult to sample from?,"I am always confused when it comes to learning sampling algorithms / techniques because they refer to distributions that are difficult to sample from. For example ""the Metropolis–Hastings algorithm is a Markov chain Monte Carlo (MCMC) method for obtaining a sequence of random samples from a \*\*probability distribution from which direct sampling is difficult\*\*."" (Wikipedia) or Importance Sampling as well. In all examples we use well defined distribution like a Gaussian to test the algorithms (which I understand fairly well).

I guess we are assuming the existence of a distribution that we can just evaluate but not sample at random from it, is this what it would mean in general?",statistics
n8t6v3,1620612294.0,[Q] How much does a bad grade in a math class affect my chances?,"Hello all I’m an undergrad stats student. I have hopes of going to a top stats MS program. I have research experience in data science areas, and have done internships. Main thing I’m maintaining is gpa. I’ve been doing well in my stats classes, but recently I didn’t get a great grade in my multi variable calculus course. I got a B-. Anyway, I’m wondering how much a bad grade in non stat related courses matter. I know linear algebra and proof based math is important to do well in, but how does calculus affect my chances? If I don’t have good enough grades right after my undergrad can I work in industry for a few years then go back to get a masters? What’s a good gpa? My stats classes have been great but it was this calculus class thay gave me a tough time. This one final exam ruined me.",statistics
n8rigr,1620606472.0,[Q] parametric not sig but non parametric is sig. what does that mean?,"Hello

I am testing diff between means of groups from a questionnaire with Likert scale questions. I understand the debate between likert being ordinal vs interval which is why I’m including both tests in my thesis.

The ANOVA p value is always greater than 0.05. However when I run non parametric tests like Mann-Whitney and Kruskal-Wallis, it returns a sig lower than 0.05. I thought non parametric were harder to find sig?

I’m not sure what to say in my results about the conflict (if there is one). I appreciate your help.",statistics
n8pu5n,1620601035.0,[Q] Weighting Survey Data for Propensity Score Matching,"Hi everyone. I am using Stata to analyze a pooled cross-sectional dataset. A certain percentage of observations are from simple random sampling, but the rest comes from stratified sampling as they tried to oversample household living in areas with certain characteristics.

I have a dataset that oversampled certain areas. Since the dataset does not include a clear strata variable, I created one by converting the oversampling indicator variable (characteristics 1 =1, characteristics 2 = 2, etc.). In short, strata is areas prone to a certain kind of disaster.

Did I create a correct strata variable?

After I use the svyset command, svy: works fine with common commands like regress and logit. However, it does not work with teffects psmatch. teffects psmatch does not allow for the pweight option, either.

I am lost and don't know what to do. Any advice will be appreciated.",statistics
n8pbwx,1620599452.0,[Q] Accurate statistics textbooks for biomedical scientists?,"I know that this question is asked quite regular, but please hear me out.

What statistics textbook do you recommend that are clear, comprehensive AND accurate on the following topics?

&#x200B;

\- Confidence intervals, P-values, and hypothesis testing;

\- Multiple comparisons;

\- Experimental design.

&#x200B;

I really appreciate accuracy, because I am not a statistician myself and have heard of several textbooks with misconceptions, especially about confidence interval interpretation or recipes that I know statisticians really disaprove . I'm planning to use these books to teach other scientists, but I'm not sure all the textbooks I have used for myself over the years are up to date and accurate.

I'm always looking for books written by statisticians or mathematicians to avoid basic mistakes, but I also appreciate abstraction without dumbing down concepts too much.

&#x200B;

I have some candidates below if it helps:

&#x200B;

**- Confidence intervals, P-values and hypothesis testing:**

1. Zar, Biostatistical Analysis 5th ed. ISBN 0131008463

2. Rosner, Fundamentals of Biostatistics ISBN 978-0538733496

3. Larry Wasserman, All of statistics (harder)

&#x200B;

**- Multiple comparison**

1. Jason Hsu, Multiple Comparisons: Theory and Methods

The first book from next section also has a chapter about this, as well as ""Milliken, Analysis of Messy Data Volume 1: Designed Experiments"".

**- Experiment design**

1. Scott Maxwell, Designing Experiments and Analyzing Data: A Model Comparison Perspective

2. Casella, Statistical Design

3. Box, Hunter & Hunter, Statistics for experimenters: design, inovation and discovery.",statistics
n8m3dn,1620590163.0,[Q] Churn probability with Ordinal Logistic Regression,"Hello everyone.

&#x200B;

I am trying to create a questionnaire to evaluate satisfaction, with which I would like to estimate the probability of the customer's churn.

I know the classic models like OLS, Logit, MNL, Probit, etc. Since ""Y"" is a probability I'll use the Logit model.

The problem is: There are so many questions (17 ordinals with 5 choices each, 7 categorical, 1 continuous) and the sample will be very small (200 consumers maximum).

When I studied these models at university there were no problems with the sample size and I don't know what to do now.

Should I reduce the number of questions on the questionnaire?For example, two questions like:

1. Was the package large enough? 5,4,3 ...
2. Was the color of the packaging to your liking? 5,4,3 ...

I could replace them with:

1. Was the packaging to your liking? Yes/No.

&#x200B;

Or is there a way to aggregate the answers for each question category (packaging, shipping, after-sales, etc.)? Perhaps taking the mode of each category?

&#x200B;

ps. English is not my first language, I hope my question is understandable.

&#x200B;

Thanks so much.",statistics
n8l845,1620587707.0,[Q] Regression Analysis,"I am writing a thesis on predicting tram faults by looking at past data. I do not know statistics, and I'm having trouble finding accurate results. I have data on which vehicle gave which malfunction in which month and year. I cannot find what is dependent and independent variables should be in a multiple linear regression model. I hope my question is clear enough!",statistics
n8l6o0,1620587595.0,[Q] Need recommendations of statistical software for beginners.," Hello, I am an undergrad student in CS. I'll be pursuing a Master's in Data Science after my graduation. I am looking to learn some statistical software, but there are many on the market. Can you recommend to me what software should I learn?

Edit - I know Python and libraries like Numpy, Pandas, etc. Was just wondering if knowing any softwares will UP my profile.",statistics
n8guor,1620575117.0,[Q] What is the likelihood of three siblings having their golden birthdays in the same year?,"Question: so my three cousins who are siblings all have their golden birthdays in the same year. What is the likelihood of this happening? (If we assume that the parents don’t give birth before 18 or after 35). We got a few different numbers some incredibly low, some incredibly high (1 in 34,000, and 1 in 101,000,000 were the two answered we came up with) personally I think it’s the latter, but I figured I’d asked some people who are more skilled in the subject.",statistics
n8emi0,1620568212.0,[Question] biostatistics book for data science?,"Hello everyone. I'm a biology undergrad. and beside university I've done some self studying in computer science and data science. now my professor advised me to read "" Biostatistical Analysis by Jerrold H. Zar "".

I was wondering if this book is enough for statistics part of data science or at least is it gonna be a strong introductory to statistics for me?

thanks for any answer or advice",statistics
n8di5h,1620564221.0,[Q] Continue my formation,"Hello,

First of all, thank you for taking the time to read this.

I have been studying stats for the last year, from probability, CI, hypthesis testing, inference and regression, I have also done a bit of time series analysis and an intro to Bayesian Statistics, mainly all through coursera.

The thing is that I want to dive even deeper into stats, specially GLM, ANOVA, mixed effects... what would be the path to follow?

Is there any online course which you will recommend?

Is there logical path that I should follow?

Thank you so much!",statistics
n8cx5c,1620562028.0,[Q] Help on figuring out what kind of variable I'm dealing with?,"The dependent variable I'm using in my model is 'frequency of park visitation'. The values encompass 'once a day'; 'multiple times a week'; 'multiple times a month' etc., up until 'never'. I want to use linear regression, but am not sure if this is allowed for this type of variable. My guess is that this is an ordinal variable, but I'm not sure. Any help is very much appreciated!",statistics
n8c4co,1620558811.0,[Q] Interpreting OLS coefficients to a percentage chance,"Hey all,

I'm gonna illustrate my question with an example of my output of an OLS regression model. Independent variable coeff = -0.02
Constant term = 0.05

Is it safe to assume this implies a relative decrease of 40% compared to the model's baseline probability?",statistics
n8bnal,1620556788.0,"[Q] Question about probability, sorry if this is the wrong place to ask.","Hi,

I would like to ask this question:

If I have 15% probability of something happening, and it takes 200 tries to happen, what's the probability of the event?
Sorry for the bad wording, I'm not great at math.",statistics
n8asyj,1620552913.0,[Q] Statistical tests in SPSS,"Hi all!! I’m currently in my first year doing an undergrad in ecology and as part a self directed project I have chosen to do on bird feeders, I am using SPSS. I am trying to find out if the feeder distance from cover (e.g a hedge) and other bird presence on feeders close by affects the frequency of feeding. I’ve got the data and put it into SPSS, but I’m a bit stuck on the statistical test side of things.

I have one column with feeder position, 1 to 5, with about 100 rows per position. Each row represents when a bird lands on the specified feeder and then the column next to it records how many birds were present on the other feeders at time of landing.

 I am wanting to run a test that compares feeder position to total number of landings for that position, and another that compares median other bird presence to total number of landings for each position. Stats isn’t my strong point but I would really like to include this in my work so any pointers would be appreciated!",statistics
n83xdf,1620525605.0,[Q] what advice would you give to someone who is going to start their undergraduate in statistics this year?,,statistics
n7x9a8,1620504192.0,"[QUESTION] Binomial distribution with n=15, how to solve it?","Hi, I'm doing an exercise where we have 15 as ""n"" and p=0,2. They ask what are the probabilities of success more than 5 times. Of course there's a way of solving it by adding all the probabilities from 5 to 15 \[P(x=5)+P(x=6)+P(x=7)+...+P(x=15)\] but it's a bit too long. I thought that I might have to approximate the binomial distribution to a normal one and then convert the normal one into an standard distribution to get the answers from the table. However, the binomial distribution is too short to be converted into a normal one, but quite too long to calculate by adding the probabilities of each ""n"". Should I solve the exercise by adding those probabilities from 5 to 15 or there's another way?",statistics
n7wcvw,1620501452.0,[Research][Question] Alternatives to latent profile analysis for a master's thesis!,"

Hi, [r/statistics](https://www.reddit.com/r/statistics/)! I'm so glad to have found this lovely community, and was wondering if you kind folks might be able to help me with a quandary.

I'm a clinical psychology student with an interest in eating behavior. I am currently designing a study for undergraduate women that is aiming to use data collected from psychometric measures of eating to create profiles of different ""eating styles"". Currently I have 5 measures I'm hoping to use: three regarding restrained eating, one asking about intuitive eating, and a final regarding binge eating. Originally, my plan was to use latent profile analysis to form groups using variables from these instruments (for example, I might see groups of ""dieters"", ""non-dieters"", ""intuitive eaters"", ""binge eaters"", etc. emerge). I was then planning on using these groups to run some ANOVAs testing for differences in outcome variables of depression, nutritional quality, yada yada.

The problem? Apparently you need \~500+ people to run a meaningful LPA. No way I can manage a sample size that big in this coming year.

Do any of you know of a statistical analysis I could run to group/sort individuals based on their scores from multiple measures? Ideally something that could be sufficiently powered with \~100-200 people?

Thank you for any help you can offer! I'd be happy to add more details as needed.",statistics
n7stif,1620491259.0,[Discussion] Opinions on Nassim Nicholas Taleb,"

I'm coming to realize that people in the statistics community either seem to love or hate Nassim Nicholas Taleb (in this sub I've noticed a propensity for the latter). Personally I've enjoyed some of his writing, but it's perhaps me being naturally attracted to his cynicism. I have a decent grip on basic statistics, but I would definitely not consider myself a statistician.

With my somewhat limited depth in statistical understanding, it's hard for me to come up with counter-points to some of the arguments he puts forth, so I worry sometimes that I'm being grifted. On the other hand, I think cynicism (in moderation) is healthy and can promote discourse (barring Taleb's abrasive communication style which can be unhealthy at times).

My question:

1. If you like Nassim Nicholas Taleb - what specific ideas of his do you find interesting or truthful?
2. If you don't like Nassim Nicholas Taleb - what arguments does he make that you find to be uninformed/untruthful or perhaps even disingenuous?",statistics
n7rbrs,1620486947.0,[Q] is Facebook prophet good for forecasting time-series data to predict stock price?,"I am a novice when it comes to data science. But do have a data engineering background so I do understand data science concepts at a very high level.

When it comes to forecasting time-series data like predicting stock prices, it seems like there are two broad main methods:

1. Deep Learning

- RNN
- CNN
- LSTM

2. ‘Traditional’ Time Series Methods:

- univariate: FB Prophet, ARIMA, SARIMA, exponential smoothing
- multivariate: Vector Auto Regression

I know it’s ignorant to ask what the ‘best’ method is in forecasting time series stock prices. That’s a very subjective question. I’m more interested in what the general sentiment is towards each method to ultimate forecast and predict stock price data. Also the trades offs to each.

I am less inclined to the traditional approaches and more interested in deep learning but I don’t know if that’s even appropriate for what I’m trying to accomplish. Thanks for any input in advance.",statistics
n7phaw,1620481314.0,"[Q] Has the multi-armed bandit problem been solved? If so, what is the optimum algorithm to follow?","So there's a gambler who is playing slot machines and each slot machine has a chance between 0:100% of outputting a ""win"". The gambler wants to win as often as possible and lose as few times as possible. What is the optimum strategy the gambler should follow?

Also, how does it change if there are an infinite number of slot machines? Also what about the case where the results are not binary (W/L) but there are many possible results (e.g. every machine can either lose, win £5, or win £100)?",statistics
n7p636,1620480246.0,[Question] variable measurement,"
I’m doing a very basic module in SPSS for a politics course and I’m finding the difference between nominal, ordinal and interval variables quite arbitrary and difficult to understand. Some help and clarity would be greatly appreciated!

If a question to a respondent was worded - do you agree or disagree with the statement ‘learning to drive is a lot of effort?’
1=Disagree
2=Neither disagree not agree
3=Agree

Is this an ordinal or nominal variable? Obviously there seems to be some rank order to it, but doesn’t seem all that different from a “Yes”, “No”, “Don’t Know” kind of question, which in my very very basic understanding would be a nominal variable?

Also if for instance, Respondents age was grouped into 3 categories:
1 = Young
2 = Middle
3 = Old
Would this be a nominal or ordinal, again there’s obviously a rank order to it but I read that Age should be considered a nominal variable?

 Or

If some was asked “how many days do you discuss sports”:
0= No day
1= One day
2= Two days
3= Three days
4= Four days
5= Five days

In my very limited understanding this would be an interval variable but again I could convince myself that it might be ordinal!",statistics
n7p48b,1620480072.0,[Q] Using R for hierarchical cluster analysis to segment products instead of customers?,"For those familiar with hierarchical cluster analysis (HCA) and segmentation on RStudio, what are your thoughts on applying HCA to segment products, such as movies, based on variables like their financial performance and characteristics (sales figures, genre, ad budget, etc).

Or is HCA only appropriate for segmenting customers based on their clear demographics and behaviours?

I'm trying to work out what movies in a large dataset are more successful than others. I'm still new to statistics, and I feel like HCA could work but have only learned about it in the context of a customer-based-dataset. Idk if this helps but I can only really work with simple stats tools like regressions, interactions, and principal component analysis to analyse my dataset.

Any help or insight appreciated!",statistics
n7jjjy,1620457359.0,"[Q] Mixed Ancova - Levene Test significant, what to now?","Hey guys,

I am running a mixed Ancova, I have two measurement points and I am using a categorial predictor. I also have Age and Gender as a covariate. When including Gender as a blocking factor and age as my covariate, the levene test turns significant.

However when including gender and age as covariates the levene test is not significant.

What can I do when the assumption is violated? I heard that a box-cox transformation is advised, but I have no idea how to do it in spss.

Also I am not sure which way of including gender is the ""best"".
Does it make the most sense to use gender as a additional categorial predictor, or is it better to include it as a typial covariat?

Best regards",statistics
n7hgd6,1620448855.0,[Question] Regression model with time-series data,"I am a first-year student so bear with me.

I have data that spans from 1980-2019 of Major League Baseball average game time and viewership share statistics, among other league average statistics (runs per game, etc). Would it be incorrect to make a regression model with the game time as the X and viewership as the Y, inferring that a _____ game time correlates to a ______ in viewership? Furthermore, viewership share is the % of homes USING their TV that watched the game. So I am hoping this helps prevent the lurking variable of increased/decreased tv habits over those 40 years. I have all the graphs and the regression summary which appear to show a strong correlation indicating that for every 10-minute increase in-game time, viewership drops by 6 percentage points.

I apologize if this is extremely simple, I'm new to the field. Thank you in advance for any insight :)

Edit: to clarify, the data has 40 rows with each representing that years averages. I.e. the time per game in a given row is the average of all 2430 games that year. Same goes for all the other stats.",statistics
n7d687,1620433789.0,[Q] Bayesian methods for sheep ancestry/parentage?,"My friend is a sheep farmer and the maintainer of a database of information for a particular breed that goes back (in the US) perhaps 40 years.
She has a particular sheep from about 15 years ago that is crucial to the lineage, but whose parentage is in question.
Genetics is not my area, but I’ve been listening to the Learning Bayesian Statistics podcast, and doing some reading. I know that Bayesian methods can be used to make predictions, but can they also be used to make “postdictions?”
That is, given the thousands of sheep in the database, many descended from the sheep in question, and others descended from other sheep (possibly descendants of mystery sheep’s parents) of that era and the interbreeding that has occurred since, would it be possible to determine probabilities of the mystery sheep's parentage?",statistics
n7cu8e,1620432677.0,"[Q] I have many observations (outcomes) generated using specific parameters, and I'm wanting to find the optimal combination (set) of parameters that maximizes the probability of a good outcome (and not necessarily the set of parameters that maximizes the outcome for the given observations).","This might be a simple question, but admittedly it has been a while since my statistics courses in college. I have a set of inputs (a, b, c and d) that produce output (e), some positive, some negative. I'm wanting to find the specific combination of inputs that maximize the probability of a positive outcome. For a while, I've been trying to find the set of parameters that maximize the outcome, but I've realized that a lot of this could be pure luck, or down to the specific circumstances at the time (which my model might not be accounting for), and so I'm wanting to rather find the parameters that would maximize the probability that I'd arrive at a positive outcome (i.e. where outcome e is more than some value x). I've performed multiple regression on my observations, which produces what I believe to be a sufficient Adjusted R Square (>0.6) and so therefore I have a feeling that the solution to this problem would involve multiple regression and a ""line of best fit"", but I'm unsure as to the exact approach to get to the ""optimal"" set of parameters. Here's an example of the data:

&#x200B;

|a|b|c|d|e|
|:-|:-|:-|:-|:-|
|\-0.15|0.9|\-3|475|790|
|\-0.15|0.7|\-2.4|925|780|
|\-0.15|0.9|\-3|525|778|
|\-0.15|0.9|\-2.3|825|729|
|\-0.15|0.8|\-2.5|725|725|",statistics
n78fom,1620420102.0,"[D] has anyone ever worked on a machine learning model for ""queues""?","Has anyone ever worked on a machine learning model for ""queues""? Suppose there is a bakery: the bakery has has ""n"" people working, ""m"" people in line""  and ""q"" orders that they are currently working on. The bakery is interested in making a machine learning model that predicts how long a customer will have to wait before the customer's order is ready and how long will the next customer have to wait before they can place an order.

Has anyone ever come across a machine learning model which can predict waiting and processing times? I have seen examples online where people try fitting exponential distributions to historical waiting times and see how well they fit, as well as trying different m/m/k combinations... but has anyone ever come across an instance where machine learning algorithms (e.g. random forest, neural networks) are used to predict waiting times?

I saw something like this: https://arxiv.org/abs/2002.10788

But there was no python or R code for this paper. Can anyone recommend some source (blog, github, website, book, YouTube lectures etc) which show and provide computer code for analyzing queues using machine learning models?

Thanks",statistics
n7738z,1620416594.0,[Q] Regression: Comparing two treatments occurring over different time spams,"I want to conduct an A/B test to test two treatments, but it's a little unusual, so I want to make sure the regression I run afterwards makes sense.

The sample will be split into two groups (control and test), and recieve a different treatment. Both treatments occur over a different timespan:

\* Control recieves the control treatment once a week for four weeks

\* Test receives the test treatment once a day for four days

Comparison will be by the average of a metric M over the 30 day period immediately after their last treatment.

So if say the start of the experiment is t=1, then all of the test treatment subjects will complete the treatment on t=4 --- while the control treatment subjects won't complete until t=29.

However, it's not so neat as that. The treatment (control or test) can start at any point in a 30 day period. It's possible, maybe even likely, that the effect of the treatment will vary from week to week, depending on the state of world that week.

I was thinking to control for this maybe I'd include interaction variables, something like (in R):

lm(avg\_m \~ treatment\*t)

where t is some representation of the time the length?

Is this a plausible experimental design? How do other people test in similar situations?",statistics
n763u2,1620414062.0,[Q] Drawing Questions from a Question Bank: How Many in Common?,"Hi everyone.

I'm a teacher and while we've been virtual for the past year I've adapted some of my quizzes to help curb the possibility of cheating.

For my quizzes, I have a question bank that the questions are randomly drawn from.  For example, the question bank has 10 questions and each student randomly gets 5 of them.

I know that in this example, the number of combinations is quite large and the odds that any two students get the *exact* same 5 questions is low.

10 choose 5=252

At first, it sounds like I've done enough to randomize the quiz.  However, I've realized that's really the right question to answer.  While they may not get the exact same questions, if two students are expected to get, say 4 questions in common, then I haven't really randomized the quiz.

How can I calculate the expected number of questions in common?  I studied math in college but don't use it much these days.  Also, sorry if this is obvious or has been asked before.  I wasn't exactly sure what to search for in order to find an answer.

Thanks!",statistics
n75xya,1620413638.0,[Q] Trading Card Probability,"Myself and my friends needed 100 more of the 225 trading cards in a collection. We bought 50 packets of 5 to make 250 cards. We got all of the 100 missing cards to complete the collection.

What is the probability of this happening assuming each card is equally likely to be in each packet (possibly multiple times)?

I am pretty confident the total number of possibilities is 225^250 - but really stuck on how to figure out the number of cases where all 100 missing cards are packed

My instant thought is that as I bought the packs in a box of 50 to be sold individually in commercial stores, the manufacturing process would create a set of 50 packs with as few duplicates as possible, therefore including virtually the entire set of 225.

Thank you!",statistics
n71668,1620401360.0,[Q] Confused about the sensitivity of a medical test (or any binary classifier) VS. probability of Positive given that the test is Positive,"Data scientist here looking back on some basic stats. Hope this doesn't qualify as homework question - it definitely isn't homework, but it's basic enough that I'm embarrassed to ask...

I'll take the example of a medical test as it is easier to reason about ""True Positives"" etc.  in this context, but this applies to any binary classification problem.

Suppose our test is applied to a sample of 100 people with the following results:

||Sick|Healthy||
|:-|:-|:-|:-|
|Positive Test|19 (=TP)|20 (=FP)|39|
|Negative Test|4 (=FN)|57 (=TN)|61|
||23|77|100|

&#x200B;

The sensitivity of that test is defined as the proportion of True Positives (TP) to the total number of positives - so in this case, `Sensitivity = 19/39 = 0.48`.

Now I was wondering: suppose we know the test is positive for a subject. What is the probability that that subject is actually sick? This is `P(Sick|Positive Test)`, which basic stats says is equal to `P(Sick ∧ Positive Test)/P(Positive Test)`. But from the table above, `P(Sick ∧ Positive Test) = 19/100` , `P(Positive Test) = 39/100`, and thus `P(Sick|Positive Test)` gives the exact same result as the sensitivity - which is obviously wrong according to what I've read about sensitivity. Where/what am I doing wrong here?",statistics
n6vr58,1620384823.0,[E] Advise for Masters Programme,"I'm currently doing an undergraduate program in data science (its mostly stats actually) and realised I do enjoy learning what I learn in my programme and so I was considering doing a stats masters programme.

My dilemma however is that although I like what I study, I'm not an individual who excels at stats compared to some of my peers who pick up the concepts more comfortably. I would say I'm just average and struggle pretty often with certain concepts. Would it then be advisable for me to continue with a stats masters even though I will probably face a large amount of difficulty or should I consider something else instead? Thanks in advance!",statistics
n6rui2,1620367886.0,[Q] Why Is Expected Frequency in a Chi Square Test for Independence Calculated With (Row Total * Column Total) / (Grand Total)?,"I know how to calculate expected frequency but I am having trouble understanding why it is calculated that way, if we are checking for independence then why do we not assume the observations will be evenly distributed? Again I know the method, I'm just trying to understand the reasoning behind it.",statistics
n6r0dz,1620364503.0,[C] Statistics Internship Advice,"Hi,

For a current undergraduate freshman looking to major in statistics, what advice would you give me to set myself up to be a solid data science/statistics internship applicant? I have basic skills in R, Java, and will be taking an online course in SQL. What else should I be doing or do you wish you had done? Thanks!",statistics
n6f52l,1620328596.0,[R] Do you report (simple) regression equations?,"I'm currently finalizing a paper that I plan to publish in a peer-reviewed journal. Before I reach out to my supervisor for such a small thing I thought I'd reach out to the community first. In my paper, I run a pretty standard fixed effects regression with only few variables. This is part of the results, but the regression results are only a small part of the work. From the perspective of a reviewer, would you complain if I don't report the regression equation? I've seen examples in journals like Review of Financial Studies, etc. both with and without reporting the equations and was just wondering if I'm overthinking this or if that's a common complaint if not handled correctly. Thanks in advance!",statistics
n6dz3x,1620325565.0,[Q] Obtaining p-values from rlmer t-values using Satterthwaite approx. df from lmer,"I found a technique on [stack exchange](https://stats.stackexchange.com/questions/430490/obtaining-p-values-in-a-robustlmm-mixed-model-via-satterthwaite-approximated-dfs) for calculating p-values using the approximate degrees of freedom from lmer and the t-values from rlmer. The [paper referenced](http://doi.org/10.1098/rspb.2019.0720) by the stackexchange post doesn't go into detail about why or how this works. Does anyone have a reference for this technique?

Here's what the code looks like:

    # fit a mixed model
    model <- lmer(tm_power_abs ~ condition * phase + (1|subject), data=powerProsLPar)
    # fit the robust equivalent
    robust.model <- rlmer(tm_power_abs ~ condition * phase + (1|subject), data=powerProsLPar)

    # get coefficients from non-robust model to extract Satterthwaite approximated DFs
    coefs <- data.frame(coef(summary(model)))

    # get coefficients from robust model to extract t-values
    coefs.robust <- coef(summary(robust.model))

    # calculate p-values based on robust t-values and non-robust approx. DFs
    p.values <- 2*pt(abs(coefs.robust[,3]), coefs$df, lower=FALSE)
    p.values",statistics
n6bawl,1620318580.0,[Q] Cronbach's alpha question,"I have 5 measures of structural disadvantage and was seeing if I could combine them into an index.

4 of the measures are percentages of social and economic variables and the 5th measure is median household income. An alpha test on the 4 percentages alone gives me a Cronbach’s α = .699 but when I include median household income the value drops drastically to .006. I am not going to be combining them into an index anymore, but I am interested is why the values are so different from adding one variable that should be correlated with the others. Is this because median income is measured on a different scale or is it simply that median income is completely unrelated to my other measures?",statistics
n6a2w7,1620315381.0,[Q] SPSS alternatives,"Hi All, we're long-time users of SPSS and are currently looking at alternatives. We conduct research into business use of software applications and services and have a team of three analysts using SPSS. We're looking into alternatives that are cheaper than the $99 per month per user that we're paying now for SPSS. We run on Macs as well.

Most of our analysis consists of the following:

* Simple pie / bar chart generation using syntax
* Means comparisons
* Frequencies
* Cross-tabs

We do frequently need to generate charts using the 'select cases' capability (e.g. to create charts showing adoption of an app for a specific industry). We use SPSS's chart template capabilities to produce custom chart layouts using our standard colors and fonts.

Beyond that, we really don't use the more advanced features of SPSS. Our typical data file consists of between 500 and 1500 records and a 100 or so variables.

We've started looking at Jamovi and JASP and are wondering if they could potentially be cheaper alternatives that are as easy to use as SPSS. We don't want to climb the learning curve for R and we are looking for something that has a more visual GUI.

Thought? Recommendations? Thank you in advance.",statistics
n69g3j,1620313709.0,[Q] Appropriate use of the cloglog link function in binomial GLMM?," Hi. I have boolean data from human participants per 4 conditions, indicating whether a given response was correct. I used a binomial distribution and compared ""logit"", ""probit"", and ""cloglog"" link functions. All things equal, cloglog gives the best fit with AIC. But is this link function appropriate for my data? (My data are quite asymmetrical, i.e. more TRUE events than FALSE). Thank you",statistics
n66uxb,1620306447.0,[Q] How to interpret the drop1() function and how to use Akaike's criterion?,"

When using the drop1() function it produces this:

Single term deletions

Model:

volume \~ factor(Implantaat) + factor(year) + factor(Implantaat):factor(year) +

(1 | Fret)

Df       AIC

<none>                                                        1360.1

factor(Implantaat):factor(year)   4         1359.2

Can someone explain what Akaike's criterion does and how to use it to determine if the interaction can be dropped?",statistics
n65o5k,1620302574.0,[Q] Which statistical test should we use?,"We are trying to analyze data collected from an experiment that we conducted for our graduate thesis research, and we need some help choosing the right statistical test.

For context, we are UX design students doing our master thesis, so we don't have much statistics knowledge. Our experiment involved letting participants play an FPS game with 6 different user interfaces and 6 different levels and measure their performance in terms of reaction time, accuracy, etc. The combination of level and user interface were randomized, meaning there are 36 possible combinations, and each participant played on 6 combinations of those. So we have 2 independent variables that are categorical, and 9 continuous/discrete dependent variables. The data we got could look something like this table below (for one participant with 2 of the dependent variables):

|User Interface|Level|Reaction Time|Accuracy|
|:-|:-|:-|:-|
|A|3|0.5|0.5|
|B|2|0.6|0.6|
|C|1|1.5|0.2|
|D|6|0.7|0.5|
|E|5|1.9|0.4|
|F|4|0.5|0.3|

Our goal is to see how much each user interface affect the player performance. But with this experiment design, the performance could be both affected by the user interfaces and the levels. Therefore we want to find a way maybe to remove the impact of the levels on the data, or isolate the impact of the user interfaces. We have looked into ANOVA, MANOVA, multilevel models, repeated measurements and some other tests but haven't found what we exactly need. Some suggestions with explanation would be appreciated.",statistics
n65ape,1620301267.0,[Question] Uncertainty in binary outcomes,"I have a larger problem but have presented what I believe is a minimal example.

Imagine that you are trying to determine the true probability of a potentially-biased coin landing on heads, and want to take a bayesian perspective. Our prior is hence that the probability of heads is beta(1,1) distributed. Say that we flip the coin once and we get a heads. Our posterior is now beta(2,1).

Then we flip once more, but the coin lands crooked against an object on the table. It looks like it would have landed tails, but say that we are only 70% sure that it would have landed tails (so 30% sure that it would have been heads)

Obviously the 'best' solution is to ignore and retest, but if these coin flips are limited/expensive that might not be ideal. So is there anyway to include this result even with the uncertainty? Possibilities I've considered are

1. Ignore result, p \~ beta(2,1)
2. Include and pretend we are certain, p \~ beta(2,2)
3. Include with uncertainty, p \~ beta(2, 1.7)
4. Include with uncertainty for both, p \~ beta(2.3 1.7)

4 seems reasonable, but I'm worried this is a statistical golem and I'm missing something obvious.

Cheers!",statistics
n640j6,1620296198.0,[E] Can anyone remember a Youtube tutorial for Bayesian statistics that used measurement of the length of a football field as its teaching scenario?,I have a vague recollection that the video had a black background with neon coloured virtual pen being used by the presenter. I watched it a few years ago and cannot find it anywhere.,statistics
n63nha,1620294660.0,[Q] Estimating a transition matrix with irregular time points,"I have a dataset which has variables `id`, `state_nr` (between 1 and 9, say), `date` and `nr_days` (the number of days since the first observation for each `id`). The observations were sampled at irregular time intervals.

I would like to estimate the probability of going from one state to any other state.

Can I estimate the transition matrix by counting the number of transitions between each pair of states and then normalizing these counts? I.e., can I just calculate

`M_ij = (nr transitions from state i to state j)/(nr of transitions from state i)`

to estimate the proportion of people going from, say, state 1 to state 7? Or would this be a bad idea?",statistics
n60nqk,1620281497.0,[D] perceptron convergence theorem,Has anyone ever heard of the percptron convergence theorem? Does this theorem basically state that a single perceptron can perfectly classify linearly sepperable data?,statistics
n5yfhb,1620272745.0,[Question] Evaluating/Critically Appraising Diagnostic Tests without a Reference," I may have the opportunity to consult on a project involving a new (first to market) diagnostic assay. What makes this different than projects I've typically worked on is that with this, I don't believe there is a gold standard method with which to compare performance. Most of the time, I am comparing to some reference through equivalence tests, ANOVAs, and the like.

So first question, in the absence of a gold standard, what statistical measures should I be considering for evaluating and critiquing the performance of this new diagnostic assay? Sensitivity and specificity come to mind, but what are some others?

Second question, I know I'm going to be asked, ""What constitutes an adequate sample size for our experiments?"" And similar to above, I typically calculate sample size using an effect size related to a reference (i.e. how small a change do we want to detect using the new method). But in the absence of a reference standard, what am I comparing it to? I feel like only a subject matter expert in the field of the assay's target would know anything about a proper effect size.

Very much looking forward to seeing what the community thinks.",statistics
n5xdfx,1620269090.0,How can I take notes and understand statistics in a college-level course?[E],"Next semester, I will be taking an economics statistics class that is supposed to be quite difficult. I did some pre-reading over the break in order to familiarize myself with the concepts before the semester, and I find myself rewriting 50% of the content in the textbook, and partially understanding what's going on. There are about 2 or 3 formulas per page, explaining the derivations, and one or two practice problems. One of my primary concerns is that I won't be able to memorize all the formulas to apply them on the exam or understand the concept presented. I was wondering if anyone could give me study tips, understanding the concepts, and how to take effective notes instead of just re-writing half of the content in the textbook?",statistics
n5wd74,1620265780.0,[Q] Are the Beta and Bernoulli Processes Normalized Random Measures with Independent Increments?,"Hi r/statistics ! I have a quick question about stochastic processes / Bayesian nonparametrics / random measures. [James et al. 2009](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9469.2008.00609.x)  introduced the notion of ""Normalized Random Measures with Independent  Increments."" Does anyone know whether  the Beta process and/or the Bernoulli process belong to this family?",statistics
n5vs4d,1620263876.0,[E] No Research/Internship Experience for PhD Application,"I am confident this question has been asked many times in the last 40 years, but I don't see any answers on reddit specifically for PhD, and only one amstat article from 2014 saying research experience is rare. Pardon my ignorance.

I transferred from a community college to a top university, and it looks like I will have no research or internship experience before the coming fall application cycle. If I have a 3.5+ GPA including proofs-based linear algebra, real analysis 1, numerical analysis 1, and probability + mathematical statistics and good GRE scores, am I likely to be admitted to any decent (not top 30) statistics PhD program, or should I just do a thesis-based master's first? The most my professors can say about me is ""went to class and office hours,"" and I will take complex analysis, mathematical optimization, stochastic processes, and linear models in the fall semester, but I don't know if I will be able to submit those grades in time.

Thank you for your honesty.",statistics
n5ugav,1620259577.0,[D] Overparametrized Models in Statistics,"everyone says that machine learning models with many parameters tend to overfit - that's why regularization (e.g. dropout techniques) acts a technique to bring parameters in the model towards 0, thus reducing ""over-parametrization"".

Why are overparametrized models bad? Why do they result in overfitting?",statistics
n5ua1z,1620259076.0,[D] trying to justify the performance of statistical models on a particular data set,"I have a small dataset (20 columns, 10,000 rows). I tried to train a random forest model on the data and got good results. I then tried to train a neural network on the same data and didnt get good results.

Now, is there any way to understand why the neural network did not perform well on this dataset? Can you breakdown the performance and the reasons why the neural network did not perform well? Something like : I forgot to study this section of the textbook so I did not perform well on the corresponding section of the test?

Are there some reasons (theoretical or empirical) that suggest why neural networks might not perform well on smaller datasets? In general, is it possible to say ""the model didn't perform well because these rows in the dataset gave it trouble, because the model is not equipped to handle this ""kind"" of data?",statistics
n5t174,1620255376.0,[Q] What does a negative R squared value mean? How do I interpret this? I ran a GLM model in R,My R^2 value is -0.001431,statistics
n5ssr2,1620254708.0,[Q] Is there a name for using the difference between separate regression models for control and treatment to estimate causal effects.,"This seems like a fairly intuitive approach to causal inference, but I have never run across it and I am wondering why.

Assume you have two regression models Y1 = E(Y|A=1,X) and Y0 = E(Y|A=0,X) where Y1 is fit only on the treatment group and Y0 is fit on the control group.  To get the average treatment effect you could imagine computing Y1-Y0 for everyone in the whole population and averaging.  This would be very similar to a standard regression except that the coefficients for X could be different between the two.

Is this a technique that exists and has a name already?",statistics
n5rk84,1620251355.0,"[Q] If you plot two Gaussian random variables against one another, the slope has a certain distribution. Nassim Taleb argues that the distribution of the slope allows scientists to ""game"" it. What does this distribution tell us, over and above the well-known fact that p-hacking is easy?","For context, the goal of Nassim Taleb's [video](https://www.youtube.com/watch?v=4Eb51iUDPkY) was to criticize psychologists for making a big deal out of small but significant correlations.

In the video, he develops the characteristic function of the slope of two iid random variables plotted against one another (X,Y are iid Gaussians, and he derived the chf of beta in y = beta\*x). I am not sure I understand what this distribution tells us - is it just telling us that the slope has some distribution, and that it's therefore not guaranteed to be zero (even when the variables are independent)? Or is there something more?",statistics
n5naq1,1620240270.0,[E] What mathematical concepts/applications should I review before starting graduate level statistics?,"I was recently admitted into an MS statistics program for this fall. I have some time to brush up on some skills before my classes start. I have taken Calc I-III, linear algebra, and elementary DE. Thank you!",statistics
n5mxj8,1620239334.0,[Q] Likelihood of winning an rng wheel?,"Not sure if this is right place or format, but I am curious about the odds of something. My friends and I are entered into a wheel. 10 total participants, we have 3 spots. The wheel will be spun 5 times, and each time a name is picked it’s removed from the wheel. How would I calculate/ what are the odds of each of the following: we win 0 times; 1 time; 2 times; 3 times?

I believe I calculated the odds of winning once at 91.67% and the inverse (winning 0 times) would be 8.33%.",statistics
n5mrf5,1620238896.0,Mixed model plotting [Q],"Hi everyone,

I am running the following mixed model:

lmer(score ~ group + time + group*time + (1|sub), data = df)

Score is a continuous variable, group is control/treatment, and time is a pre/post measurement (time 1 time 2). Subject is modeled as a random intercept.

I then plot this with the lsmeans package in R.

The problem I'm having is that at Time 1 the groups don't start from the same place, so the effect of the intervention is somewhat difficult to interpret at the second time point. In other words, the baseline looks uncontrolled for, even though I'm controlling for baseline with subject as a random effect. Does anyone have any suggestions for this?",statistics
n5mml9,1620238552.0,[Q] What are some approaches you've been using to handle forecasting in light of COVID?,"The data I'm working with is yearly enrollment figures for schools in a state, going back to 1984. It follows what could be sinusoidal trend (one period, not enough to say that it's a seasonal pattern), with a precipitous drop in 2020 due to COVID. There is very little noise in the dataset with exception of this one COVID related drop.

I'm not really sure what to do in this situation. What I'd like to do is capture is the uncertainty of creating a forecast in light of one datapoint that departs from a long term trend. Or at least, be able to present pessimistic and optimistic forecasts. I think enrollment will eventually fall back in line with that trend, but without additional data it's unclear how fast that would occur.

Any ideas?",statistics
n5ma7m,1620237715.0,[E] Summary Song #10 - The ROCk Curve (Stats Parody - Foo Fighters The Pretender),"Hello, I'm back with the latest (and final) parody in my professor's series. Hope you like it!

Link: [Summary Song #10 - The ROCk Curve (Stats Parody - Foo Fighters The Pretender)
](https://www.youtube.com/watch?v=Ae46DDN2K0A&ab_channel=RafaelMoral)",statistics
n5k7jg,1620232540.0,[Q] Creating an index with PCA (principal component analysis),"Hello everyone,

I have run a PCA in Stata with 4 components.
Of these 4 components, only the first 2 have eigenvalues > 1 and their cumulative variance explained is 0.72.

I want to create an index using these two components, but I am not sure how to determine their weights.

I was thinking of weighing each component by the variance explained, so that Index = PC1*(0.52/0.72) + PC2*(0.20/0.72).

Is it correct? Are there more precise ways to weight the principal components?

EDIT: do I have to “rotate the components”? I didn’t understand what this procedure implies.",statistics
n5ic23,1620227846.0,[Q] Is there anything weird with this coding scheme...,"It feels strange to me, but I'm not sure if it's just an approach that I'm less familiar with.

Lets say it's a study where people look at pictures and rate their pleasantness. The pictures are coded for the objects they contain. Imagine these are the predictors:

* Picture contains only a tree (0/1)
* Picture contains only a mountain (0/1)
* Picture contains a tree and a mountain (0/1)

My instinct would have been to just have two variables here, one coding for the presence of a tree, one the presence of a mountain. But this study has done the above instead.

Is this a common approach? Am I right that there is something strange with it?

*Edit* Let's also say there are also the following predictors:

* Picture contains only a river (0/1)
* Picture contains a tree and a river (0/1)
* Picture contains a river and a mountain (0/1)",statistics
n5hwho,1620226747.0,[Q] Including gender [male/female/nonbinary] as a covariate in ANOVA SPSS,"Hey guys,

I am running a repeated measure ancova with Life Satisfaction as my DV. I have a significant influence from the gender variable \[male/female/non binary\] on my DV. So I want to use it as a Covariate. All the necessary conditions for running an ANCOVA are satisfied, but I am unsure of one :

To check if the interaction between the IV and the covariat is non significant, I ran an normal ANOVA with my IV and Gender as my between subject factors and Life Satisfaction as my DV. The interaction between the IV and the Covariate Age turned out non significant. Is this the correct way to check for the assumption?

Also I am unsure whether I can simply include the gender variable as a covariate in SPSS. I know that categorial variables can be included if they are dummy coded. But since the gender variable has more than 3 categories I am not sure if I can just do that.

Note: There is only one Person in the non binary category.

Thank you guys in advance!!!",statistics
n5hvsr,1620226693.0,[Q] Does it makes sense for my null hypothesis to be mean < 2.5 and alternative hypothesis mean >= 2.5?,"I've read that the null hypothesis will definitely have a form of equality. But if the case above is possible, is it possible to do a t-test with 2.5 as the test value?",statistics
n5hcte,1620225296.0,[Q] Help Understanding the Limits of Chi-Square Test for Analysis,As far as I understand a chi-square test tells us if the overall distribution of frequencies differ in what is observed vs. what is expected. Is there a way to discern which categories specifically seem to deviate from what is expected?,statistics
n5gcmo,1620222530.0,[E] French-language beginning statistics textbook,"Hello all, please forgive me for an off-the-wall question here.

I am learning French, but obviously most of the language instruction won't cover topics in things like statistics.  I wanted to enrich my learning by reading through a familiar topic in the language I'm learning.  Does anyone have a recommendation for an introductory statistics text that is published in French?  Thanks!",statistics
n5fje2,1620220174.0,"[Q] How to compare metrics? (QWK, MSE, r)","I have two machine learning models trained on the same task using the same data; call them A and B. I have calculated the QWK, MSE, and r for both models using their predictions on the test set. I want to use these metrics to determine how much better (or worse) A is than B.

How should I go about this? My supervisor has led me to believe I can just subtract `QWK_B` from `QWK_A`, and that the resulting QWK delta will represent the gain (or loss) of A over B, but is that correct? And what about MSE or r? I’m pretty sure literally subtracting the metrics in those cases is not valid, in which case I don’t know how to compare them.

Any advice appreciated, TIA!",statistics
n5e89u,1620216014.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
n5dz2c,1620215131.0,[Career] Can a statistics-heavy thesis make up for a non-quantitative degree?," Long story short, I am currently finishing my master in health economics. The degree involves some statistics, but not nearly as much as a degree in econometrics or statistics. Most of the people in the program have a background in medicine and therefore the math is rather basic.

Since January, I have been working on my master thesis in cooperation with a well-known pharma company (market access department), which is centered around (Bayesian) health economic modelling. Everything is coded in R and Stan. My supervisor and me will try to publish an article based on my thesis, preferably in Medical Decision Making, but it is not clear yet whether that will work out.

Throughout the course of this project have found that I enjoy statistical modelling a lot and am considering a career as a statistician or data scientist, somewhere in the pharma/healthcare industry. However, it seems that for such roles employers demand a strictly quantitative degree like statistics/econometrics/mathematics/computer science etc.

I did a bachelor in economics which gave me a solid foundation in math and statistics that I am currently refreshing. I now really wish I did a master in econometrics/statistics instead of health economics, but it's too late and I don't really want to do another master.

Do you think I have a chance of landing a job as a statistician/data scientist? Maybe someone has experience in the industry and could help. I live and work in the EU, if that matters.",statistics
n5czn9,1620211471.0,[Q] Defect counts in control?,"I monitor a process that tracks the presence of defects in 10 specific places. Each of the locations can have the following level of defect, none, trace, very light, light, moderate, moderate to heavy, and heavy. I don't much care about the defect level, just if the defect is present. Any level of defect is just a varying degree of bad, the goal is to have none. What kind of statistics can I do on this to keep track of the process to make sure it's in control. The data is not normally distributed, the mean is 0.89 and the median is 0. The histogram is skewed to the right, trails off to very low frequencies up to a count of 10. It's uncommon to ever have 10 locations with defects, but it has happened a few times. I have looked a days between defects, that data still doesn't look very normal. Any suggestions would be appreciated. I want to track this process correctly, it's very important to know if this process is in control. Where can I learn about this? Thank You",statistics
n5ckkz,1620209778.0,[Q] Effect of underreporting on estimator in linear regresion,"Hi, sorry as this might be a dumb question. I'm taking an introductory level econometrics course that uses statistics, particularly linear and multilinear regression.

I'm having trouble understanding a particular concept in how the underreporting of data affects the estimator. Given that the rest of the terms are unbiased, and that the regression formula is: Y\_i = Beta\_0 + Beta\_1 X\_i + u\_i, why does an underreporting of the X variable by 20% cause the Beta\_1 estimator to be biased upwards by 20%?

I have assumed that the Beta\_1 estimator would be biased upwards by 25% instead, since it would need to fulfil (\\hat Beta\_1)(0.8 X\_i) = (Beta\_1 X\_i).

I have already asked my professor, but he redirected me to the textbook that gave me [a rather unconvincing argument](https://gyazo.com/1b88f2f51589da31bf283284aa2bd1f9) that had no explanation. Thank you.",statistics
n59tsi,1620198295.0,"[Q] Bootstrapping confidence intervals from data that is also simulated, then repeating...is that a thing?","This is confusing me since I'm essentially doing simulations of simulations, which feels incorrect right off the bat.

What I'm trying to do: figure out how many samples I will need to collect so that the bootstrapped confidence intervals of my metric of interest (i'll call MOI) are within a certain lower limit (no formula exists to calculate this directly).

What I've done:

1) Run a data simulation for some N patients where a score predicts whether they are sick (in this case I simulate it to have an AUC of ~0.92). With a massive sample size, the MOI is 10, so I'm considering that the ""true"" value.

2) Run the boot() package in R to bootstrap the CI for for MOI using 1000 replicates (I focus on the bias-corrected and accelerated CI) - I want to see what initial N (sample size) I need so that my confidence interval lower bound is reliably above a certain value (5). The upper bound doesn't matter.

With n=200, I get an estimate of 9, and the boot() package gives me a CI of [5 - 17]. However, this of course depends on the seed...the next run gives 29 [12 - 93], the next  10 [4.8 - 19].

With n=500, I run the script many times and the lower limit never dips below 5. But how do I eloquently do this - i.e. repeatedly simulating the data, bootstrapping the data, then checking the distribution of results until I find an N where <5% of these (fake) studies have a lower CI for MOI that is <5...is this ludicrous?

edit: initial post had some weird numbers - fixed",statistics
n58o9p,1620193989.0,How to predict the likelihood of the next number in a sequence? [Q],"

Where do I learn about this?

I'm a noob trying to figure something out. To keep it simple let's say I have a sequence of just 0s and 1s and each has approximately a 50% chance to be the next number when taking the whole sequence into account. Like this:

0001011101011110001010010101010111100010000111 ..... forever

But the numbers in the sequence are not random.. they are based on some variable unknown to me and just happened to end up almost 50/50, so some patterns start to form that would not be likely if each number truly had a chance to be 50/50 each time. Is there a way to come to conclusions such as: ""if 0 occurs x times in a row, a 1 being the next number is likely to happen x% of the time?"" just using statistics and not actually knowing the variable which affects the next number.  Is this possible? and if so how would I do it?

&#x200B;

Here's the actual sequence in question, turned to 1s and 0s to fit the example, it starts from the bottom and goes up.

>!01001101001101011101110011001001011111010001001100000110011111101001011100110111101101110001110000101011010110100110101011110100011010100011110101101110100001110100011011111110110010111111101010011110110101011111010110101110001101111011101011100111011001011010011010110101001011100101010010001010000000101011101111010100110111010110101101101110111110011100011110001111101110110101111010101011100110010010001110011101110111010010111010011100000010111010011111001111100001111010011111001001001001110100001001110011101011101111111101001001101110000010001101110111100111110011101111001111101101100001000101000110111010011000001110111001000000101000000101010000111011111000010111100111101000011110100011100110110111101110101010001011101111010001010010111101100101110100111010110111010010001010000110111000111001111110010001001101110101101111110110010011001111000010101011010010010111110110101111110110011111111010111101110010111111001100101100011011000110001101110110111010110001100100110011001111111001001011101101011010010001010100111000100001011100010101110110111111101110000110101010101011000110011010101111110010111101010011110000000001001101010101100101100111001001000110001000100110101010111001101010101011111010111100101101000001110110101101010100011100010011010111011101010010111000111100111011111001101001110000011001101011010101100010001001110011101000100101010101010001000011001001100111001111011111000001001101101011001110000001101010010001110000011101111010011000011011100111000101001001001110001100110010111010011011101100110000101010100101001000101001110100101101001011110000011000001101111100010001011001011101111011111001101011011110100010011000101000111001100100010111011110110110101001010111010101101001110101001111110001111011101111011001110101001110101111110011000111100100101100100110101110101011101111010010100011001101101000100111101010000110000011011000111011010110011110111110111100100100100000111101111111011001101000010010001101011001111011111111010111010011010001100101010001010111101111101101111100100111101010101010100011011111110110100101110101101001011111111001100101100000101100111111001110011111000110011011010010011101000011110100000100111101100101001010011100111111000011000011101000000111011010011110101011100010111100000010010001011110100100110000011000110001110111110001011110111001011101110000101111101111011101011111011000101110011100000001011011011001110111010101110111001011100001111100100011110111001011101000100000001101010100011011111000111101101000000111100011000101110000111101110111000010110110111011100010010011011000111011101111011011111001101100010100111011111011111101110001001110000100111110101111101101111001010010100011010111101111010100001110000100101100011101101011111100000100001101011010011001010100010010100001011001101101111110111011100110011101110111111010011110101010011001010001011011111101011111101011110010111010100011101011111101000010010110111111000010001010111011111000011101111001100100111100111011011110100101010111011000110100101111010000101000101011010011010111011100111100110100110111101010000010000001101110100011110101101001010111011001001010101101101111100100100010010110100100101001000000001011000110101110110000111011100110011011000110101101110001010101100101010011100101000111101001111010101011000111001111001001110110001110100101000101000111010101110100011011011000001011010#N/A0010111101001101011001111010101001000010101011001100100100101100101100101101111001011010010110110001011101101001010100011101111100100010101110110001111110001101001010111110001001011111011111101001101110110111010001000001011100011011110001101001111010100011000101110110011011100110111111011100011011111110111011011100111100101101111001101110101011111010000110010011001100001101010110100100011000100011101110010001000101101011100011101101001110010010100111111010000101101001110101010010111011010010101111100101110000111100101101011111110011101111011000110101100001000011111110001100010110110101001101010101000111011101011011111110110010001001111101001011011011011110010100101101010101100011011110010101000100101001110101110101111101010111011100001101010100001010111100111011001010011010110011000111111111001101100010010110110100101101111010111011110101111001100001111100101000011101000110001101011010111011011111101000110001110001011101110010001110110100000110100001110111100000100110110110100100101110101111011110110111011001010010111101000010001001101110101101011010111110100010010101100101111111101011110111110101000101101000110011011001010100110111001111101111100010011001010011001101011010011011000010111111110010100110101001100010000110110010000010#N/A1001011100011000100110100000101011001101000111101001010111011110100001001100100011001110100000101101011001111000111101000010001000110001001000110010100110100001100110110010000110000001001010101010001110010101000110101101011010001011000001100111001010010001110111010111101000011001001100101110110111100011101100100110010110110110000010000100001010101001100100111011100010101100100010100001110000100101111000100111111000001011011100011101011010001001110001010100111101001000001001000010101100111011101110001001111100100001100111010110100011000001010111001011001100000110001000000100010001001100101101010011001111111000100100111110110110101001010111000100110100100000111100010001010101011000001100110100111101110001100111110011010110101001011000100010110011110!<",statistics
n564t6,1620185103.0,[Q] Looking for a statistical method that allows me to spatially distribute a value within a cell to it's surrounding cells in a geometric-series-like way.,"I have a grid with some cells containing vehicular activity, and some cells that don't. I'd like to fill these cells that lack information according to their surrounding cells, such that if the cell is next to it, it gets a fraction of the cell's value.

For example:

    o o o o o o
    o x o o o o
    o o q o o y
    o o o o o o

In this example o and q are empty cells, and **x** and **y** are cells with information. In this case I will use **0.5 * (1/2)^i** to determine the maximum fraction the filled cells will distribute to their surrounding cells. Where **i** is the ring surrounding the filled cell, **i = 1** is closest.  So the cells in the first, second and third ring will get 0.25*x, 0.125*x and 0.0625*x, respectively.

Since **q** is in the first ring of **x**, it should get 0.25/8 times the value of **x**, since there are  8 cells surrounding **x** in the ring that has allocated a maximum of 0.25 times the value of **x** and each should get an eighth of this maximum value.

Also, it should get 0.0625/24 times the value of **y**, since **q** is in the 3rd ring from **y** and there are 24 cells in this ring.

In this way the filled cells should keep at least 50% of their initial value and distribute the other 50% ad infinitum to their surrounding cells. I clearly plan to truncate this, but that's besides the point.

I don't know if this procedure i have described has a name or if there is a better way to do it, so I'd appreciate any guidance here.",statistics
n53f3y,1620176595.0,[Q] Moderation v Mediation," Every time I look up the difference between moderation and mediation I understand the basic examples they give. However I still don't think I have it right in my head (and my supervisors agree). Using this specific example, can any one explain the difference between self compassion mediating the link between social support and mental health, and self compassion moderating the link between social support and mental health? My previous thoughts were that the former would mean self compassion is necessary for this link to exist, and the latter meant self compassion would increase the strength of this link. Thanks so much in advance!!",statistics
n51cht,1620170519.0,[Q] Will effect size estimates be more accurate with a larger sample?,"My question is: if I run 50 studies with 100 participants, and 50 studies with 200 participants, all examining the exact same effect in the same way, will effect estimates be more uniform in the second case?

I know that effect size is supposed to be independent from sample size. But it makes sense to me that with a larger sample size we should get a more accurate estimate of effect size. This seems to mean that these estimates will vary more so across smaller studies.

Is this true?

And then as a kicker, will they vary more as a function of the effect size? That is, if there are 50 studies examining an effect with an effect size of Cohen's d of .1, and 50 studies examining an effect size of .5, does it make sense to expect more variation in effect size estimates in the studies on the smaller effect?",statistics
n504t1,1620167137.0,[D] basic questions about linear regression,"1) often we are told that linear regression models with many beta coefficients are ""undesirable"" (e.g. 100 beta coefficients, 100 predictors) - in general, these models are said to be unstable, high variance and likely to perform poorly. Does anyone know why this is?

2) this is a common sense question: suppose you have 3 variables (1 response, 2 predictors). You make a plot of these 3 variables and you notice that the plot of this data is clearly NOT linear. Therefore, you would decide NOT to use a linear regression model. Is there any mathematical logic that shows why a linear regression model is unable to well represent non-linear data? For 3 variables, i guess you could show this visually - but for higher dimensional data, what is the mathematical justification used to understand why a linear model can not capture non linear data?

3) in the previous question, i asked if linear models are ""too rigid"" to capture non linear patterns. But what about the opposite? Suppose you take the same example with the 3 variables : 2 predictors and 1 response. This time you have new data and make a plot, and the data appears to have a strong linear patterns. In this example, if you had still chosen to use a non-linear model : has their been any mathematical research that examines the ability of a non-linear model to capture linear patterns? In this example, would a linear model have some advantage at recognizing and capturing linear patterns compared to a non-linear model? Or in general, are linear patterns completely within the domain of non-linear patterns and as such, non-linear models are not expected to have any disadvantages at recognizing linear patterns (compared to linear models)?

4) Are non-linear patterns more likely to occur in bigger datasets (more columns and more rows)? Could we not say that if there are more data points, there exist more geometric configurations that these data points can be arranged in -  making non-linear arrangements more probable?E.g. any 2 points can be connected with a line, but 3 points can begin to be arranged on nom linear arrangements.",statistics
n4yf8k,1620162745.0,[Q] Can Bonferroni (or Holm-Bonferroni) be applied to a non-independent collection of two-way ANOVA p-values?,"Hello, I'm a computational biologist. We have an experimental setup where we are testing effect A, effect B, and their interaction, on the genes of response organism Y. Y has many genes which we measure. Therefore, if I think about it one gene at a time, the analysis looks like a straightforward two-way ANOVA:

gene_response ~ A + B + A.B

But like I said, the organism has many different genes. In one replicate, we measure all of these.

In similar studies, people will do a straightforward multiple comparisons correction, dividing alpha by the number of genes.

But in those similar studies, there usually isn't the two-way factorial treatment structure. They amount more to a single t-test per gene, the result of which is corrected for multiple comparisons.

Is it ""allowed"" to adjust p-values from different ANOVAs the same way you would from different t-tests? And as a follow-up, imagine I picked Holm-Bonferroni. Would I line-up the p-values from each independent varianble (i.e. all the A main effect p-values, then in a separate list all the B main effect p-values, then in a third list all the A.B interaction p-values), or would I make one ""master list"" first?

Thanks!",statistics
n4xjl3,1620160579.0,[Question] Indicating the difference between missing and censored data?,"So I'm working with a dataset. Let's say I have a variable ""time to fever clearance"" or TFC. There are missingness markers for censored stuff like -7=""discharged before clearance"" or -8=""died before clearance"", and then there is blank for actual missing.

I'm going to be doing regression on this data, so I can't really keep values of -8 and such. So how do I indicate the difference between actual missing vs censored without keeping values like -8 in my dataset? Should I just make them all as missing? Should I learn to work around the negative indicators? Or should I make a new variable just for indicators and mark the rest as missing in the original variable? How would I take that into account in my regression?

Thank you in advance for any help. (Also, I'm sorry if this is a dumb question, maybe I'm overthinking it.)",statistics
n4w4a6,1620157115.0,[Q] Will p-values vary more from study to study when the effect is small rather than large?,Just want the title says. If you run ten studies with n = 50. Will the p-values vary more if examining an effect with Cohen's d of .1 vs .5?,statistics
n4vyak,1620156693.0,"[D] ""Classifier Technology and the Illusion of Progress"" (2006, Hand)","https://arxiv.org/abs/math/0606441

I found this interesting paper over here, where the author argues that more complex algorithms (e.g. deep neural networks) do not always have significant advantages over simpler algorithms in the real world (hence the illusion). The author brings up many reasons as to why this can happen - some of the reasons are related to mathematics, others are related to experimental design.

(Note: the author brings up a point here that I am not sure why this is true: ""Conversely, in
the two-class case, although few real data sets have
exactly linear decision surfaces, it is common to find
that the centroids of the predictor variable distributions
of the classes are different, so that a simple linear surface can do surprisingly well as an estimate of the true decision surface"" ...

Why is it common  to find that the centroids of the predictor variable distributions are different? Why does this allow for a linear surface to estimate the true surface well?)

Here were the thoughts I had after reading this paper: This was paper was published in 2006, before the ""deep learning revolution"" (e.g. in 2012 when Convolution Neural Networks clearly outperformed humans at the imagenet competition). Is it possible that the results from this paper are somewhat irrelevant and outdated? Researchers, universities and companies (e.g. google, Facebook, Microsoft) have probably spent a billion dollars since 2006 on developing more and more complex machine learning models. Using common sense, many of these models have performed well enough so that more research will be done in the future. I agree that for certain problems, perhaps simpler models (e.g. linear regression, decision trees) can perform just as well as deep learning models ... but surely, there are many problems in the real world which require more complex models? Can an argument made as to why complex models are required, using concepts such as the VC Dimension (https://en.m.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension)? Relating to problems such as the initial ""x-or perceptron"" problem - could we not say that big data (data with many columns and many rows) is less likely to be linearly sepperable (i.e. harder to ""shatter"" - shatter =  classify perfectly) compared to smaller datasets? Could we not say that if there are more data points, there exist more configurations that these data points can be arranged in -  making it less probable for them to be analyzed using a simpler model (the VC dimension of a simpler model is lower than the
VC dimension of a complex model) ? Does this fact alone somewhat justify the need to develop complex models?",statistics
n4vh1v,1620155563.0,[M] I discovered RIOT GAMES lying about the existence of LOSERS Q in League of Legends by using statistics. At least read the funny introduction.,"Introduction: Matchmaking in League of Legends apparently uses algorithms to put all their undesirables who have soaked up a high ratio of reports together on a team.  This is known as loser's q.  If this was not the case, you would see feeders on your team 50% of the time and 50% on the other team.  Yet I played over 3100 games in the past two years, and 80% of the time the feeder was on my team.   Calculating coin flips can be done in this link: https://www.wolframalpha.com/widgets/view.jsp?id=d821210668c6cc5a02db1069cc52464f

We have 2480 heads out of 3100 coin flips and it ends up being 1x10^-261.  And one of the cover up agents said, ""This is nothing more than common statistical variance"" LOL.

You know how cover up agents are right?  They deny, censor, insult, push misinformation, redirect the conversation, discredit, etc etc.  But the truth wins out!

Read: https://crystalfighter.com/lol/loserq/loserQScience.html if you want to see the breakdown of the last 51 games and discussion of the previous 3050.

Read: https://crystalfighter.com/lol/loserq/coverup.html if you want to see the attempt at coverup that was more than revealing... That moment when they try and hide stuff so well that they just show their cards to you.",statistics
n4t3s6,1620146892.0,[E] Brand New Stats Student Doing Into to Stats (Need Help),"

Hey everyone! I have some data and I am told I have to rank it by ordinal rank. I am confused as the prof is asking us to "" Look for tied values. The count row shows you which ranks are used up by the tied scores. Break any ties by assigning the average of the ranks involved to all the tied scores. ""

I am unsure what to based on that. My two number sets are as follows:

63,64,67,69,70,82,85,88,96,97

11,12,13,13,14,15,15,16,17,18

Any help or advice on how to do this would be great. My book isn't really helping :(",statistics
n4sv2j,1620146322.0,[Q] Can I use one way ANOVA here?,"Hi,

for different sets of data (4 groups), I have been asked if assumptions of variance equality were met, since I used one way ANOVA to test for statistical significance. I am not an expert on this at all, so would appreciate any insight you might have for me.

For some analyses, variances were unequal based on Bartlett's test using Graphpad Prism. Based on my research and limited understanding, this may not be an issue and I could still use one way ANOVA if the samples have the same size. Is that correct? Does ""same size"" mean that samples have the exact same number? In my experiments, the sample sizes are roughly the same, as in 45-54 or 30-45. So can I still use one way ANOVA or would I have to change my statistical test?",statistics
n4qk0o,1620140680.0,[Q] Need help understanding joint probability of three variables,"Hello all. I am describing the environmental conditions at the site of an offshore wind turbine. The sea state at the site is described by three stochastic variables: **wind speed**, **wave height** and **wave period** (or frequency). The code for designing offshore installations (DNV-OS-J101) demands:

>""Wave height according to joint probability distribution of wave height, wave period and wind speed"".

In other reports on (basically) the same issue, the following is done:

* Wind speed governs the wave climate. The wind speeds are divided into say 2 m/s intervals, and the probability of the wind speed falling within a given interval is calculated.
* The corresponding wave heights and periods are calculated.
* Example: say there is a 0.1 probability of the wind speed being between 2 and 4 m/s. The wave height and wave period with a probability of 0.1 is calculated from their respective CDFs.

As i understand, the joint probability is given as P(X=x,Y=y,Z=z) where the capital letters are stochastic variables. In the above, P(windspeed=2..4)=0.1, and then the other two variables are isolated from P(waveheight=y)=0.1 and P(waveperiod=z)=0.1. I am doubting whether this is a joint probability distribution, and I suspect I may be missing a major part of understanding what joint probability means.

I do have the CDFs and PDFs of all three variables, so the question is really what I should do to obtain the wave height, according to the joint distribution, as in the quote above. Any insights will be much apprechiated, and please ask questions if I should include more info.",statistics
n4oa89,1620134763.0,[Q] regression equation for testing,"230 data, 200 for creating the regression equation, and 30 for testing, how can i compare the actual value vs the predicted value and find the error percent? Will i average the 200 data to compare it to the 30 data? And how can i get the error will subtract the 30 predictive values to the average actual values?

Thank you for answering.",statistics
n4np0i,1620133027.0,[Q] Theoretical vs applied stats programs and biostats vs regular stats program?,"So i'm planning on getting a masters in stats to go with my degree in evolutionary biology in order to be a more attractive candidate for jobs in and out of academia and I'm uncertain whether to get an  applied or theoretical stats degree? In addition, while I'm not super interested in public health and medicine, I do want to target my statistics towards areas of ecology and animal behavior (working for fish and game, or university animal behavior labs that sort of thing) I still don't know if I should apply for biostats programs still even though they focus on public health. Any advice would be enormously appreciated!",statistics
n4mzd9,1620130808.0,[Q] Any good books about an introduction on Survival Analysis?,,statistics
n4mc6f,1620128841.0,[D] PreDoc Programs in Statistics/ RAship for Students,"I am currently exploring the option of pursing a PhD in Statistics ( Motivation mentioned at end)

I am currently doing Masters in India at one of the top institutes. I have good grades, both in my bachelor's and also in Master's till now.
No research experience but going to work on a research project in Summers which may lead to a paper if I can prove some Results.

My question to the community is that are there any PreDoc Programs like those present in Economics for students. These Programs allow students to work with an instructor for a year on a research project and also take some papers at the institute before ultimately going for a PhD. Alternatively, referred as RAships.

I searched on Google but didn't find anything.

Will I have to contact an instructor personally to get such an opportunity? Is it possible to get funding for the same in US or anywhere else?

My reasoning for searching for a RAship is to get admission into the top places for Bayesian Statistics- Duke, Columbia etc. I am definitely not at that level right now but would like to give my best efforts to get there and work with the best minds. Alternatively, what do I need to do to get admission in thes top programs for Bayesian Statistics.

Also, Alumni from my course have been placed in Top 50 Statistics PhD Departments but none in Top 20 in last few years. All went directly for PhD.


PS - Motivation : I took a course on Bayesian Modelling this semester and really enjoyed it. It is something in which I would like to work further. I talked with my instructor and he said that the best way to work in this area is to do a PhD and then search for opportunities in Academia or Corporate Research.",statistics
n4maxn,1620128719.0,[Q] What would be an appropriate statistical analysis?,"

Hi all

I am a bit confused about the statistical analysis I should perform on my data (when I have it). I have been advised to do a multi-level regression model but what I am looking at doesn't make sense. Alternatively, I have thought about doing a multiple regression. The measures are made up just to give an idea...

My IV is the score on an anxiety test and the three levels are control , at-risk and clinical.

My DVs are IQ score, performance on a breathing exercise and questionnaire and support network.

Confounding variables are stress and depression.

I want to look at if anxiety has a relationship with IQ score, breathing and support network.

I then want to see if IQ and breathing have a relationship with support network.

Finally, I would like to see how the three groups differ on the DVs.

Any help would be appreciated.",statistics
n4kud9,1620123350.0,[Q] Distributions for (parametric) PH and AFT models in survival analysis.,"When estimating fully parameterised proportional hazard (PH) or accelerated failure time (AFT) models, we select a distribution according to our assumptions made on the dependent variable, and then model the covariates effect on either the hazard or the expected duration.

I get that some distributions, for example the Weibull, can be used in both cases, but others, for example the log-normal, cannot be used in PH models. Why is that? I suspect that it has to do with whether the relevant hazard function is monotonic or not, is that correct? My text book (Cameron & Trivedi, 2005) doesn't really explain why.",statistics
n4i0w4,1620111327.0,[D] Inevitable Manual Work Required in Statistics Projects,"I have feeling that not many people are willing to admit - but ultimately, is a significant part of many data mining projects (e.g. checking data quality, parsing through data, etc.) still done manually?

For example here is an example I just made up relating to Supervised NLP (Natural Language Processing) Classification : Suppose I have 1000 medical reports of patients, containing unstructured text made by a doctor during a hospital visit. For a given patient, each report contains all the text notes that the doctor made for that patient, for visits between 2010 and 2020. These reports make mention of the patients bio data (e.g. age, gender, medical history, etc.) and the details of the symptoms that the patient is experiencing over a long period of time (e.g. let's say that these reports are 2000 words on average). The problem is, different doctors have different styles of writing - each of these 1000 reports is different from another. If a human were to read the report, the human could figure out what happened to the patient - did the patient have a serious condition (let's call this ""class 1"") or a non-serious condition (let's call this ""class 0""). This is what we are interested in predicting for future patients based on the limited medical notes made by doctors for these future patients.

The problem is - there is no clear and fast way (not that I know of) to take the 1000 medical reports that are available, and label each report as ""class 1"" or ""class 0"". For example, for ""class 0"" : one of the doctors could clearly write at the end of a report ""all medical tests were conducted and the results and were all negative"", and another doctor could end the report by saying ""the patient should seriously consider changing their lifestyle and eat healthier food. benign."" .

In this example, how would someone assign labels to all these 1000 cases, without manually reading them and deciding if the information in the report corresponds to a ""serious condition"" or a ""non-serious condition""? I was thinking of using something like ""sentiment analysis"" to capture the ""mood"" of these reports, and use sentiment analysis a method to informally gauge if the tone of the report is ""dark"" (serious condition) or ""light"" (non serious condition). But I am not sure if this is the best way to approach this problem. Is there a way to do this without reading all the reports and manually deciding labels?

In the end - this is what I am interested in doing : suppose a new patient comes in and on the first visit, the doctor makes some quick notes (e.g. patient is male, 30 years old, 180 cm, 100 kg, non-smoker, frequently complains of chest pains, no high blood pressure, works a construction worker and takes daily medicine for acid reflex). Just based on these quick notes and the 1000 reports available (NOTE: I am trying to illustrate a point here, that the medical notes for the new patient and the 1000 reports DO NOT have the same format), can a researcher predict (supervised classification, e.g. decision tree) if this patient will have a ""serious"" or a ""non-serious"" condition?

PS: suppose the doctors have a very detailed medical encyclopedia on their computers - can this medical encyclopedia be used alongside the 1000 medical reports to improve the prediction results?",statistics
n4fqp5,1620101773.0,[Q] Help,Help I’m doing a project for statistics regarding comparing two sample proportions. What are some easy examples for some statistic projects to do? There needs to be an excel from which the data has to come from. It can be a confidence interval or hypothesis test. I’m sorry if my English is bad it isn’t my native language.,statistics
n4dalb,1620093226.0,[Q] what statistical analysis or statistical tool should i use?,"For example I have an response variable of number days from a patient to fully recover from fever and my independent variables (categorical values) are age (60 to 69, 70 to 79, 80 to 89, 90 to 99), bmi (obese, normal, underweight, overweight) and blood type ( A + -, B+ -, AB+ -, O+ -). I want to compare that ages 80 to 90 with a bmi of obese and a blood type of AB+ takes longer time recover than the those with age range of 60 to 69 with normal bmi that has a blood type of O+

what statistical analysis or statistical tool should i use?",statistics
n4bvwm,1620088740.0,"[D] relationship between ""topological data analysis"" and dimensionality reduction methods (like ""principle component analysis"", ""manifold learning"") and data visualization (""tsne"")","Recently I came across this topic of ""topological data analysis"" (https://en.m.wikipedia.org/wiki/Topological_data_analysis , https://towardsdatascience.com/tagged/topological-data-analysis , https://medium.com/@varad.deshmukh/topological-data-analysis-a-very-short-introduction-611d3238a0bd) .

Has anyone ever used this methods from topological data analysis? Is this more for data visualization or dimensionality reduction?

Suppose if I am working on a supervised binary classification problem - how can topological data analysis be used in the context of this problem?",statistics
n4a7w9,1620083673.0,[Q] Is there a way to untransform points in an ordination?," Forgive me if I'm using the wrong vocabulary. This might explain why I haven't been able to successfully google the answer yet.

Here is what I have going on:
I have created an ordination using principal coordinates analysis (PCoA).
Based off the first two axes I have plotted a set of multivariate data in 2d.

My Question:
Is there a way to untransform the x and y coordinates of a specific point to return the original multivariate data? What is that called and how easily can it be done in R?

thanks!",statistics
n49vuq,1620082724.0,[E] Casella Berger in PDF?,"Does anyone has Casella and Berger Statistic Inference as PDF without being images? I would like to use the Search tool since it's a +600 page book.

I didn't read anything about asking for book in rules so I hope this doesn't goes against them.",statistics
n45w5p,1620072370.0,"[Q] In structural equation modeling, can a manifest variable indicate more than one latent variable?","I've run my model, and the fit is not good. So I looked at the modification indices to make adjustments, and the numbers suggest I should correlate a manifest variable with multiple latent variables.

Is this okay in SEM? I was under the impression that each manifest variable should go with a single latent variable, am I mistaken?",statistics
n456oa,1620070595.0,[Q] Confused between F critical and Alpha.,"Hello, good people! I hope everyone is doing well. I am learning basic statistical tests as a requirement for my university.

Since I am enjoying holidays now and I am interested in stock anomalies and decided to run some basic statistical tests on the data from my country's stock exchange index.

I ran a F-test (two sample for variance) between the week starting day and the other days of the week using the built in excel tool. As far as I have learned from different sources, if-
1. F > F Critical = Reject the null hypothesis
2. P value < Alpha= Reject the null hypothesis

Now, my results showed:
1. F < F Critical = So, I can't reject the null hypothesis
2. P value < Alpha= So, I can reject the null hypothesis


My question is, which one should I use to give my judgement about rejecting or not rejecting the hypothesis? Is any one of F critical and Alpha more meaningful than the other?


Thanks in advance.",statistics
n422s9,1620063208.0,[Q] Robust two-way dependent/within ANOVA?,"I’ve been sifting through WRS2, and don’t see one. Something like pbad2way, but for dependent groups (with unequal sample sizes). Any other packages that might be helpful?

Bootstrap would work.

An anova with trimmed means and Winsorized variance would work too.

Thanks",statistics
n3wm2w,1620049933.0,[Q] Sample size too large! Election projections accurate within 15 minutes after closing voting booths? Please help a statistics noob!,"Hi everyone, I'm quite a statistics beginner so I'd really appreciate some help. I'd like to figure out by when the election projections are accurate enough (<1% error) for me to regard, assuming the voting booths close at 6 pm.

Suppose I expect a party to gain 4.5 million votes, 10% of all votes (p=0.1). I also expect all votes to be counted within ten hours. This gives me an average of \~104,000 votes (n=104,000) counted for this party per 15 minutes. Assume the projections are updated every 15 minutes based on this influx of newly counted votes. Assuming also that the votes follow a normal distribution, I would have a standard deviation of merely 140.57 votes (ROOT104,00\*0.1\*0.9).

Surely that can't be right? There's no way this accurately reflects reality, right? What am I doing wrong, or how can I do this differently? Maybe I shouldn't assume a normal distribution? It just seems to me, that the sample size is too big and therefore the deviation too small... Perhaps there's a way to add more uncertainty? I'd greatly appreciate any help!",statistics
n3u4vh,1620042959.0,[Q] How to choose threshold between absolute and squared errors in robust Huber loss function?,"The [Huber loss function](https://en.wikipedia.org/wiki/Huber_loss) for residuals e is

L(e) = 0.5\*e\^2                for |e| <= d

L(e) = d\*(|e| - 0.5\*d)    for |e| > d

It is quadratic in |e| up to value d. I want to write a program to estimate the location of data using Huber loss, but what is a good default choice for d?",statistics
n3t1at,1620038700.0,[Question] Which data program to use? How to learn more about this topic?,"Dear Statistics People,

We are doing a student project as part of our biology bachelor, collecting data about hand features and collecting additional data about other traits/factors which may or may not be correlate with those hand features. Now, the question is how to process that data. Are there some (free) genius programs which may do the work? Also are there ways to put in the data and get out usable graphs/charts/diagrams?

I could imagine something like: ""deviation of the norm (reg: hand features) correlated to traits/factor w, x, y and z"" Where you see a larger corelation between the deviation of the norm and, lets say, trait w and x which belong to the category of disease. And less correlation between deviation of the norm and trait y and z which belong to the category of character traits.

In one I'd like to depict the correlation between the single factors (w,x,y,z) and in a second graph the correlation between the categories (disease, character traits).

This is just an example. In reality there will be much much more traits and categories to connect. Also using different groups: male, female and male+female. So, this is going to be a huge mess. That's why I'm looking for a program and/or some advice.

Disclaimer: You are not doing my homework by helping me. Our uni didn't ask for that sort of extra work, but as I'm interested in this topic I want to treat this project as a chance to learn about it, thus increase its complexity just for the sake of it.

If You know any programs or can recommend great sources to learn about that topic or have some good advice, that would be awesome.

I really hope You can help me somehow.

:)

EDIT: Thanks a lot for all of Your very helpful answers!!!",statistics
n3rm9e,1620032607.0,[Q] Best statistical analysis for data that deals with duration?,"Hey all, going about my virology course and I'm currently trying to figure out if there's a correlation between the duration of sickness (COVID-19) between hospitalized and non-hospitalized patients. I have exact numbers for how many and how long these patients were sick, I just want to know if their being in a hospital or not affects how long they are sick. Thanks so much!",statistics
n3nl83,1620015128.0,[D] stochastic block model vs. standard community detection algorithms,"Has anyone ever come across the ""stochastic block model"" (https://en.m.wikipedia.org/wiki/Stochastic_block_model)? All in all, this seems like a community detection algorithm for graphs (i.e. network clustering).

Does anyone know in which circumstances it would make more sense to use ""stochastic block models"" compared to community detection algorithms such as ""louvain clustering""?

Thanks",statistics
n3lcl5,1620007112.0,[Question] Formula for calculating character life probability in a video game,"Hello, I play a video game called tierras del sur, its a small 2d indie game with an active comunity of around 1000 concurrent players.

I usually do some small math on my head but I dont know how to calculate probability for the value of characters and I need some help.

So the game works like this: A character levels up from 1-50, levels 1-25 are quite easy and get progressively harder, with the maximum player right now being level 40. From 40-50 it gets incredibly slow and will take years before someone reaches 50.

Characters have life and mana. Both increase with each level but mana increases on a fixed value, while life increases based on an average depending on the class. (Mage is squishy so higher average, paladin is tanky so higher average)

The averages are, for example a human mage, 6.5. So each time you level up you ""roll the dice"" for a life increase of 5,6,7 or 8. This value determines the worth of your character by being higher or lower than your expected average for each level. This can go down to a defined cap of -10, And up indefinetly, so theoretically you could become a level 50 mage with 75 points above your expected life if you rolled an 8 on each level.

 Example: You create a character. It has a base life of 15. Every time it levels up, that life can increase by, for example in mage, 5, 6, 7 or 8. All rolls are equal: 1/4 chance.

So say your character levels twice and both times it rolls a 5. It will have a life of 25, But the expected life is 28 since the average of rolls is 6,5. That character would be -3. If it rolled 8 both times it would be +3. If it rolled a 6 and a 7, It would be an average character.

Most valuable characters hover between +10 and +20. With some exceptional charactes reaching +25 above level 40.

The way people go about this is create a character up to level 15 (which takes about 2-3 hours) and if the values are above +8 they will continue with a character.

My question is, to evaluate the value of time to character worth, what formula I could use to calculate the probability of a character above +10 at a selected level. Say I wanted my mage to be +15 at level 15, how many characters I would need to create on average. And if it would be more worh it for me, for example, to create a character to level 7 and try to roll 4 perfect 1/4 dices.

Sorry for bad english.",statistics
n3l7v6,1620006634.0,[D] Importance of Kolmogorov's Probability Axioms,"https://en.wikipedia.org/wiki/Probability_axioms

I read earlier today, that Kolmogorov's Probability Axioms are some of the most important results in probability.

Can someone please explain why these are so important? What relevance and application do they have?

Thanks",statistics
n3ign6,1619997199.0,[Question] creating linear regression channel,"Hello friends.

I am attempting to recreate the linear regression channel in excel but struggling with the deviation.

I’ve ran the regression and have the slope/intercept/best fit line.

How do I get the deviation away froM the slope? Say I want 2 standard deviations away? Is it the 95% upper limit * the slope? How would I increase it to 2.5 with the regression output or is there another mathematical way?

I can’t seem to figure out the answer and maybe I’m asking the wrong questions which is why I can’t find the answer online. It’s been a long time.

Any help would be appreciated!",statistics
n3hfx2,1619993925.0,[Question] Simple Sample Question," Hello all, I had a question on how to properly calculate the sample for a research project that I am helping with. If I have an overall target population of 8,000 and I want to sample those within the districts of a given country do I calculate the sample size based on the target population within each district? Just want some clarity on this. Thanks",statistics
n3getb,1619990859.0,[Discussion] Such thing as too any events of interest in a data set for survival analysis?,"I'm familiar with the challenges when there are too few events of interest when analyzing data using survival analysis (for example having 10 variables in your model but less than 100 events or 10 events per variable) but I am curious if there is a problem with too many.

I'm comparing a few different models on a dataset and the event of interest I created has over half of all patients experiencing this event. Strictly looking at the Concordance indices of the models there doesn't seem to be a drop or improvement in performance when compared to a previous event that had only 1/4 patients experiencing so I am just curious peoples' thoughts.

&#x200B;

TLDR: If covariates >>> events is high dimension survival data and it brings challenges, how about having too many events per variable?",statistics
n3cmt2,1619980300.0,[Q] Is a two-way ANOVA test suitable for my thesis analysis?,"Hello, for my thesis I will be comparing the yearly income of Type A companies between the years of 2010-2020, to the yearly income of Type B companies between the same years. I want to see if these yearly incomes between the two types of companies (I have 50 companies for each category) have progressed in the same way over the same 10 year period. My roommate suggested I do a two-way ANOVA test. Doing some research though, I am very much confused if this is the best way to go. Any suggestions? Thanks a lot.",statistics
n3bjev,1619977086.0,"[Q] My mom is big on astrology and I just watched a guy on ""The Cut"" on YouTube guess 4/12 people's signs right.","So as the title says I just watched an astrologer guess the signs of 12 people and managed to get 4 of them right. Given 12 people with 12 different signs (none repeat), how many are you likely to get right accidentally?",statistics
n3agmq,1619974070.0,[Question] Want help understanding the model in a paper on climate change and lyme disease,"&#x200B;

Trying to understand the model behind this paper

[https://www.hindawi.com/journals/cjidmm/2018/5719081/](https://www.hindawi.com/journals/cjidmm/2018/5719081/)

It's a paper examining the link between climate change and the incidence of lyme disease.

Can anyone help me understand the model used and give me a basic overview of how it works?",statistics
n39zh5,1619972740.0,[Q] any apps or websites that can help me copy and paste symbols into word?,,statistics
n39k3q,1619971610.0,[Question] Books on more philosophical aspect of Statistics?,"Hello, I recently got interested in statistics and wanted to read some books that would give me a good introduction to it.

I'm not looking for a book that goes more technical and teaches me about the different techniques, but I was hoping to find some book that talks about maybe what exactly is valid data, etc... more like meta-statistics? or more philosophical statistics?

I hope my question makes sense...

Thanks",statistics
n37zr6,1619967313.0,"[Q] What is the best approach to analyzing how ""normal"" patient visit counts are?","I'm currently looking at patient visits and no-show rates for my clinic and I'm wondering what would be the best way to show if the current month/quarter patient count is within a normal range? I usually just report the descriptive statistics and show the counts by month along with an overall average, and then I also show what the last 5 months of patient counts looked like to see how the data trends. I'm wondering if there is a test out there or a better way of showing if the current report data is within a ""normal"" range, and if not, to flag it for attention in my report only if it's outside of a normal range. Because right now it's nice getting raw counts, but we don't know if we should be concerned or not. Would it be better to show this data in comparison to the previous year's data? Or is there a statistical test out there that shows this better? It will be mainly used to facilitate a discussion on whether the patient count drops/rises requires a discussion from our leaders.",statistics
n37exd,1619965572.0,[Q] Would I face any pitfalls if I only used inter and intra cluster distance for determining the quality of my clustering?,"Hi all,

I currently have a function in R which generates a distance matrix from some data, where I have a pre-defined grouping of it. My goal is to evaluate the performance of a parameter in this function by going from 0 to a high number, where I believe the evaluation is possible because I already know the correct clusters beforehand.

I'm thinking of doing this by calculating the inter and intra cluster distances generated by each increase in the parameter, where the optimal point of the parameter would be the point where the inter cluster distance is the highest, and intra the lowest. I was wondering if this strategy is discouraged or not by statisticians however, or if better strategies of doing this might exist (especially if they are implemented in R). Thank you all for your help in advance.",statistics
n359i3,1619957859.0,[Q] what test should i use for normally distributed in regression equation?,What should i use to identify of the outliers of the individual regression equations are normally distributed? What are the common reasons for outliers in regression analysis?,statistics
n34rln,1619955906.0,[E] Incoming freshman in college about to take statistics major in actuarial science.,"Just for some context I just got my college results and I got into the university and program I wanted. Now that I’m sure I’m going to be taking statistics as my course I want to be productive with my free time and be ahead of the game.

If anyone has any resources for me that I should check out and learn let me know!

Also if anyone has any advice for me would love to hear them as well.",statistics
n2zo96,1619932390.0,[Education] Modeling for optimal bet size in a dice-game,"Currently taking an self-study game theory elective and there seems to be a practice question right out of statistics/probability.

* You begin with a starting balance of $10;
* A dice game where a 100 sided-dice is used;
* a roll with a value greater than and/or equal to 55 results in a payout of 2.2x your initial bet (you get your initial stake back plus an additional 1.2x of your stake back as reward);
* a roll with a value lesser than 55 results in a loss of your bet
you may increase your bet size by a multiple of your choice only after winning or losing a bet (e.g.: 1.1, 1.2, 1.3, and so on). This choice is systematic and must apply to all your wins and/or losses.
* Calculate the optimal bet-size to achieve an ending balance of $30.

What is this question even asking? I'm guessing that ""optimal"" in this case means minimizing the probability of losing your $10 before reaching $30? I know some python so I can build a model to simulate this, but I have no theoretical idea (I think this is a perfect play question?) of where to start with something like this.",statistics
n2yzik,1619929500.0,[Q] Can a model satisfy the Gauss-Markov conditions (BLUE) if there's omitted variables bias?,,statistics
n2yumd,1619928945.0,[Q] best next step to analyze this set of data,"Hello,
I have a set of data which includes the daily number of cases of influenza in our hospital for a whole year. We also have the number of diagnosis of fever recorded overall and some more symptoms.

How can i evaluate if there is a trend here?

I read some articles that used analyze-it for some studies that are a bit alike.

Right now i have the databse in excel, the contents are dates, fever, diarrhea, inflenza

I want to see if the number of confirmed influenza as it was rising or falling if it followed a similar pattern to our fever cases we recorded.


Should I use analyze-it? Should i do a spearman analysis with it?  But thay will not give me the trend will it?


Sorry if I don't make much sense, i am still learning my way.

Thanks.",statistics
n2w7pg,1619918815.0,[Q] What fraction of data to trim in trimmed mean?,"For normally distributed data, the sample mean is the best estimate of the mean, and for the Laplace distribution the median (50% trimmed mean) is optimal. When the distribution of the data is unknown, how should the fraction of data to trim in computing the mean be chosen? In general, higher kurtosis suggests trimming a larger fraction of data, but is there a quantitative rule?",statistics
n2w6mm,1619918698.0,[Q] Do “statisticians” still exist?,"^^ Just wondering if that still is a job that exists, given the surge of data analytics and data science.",statistics
n2vzo5,1619917998.0,[Q] What is the best way to normalize crowd-sourced (nature) observation data?,"From this post: [https://www.reddit.com/r/mycology/comments/n1zh6f/i\_made\_this\_map\_of\_the\_highest\_density\_of\_edible/](https://www.reddit.com/r/mycology/comments/n1zh6f/i_made_this_map_of_the_highest_density_of_edible/) yesterday and got a lot of comments suggesting I **normalize the data to the population** i.e. per capita.

However, someone was saying that they think ""log-observation"" would be a better approximation (doubling the number of observations wouldn't double the number of species), and another user was suggesting I normalize my data to **total** observations: (# edible occurrences / total # of observations)

...

Any help would be appreciated, I am not a statistician or GIS guy or anything, just curious about this stuff",statistics
n2ue7x,1619912284.0,Is it ok to use transformations if x-axis is small to begin with? [Q],"\[Question\]

I am wondering if it's advisable to use transformations when the dependent variable is already small?

When using sqrt or ln transformation, it reduces the x-axis to two or three (originally an 11-point scale). Would this potentially impact the test, making it more difficult to distinguish differences between the independent variables?

(I'm running a two-way anova. It's pretty skewed by default.)",statistics
n2nzna,1619893067.0,[Q] MLR Categorical Interaction Term Question,"I am trying to understand when to add interaction terms in a MLR model. I reduced my model using pairwise selection and was left with 8 categorical variables to predict MonthlyCharge, using a telecommunication churn data set. The residual vs fitted, normal q-q, and residuals leverage plots do not appear to support that the model fits the data well.

I added an interaction term between all the variables (V1*V2*...*V8) and the residual vs fitted, normal q-q, and residuals vs leverage plots look great. The predicted vs actual MonthlyCharge is also nearly perfect.

I'm having trouble understanding how to interpret this term, though. I originally added this term just to experiment with possible IV inputs, not expecting such positive results.  Is there a systematic way to calculate which terms should be added by additional interaction terms, between categorical variables? When I examine the model summary in R, it looks like this interaction term uses every possible combination with 2 or more of the variables, not just all of them interaction together. I assume there must be something wrong with adding an interaction term for all variables, just looking to understand why.",statistics
n2nkg4,1619891892.0,[Q] maximum entropy method with random constraints?,"I'm working on a research problem that involves measuring constraints on a function f(x) = c and then finding the distribution p(x) that has the largest entropy while respecting the constraint.  The problem is that when I measure c from the data, there is uncertainty involved so I don't know exactly the value of c.

To put it in a bayesian context, let's say the best I can determine with total certainty about c is a prior distribution. For example, it is well known that if f(x) is the expected value of x, then p(x) is an exponential distribution with mean parameter c.  Now what if all I know about c is that it's a normal random variable with mean mu and standard deviation sigma? How would I find the solution p(x) that meets these criteria?

If it helps, here are some important properties of p(x) I know with certainty:

(1) p(x) is a member of the exponential family,

(2) -1<x<1

(3) the sufficient statistic  is a set of Legendre polynomials.

(4) The function f(x) are the expected values of the Legendre polynomials.

(5) The maximum likelihood estimate of the distribution p(x) is easily obtained from any given value of c.

(6) the MLE obtained from (5) is also the maximum entropy solution, because it is unique (only one distribution p(x) satisfies the constraint).

Any thoughts or relevant articles would be appreciated. Thank you!",statistics
n2l3rd,1619884522.0,"[C], [Q] MA vs MS in stats for finding a job?","My school (Binghamton university) has a 4+1 mathematics bachelors + statistics MA program. The program looks pretty solid, plenty of challenging and interesting classes, and I can complete it for cheaper and more quickly that if I were to get a masters at another school. However, I’m worried that it might be disadvantageous to get an MA rather than an MS, in terms of finding a job. What do you all think about this? Also, for context, my undergrad is a BS in mathematics and I have a 3.98 gpa.

Here is the curriculum for the MA: as you can see, it certainly looks solid, and I know all the grad statistics courses will be rigorous and challenging.

https://www.binghamton.edu/math/graduate/statistics/curriculum.html",statistics
n2kvmy,1619883833.0,[question] is this kind of monumental forecasting error common in real world ?,"
SBI Research (huge credible corporation) forecasted a second wave in India with 97.5% CI (1.8 million cases, 5 million cases) in 100 days starting from 15 Feb 2021.

 I thought since it's one of biggest corporation of the country and the world, the numbers would be somewhat accurate. But in **last 30 days alone more than 6.6 million new cases** have been registered.

My question is, **is this kind of forecasting error really common ??** If yes, then **what's the point of doing forecasting ?? ** As a student of statistics I thought that forecasting done in big organizations must be somewhat accurate.

Please note that i ask this question just to understand the practical importance of statistics in real world and not to defame any organisation.

Link to SBI Research report - [link](https://www.google.com/url?sa=t&source=web&rct=j&url=https://sbi.co.in/documents/13958/3312806/310321-SBI%2BSpecial%2BResearch%2BReport%2B-%2BSecond%2Bwave%2Bof%2Binfections%2B-%2BThe%2Bbeginning%2Bof%2Bthe%2Bend.pdf/bcfa734c-9ec0-4572-21c0-3a5217beaf76%3Ft%3D1617181552645&ved=2ahUKEwjAwemj5qjwAhWn73MBHVkjCLEQFjAAegQIBRAC&usg=AOvVaw3l8TG9Qsj2NgVI4xJ8ri2U)",statistics
n2k2gh,1619881369.0,"[Q] So, this is probably a frequent question, but why do hypothesis tests require the assumption that n<N(.1)?","As I study for my AP Statistics exam, I would like to know the relevancy of this assumption.",statistics
n2jh1k,1619879475.0,[Q] What does it mean to orthogonalize a variable and how can I do it?,"I have to replicate a paper in which the authors “orthogonalize each variable against a set of macroeconomic conditions, to reduce the likelihood that the proxies are connected to systematic risk”.

After the orthogonalization, the authors take each of the orthogonalized variables to form an index using PCA.

I have tried to google it but I couldn’t understand how can I orthogonalize each variable.

Any help would be really appreciated

EDIT:
Link of the paper:

http://people.stern.nyu.edu/jwurgler/papers/wurgler_baker_cross_section.pdf",statistics
n28c55,1619832937.0,[Q] Are there any careers in data science and plant research?,"I’m a junior in high school and I’m think of pursuing a career in statistics/data analytics. I’m passionate about plants and permaculture, but it’s not really feasible career-wise, so I’m wondering if there’s a way to merge the two into one career.

Are there any of you who works with data and plants?

If so, what led you to choose this pathway and how did you enter?

What are the pros and cons of your job?

What do you recommend to someone trying to enter this field?

Thank you!",statistics
n24sbf,1619820851.0,"[Q] Primer for Biological Statistics in RStudio: ANOVA, Regressions, correlations, bar and line graphs","Ecologists, environmental scientists, foresters, horticulturalists, and biologists have two specific requirements for performing statistical analyses. Hereforth is a primer - a simple and hopefully clear distillation of the important components amidst the vastness of the field. This was presented to graduate students at the University of Toronto.

[https://www.youtube.com/watch?v=GDrEwz8r8Xc](https://www.youtube.com/watch?v=GDrEwz8r8Xc)

First, a general introduction to probability, assumptions of inference, and hypothesis testing. The second requirement is to perform the analyses, including managing the data using some statistical software.

At the vanguard of such software is the R statistical software [https://www.r-project.org/;](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWVHOVNHcG95V1ZFcWF5SDdsdXVFUFgwVk9YZ3xBQ3Jtc0ttYUZYVmQzQ1E4MkRaNTFqN2NjNXE4TXNqMW5UZ1BuZGhmZUk3SjUwQ3RFT24tLW5IZkdpczJ6T0t5dWdlU1FaOFJDVngxVUlrYWRnOVREZVhXaHNQaXk0VWN1dHVXWTRRWFBxS1ZKY0RvNTRyTjRlWQ&q=https%3A%2F%2Fwww.r-project.org%2F%3B)​ and its integrative environment Rstudio [https://www.rstudio.com/](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqazB0NjQtTlZvRlp4cDZudWM0dzJfOTQyaEViQXxBQ3Jtc0tsY201bG5pbGltSWhWOVl2YUlvQlNQbk9Delg2bWVHRlluOGNQNUFqUlhqeEVBUEtwcHFNMDRjR2ZsZGV4YzVac0pzV050TzVGbElPdEN3MThyTGFLODFiRlJMOWdESkc5R0NOdW53SGZuMDAtRHBwaw&q=https%3A%2F%2Fwww.rstudio.com%2F)​. Few programs constitute the virtues of open-sources highly integrated and powerful programs as the R statistical software - taught to the modern student in most institutions.

The following video comprises the time-stamped functions and analyses:

1. Intro to data management, probability, and data presentation ([0:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=0s)​-[13:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=780s)​ min)
2. Intro to producing graphs with R studio ([13:15](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=795s)​ - [17:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=1020s)​ min)
3. Subsetting the data ([23:20](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=1400s)​)
4. 'attach' function in R ([23:47](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=1427s)​ min)
5. 'summarySE' ([24:45](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=1485s)​ min)
6. Using the plot function ([28:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=1680s)​ - [34:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2040s)​ min)
7. Package 'sciplot' for bar graphs 'bargraph.CI' function ([34:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2040s)​ - [36:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2160s)​ min)
8. Analysis of Variance including Tukey HSD (ANOVA) ([36:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2160s)​ - [40:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2400s)​ min)
9. Creating Line Plots and Scatter plot ( [42:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2520s)​-[45:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2700s)​ min)
10. Regression analyses via 'lm' function - linear - ([45:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2700s)​ - [48:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2880s)​ mins)
11. Correlation analysis ([48:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=2880s)​ -[51:00](https://www.youtube.com/watch?v=GDrEwz8r8Xc&t=3060s)​ mins)

The video finishes with a summation of what we've learned. If you like this material, then please like and subscribe to this channel.",statistics
n244fx,1619818823.0,"[Question] Statistics on manifolds. I ve ran into a problem where I have data living on a riemannian manifold. I ve looked around but didnt find any good resources. How would onr go about defining mean , sd etc ? As my manifold is not linear I can really define addition etc.",,statistics
n212yu,1619809872.0,[Q] Omitted Variable Bias in Non-Linear (Binary Outcome) Models.,"I am trying to analytically derive the omitted variables bias for binary outcome models. In particular, I am trying to get a deeper understanding of Scaling bias.  Do you all have any sources that would help with this?",statistics
n1wtp0,1619798083.0,[Q] Would you describe this data as biased?,"An UK based feminist made an anonymous online poll about women subjected to male violence and concluded that 99.3% of women living in the UK were subjected to sexual violence at least one time in their lifetime, and average woman will experience violence(both physical and sexual) at least 37 times in  her life: [Image](https://pbs.twimg.com/media/E0NHhTFXMAQdF5K?format=jpg&name=medium)

[Full study can be found here](https://irp.cdn-website.com/f9ec73a4/files/uploaded/Key-Facts-Document-VAWG-VictimFocus-2021a.pdf)

Her recruiting tweets for poll specified that she wanted women experienced any violence in their lifetimes at least one time: [Example1](https://pbs.twimg.com/media/EnLqArSWMAAdsMA?format=jpg&name=4096x4096), [Example2](https://i.imgur.com/L4EaOLN.png) (she doesn't specify this in the study itself)",statistics
n1w1ay,1619795836.0,[Q] Has anyone here used the Kruskal-Wallis test when comparing data distributions?,"I’ve been working with 4 categories of data and trying to compute the “H” statistic to get an idea for how truly different each of the distributions (categories) are.

I have N=4 categories, so 3 degrees of freedom. There are several hundred data points/values within each category.

According to what I’ve read online, when there are more than 5 samples in each category you can treat H as Chi Squared.

Now, when I compute H, I end up with a value of 68.9. According to the look-up table of p values for 3 degrees of freedom, this is significantly greater than the 99.9th (p = 0.001) value of 16.27.

Is my H value reasonable? If so, what is this telling me? That there’s a much greater than 99.9% chance that the 4 categories/distributions I’m looking at have significant differences between them?

Is there any way I can take this further?",statistics
n1vsy1,1619795155.0,[Q] What are the best papers/books on 'regression to the mean'?,There's so much mis information on the subject on the web. I'm doing research that requires me to understand the nuances of the descriptive statistic.,statistics
n1vmup,1619794693.0,[Q] Find minimum number of points to qualify in a sporting event,"Hi!

Please direct me to another subreddit if this is the wrong one.

I'm following an e-sport where you qualify to the word finals by competing in 4 different tournaments throughout the year and getting placement points from these tournaments.

I'm trying to find out what the lowest number of points would be for a team to be in the top 7 (within a certain probability) after all tournaments have ended.

Is there a method or formula I could use for this?

The concrete example can be looked at here: https://liquipedia.net/pubg/PUBG_Global_Championship/2021/Europe/Points

E.g. Heroic won the first of four tournaments and have 200 points. How many points would they need from the next 3 tournaments to ""safely"" qualify as a top 7 team?

Thanks for any help or tips!",statistics
n1vf12,1619794059.0,[Q] Multiplier for average growth,"I have a list of student test scores ranging from 0-20, 20 being the highest score a student can receive.  I am looking to find the average growth of students, and with all students included, my average is 5.5 points from pretest to posttest.

Where I'm struggling is that students who scored 15 or higher on the pretest are bringing down the average, even if they grew (some up to 20 which is the maximum).

How can I account for this to find a true, average growth score?  Do I multiply growth points by some factor for any student who started at a 15, 16, 17, and so on?  If so, how do I know what to multiply it by?",statistics
n1ltu0,1619755201.0,[D] How sensitive are statistical models to the richness of information within the data?,"I spent the last hour thinking and creating an example that illustrates my question : https://imgur.com/a/36gU0pb

My question indirectly relates to exploratory data analytics and feature selection for statistical models. Suppose you have some variables (let's assume they are categorical variables for this example) - when you make a histogram for these variables, they appear extremely skewed. On first glance, you would not want to include heavily skewed variables as inputs for a statistical model - e.g., if 99% of the variable is a single value, how informative and useful could it be to a statistical model?

But how do you know that these heavily skewed variables don't contain some very useful information in the 1%, that might really help you in making future predictions?

Sometimes, using the context of the problem (e.g. if you working on a biology problem, consult with the biologists) you might be able to gain some insights - other times, you can try to use some logic to figure out if these heavily skewed variables are in fact useful for the model ... but when you have big and complex data, how is it possible?

I posted an example above that illustrates this problem (https://imgur.com/a/36gU0pb) - I would be curious to know if any of you have dealt with similar problems in the past.

Thanks",statistics
n1l42b,1619752498.0,[Q] what are some public datasets for proportions that would be a good project idea?,Hello I’m doing a statistics project requiring 2 proportions and comparing them. Does anyone know of any datasets from trustworthy sources that have the data? Sorry if my English is bad it isn’t my native language.,statistics
n1k6x0,1619749147.0,[Q] Measuring the Sensitivity of Decision Trees on Training Data,"Decision trees are known to be quite non-robust and can fundamentally change due to small variations to data (hence the appeal of random forests), but is there a way to measure the potential sensitivity of a decision tree  preferably before fitting one? It's intuitive to imagine that decision trees (and I guess all models) get better with more data (assuming the data is representative, ofc) but is there a generalisation/theory of a decision trees robustness given an increasing sample size? Or is it too reliant on the features of a given dataset and thus varies on a case-by-case basis?

(I guess this also applies to other non-parametric / information theoretic methods to various degrees?)",statistics
n1j1xi,1619745113.0,[E] Any summer online multivariate statistics courses that give ACADEMIC CREDIT?,"Hello, I’m a graduating senior, and unfortunately my school doesn’t provide the Multivariate Data Analysis course during the summer, which is when I have to graduate. However, my advisor says that I am eligible to do a “course equivalency” meaning I can take this course at another private institution, school, etc. as long as the program gives academic credit. Does anyone know any programs this summer that provide this? Thank you!",statistics
n1gls7,1619737112.0,[Q] Testing multicollinearity/homoscedasticity in a structural equation model?," I'm unclear about testing these assumptions on a model without clear independent/dependent variables. Which observed variables should I be testing for multicollinearity? And for homoscedasticity, do I just plot the residuals for relationships between ALL observed variables?

Any advice you have would be amazing. TIA

Model here: [https://imgur.com/a/CsbrvXl](https://imgur.com/a/CsbrvXl)",statistics
n1fldu,1619734168.0,"[Q] P-value indicates no significance, bootstrap confidence interval does neither cross nor include 0 however. SPSS","Hi guys,

I´m asking this for my girlfriend who's currently working on her master thesis and stuck with her data analysis and interpretation in SPSS.

She executed a normal moderation Model 1 macro process by Hayes and due an asymmetrical confidence interval chose to run a bootstrap. Whereas the main output (p-value) indicated no significance, the bootstrap interval does neither cross nor include 0 however, which is usually a sign a significance. The lower CI limit is 0,013 however, which to me seems dangerously close to 0.

As you can probably tell by now, im not that much into SPSS or Statistics either. Her English sucks however, that's why I'm writing this right now.

Any help on what she could try next would be immensely appreciated. Her supervisor sadly couldn't care less.

Cheers guys, stay healthy!",statistics
n1dr7t,1619729033.0,[Q] Help understanding NeurIPS 2013 Dirichlet Process Mixture Model paper,"I'm struggling to understand certain  parts of the 2013 NeurIPS paper ""Online Learning of Nonparametric  Mixture Models via Sequential Variational Approximation"" ([https://proceedings.neurips.cc/paper/2013/hash/8c19f571e251e61cb8dd3612f26d5ecf-Abstract.html](https://proceedings.neurips.cc/paper/2013/hash/8c19f571e251e61cb8dd3612f26d5ecf-Abstract.html)).  If anyone on this subreddit is familiar with Bayesian nonparametrics  and has five minutes, I would really appreciate answers to the questions I posted at Math Stackexchange:

[https://math.stackexchange.com/questions/4121431/online-stochastic-variational-inference-for-dirichlet-process-mixture-models](https://math.stackexchange.com/questions/4121431/online-stochastic-variational-inference-for-dirichlet-process-mixture-models)

Based  on the paper's reviews, reviewer 4 had these same questions and I think the author intended to  add answers to the supplement (the  supplement starts with, ""This  document provides proofs of theorems  presented in the paper"") but never actually got around to adding proofs or answers.

I've emailed the sole author but I have yet to hear back from him.",statistics
n1bzl2,1619724169.0,[Q] Multicollinearity issue with fixed effects regression and dummy variable,"Hi!

 Im doing a fixed effects regression on a panel data with N∗T=870N∗T=870 observations where N = 290 and T = 3. The entities are districts observed over a total of 3 time periods. I want to interact my main independent variable with a dummy variable, where the dummy variable takes the value 1 if a ""large"" district and 0 o.w. Will this cause issues with multicollinearity, since the entity fixed effects are essentially dummies for each entity?

Ive posted the question with more details here:

Ive posted the question here:  [panel data - Multicollinearity with fixed effects regression and dummy variable - Cross Validated (stackexchange.com)](https://stats.stackexchange.com/questions/522104/multicollinearity-with-fixed-effects-regression-and-dummy-variable)

&#x200B;

Thanks!",statistics
n1aqqt,1619720773.0,[Q] SPSS Partial Correlation,"How can I control for a variable while looking at the correlation between two variables, one of which is categorical. Basically the IV has two categories and I’m looking at how they differ on the DV. How to I run a partial correlation analysis with all of this? I tried running a normal partial correlation but it doesn’t account for the two groups for the IV.",statistics
n197j5,1619716544.0,[Q] Exploratory Data Analysis,"1. How to learn exploratory data analysis in python? Any links or references would help.

2. What statistical values should we verify while performing this? Min, Max and similar things or do we need to find more information on the problem statement?

3. Does this include data description and visualization as well? What libraries do we use generally for python?",statistics
n182ey,1619713421.0,[D] is it common to use the ZIP code as a predictor variable in statistical models?,"Suppose you want to make a model that predicts if a student will drop out of university- you have historical information about many students and whether they dropped out or not. You also have access to the ZIP code (postal code) where they lived.

1) Is it common to actually the zip code as an input variable (probably not, since there are too many categories)? Or, maybe use the first 3 numbers of the zip code as an input variable?

2) I was always told to avoid using a predictor variable that has too many categories. Is there a mathematical reason behind this? From a mathematical standpoint: if your data has 1000 rows and one of your predictor has 450 categories - mathematically speaking, why might this harm your statistical model? I can understand it intuitively - having too many categories means too much information and your model might get ""confused"" - but is there a mathematical explanation?

Note: I know you can just take students from different cities and make a sepperate model for students in the same city - but I am not interested in doing this.

CLARIFICATION: I am using zip as a CATEGORICAL variable!",statistics
n12ln1,1619696954.0,[q] MLR With Categorical Predictors,"I'm running an MLR on mixed churn data. After using pairwise selection to reduce the IVs, I'm left with only categorical variables to predict monthly charge. I think this makes sense intuitively and the predicted vs actual plot on my test data is very close but I just want to make sure I'm not missing something. The plot does not have the typical cloud of points I'm used to seeing.  There are 2 perfect lines of points slightly above and below the y=x line.",statistics
n114ff,1619690557.0,[Q] Significance of a Relative Influence Factor,"Hi,

I am currently reading a [Paper](https://onlinelibrary.wiley.com/doi/full/10.1002/smj.2502) in which the authors study the effect of relative Merger and Acquisition experience on bargaining power in a deal.

Their argumentation:

>Specifically, we argue that the differential between the acquirer and the target’s experience determines which one will bargain better terms, and thereby, obtain more value at the expense of the other party.

They state that:

>Most prior studies have only theoretically considered the acquirer’s experience, and even the few studies that considered both parties’ experience (e.g., Porrini, 2004) did so in *isolation* of each other without theorizing about relative experience.

As the authors argue, M&A experience of the parties involved in a deal is a factor frequently examined in the literature and has been included as an explanatory variable in many studies. In many cases, the experience of the target **and** the bidder is included as IV's in a model. (For example, to explain the deal premium, i.e. the difference between the purchase price and the share price of the target).

The relative experience variable is constructed as the count of all M&As that the firm completed during the 10 years preceding the focal M&A. In a second step the target’s M&A experience is substracted from the acquirer’s M&A experience to measure the difference in experience between the parties. This variable takes positive values if the acquirer’s experience exceeds that of the target and negative values if the target’s experience exceeds that of the acquirer.

The calculation of the variable is straightforward, yet I am having trouble interpreting the relative M&A experience. To what extent is the meaningfulness of the relative factor higher compared to a model where I include the deal experience of the target and the bidder as **two separate** variables?",statistics
n0zwgr,1619684637.0,[Q] How can I interpret the substantive significance of a likelihood?,"If I run a linear regression and get an R-squared, it has a  substantive interpretation: this is how much of the variance in the  sample the model explained. If I add a term and see an increase in  R-squared, that also has a substantive interpretation. An increase from  R-squared from 0.1 to 0.5 is substantively important. An increase from  0.1 to 0.105 probably isn't, even if it is highly significant.

Many models don't have a natural R-squared, so instead we look at the  log likelihood. Is there a natural way to understand the ""size"" of a  log likelihood? When we compare two log likelihoods, we might do a  likelihood ratio test. That tests whether one model is significantly  better than the other. But is there a way to understand the substantive  importance of the improvement, as there is for the R-squared?

I thought that log-likelihood divided by N might work, since it gives  the ""per-person"" probability of the data given the model. But I'm not  sure.",statistics
n0zmef,1619683324.0,[Question] Inference on (normal) multiple linear regression model parameters.,"Hi guys, statistics student here. Really striving to understand how inference on the parameters of a NMLR model work. I can't get what tests are meant to be used and why, would appreciate if you could link me anything (text, videos) which could make this argument less opaque. Thanks in advice.",statistics
n0y0u8,1619675950.0,[D] properties of the SMOTE algorithm,"https://arxiv.org/abs/1106.1813

https://en.m.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis

Has anyone ever used the SMOTE algorithm before in predictive modelling?

I had 2 questions:

1) Does anyone know if it can be shown that SMOTE might ""harm"" the results of a predictive model (e.g. reduce accuracy instead of increasing accuracy)? Can it at least be shown that SMOTE is not likely to worsen the results of a predictive model?

2) Is this the general idea of SMOTE? Suppose you are collecting data about two different types of birds, from two different islands, for the purpose of some predictive model. You collect all the data from the first island, but while collecting data from the second island, a hurricane happens and you have to leave. This results in your being imbalanced from the second island/type of bird. Therefore, to help your model, you use SMOTE to augment the available data from the second island, and potentially improve your model. Birds from the second island are not inherently rare - they are just rare in your dataset because of the hurricane that prevented you from collecting samples. Suppose the second type of bird is actually a very rare species - is it fair to assume that SMOTE wouldn't really help you?",statistics
n0vy39,1619667292.0,[q] help interpretting regression,"I ran a logistic regression,; for he variables NOT in the equation variable A is NOT significant, but black race is (i..e. black race has a significant relationship to the outcome), and their interaction is also significant. for the variables IN the equation, none became significant. however the model is significant. in this case do i say that any are significant associations? is there an interaction? why is the model significant if none of the variables are?

I also ran a regression with a different outcome variable that is continuous, and for variables not in equation only race was significant (not variable A and not their interaction)  but for variables in the equation, race remained significant, yet the model is not significant.

Would appreciate any insight into interpretation of whether an interaction exists.",statistics
n0v8la,1619664724.0,[C] Career advice in stats with a focus in animal behavior/biology,"Hey all, I have quite a conundrum ahead of me and help from any statistical professionals and students would be super helpful. Currently, I have a master's in evolutionary anthropology and a BS in biology with a focus on animal behavior. After I graduated from grad school I found a lot of my interests didn't really mesh with the current job opportunities. Something that I realized though is that a lot of grad students and even professors struggle with stats, especially in the medical field and I thought that there could a position either in a lab or in a biology/anthropology department to be the resident statistician if I got a masters in stats. However, I talked to a stats professor and he said that those positions don't really exist. So I'm kinda stuck at where I want to go next as I'm not sure what else is out there that I can do stats-wise that relates to biology and behavior. Any advice on what careers I can pursue in alternative what I had originally thought of that is related to animal behavior would be amazing!",statistics
n0v2cx,1619664089.0,"[D] Confused on How to Proceed : ""Binning Data""","

I am working on the following problem : I have a dataset and I want to fit a random forest model to the data. To illustrate my example, I created some fake data and fit the random forest model (I am using the R programming language):

\`\`\` #load library

library(randomForest)

\#create data

var\_1 <- rnorm(1000,10,10)

var\_2 <- rnorm(1000, 5, 5)

var\_3 <- rnorm(1000, 6,18)

favorite\_food <- c(""pizza"",""ice cream"", ""sushi"", ""carrots"", ""onions"", ""broccoli"", ""spinach"", ""artichoke"", ""lima beans"", ""asparagus"", ""eggplant"", ""lettuce"", ""cucumbers"")

favorite\_food <- sample(favorite\_food, 1000, replace=TRUE, prob=c(0.5, 0.45, 0.04, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001))

response <- c(""a"",""b"")

response <- sample(response, 1000, replace=TRUE, prob=c(0.3, 0.7))

data = data.frame( var\_1, var\_2, var\_3, favorite\_food, response)

data$favorite\_food = as.factor(data$favorite\_food)

data$response = as.factor(data$response)

\# fit random forest model

rf = randomForest(response \~ var\_1 + var\_2 + var\_3 + favorite\_food, data=data, ntree=50, mtry=2) \`\`\`

In this example, you can clearly see that for the ""favorite\_food"" variable. most people either like ""pizza"" or ""ice cream"" - the other categories (e.g. onions, eggplant, etc.) are almost none:

\`\`\` histogram(data$favorite\_food) \`\`\`

[https://imgur.com/a/s8bQ46j](https://imgur.com/a/s8bQ46j)

In this example, it would make sense to ""bin"" (reduce) the ""favorite\_food"" variable into 3 categories : ""pizza"", ""ice cream"" and ""other"". In this example, this is clear - but for bigger and more complex data, this is not always as clear.

Is there a common method in statistics that can be used to automatically ""bin"" variables having many categories, into fewer categories? I was looking into methods such as Factor Analysis ([https://en.wikipedia.org/wiki/Factor\_analysis](https://en.wikipedia.org/wiki/Factor_analysis)) and Latent Class Analysis ([https://en.wikipedia.org/wiki/Latent\_class\_model](https://en.wikipedia.org/wiki/Latent_class_model) ) - but I am not sure if these methods apply to this problem that I am working on.

In my real data, I am also trying to fit a random forest model and I have several categorical variables (e.g. such as favorite\_food) with hundreds of categories.

Can someone please suggest a statistical method that can be used to deal with this problem?

Thanks",statistics
n0uorf,1619662718.0,[Q] Bootstrapping for standardized rates using complex survey data,"When analyzing complex survey data (e.g. CCHS, NHANES), are bootstrap weights necessary when estimating CIs for age-standardized prevalence? The formula for the standard error of the age-adjusted rate (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm) only needs the count, population number, and number of individuals in the strata for the standard population. None of these would change whether or not you use the bootstrap weights",statistics
n0rm62,1619652261.0,[C] PStat/ GStat Certifications,"Is there any point in getting these certs from ASA or RSS? I see some people have it, but this doesn't seem like industry standard as the CFA/CPA is. In your opinions, are the benefits afforded by these certs worth the annual fees?",statistics
n0r68n,1619650862.0,[Q] Interaction and squared terms in regression,"How do I go about finding interaction and which terms to use as squared terms within a model? I have a model with 12 relevant variables.

Is it just common sense, or is there some formula that could be used to determine whether an interaction can occur, or squared terms would make sense?",statistics
n0pn0t,1619646321.0,[Question] What effects to these have on regression models?,"So let's say some variables have a high skew value, it means the model is not symmetrical,  skewed to the right, it has outliers, but what other implication does this have on a regression model? Like how and why would this affect a regression model?",statistics
n0phd8,1619645870.0,[Question] How to approach (pairwise?) comparison of many values to a standard with R and achieve a tabular output?,"Hobbyist/newcomer here; I have a dataset consisting of responses to the Census' Bureau's American Community Survey, which looks like this:

&#x200B;

| zip   	| totalresponses 	| hispanicresponses 	| MOE 	|
|-------	|----------------	|-------------------	|-----	|
| 01331 	| 2000           	| 211               	| 20  	|
| 18774 	| 785            	| 523               	| 102 	|
| 93571 	| 52000          	| 1455              	| 444 	|
| ...   	|                	| ...               	|     	|

&#x200B;

I would like to compare the percentage of hispanicresponses to the national percentage by zip code, so I end up with a table of results showing me how much each zip's percentage differs from the US percentage. Does anyone have suggestions on how to achieve that using R?",statistics
n0pgi5,1619645801.0,[Q] Why do we use logit for logistic regression?,"I've used logistic regression as one tool from many other classifiers, without any really deep understanding of what and why.

Now I have to teach my team about it, thus I finally want to understand the math it, and so I'm struggling with the following question.

So we use logit(p) on the left side of the equation, because the linear polynom on the right side has the domain of (-inf, +inf), while p is defined on \[0, 1\]. I've tried alternatively to use the expression

    1 if y_pred > 0.5 else 0

with the ordinary linear regression for classification, and it produced the same accuracy on my toy dataset as a proper logistic regression.

So are there any mathematical reasons to use logit, or it is just a customary thing, possibly leading to more efficient computations, especially if gradients are involved etc?

Specifically, does logit provide a guarantee that we're getting a probabilty of the class, and not just some number between 0 and 1?

If my questions doesn't make sense, here again what I did. I've prepared a dataset, consisting of the numpy matrix X with the shape (5000,3) and the labels y in shape (5000,1). The labels contained only 0s and 1s.

I've fitted then scikits LinearRegression class directly to those X and y. Of course, when I use the model to predict on a separate test dataset, it can return values outside of the (0, 1) domain. I'm bringing them back into 0s or 1s using the code line above, and then I'm calculating the accuracy score.

Next I use exact the same dataset to fit a LogisticRegression class, and I'm getting essentially the same accuracy score on the same test set. So, on the first sight, it *looks* like I can use just any way to convert the domains, if we're not interested in probabilities of the class.",statistics
n0os5s,1619643879.0,[Q] Help with chi-square for a research paper,"I'll try to keep this brief. I'm writing a research paper for psychology. However, it is being written in future tense because we aren't actually conducting the research (Covid). I still have to put something in the results and data analysis portion and were being told we would use chi-square. I did fine in stats class because we were always given data and a study to work out, but I never made my own.

My study consists of observing 60 total people walk by two different people begging on the street (so 30 people each). My hypothesis is that more people will give to someone who appears unable to work than someone who could work (testing bias).

Can anyone help me figure out the best way to word how I would work this out with chi-square? I think what's throwing me off is having two separate, random groups of 30 (I had to come up with something that didn't involve recruiting participants).",statistics
n0nfqg,1619640135.0,[Q] [E] What sort of things would you try to get on your CV if you wanted to make a statistics PhD application?,"Context:  Right now, I have an undergraduate degree in Mathematics. Since graduating, I've been working as a programmer, but I have an offer to do a Master's degree in statistics next year.

I'm thinking I'd like to do a PhD after my Master's, but I'm a bit worried that I would have no research experience, and generally not much to put on a PhD application compared to other candidates. Any thoughts on how you can put yourself into a good position for when it is time to start making applications? For example, would it be prudent to start working on my own statistical projects? I don't really see how else it would be  possible to get 'research experience'

Thanks in advance!",statistics
n0mg7d,1619637432.0,[Question] about (r)lmer formula syntax,"I have a group of subjects that participate in two conditions (*condition*). Within those two conditions, they do the same things (*phase*). I measure one thing (*dv*) in each phase. I'm confused about the proper formula syntax.

Would it be this, because *subject* is the grouping factor?
```
dv ~ condition * phase + (1 | subject)
```

or would it be this, because subject is ""nested under"" condition (or is that vice versa)?
```
dv ~ condition * phase + (1 | subject/condition)
```

or something completely different?",statistics
n0m3mi,1619636465.0,[Q] Is the Chi-Squared test appropriate to determine statistical significance for grouped continuous data?,"For instance, if I wanted to find out if the age distribution of people at an event was reflective of population age distribution, could I group people by age (eg 0-4, 5-9, 10-14 etc) and then perform a chi-squared test based on the number of people in each age category? If not, what would be a better statistical significance test for this kind of application?",statistics
n0lmpa,1619635179.0,[q] can we use Pearson’s and spearman correlations for binary variables such as a correlation between race and gender?,,statistics
n0lkf7,1619634996.0,[Q] Question about data transformation for ANOVA in R,"I have some data from a mixed between- and within-subjects experiment where participants were divided between 4 conditions and each group completed 2 blocks of a task. I want to run a mixed two-way ANOVA to see if RT in the task changed as either a function of condition group or block number. The RT data is all normally distributed except for one section which contains many outliers: condition 1, block 2. This is making RT non-normal, so I can't do the ANOVA. I can't find any non-parametric equivalents of the mixed ANOVA, and because the majority of the data contains no outliers I feel like there should be a parametric solution.

My question is whether I can use data transformation to help here? I'm using R, and when I do sqrtRT <- sqrt(mydata$RT) then sqrtRT passes the Shapiro-Wilk normality test. But how can I use sqrtRT in place of mydata$RT in the ANOVA?",statistics
n0lk3n,1619634972.0,[Q] CLT : What's the point of being able to do means comparaison tests when the original distributions aren't normal ?,"If I know the mean of a normal distribution, I have a pretty good idea of what the distribution is and looks like. If I know that 2 normal distributions have the same mean (and the same variance, which afaik, is an assumption of mean tests ), I'm pretty sure they are close to identical. And so using T-tests and other mean tests, if I compare 2 sample means from normal distributions and conclude from my test that those means are the same, I know that they belong to the same population distribution, right ?

But how does it make any sense of drawing conclusion from knowing that 2 sample means have the same population mean if the distribution they belong to arent normal ?? Those two distribution can have the same mean (or not) but could be very differents from each other ! Therefore it's not like I can infer they belong to the same distribution based on their mean since they arent normal !

What am I missing here ? Thanks for the help

EDIT: adding my thinking process I said in a comment :



I mention the CLT because the CLT apparently ""implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions "" and ""tells us that if a population distribution is non-normal, its sampling distribution of the sample mean will be normal for a large number of samples ""

Which makes us able to compare means of 2 distributions and do things like T-tests for distribution with any shape. Now, maybe it might make sense to compare the means of distributions that ""aren't normal"" but then my question is why ? What conclusions do you draw from knowing that the means of those 2 distribution are equal or not when the distribution aren't normal ?

And I mean that practically, in real world phenomenon. If I have 2 conditions and I'm trying to figure out if their distributions comes from the same population distribution, knowing that they come from the same population (have the same distribution) it means to me they are the result of the same process. If my observations are the product of 2 differents distribution I know it is not the same process at plays that generates those data.

When I uses T-tests and I know that the mean and variance are equal (or equal parameters for any other distribution) , I know my 2 means come from the same distribution (null hypothesis) and therefore HAVE THE SAME DISTRIBUTION/come from the same process. But it only works if the distribution are normal! (or test on parameters where I figure out that all parameters of distribution are equals) That's afaik, what's being done in science all the time.

Using a T-test and knowing that all my distributions are normal with same variance and that the mean are not different from each other, I know they come from the same dsitribution (same laws generate the data), that makes sense to me.

But now, when the CLT claim that we can use those mean test for any distribution, I wonder what's the point of knowing that the means are the same since the distribution tehy come from are likely not the same even with the same mean ( u cant draw the same conclusion as above), so why would you do that ? what conclusion can you make from it ?",statistics
n0kf1w,1619631863.0,[Question] Can I remove a significant variable from a regression model?,"I have an assignment to build a regression model, then analyse it etc.

Now for my starting model I used all of the variables, and got that they were all significant at 1%. I doubt that would be it, since I don't think we would get a dataset for this assignment where the basic model is perfect, so my question is:

if I see that there is multicollinearity between variables, would it be methodologically correct to remove them even if they are significant? (and then test if the new model will show better R\^2, BIC values than the starting one) or if a variable is significant it shouldn't be removed at all?",statistics
n0k82q,1619631343.0,[Q] Very quick question. Is there a problem having one predictor that is predictable from a combination of the other two?,"Imagine a study where people rate pictures on mood. The predictors are whether there is blue in a picture (yes/no) and whether there is red in a picture (yes/no). The analysis is a mixed effect linear regression.

Is there a problem in adding a predictor that is whether there is both blue and red in the same picture (yes/no)? In this example the model is like this:

Rating = BluePresent + RedPresent + BlueAndRedPresent

My gut says this is wrong, because BlueAndRedPresent is redundant with a combination of the first two predictors. However, R actually lets me run this with simulated data and gives a separate coefficient for each predictor.",statistics
n0iqon,1619627378.0,[Q] How can I politely describe why having a censored event every day for every subject in TTE is incorrect?,"A friend of mine is new to TTE, and is trying to rerun a random survival forest that their boss provided them with updated data. They came to me to ask for a quick rundown of how survival analysis works and we quickly came to a sticking point:

Their data is daily observations for each subject with a censor if they are still going at the end of the day and an event if the subject died. It looks like this:

    Subject Time Event
    1       1    0
    1       2    0
    1       3    1
    2       1    0
    2       2    1

They are then feeding this into the model with no control for repeated observations.

I have never worked with a random survival forest before, but from standard cox survival analysis, my first reaction to this is to gargle incoherently before shouting ""That is not how TTE works"". (Am I wrong when it comes to random forests?)

I am having a lot of trouble convincing them that this is not how a TTE model typically takes data.

When I try showing examples of other TTE datasets, I get a response of ""But that does not say we can't do it this way.""

The closest I have come is on the repeated observation approach, but they just dug up another method for TTE with recurring events and said ""Well, this is like that, so we can adapt RSF to take into account recurring events.""

I think that one of the sticking points here is that they are using a few variables in the model that also change over time, and they really want to be able to keep those variables in their predictions. (Even though, when using the model in the real world those data would not be available at the time of prediction.)

Am I nuts? or are they nuts? Any suggestions for better arguments?",statistics
n0h663,1619623190.0,"[Q] Can you do a PCA that includes continuous, categorical, and continuous data? Need help with direction for data analysis.","EDIT: whoops, title should say “ordinal, categorical, and continuous data”!


Hello all,
I’m a graduate student trying to analyze data for my dissertation. I have ordinal data for my dependent variable (abundance of frog calls, on a scale of 0-3) and a lot of/too many independent variables (things like site size, water quality metrics, soil type, distance from other sites) that are mostly continuous, but with two categorical variables. I want to know if the abundance of frog calling is related to any of the independent variables.

From conversations with my advisor and others, I think I need to do a correlation matrix and cut out variables that are highly correlated.
Then I should do a PCA to pick out variables to use for further testing.
Then I should do a multiple ordinal regression to test the significance for the selected variable’s effect on the dependent.

What I don’t understand: can I do a correlation matrix and a PCA with ordinal, categorical, and continuous data together? I did read about doing polychoric PCA but I’m confused about if that’s only for if ALL of your data is ordinal.

Any insight is much appreciated!",statistics
n0gw1l,1619622440.0,[R] [Q] Pressed into upgrading my thesis to a Meta-analysis.. deadline in 2 weeks,"Hey guys!

I'm a university student from Europe... At the very end of my studies!

Feel free to skip this bit, but I feel some background info might be helpful: for my degree, our university demands we write and present a research work done by a student and lead by a teacher. I found a nice teacher with plenty of published research, met with him, and he accepted me as his understudy and charged my with writing a systematic review on the efficacy of a surgical intervention on pain relief in patients with a certain illness. I couldn't be happier at the time!

Fast forward some months and the situation has changed dramatically: the teacher ghosts me for weeks, I often have to send the same email 2-3x times, takes weeks to reply with useless information, can't be bothered to read my drafts.. basically I've been pressuring him since February to read the thing: I'm still missing part of the results portion of the thesis but I need help to go forward, and finish the work so I can submit it to the University and present it. I must do this to finish my degree.

Last week we finally had a meeting, he skimmed through my draft and non chalantly said that so far so good and that I have carte blanche to finish the results. I told him I needed help with that, hence this meeting but he replied I needed to do it on my own. He also upgraded the research design to a meta-analysis, knowing full well I don't have the necessary knowledge to do it alone. I was shocked for a second and after regaining my composure, I told him, for a second time, that I needed help. He dismissed me saying I needed to do it myself. I don't want to sound like a drama queen but I never felt so abandoned in my life 🤦

I have considered charging a complaint but nothing useful would come of it in time.

I have to deliver this paper, corrected, to the University, by mid-May. I have done:
- research and introduction
- methods and PRISMA flow diagram
- data extraction to an Excel spreadsheet (number of patients, outcome, etc)

Now I'm stuck. I've recommended to use Cochran's Review Manager 5 to do the data analysis but I have no clue what to do next... My outcome is whether or not a given pain threatment is effective. But I don't know how to take it from there and I've only got 2 weeks, split with classes and exam prep to do this. Got any clues on how to proceed? Thank you so much!

TL;DR: thesis got upgraded to meta-analysis. Have no idea on how to move forward after data extraction.",statistics
n0ftrs,1619619509.0,[Q] Need help figuring what test to use - Dissertation,"Hi there, for my dissertation research I made a questionnaire surrouding (university) student attitudes to immigration which I intend to analyse using SPSS. However I'm stuck on deciding how exactly I analyse the data. Any help?",statistics
n0ews1,1619616837.0,[Q] [E] Need help in making research plan,"I am interested in applying for master's study and I need to make a research plan for the scholarship I am applying. I plan to study Mathematical Statistics to understand about data science and machine learning stuff theoretically much deeper. What are the courses/classes I need to take and what would be good or redundant to take? I only know I need to take Theory of Statistical Mathematics class but I don't know what else.

Some info:
-I have an applied physics undergraduate degree (oceanography) so I  am somewhat familiar with statistics. Also from learning data science these couple of months.
-I plan to study in Japan so I would be a research student first before actually taking classes.",statistics
n0dfv2,1619612034.0,[Q] What is the variance of this?,"If every minute I do X with probability 1/Y... then I'm guessing that the expected period between doing X's would be Y minutes. Is that correct?

How do I work out what the variance of this period is? Is it exponentially distributed and is the variance Y^2 minutes?

EDIT: this is geometric, and there's a good video here about it: https://www.jbstatistics.com/introduction-to-the-geometric-distribution/ (thanks for the help!)",statistics
n0d7cq,1619611223.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
n09bku,1619594375.0,[Q] Counterfactual vs Vanilla Contrasts,"I still don’t quite get what the difference between counterfactual outcomes and just regression contrasts is. With G computation, it just seems like its the exact same thing rebranded.

So what is so special about it and what is the hype? We never did causal inference in my program so I am trying to connect it back to what I do know about GLMs and contrasts

So a regular contrast estimates E(Y|T=1,X)-E(Y|T=0,X)

A counterfactual contrast is E(Y^(1))-E(Y^(0)) or something like that where the ^ indicates here its a potential outcome under getting that T.

But in practice with G computation what I see is happening is various assumptions are being made and people use the vanilla contrast to do it. For GLMs, it may just be on the response scale rather than link scale. But couldn’t this be done via delta method and vanilla contrast too?

All this terminology in causal inference and especially the DAGs I feel really obscures the main point.

Is the only difference that you impose additional assumptions such as exchangeability, consistency, positivity, SUTVA and then interpret the vanilla contrast on observational data as a causal effect?",statistics
n08rmn,1619591877.0,"[D] Standard approach for ""binning"" categorical variables together","Suppose you have a dataset where some of the predictor variables are categorical and have hundreds of possible (discrete) values. Are there any common ways to ""bin"" all these values into general groups?

E.g. suppose one of the variables is : 50% ""A"", 25% ""B"" , 20% ""C"", 0.5% D, 0.5% E, 0.5% F ....etc.

Could you reformat this variable as A, B, C, OTHER ?

Is this a common technique? Is this acceptable? Some statistical computing software can not always handle so many categories, other times perhaps it is advantageous to ""bin"" many low frequency entries together to facilitate statistical modelling?

thanks",statistics
n06qh6,1619583564.0,"[D] Are the ""functions"" that neural networks are trying to approximate ""conceivable""?","Based on the ""universal aproximation theorem"" (  https://en.m.wikipedia.org/wiki/Universal_approximation_theorem),
neural network are said to be able to approximate any ""function"" reasonably well.

From a very basic definition in math, here is what I think of when I hear the word ""function"" :
 https://www.mathsisfun.com/sets/images/function-sets.svg

Suppose you have a task in which you have pictures of cats and dogs. You want to train a neural network to recognize pictures (i guess pictures can be considered as large matrices of numbers). In this case, what is the ""function"" that the neural network is trying to aproximate?

Like in this picture (https://www.mathsisfun.com/sets/images/function-sets.svg),  can you say that the ""orange circle"" are the numbers contained in the pixels corresponding to ""cat"" or ""dog"" ...and these are ""mapped"" to the  ""yellow circle"" containing ""cat"" or ""dog""?

In this example, is the ""function"" an abstract concept that can not be directly observed (numbers contained in pixels -> dog or cat)?",statistics
n06jb5,1619582828.0,"[D] Do all machine learning algorithms indirectly use the ""nearest neighbor"" principle?"," Do all machine learning algorithms indirectly use the ""nearest neighbor"" principle? I.e. ""birds of the same flock fly together""?

For example, (my naive understanding of neural networks) neural networks make a ""network"" that is composed of a  distinct combination of (mathematically significant) ""weights"" (through the backpropogation algorithm) that shuttles the data through the network; and in the process predicts and assigns them to an ""ouput label"" (e.g. ""1"" or ""0"").  The assignment process has a certain statistical accuracy.

So for new data, can we say that the neural network works indirectly using the ""nearest neighbor principle""? E.g two similar data points will be ""shuttled and assigned"" to similar ""output labels""?",statistics
n0653j,1619581416.0,"[D] Official term for ""model stability""?","Is there an official mathematical term for ""model stability""?

 E.g.  for two inputs that are slightly different, the same statistical model would produce notably different outputs?",statistics
n063sb,1619581286.0,"[D] reasons to discourage using linear regression on ""big data""","Are there any mathematical justifications as to why (obvious question) we shouldn't use linear regression on big data?

For example, is there a math formula that shows the more ""data points"" (rows and columns) you have, the probability for these points to become ""non-linearly sepperable"" increases?

Is there a mathematical formula that explicitly shows that ""linear regression models can not model non-linearly sepperable data""?

Is there a mathematical formula that shows when you have more ""data points"",  the standard error of a linear regression model (e.g. the beta parameter estimates) are more likely to rapidly increases?

Is there any mathematical formula that shows linear regression models for big data are ""unstable""? E.g. for two inputs that are slightly different, the same linear regression model would produce notably different outputs?

Thanks",statistics
n05xmw,1619580664.0,"[D] difference between ""inductive bias"" and ""model assumptions""","Recently, I came across this term ""inductive bias"":

https://stackoverflow.com/questions/35655267/what-is-inductive-bias-in-machine-learning

https://en.m.wikipedia.org/wiki/Inductive_bias

I am having difficulty understanding what is the difference between inductive bias and model assumptions.

An example of an inductive bias (stackoverflow link) says: ""in Logistic Regression: There exists a hyperplane which separates negative / positive examples ""

Wouldn't this be the same as a model assumption? Can someone please explain the difference?

Thanks",statistics
n05tyk,1619580304.0,[D] typical difference in depth between neural networks and deep neural networks?,"I know this might sound like a silly question: but when people use the term ""deep"" neural networks - is there a minimum number of layers/neurons required for a neural network to be called ""deep""?",statistics
n05ryd,1619580115.0,[D] do machine learning models handle multicollinearity better than traditional models (e.g. linear regression)?,"When it comes to older and traditional models like linear regression, ensuring that the variables did not have multicollinearity was very important. Multicollinearity greatly harms the prediction ability of a model.

However, older and traditional models were meant to be used on smaller datasets, with fewer rows and fewer colums compared to modern big data. Intuitively, it is easier to identify and correct multicollinearity in smaller datasets (e.g. variable transformations, removing variables through stepwise selection, etc.)

In machine learning models with big data - is multicollinearity as big a problem?

E.g. are models like randon forest known to sustain a strong performance in the presence of multicollinearity? If so, what makes random forest immune to multicollinearity?

Are neural networks and deep neural networks abke to deal with multicollinearity ? If so, what makes neural networks immune to multicollinearity?

Thanks",statistics
n050u1,1619577552.0,[Q] help: multivariable linear regression,"Help: multivariable linear regression

I have very limited stats knowledge but I wasn’t able to out source to a statistician for my research project....I have a pretty small sample size of patients (n=159) (it is definitely not powered) and basically I’m looking at a lot of relationships in a variety of ways; I’m wondering if I can present my data in terms of just the R^2 values as far as what the best overall relationships are or if I really need to get into the b coefficient and p values, CI, etc. (can I just call it “descriptive statistics” since it’s not powered anyway and avoid all that?)

Or maybe if I use the R2 values to determine the best relationship maybe I can go into that one in further detail?",statistics
n04ur4,1619576973.0,[Q] Propogating standard errors in predictions from regression models,"Hi all,

Trying to remember my university stats classes. If we are making a prediction with outputs of a regression model, I'm keen to work out what the standard error around the final predicted output would be.

For example, from the regression output below, I am trying to predict the utility of a patient with seizures twice per day and with type 2 seizures. As its on the normal scale, the predicted value is just intercept + coefficient(twice per day) + coefficient(type 2 seizures) = 0.857 - 0.150 - 0.06 = 0.647. How do you calculate the standard error of this final prediction?

https://imgur.com/a/FIbNXT5",statistics
mzzqmt,1619560638.0,[Q] Having an a priori estimate of an interaction coefficient in logistic regression.,"I've posted on this topic before but this is a bit of a different question. I am coming up with estimates of coefficients for a logistic mixed effects regression in order to simulate data for a power analysis.

I am struggling with the interaction coefficient.

Let me start by describing the general pattern I expect. I'll make up a study to be able to do that:

The dependent variable is recognition accuracy. I have two binary predictors that are effects coded. I expect the general pattern to be like this:


 | IV1 - A | IV1 - B
---|---|----
IV2 - A | High Accuracy | Medium Accuracy
IV2 - B | High Accuracy | Low Accuracy

How would I go about estimating a coefficient for the interaction?

Edit: IV1 and IV2 are my two predictors. Each with two levels: a level A and a level B.",statistics
mzw7up,1619551027.0,[Q] Can you isolate the individual effects of an exposure in a regression model that uses dummy variables to incorporate two exposures?,"In my regression, I have two exposures of interest, exA and exB.
I have created dummy variables to incorporate these two exposures into one variable:

group1 - exA, exB [ref, not included in the model]

group2 - exA, no exB

group3 - no exA, exB

group4 - no exA, no exB

In my regression model, I have included dummy2-4 as variables in the model and am using group1 as the ref (i.e. when group2-4 are all 0).

If I get a coefficient of Z for group2, for example, this would mean that the risk of having the outcome is Z for group2 vs ref (group1). Since group2 is [exA, no exB] and group 1 is [exA, exB], can we attribute the difference in risk Z due to exB status?

If I think that there are interaction effects between exA and exB, would it even make sense to try to tease out the individual effects of exB and exB using coefficients in the model?


[I realize that running a regression with individual components exA and exB would make more sense, but I'm trying to work out the dummy variable concept in my head through this example]",statistics
mzvlav,1619549332.0,[Q] Spearman's Rank Correlation for Qualitative Data,"1) How can we use the spearman's rank correlation in case of qualitative data? Are there any advantages to this?

2) Also, what other correlation techniques could be used for qualitative data?",statistics
mzv55v,1619548112.0,[Q] I Need help with regression model,"A) we know that the value of company2 is 15000€ in December (that is, month 12). Calculate the value of company1 in December using regression model (Y=3.986x-1023.606)?

Month 11 is
Company1:3400€ company2:11500€

How can I calculate that?",statistics
mzqnmn,1619536368.0,[D] deciding how much data to use for a statistical model,"This is a concept i always struggled with: in statistics, is ""more data always better""?

Suppose you 50 years of data about hospital visits. You are interested in supervised classification. You have predictors such as age, height, weight, blood type, salary, etc. You are interested in predicting if the hospital stay will be less than 1 day or more than 1 day. This can be easily solved using random forest.

My dilemma is: using all 50 years of data might be able to capture a wide variety of patterns  ... but since we are interested in predicting future information, maybe some of the older data is less relevant and might surpress more current trends?

How do you deal with this problem? I thought of multiplying older observations by 0.5 to reduce their influence, but I am not sure if this is an acceptable approach.

Does anyone have any suggestions?

Thanks",statistics
mzqiih,1619535984.0,"[Q] Best books for complete regression analysis with R that have every step for publication quality regression analysis (regression, assumption checking, effect size estimation, interpretation of results and everything else that is needed to write high quality article)","What book you suggest for regression analysis with R that every step for publication quality regression analysis? By publication quality I mean everything that should be done for regression analysis for high quality peer reviewed article (regression, assumption checking, effect size estimation, interpretation of results, etc)",statistics
mzqhdl,1619535897.0,[Q] I have a question about predictors in a multiple regression,"Hi! In my study I have two groups (desktop vs VR) and my outcome of interest is X. However, I also measure Y (as a control), Z, and W, and I am interested in their effect on X. Based on the literature, the condition (desktop or VR) is likely to also affect the other variables I am measuring. Can I still run regression analysis in the form of:

X = a + b\*Condition + c\*Y + d\*Z + e\*W (and then test for any interactions)?

Or would I need to run a regression / condition group: so run it once with data from Desktop only and once with data from VR only and test the effect of condition on X with a different method? (I am aware of testing the assumption of multicollinearity, I am just worried that because the condition likely affects the values of the other predictors it is not a good idea to run one regression on the entire sample)

My research questions are whether the variables (condition, Z and W) have an effect on X; and whether there are any relationships between any of the three and if that relationship has an effect on X (I see this as interaction).

Any help with this would be greatly appreciated. Also, I apologise if this is a stupid question.",statistics
mzq4ig,1619534918.0,"[D] appeal of ""occam's razor"" in statistics and machine learning","People often refer to ""occam's razor"" in statistics, that simpler models are preferred to complex models, provided both models have similar performance.

Why should we prefer a simpler model? Does this have to do with the variance-bias tradeoff?",statistics
mzphhh,1619533157.0,[D] What's your favorite concept/rule/theorem in statistics and why?,What idea(s) in statistics really speak to you or you think are just the coolest things? Why? What should everyone know about them?,statistics
mzp1na,1619531902.0,[Q] What's the difference between a QQ-plot and a normal probability plot?,,statistics
mzog1s,1619530069.0,[Q] how do generic probabilities work?,"If a certain genetic condition is diagnosed in 1/100 people, and I have a risk factor that studies have shown increases my risk by 2x, does that mean I have a 1/50 chance of being diagnosed with the condition?",statistics
mzkhvk,1619515384.0,[Q] Central limit theorem and addition of independant random variable,"Hi all,

So I'm studying CLT and I see that its at the basis of the normal law in most cases. So if we ""add independant random variables"" together and stack them we will end up with a normal law.

But I have rouble understanding what's being meant by independant random variables in this case. For example with the usual sample means and sampling distribution, how are the means independant since they all come from the same distribution that has a pretty well defined logic behind it ?

I have been told that to obtain a normal law, each observation we make must itself be the result of an addition of independant phenomenon and that it is misunderstood a lot. Because if it's true almost no phenomena should follow a normal law since a single observation is most often the result of interdependant events (determined by precise logic and laws of nature). What do you think about that ? Where can I learn more about it ?",statistics
mzkcp6,1619514753.0,[Q] Central limit theorem and normal law," Hi all,

So I understand that when we sample a distribution and take the MEANS of sample and create a sampling distribution of means it will tend to a normal distribution. And that it's at the basis of T-test and all of mean test

But what about the samples' distribution and the population distribution of the phenomena we are studying when it is not normal ? Ok we will have a sampling distribution that is normal but making a test based on means to it doesnt make any sense, right ? and doesnt having the original distribution being normal isnt an assumption in order to make T-test and others standard tests ? What's the point then ?",statistics
mzk05r,1619513199.0,[Q] Does it make sense to compare the standard deviation of 2 samples of very different sizes?,"Say I have two samples of very different sizes: sample 1 has 50 observations, sample 2 has 500.

I would like to compare the standard deviation of both samples. Does it make sense to do so without any use of undersampling / oversampling methods?",statistics
mzjb7f,1619510105.0,[Q] Mutivariate Linear Regression vs Multiple Linear Regression,"I started learning multivariate linear regression in a multivariate statistics module and I'm struggling to understand the difference with the following:

Would a multivariate model with k target variables be equivalent to running k multiple linear regression models, one for each of the target variables in the multivariate model?",statistics
mzhlqr,1619502482.0,[Q] Homework question regarding OLS regression,"Hello all,

I'm taking an advanced stats class for this graduate program that I'm in and me and some classmates are stuck on the current homework assignment. We are using SPSS. The homework requires us to run OLS regression on some variables and then take a quiz using the results that we get. We followed the directions (clean variables, transform certain variables into logged versions of themselves and others into squared versions) but still can't get the ""correct"" results. Actually, the results we keep getting are a little outrageous. We are getting coefficients in 5 digit numbers and the answers are only 3 digits. We've started over and followed the instructions several times but still can't get any results even close to the correct answers. The worst part is that the class is asynchronous and the professor doesn't have constant office hours so we can't even ask him for help most of the time. I know that this is a difficult question for you guys to answer because you'd have to see every step we took before running the regression model so if you need any additional information please dont hesitate to message me, I'd be happy to provide screenshots and stuff. Please and thank you!",statistics
mzgol7,1619498680.0,[D] books/references for learning about newer machine learning models,"A lot of books that are currently available do not contain a lot of material on newer models like ""transformer"" models (e.g. in the context of time series). Can someone recommend some book/source that introduces transformers?

Thanks",statistics
mzgalq,1619497148.0,[Q] Probability question,"I have someone who is trying to pass a multiple choice exam for state licensing, each question has 4 choices and only 1 correct answer. The exam question bank is roughly 300 questions, the exam is 120 questions. Passing grade is 80%.  The person in question has taken and failed the exam 16 times.  If one were to randomly select answers, how many times would it take to achieve a passing score?",statistics
mzfchf,1619493635.0,[Question] Most Appropriate Statistically Analysis,"I  am looking for assistance in finding the most appropriate statistical  analysis for my data set. I am investigating the effectiveness of different survey methods in the detection of burrows.  Each method is tested against the same burrow across six grids, and properties of those burrows are recorded as the additional predictors.  Version 1 of my  data set looks similar to this,

Method 1 Method 2 Method 3 Vegetation Activity

1 1 1 Grass Active

1 1 1 Grass Inactive

1 1 1 Shrub Active

0 1 1 Shrub Inactive

0 1 1 Canopy Active

0 0 1 Canopy Inactive

As you can see the predictors are categorical and the responses are binary. I ran logistic regression using R with the following code and the results are not what I have expected?

    LM1 <- glm(Method 1 ~ Vegetation * Activity, data=Logistic, family = binomial) anova(LM1, test=""Chisq"") summary(LM1)

It basically stated that  grass has a statically significant effect on burrow detection, okay.  But I am more interested in whether the method did not detect the  burrows. I may be confusing the output data and interpreting it wrong.  For example, I would have thought canopy would have a significant effect  as the method didn't detect any burrows in the example set, only  roughly 20% in my actual dataset but it did not come out as significant  >0.005.

So I transformed the data to a continuous response based on the grids to look something like this

Burrows Method Vegetation Activity Grid

6 M1 Grass Active 1

4 M1 Grass Inactive 1

2 M1 Shrub Active 1

6 M2 Grass Active 1

5 M2 Grass Inactive 1

3 M2 Shrub Active 1

And ran an ANOVA on that dataset, although I'm not sure if this is correct,  as there were only 14 burrows in grid 1, and there is overlap between burrows and methods.

Basically, I  would like to know the best way to determine if vegetation and/or activity affect the detection of a burrow within a  SINGLE method. Then,  potentially determine the difference between methods within the predictors, eg is method 1 better at detecting burrow in grthe ass, method 2  is better in shrub etc. Then, if there is an overall difference between burrows detected by the three different methods.

Sorry if this is all over the place, not sure how to explain my problem in writing

Thanks in advance",statistics
mzezrl,1619492416.0,[Question] What is the appropriate way to analyze baseline characteristics?,"So say you have:


Group 1 (N=60): 3, 37, 15, 2, 3


Group 2 (N=66): 5, 50, 10, 4, 1


Should I use X-square to test for the overall group, or should I test to compare each specific variable (for example for the first # doing 3 yes, 57 no for group 1 and 5 yes, 61 no for group 2)


What's the appropriate way to conduct the test?",statistics
mzd5d9,1619486221.0,[Q]Probability of a binary outcome averaging to a different value after a certain number of trials,"Hello,

I took statistics in college but only the baby course they give to engineers.  I had a discussion with a co-worker about how unlikely some event might be.

The idea is imagine we are flipping a coin which has a 40% chance of landing heads and 60% of landing tails.  I'm interested in how I'd go about finding the probability that after x(maybe 100) flips that the total number of heads is more than the number of tails.

This is a super easy problem but I can't seem to remember how I'd go about this.

Thank you!",statistics
mzaw0i,1619479163.0,[Q] Can you help me intuitively understand an interaction coefficient in linear regression with effects coded predictors?,"Let's imagine an experiment where people look at pictures and then rate their mood after each one from 1 (sad) to 7 (happy). The pictures can either be happy or sad (IV1), and participants are either doing the experiment on a high resolution or a low resolution monitor (IV2). (This is not my real experiment, just an example.)

These two predictors are effects coded and the data are analyzed at the trial level with mixed effects linear regressions.

Let's say the coefficient for picture type is +1. I think this means that on average, mood after happy pictures is rated two points higher than sad pictures (remember it is effects coded).

Let's say the coefficient for screen type is +.5: people are on average 1 point happier when doing the experiment on high resolution monitors.

Can you help me intuitively understand the interaction coefficient? Let's say, for example, I expect the effect of picture type to be a three point difference on the high resolution monitor, and a one point difference on the low resolution monitor. What interaction coefficient would that translate to? I think that I know how to work this out with dummy coding, but I am at a loss now with effects coding.",statistics
mz9w0w,1619476230.0,[Education] Stuck in one location for ~3 years - MS in Data Analytics worth it?,"TLDR: I’m looking for viable ways to “break” into the field of data science from a social science background and wondered if the following program will give me enough of a foundation to make the move.

I have a BA in political science, brief work R was required for methods and I really enjoyed it. I’ve taken Java I and II, Discrete Mathematics, Calc I-III, and Linear Algebra.

At my uni I already attend we have a MS that goes as follows:

Core:
Intro to Database Systems,
Intro to Machine Learning,
Big Data Analytics,
Deep Learning,
Intro to Statistical Computation,
Advances Statistical Methods

2 Electives from the following:
Data Mining,
NoSQL Databases,
Data Visualization,
Advanced Topic classes (vary by sem),
Operations Research Methods

And then Practicum

Would this be useful? It wouldn’t cost me too much out of pocket, <$10k. I have a decent govt job right now doing something completely unrelated (IT, work with Mainframe but it’s being automated away).

I don’t have a super strong comp sci background (clearly...) and while I’m in this location (for personal reasons) I thought I could make the most of it? If I’m shooting myself in the foot thats totally valid also and I’m okay with just working and waiting to apply later to Applied Stats or something else. I didn’t get any chance to do research in undergrad, and there’s a decent opportunity for that in this program. I’ll be able to keep my current job when enrolled in this program also so no huge blow to “opportunity costs” since that’s what I’d be doing anyway.

Beyond this would I need a second MS or any further education, or will this be sufficient to get me started? Thanks for any help/advice!",statistics
mz7lve,1619470093.0,[Q] Is there any downloadable or browser program which can make more detailed stats?,"So recently we won a tournament. And I want to analyze the data, mark up the bad rates,  what was the distribution, etc.

Is there a good site/ program (what not relies on coding,) to do this rather than using Excel.?",statistics
mz7ab8,1619469242.0,[Q] How to report a Kruskal–Wallis test to APA student guidelines?,"I seem to find many articles using different methods to report the statistics. Any idea or link to an article reporting it correctly (that I would then be able to reference)?

I am attempting to report:

The distribution of the scores did not improve when transformed using a logarithmic scale and therefore the data was analysed using a series of Kruskal–Wallis tests and reported here using similar statistics to \_\_\_\_\_. Relationship LSNS-R score significantly differed between the drug groups, (*X2*)= 7.01, p=.030), with posthoc pairwise comparisons indicating that, after conducting a Bonferroni correction, the MDMA (Median= 90.15) group scores were found to be significantly higher than the polydrug group scores (Median = 71.41, p=.037; see Figure 1).",statistics
mz5p7v,1619465090.0,[S] GUIDE Classification and Regression Tree/Forest Algorithm,"Hi everyone, I'm just wrapping up a course I'm taking this semester on classification and the GUIDE algorithm. I thought I would share some details about the GUIDE algorithm developed by my professor Wei-Yin Loh over the past 30 years. GUIDE (Generalized, Unbiased, Interaction Detection and Estimation) has many features that make it stand out among other Classification and Regression Tree/Forest Algorithms.  From the GUIDE Manual:

""GUIDE is the only classification

and regression tree algorithm with all these features:

1. Unbiased variable selection with and without missing data.

2. Unbiased importance scoring and thresholding of predictor variables.

3. Automatic handling of missing values without requiring prior imputation.

4. One or more missing value codes.

5. Missing-value flag variables.

6. Periodic or cyclic variables, such as angular direction, hour of day, day of week,

month of year, and seasons.

7. Subgroup identification for differential treatment effects.

8. Linear splits and kernel and nearest-neighbor node models for classification

trees.

9. Weighted least squares, least median of squares, logistic, quantile, Poisson, and

relative risk (proportional hazards) regression models.

10. Univariate, multivariate, censored, and longitudinal response variables.

11. Pairwise interaction detection at each node.

12. Categorical variables for splitting only, fitting only (via 0-1 dummy variables),

or both in regression tree models.

13. Tree ensembles (bagging and forests).""

Additionally some things that I have noticed while using GUIDE are:

1. Very neat aesthetically pleasing tree diagrams of even very large trees in Latex.
2. Comparatively short run times
3. Variable Importance Scoring

GUIDE can be downloaded for free here: [http://pages.stat.wisc.edu/\~loh/guide.html](http://pages.stat.wisc.edu/~loh/guide.html)",statistics
mz4rsq,1619462715.0,[C][R] Comparative analysis,"A quick aside: stats was my worse class in grad school. So the measurement I'm imagining in my head may not really be a possibility but here goes.

I'm working on a grant and I need a tool that measures food affordability. The problem is, not only is that a nebulous term, but the agreed upon measures already in existence are widely disputed in public health.

In short I need a was to quantifiably prove that the price of [an objectively nutritious thing] a 1lb bag of apples is ""affordable""

[And for the sake of continuity, let's say affordable is a reasonable purchase for a family of 4 that is just above the federal poverty line.]

Current measurements include price per unit of mass, price per portion, and price per unit of energy (calorie).

The problem of course is, if you compare a bag of chips and bag of apples per calorie, the chips seem like the better option. Price per mass fails because we don't consume foods in mass comparative samples. [i.e. few people eat the same mass of ice cream and carrots at dinner.]

What I would like would be a measure that compares price per recommended serving size vs nutritious value. But again such a thing may not yet exist",statistics
mz4dy6,1619461689.0,[Q] Test of Proportions Question,"I've got a strange proportions question...

The proportion of neck pain for males and females following a collision is 0.24 and 0.45, respectively. I have a data-set where 10 males and 10 females went through two collisions each, and none of them ever developed neck pain. Obviously this data calls for a binomial test, but would the correct p-value be (1 - 0.24)\^10 (1 - 0.45)\^10 = 0.000162, or should it be broken down by sex to (1-0.24)\^10 = 0.064 and (1 - 0.45)\^10 = 0.0025? Should I factor in the two collisions by assuming that they're independent (thus doubling the sample size) or is that too disingenuous?

&#x200B;

Thanks in advance!",statistics
mz3ypd,1619460569.0,[Q] I need help with SPSS,"This is the task

(b) Create a new variable Grade by using the following rule: Grade is 5 if ratio ≥ 0.9, 4 if 0.8≤ratio<0.9, 3 if 0.7≤ratio<0.8, 2if0.6≤ratio<0.7, 1 if 0.5≤ratio<0.6 and 0 if ratio < 0.5.

Can you tell me step by step how can I apply that to spss?",statistics
mz22k5,1619455651.0,[Q] Data issue investigation: experience & market timing," Hi all, I'm doing research into whether more experienced fund managers refrain from raising funds in recessions. Basically, I proxy experience with the number of previous funds a manager has had and created a recession year dummy variable. My aim is to create a simple graphic that shows whether experienced managers wait for the recession to be over. Which would lead to a lower average experience in such a year (current approach).

However, based on this approach I see little to no difference in experience between recessionary years and non-recessionary years. My concern is that there may be a change in the distribution but not a change in the average. To complicate things, the average number of experience increases over time, and since recessions are spread out, I need to somehow compensate for this.

I feel stuck, so I am happy to hear any suggestions or alternative approaches.",statistics
mz10x5,1619452887.0,"[Q] If I am building 2 different types of models to predict the same thing, does my partition need to be the same to train each model?","Basically the title, but for clarity. Let’s say I am building two models to predict some binary response. One model will be a Boosted Logistic Regression, and the other an Artificial Neural Network (Hypothetically). When building and evaluating training models do I need them to use the same exact data partition in order to make a comparison later on? Or does the partition only need to be validated? Thanks",statistics
mz0kew,1619451686.0,[Question] Resources with step-by-step explanations for conducting statistical analysis on Likert scale/item data?,"

Hellow [r/statistics](https://www.reddit.com/r/statistics/)

I'm  in the middle of a project and I have to conduct some analysis on  Likert-type data. I've searched online for days for any guide as to how  to perform ***any***  analysis but I can't find anything specific. Can anyone recommend some  resources like books or articles for non-parametric tests  (Kruskal-Wallis, Mann-Whitney, ordinal regression, etc)? Preferably  something with a step-by-step explanation, because I need to understand  the reasoning behind the tests.",statistics
myz0fw,1619447547.0,[E] How to customize my MStat program,"Hello! I was recently admitted into the MStat program at my local university and am starting this fall. I’m really excited because I majored in math and found that the statistics and probability courses I took were really interesting to me, whereas the pure math stuff (ugh real analysis) was not a ton of fun.

Anyway, I’m reaching out to the community today to get some guidance on what would be the best way to tackle my program. Where I’m at is, typically the degree requirements include

1) One section of introductory probability

2) Two sections of introductory statistical inference

3) Two graduate sections of linear models

4) One graduate section of mathematical statistics

5) Four graduate electives, either from the Math Department or “scientifically oriented” sections from other departments

So when I completed my BS, I already worked through items 1 and 2, and so that opens up three additional electives for me. So I am pretty much in a boat where I can tailor this degree to be just about whatever I want since the only statistics I’m required to do are the graduate sections of linear models and mathematical statistics.

I have seven electives! Who would have thunk it? So I’m trying to figure out what to do with all of this freedom. The thing that immediately came to mind is that my computer programming is definitely lacking, and so I thought I would go through the CS department’s prerequisites to eventually take two graduate sections of software development, and then some combination of a few different graduate sections of probabilistic machine learning and artificial intelligence.

**My question is: are there areas where my electives might be better spent?** I have a very naive idea of what machine learning and artificial intelligence are, but based on what I’ve read it seems like some experience with those ideas would be helpful when I enter the workforce. It could be that I am just selecting these because they are particularly popular areas in the industry right now, and I recognize I am biased by that. And of course I still want to use some of the electives to pursue more mathematical sections (stochastic processes and time series analysis come to mind), but where I have all of this freedom to cater the program to my needs, I immediately felt like this was a great opportunity to really apply myself and learn how to make computers do cool things while also bolstering my statistical know-how.

Any insight you can offer to me is appreciated! And obviously I would really prefer that responses come from folks that have been through MStat or PhD programs themselves. :)",statistics
myxr35,1619443956.0,[Career] current Phd Stats student seeking advise,I m currently at the end of my Phd in computational statistics. It s been a wild ride. Although I love research I wouldnt want to continue at university. So I wanted to ask if you have any names/tipps of Eu based outer university research facilities ? Or even straight industry ones. I just dont want to stay at uni with all its politics but hope to somehow be able to stay in research. Any ideas would be greatly appreciated !,statistics
mywbg2,1619439411.0,[Q] How would grocery shopping spending be modeled?,"Where spending events are dependent on each other and the money spent is correlated to the time inbetween events? I want to be able to use my past time stamped spending to make a simulation of what may happen in the future, like a series of future dates and amounts.",statistics
myw5p2,1619438848.0,[Q] How to create a heteroscedastic heteroscedastic variable in a dataset,"Hello r/statistics,

I'm currently preparing a workshop on Linear Regression and wanted to include a heteroscedastic variable in my dataset, so that the students could learn how to look for it.

I tried a lot of things (in python) but couldn't get the typical cone shape of the residuals I wanted.

Has anyone any idea on how to transform the data in a way, that it looks the way I want?

Thanks in advance",statistics
myq94y,1619414118.0,[Q] PLS HELP I AM SO HIGH,"If you take 50 red m&ms and 50 blue m&m’s in a bowl and mix them all together, what are the odds of randomly picking both a red and blue m&m at the same time(I hope this makes sense)


Edit: you are picking 2 m&ms at the same time

Thank you",statistics
mypfvm,1619410949.0,"[Q] The Null hypothesis is p=0.77. If the alternate hypothesis is two sided, what must be done to the p-value if you look up the s-score on the z table?",I’ve been looking through definitions and whatnot for two sided alternate hypothesis and nothing so far has helped come to answer for this problem. Also that number is different than the one in my problem cause I wanna try and do it myself. I’m just completely stuck.,statistics
myoaeg,1619406635.0,"[Q] When comparing three different groups, would using different sample sizes for the groups be accurate?","If you check the number of students used to measure IQ, Kazakh has a way larger sample size while Uzbek and Russian are way smaller.

https://www.researchgate.net/publication/262679272_A_study_of_the_intelligence_of_Kazakhs_Russians_and_Uzbeks_in_Kazakhstan",statistics
myktk5,1619394599.0,[Q] Question about IV & Regression,"if I have a model Y = B0 + B1X1 + B2X2 + Set of controls + E
X1 and X2 are explanatory variables. Does my instrument have to have a causal effect on both x1 and x2? or just X2 since my endogeneity problem is a measurement error in B2 X2",statistics
myk29x,1619392108.0,[Q] Can I run a Multinominal Logistic Regression if the dependent variable comes from “check all that applies” question?,"I’m looking for a way to analyze a dataset with multiple Xs and a single dependent Y, which however comes from a “check all that applies” survey question. I have decided to code these all that applies responses into three categories, as it is about people’s attitudes: positive, negative, and neutral. However, these are not mutually exclusive and person could for example choose both positive and neutral answer. How do I go about analyzing this? Can I still use a multinominal logistic regression, and if yes, how do I treat this Y? Or what are my options? Thank you in advance!",statistics
myinjq,1619387796.0,"[D] 7 years since Norm Matloff's blog post ""STATISTICS: LOSING GROUND TO CS, LOSING IMAGE AMONG STUDENTS"". How has the statistics vs CS situation evolved?"," [Statistics: Losing Ground to CS, Losing Image Among Students | Mad (Data) Scientist (wordpress.com)](https://matloff.wordpress.com/2014/08/26/statistics-losing-ground-to-cs-losing-image-among-students/)

I will quote the blog post below.

# STATISTICS: LOSING GROUND TO CS, LOSING IMAGE AMONG STUDENTS

The American Statistical Association (ASA)  leadership, and many in Statistics academia. have been undergoing a period of angst the last few years,  They worry that the field of Statistics is headed for a future of reduced national influence and importance, with the feeling that:

* The field is to a large extent being usurped by other disciplines, notably Computer Science (CS).
* Efforts to make the field attractive to students have largely been unsuccessful.

I had been aware of these issues for quite a while, and thus was pleasantly surprised last year to see then-ASA president Marie Davidson write [a plaintive editorial](http://magazine.amstat.org/blog/2013/07/01/datascience/) titled, “Aren’t *We* Data Science?”

Good, the ASA is taking action, I thought.  But even then I was startled to learn during [JSM 2014](http://www.amstat.org/meetings/jsm/2014/) (a conference tellingly titled “Statistics:  Global Impact, Past, Present and Future”) that the ASA leadership is so concerned about these problems that it has now retained a PR firm.

This is probably a wise move–most large institutions engage in extensive PR in one way or another–but it is a sad statement about how complacent the profession has become.  Indeed, it can be argued that the action is long overdue; as a friend of mine put it, “They \[the statistical profession\] lost the PR war because they never fought it.”

In this post, I’ll tell you the rest of the story, as I see it, viewing events as a statistician, computer scientist and R enthusiasist.

# CS vs. Statistics

Let’s consider the CS issue first.  Recently a number of new terms have arisen, such as *data science*, *Big Data*, and *analytics*, and the popularity of the term *machine learning* has grown rapidly.  To many of us, though, this is just  “old wine in new bottles,” with the “wine” being Statistics.  But the new “bottles” are disciplines outside of Statistics–especially CS.

I have a foot in both the Statistics and CS camps.  I’ve spent most of my career in the Computer Science Dept. at the University of California, Davis, but I began my career in Statistics at that institution.  My mathematics [doctoral thesis](http://projecteuclid.org/euclid.aop/1176995798) at UCLA was in probability theory, and my first years on the faculty at Davis focused on [statistical methodology](http://biomet.oxfordjournals.org/content/68/3/685.abstract).  I was one of the [seven charter members ](http://www.stat.ucdavis.edu/about/history)of the Department of Statistics.   Though my departmental affiliation later changed to CS, I never left Statistics as a field, and most of my research in Computer Science has been [statistical in nature](http://dl.acm.org/citation.cfm?id=1103326).  With such “dual loyalties,” I’ll refer to people in both professions via third-person pronouns, not first, and I will be critical of both groups.  (A friend who read a draft of this post joked it should be titled “J’accuse”  but of course this is not my intention.)   However, in keeping with the theme of the ASA’s recent actions, my essay will be Stat-centric:  What is poor Statistics to do?

Well then, how did CS come to annex the Stat field?  The primary cause, I believe, came from the CS subfield of Artificial Intelligence (AI).  Though there always had been some probabilistic analysis in AI, in recent years the interest has been almost exclusively in predictive analysis–a core area of Statistics.

That switch in AI was due largely to the emergence of Big Data.  No one really knows what the term means, but people “know it when they see it,” and they see it quite often these days.  Typical data sets range from large to huge to astronomical (sometimes literally the latter, as cosmology is one of the application fields), necessitating that one pay key attention to the computational aspects.  Hence the term *data science*, combining quantitative methods with speedy computation, and hence another reason for CS to become involved.

Involvement is one thing, but usurpation is another.  Though not a deliberate action by any means, CS is eclipsing Stat in many of Stat’s central areas.  This is dramatically demonstrated by statements that are made like,  “With machine learning methods, you don’t need statistics”–a punch in the gut for statisticians who realize that machine learning really IS statistics.  ML goes into great detail in certain aspects, e.g. text mining, but in essence it consists of parametric and nonparametric curve estimation methods from Statistics, such as logistic regression, LASSO, nearest-neighbor classification, random forests, the EM algorithm and so on.

Though the Stat leaders seem to regard all this as something of an existential threat to the well-being of their profession, I view it as much worse than that.  The problem is not that CS people are doing Statistics, but rather that they are doing it poorly:  Generally the quality of CS work in Stat is weak.  It is not a problem of quality of the researchers themselves; indeed, many of them are very highly talented.  Instead, there are a number of **systemic reasons** for this, structural problems with the CS research “business model”:

* **CS, having grown out of research on fast-changing software and hardware systems, became accustomed to the “24-hour news cycle”**–very rapid publication rates, with the venue of choice being (refereed) frequent conferences rather than slow journals.  This leads to research work being less thoroughly conducted, and less thoroughly reviewed, resulting in poorer quality work.  The fact that some prestigious conferences have acceptance rates in the teens or even lower doesn’t negate these realities.
* Because CS Depts. at research universities tend to be housed in Colleges of Engineering, there is **heavy pressure to bring in lots of research funding, and produce lots of PhD student**s.  Large amounts of time is spent on trips to schmooze funding agencies and industrial sponsors,  writing grants, meeting conference deadlines and managing a small army of doctoral students–instead of time spent in careful, deep, long-term contemplation about the problems at hand.  This is made even worse by the rapid change in the fashionable research topic *de jour,* making it difficult to go into a topic in any real depth.  Offloading the actual research onto a large team of grad students can result in faculty not fully applying the talents they were hired for; I’ve seen too many cases in which the thesis adviser is not sufficiently aware of what his/her students are doing.
* **There is rampant “reinventing the wheel.”**  The above-mentioned  lack of “adult supervision” and lack of long-term commitment to research topics results in weak knowledge of the literature.  This is especially true for knowledge of the Stat literature, which even the “adults” tend to have very little awareness of.  For instance, consider a paper on the use of mixed labeled and unlabeled training data in classification.  (I’ll omit names.)   One of the two authors is one of the most prominent names in the machine learning field, and the paper has been cited over 3,000 times, yet the paper cites nothing in the extensive Stat literature on this topic, consisting of a long stream of papers from 1981 to the present.
* Again for historical reasons, CS research is largely empirical/experimental in nature.  This causes what in my view is **one of the most serious problems plaguing CS research in Stat–lack of rigor**.  Mind you, I am not saying that every paper should consist of theorems and proofs or be overly abstract; data- and/or simulation-based studies are fine.  But there is no substitute for precise thinking, and in my experience, many (nominally) successful CS researchers in Stat do not have a solid understanding of the fundamentals underlying the problems they work on.  For example, a recent paper in a top CS conference incorrectly stated that the logistic classification model cannot handle non-monotonic relations between the predictors and response variable; the paper really stressed this point, yet actually, one can add quadratic terms and so on to model this.
* **This “engineering-style” research model causes a cavalier attitude towards underlying models and assumptions.**  Most empirical work in CS doesn’t have any models to worry about.  That’s entirely  appropriate, but in my observation it creates a mentality that inappropriately carries over when CS researchers do Stat work.  A few years ago, for instance, I attended a talk by a machine learning specialist who had just earned her PhD at one of the very top CS Departments  in the world.  She had taken a Bayesian approach to the problem she worked on, and I asked her why she had chosen that specific prior distribution.  She couldn’t answer–she had just blindly used what her thesis adviser had given her–and moreover, she was baffled as to why anyone would want to know why that prior was chosen.
* **Again due to the history of the field, CS people tend to have grand, starry-eyed ambitions–laudable, but a double-edged sword.**   On the one hand, this is a  huge plus, leading to highly impressive feats such as [recognizing faces in a crowd.](http://cacm.acm.org/magazines/2014/8/177012-hello-my-name-is/fulltext)  But this mentality leads to  an oversimplified view of things,  with everything being viewed as a paradigm shift.  Neural networks epitomize this problem.  Enticing phrasing such as “Neural networks work like the human brain” blinds many researchers to the fact that neural nets are not fundamentally different from other parametric and nonparametric methods for regression and classification.   (Recently I was pleased to discover–“learn,” if you must–that the famous book by [Hastie, Tibshirani and Friedman](http://web.stanford.edu/~hastie/local.ftp/Springer/OLD/ESLII_print4.pdf) complains about what they call “hype” over neural networks; sadly, theirs is a rare voice on this matter.)  Among CS folks, there is often a failure to understand that the celebrated accomplishments of “machine learning” have been mainly the result of applying a lot of money, a lot of people time, a lot of computational power and prodigious amounts of tweaking to the given problem–not because fundamentally new technology has been invented.

All this matters–a LOT.  In my opinion, the above factors result in highly lamentable opportunity costs.   Clearly, I’m not saying that people in CS should stay out of Stat research.  But the sad truth is that the usurpation process is causing precious resources–research funding, faculty slots, the best potential grad students, attention from government policymakers, even attention from the press–to go quite disproportionately to CS, even though Statistics is arguably better equipped to make use of them.   This is not a CS vs. Stat issue; Statistics is important to the nation and to the world, and if scarce resources aren’t being used well, it’s everyone’s loss.

# Making Statistics Attractive to Students

This of course is an age-old problem in Stat.  Let’s face it–the very word *statistics* sounds hopelessly dull.  But I would argue that a more modern development is making the problem a lot worse–the Advanced Placement (AP) Statistics courses in high schools.

Professor Xiao-Li Meng has written extensively about the [destructive nature of AP Stat](https://www.stat.columbia.edu/~gelman/stuff_for_blog/tast.2009.pdf).  He observed, “Among Harvard undergraduates I asked, the most frequent reason for not considering a statistical major was a ‘turn-off’ experience in an AP statistics course.”  That says it all, doesn’t it?  And though Meng’s views predictably sparked [defensive replies ](http://magazine.amstat.org/blog/2009/11/01/statviewnov09/)in some quarters, I’ve had exactly the same experiences as Meng in my own interactions with students.  No wonder students would rather major in a field like CS and study machine learning–without realizing it is Statistics.  It is especially troubling that Statistics may be losing the “best and brightest” students.

One of the major problems is that AP Stat is usually taught by people who lack depth in the subject matter.  A typical example is that a student complained to me that even though he had attended a top-quality high school in the heart of Silicon Valley, his AP Stat teacher could not answer his question as to why it is customary to use n-1 rather than n in the denominator of s2 .  But even that lapse is really minor, compared to the lack among the AP teachers of the broad overview typically possessed by Stat professors teaching university courses, in terms of what can be done with Stat, what the philosophy is, what the concepts really mean and so on.  AP courses are ostensibly college level, but the students are not getting college-level instruction.  The “teach to the test” syndrome that pervades AP courses in general exacerbates this problem.

The most exasperating part of all this is that AP Stat officially relies on TI-83 pocket calculators as its computational vehicle.  The machines are expensive, and after all we are living in an age in which R is free!  Moreover, the calculators don’t have the capabilities of dazzling graphics and analyzing of nontrivial data sets that R provides–exactly the kinds of things that motivate young people.

So, unlike the “CS usurpation problem,” whose solution is unclear, here is something that actually  can be fixed reasonably simply.  If I had my druthers, I would simply ban AP Stat, and actually, I am one of those people who would [do away with the entire AP program](http://www.theatlantic.com/national/archive/2012/10/ap-classes-are-a-scam/263456/).   Obviously, there are too many deeply entrenched interests for this to happen, but one thing that can be done for AP Stat is to switch its computational vehicle to R.

As noted, R is free and is multi platform, with outstanding graphical capabilities.  There is no end to the number of data sets teenagers would find attractive for R use, say the [Million Song Data Set.](http://labrosa.ee.columbia.edu/millionsong/)

As to a textbook, there are many introductions to Statistics that use R, such as Michael Crawley’s *Statistics: an Introduction Using R,* and Peter Dalgaard’s *Introductory Statistics Using R*.  But to really do it right, I would suggest that a group of Stat professors collaboratively write an open-source text, as [has been done for instance for Chemistry.](http://chemwiki.ucdavis.edu/)  Examples of interest to high schoolers should be used, say this [engaging analysis on OK Cupid](http://blog.okcupid.com/).

This is not a complete solution by any means.  There still is the issue of AP Stat being taught by people who lack depth in the field, and so on.  And even switching to R would meet with resistance from various interests, such as the College Board and especially the AP Stat teachers themselves.

But given all these weighty problems, it certainly would be nice to do *something*, right?  Switching to R would be doable–and should be done.",statistics
myfj0q,1619378783.0,[D] why are neural networks better than polynomial approximation?,Has anyone ever come across a formal mathematical explanation as to why neural networks  are more powerful than polynomial approximation?  Have some results (e.g. papers) been proven that conclusively show neural networks have certain advantages over polynomial approximation?,statistics
myd89g,1619372312.0,[Q] Concerning racism and poverty,"Hi all, I'm curious if anyone has some studies related to racism and poverty. That is, I'm trying to solve a question on whether or not those living in poverty are more likely to be racist. Every time I google this question, the only thing that comes up is statistics concerning people that live in poverty beause of discrimination, which is not what I'm looking for.

&#x200B;

If anyone could link me to what I'm looking for, that'd be awesome, thanks for your time!",statistics
my7yw1,1619356038.0,"[Q] in order to test for a structural break, do my variables need to be correlated at all?",My dependent variables are several stocks and independent variables are several indices. Have tried different combinations but the R is quite low. Can I still test for a structural break?,statistics
my7kz1,1619354627.0,[Research] MSc student looking for help on deciding statistical analyses for thesis,Hello to anyone who feels inclined to help out a struggling grad student! I am currently working on my thesis proposal and racking my brain trying to figure out what statistical analyses make the most sense for my project. What I am mainly looking for is an appropriate test or tests that'll help me compare different metrics of corals that undergo two different coral restoration methods. Any help would be greatly appreciated!,statistics
my7k93,1619354547.0,[Q] This may be a noob question but how do I interpret the confint function? How can I see if the conf. Int. contains 0?,[This is what comes out of the confint function.](https://i.imgur.com/xUIqc7Y.jpg),statistics
my66oz,1619349096.0,[Q] Looking for statistics about the comprehension of sexual violence?,"Sorry if this isn't the right sub but I'm looking for statistics about the comprehension of sexual violence, whose participant isn't grouped by gender. ""What's your understanding about sexual violence, what do you regard as sexual violence, do you know sexual violence is"" kind of items. Thank you!",statistics
my5j9v,1619346254.0,[Q] Literature on Monte Carlo Simulation,"I am looking for a standard work on Monte Carlo Simulation, can anyone point me towards some books you enjoyed?

The book should function as a reference for most common topics relating MC and maybe explain some statistical concepts needed on the way. (I have studied theoretical physics, so I have heard about a bunch of things, but I want to develop a deeper, intuitive understanding of the matter).

If you can recommend a statistics book that is written didactically well, I'm interested, too!

Thank you in advance!",statistics
my16bp,1619326457.0,[D] EU proposing to regulate the use of Bayesian estimation,"I hadn't paid close attention to the news about the EU wishing to regulate AI, thinking it would be mostly focused on Deep Learning. It turns out that AI techniques does include Statistical techniques.

From Gelman's [blog](https://statmodeling.stat.columbia.edu/2021/04/22/eu-proposing-to-regulate-the-use-of-bayesian-estimation/).

> (c) Statistical approaches, Bayesian estimation, search and optimization methods.

Roughly skimming through the [document](https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=75788), I see some things I can comprehend/agree with. On the data side, having rules around PII data and logging. Apart from that it isn't quite clear to me how this influences day to day work in modeling?",statistics
my0grk,1619323685.0,[D] Reservoir Computing/Echo State Networks vs LSTM's and RNN's?,Has anyone ever heard of Reservoir Computing or Echo State Networks (https://en.wikipedia.org/wiki/Reservoir_computing)? Does anyone have any idea in what situations they should be used compared to models such as RNN and LSTM?,statistics
my0f9w,1619323521.0,[Q] Estimating Sample size required for an instrument variable study,"Hello, I'm designing pretty much a textbook instrumental variable study. Paraphrasing the actually set-up, we're planning to offer in-store discount coupons and trying to assess whether providing coupons is a good idea.

Given there will be a clear self selection involved (more loyal customers will opt in to more discounts) we're sending a mailer with discount to a random subset of customers and a mailer with no discount to the control. Assuming that we have a strong first stage, I'll estimate the true effect size of incremental discount via a 2SLS.

However, in this scenario, how can I decide how many people to send the mailers to?",statistics
mxzqpi,1619320910.0,[Q] Theoretical regression books,"I'm looking for recommendations on a proof-based regression book. I know this question has been answered to death but I'm specifically looking for a rigorous and compact regression book. Some of the current regression books out there are way too long, 1000+ or 800 pgs . So far I have found Linear Regression Analysis by seber and lee. is ESL good for regression?

I have a math undergrad and an incoming grad student for computational finance. I'm have self-studied statistical inference by Casella (up to chapter 10), finishing up the exercises right now. please lmk if you recommend reading the last 2 chapters of casella; they're about anova and regression.

Thanks!",statistics
mxzpne,1619320793.0,[C] What to know before becoming a data quality analyst?,"I am interviewing for a data quality analyst position at a global clinical trial company. The position expects relevant knowledge of statistics, data management, SQL, Excel, and/or clinical trial design. What statistical concepts are used in data quality and what should I know regarding Excel, SQL, and data management? I also have no knowledge about data quality or clinical trial data. Any resources/courses would be helpful. I have a bachelors in statistics and am fairly confident in using SQL, Excel, and R.",statistics
mxy5ys,1619315268.0,[D] how accurate were the statistical models you developed on real-world data?,"When it comes to real-world data, how accurate were the statistical models you developed? Were these models able to consistently and accurately make predictions?

E.g. for supervised binary classification, has anyone been able to develop a model that had high accuracy, high sensitivity and high specificity?",statistics
mxxycr,1619314597.0,"[E] What’re some good free/cheap online resources for learning stats, specially regression methods, multivariate analysis, and bayesian stats.","P.s. I have a strong mathematical and comp sci background, in case that’s relevant.",statistics
mxxtlm,1619314126.0,[Q] Can we use dissimilarity measure in cluster analysis instead of distance measure?,"Hi! I’d like to ask that weather we could use dissimilarity measure in any cluster analysis algorithm (e.g. k-mean, hierarchal or k-median etc) instead of distance measure as well? If the distance measure do not provide the true difference between the objects? If not, then why not?
Thanks",statistics
mxx2oe,1619311471.0,"[Q] If you have f(x*,y*), where x*,y* are distributed by two different normal distributions, and f is a function that combines the two, what is the distribution of f?",,statistics
mxx20p,1619311401.0,[Q] Can a stratified random sample be paid to take part in studies?,"
Specifically im talking about the 5k people sample used in SBV Intelligence Test.

Money may result in higher motivation and have impact on score - found in some studies.

Couldn’t find info about this and dont want to assume anything.",statistics
mxvj73,1619306258.0,[Q]Trying to see if there's a practice effect across 2 blocks of a task,"Hi, I'm an undergraduate student working on a Psychology dissertation, just wondering if I anyone could help me out.

In my experiment I've measured average reaction time in 2 blocks of a task from participants in 4 separate conditions (A, B, C, and D). First I took the raw data and ran a paired samples t-test on (RT ~ block) which showed that overall mean RT improved in block 2 in general. Now I am trying to identify whether this was purely due to a kind of practice effect, or whether e.g. participants in condition A improved more between blocks than participants in condition B did. If there was a practice effect, I'd like to isolate it and factor it out to find any condition effect.

I have already run a one-way ANOVA on (RT ~ condition) for each block, which showed that in block 1, RT was signficantly faster for conditions C & D than for conditions A & B. But in block 2, RT did not significantly differ between any conditions.

I have also run a paired t-test on (RT ~ block) for each condition, which showed that in condition A, RT was significantly faster in block 2.

I'm now kind of stuck on what to do next. It seems like RT improved in block 2 for all conditions, but condition A may have caused it to improve even more. I want to know a way to confirm/test this. If it helps, overall RT difference between blocks =  295.4847, and RT difference between blocks in condition A = 865.939. Is it sufficient to just say that because condition A's difference was higher than the overall mean difference, A had an effect? Or should I subtract the mean difference from A's difference or something?

Apologies if this is unclearly written, or if I'm missing anything glaringly obvious. This is my first time posting here and  I'm pretty stressed and tired... Any help would be very much appreciated, thank you. Also I should say, I'm doing all this in RStudio",statistics
mxs6re,1619295937.0,[Q] How to determine which variable drives change when you don't have a dependent variable?,"I have a list of all shops that closed by 5 brands (1000 shops in total).
I also have some numerical variables, where the answer should lie as to why those brands decided to close those shops. How do I find out which variable was the most important for each brand?
If I also had a list of shops that are still open, i think that would be quite easily done by logistic regression. But here, my 'dependent variable' has the same value all throughout - closed. The variables i have are all continuous and mostly demographic, how old and how well off the people who shopped there were.
So i have those dependent numerical variables, and then another column that is Brand.
Any ideas?",statistics
mxq9hr,1619290220.0,[Q] What are the odds?,"Probably simple question for this sub:

I'm standing in line for my Covid-19 vaccine.  It's my birthday today.  Both the guy behind me and the guy in front have birthdays today.  What are the odds??  Curious about this.  Also, if possible, would you include the equation used to figure it out?

Many thanks in advance.",statistics
mxm0rk,1619277591.0,[Q] Appropriate statistic for measuring something over time,What would be the appropriate statistical method for measuring something over time? I was thinking paired t test or regression but I’m under the impression they require a comparable set of data that isn’t just a year progressing.,statistics
mxl6x1,1619274958.0,[Q] How to calculate statistical significance for percentages?,"Hi! I conducted a survey in which participants had to chose between 5 options. I am trying to figure out if any one option was chosen at a rate significantly higher than chance (which would be 20%) and I'm not sure which test to use? It's been a while since I was in a stats class. There were only 36 people in the sample as a whole so I have both the counts for each of the 5 options and the percentages of each and I'm just not sure how to proceed. For example, one of the options was picked 38% of the time and I need to figure out if that is actually significant. Thanks so much!",statistics
mxkxbx,1619274103.0,[Q] Calculating Probabilities in Clue/Cluedo,"In the game Clue there are 21 cards, and 1 of each type (Weapons - 6 cards, Rooms - 9 cards, People - 6 cards) is randomly selected and placed in an envelope.  The remaining 18 are distributed among the players.  The goal is to determine which three cards are in the envelope.

In a game with 3 players, each player will receive 6 cards. I’m trying to probabilistically determine which cards are in the envelope based on known information throughout the game.  I’m convinced that estimating the likelihood of each specific card being in the envelope can be calculated independently, and the sum of all the unknown cards should sum to 1.

Before the first turn, 6 cards are known because they are in my hand (I have w1, w5, r2, r6, p1, p3).
So the probability that the unknown cards are in the envelope are:

w{2,3,4,6} = .25

r{1,3,4,5,7,8,9} = .143

p{2,4,5,6} = .25

Scenario 1: I suggest w2, r1, p2 - and the next player shows me w2.  Now the card is known, so the envelope card probabilities are:

w{3,4,6} = .333

r{1,3,4,5,7,8,9} = .143

p{2,4,5,6} = .25

Scenario 2: Player 2 suggests w3, r1, p3 to player 3, and they show them a card.  Knowing that one of those three cards is not in the envelope must decrease the probabilities for those three, and increase them of other unknown cards, but by how much?

Scenario 3: Player 2 suggests w6, r5, p4 to player 3, and they don’t have any of the cards.  Knowing that none of those three cards is in their hand (and therefore are more likely to be in the envelope) must also increase the probability that one (or more) of those cards is a winning card, but how much?

Thanks!",statistics
mxjkyc,1619269475.0,[Q] What are some ways (or heuristics) to estimate a distribution when only given the mean and the median?,"If you only know the mean and the median of some data, like some exam scores, is it possible to imagine what the distribution looks like?

Of course, you have an infinite number of distributions that fit the values of these two summary statistics. But some distributions are more likely in the real world.

So, based on real-world distributions, what are some ways (or heuristics) to estimate a distribution when only given the mean and the median?",statistics
mxi6nm,1619264037.0,[Q] How to use Kruskal-Wallis to check if continuous variable Y has correlation with categorical variable X?,"I used Kruskal-Wallis on my data that has a continuous Y variable and categorical X variable (more than 2).

I got the following result: Statistics=784.547, p=0.0000 with alpha: 0.05.

What does this mean? Does this mean that there is some correlation between my X and Y variables?",statistics
mxi1p3,1619263435.0,[D] Pluralsight statistics course recommendations for machine learning projects,"I'm beginner who's signed up in plural sight and I'm keen to learn R, enough statistics to work on data analysis projects in Kaggle etc. I've used python before in university. Looking forward to your replies, thanks in advance",statistics
mxgrk4,1619257678.0,[Q] Would there be any point in trying to beat the betting companies?,"Betting companies employ many statisticians to calculate odds on various  (mostly sporting) events. Of course, they most likely have access to some really great data and have a lot of resources in general. However,  betting companies will host odds on many different types of events. Do many statisticians try to beat the betting companies for particular events where they might be able to invest more time into creating accurate models to calculate odds? In a sense, try to 'out statistics'  the betting companies?

Let's take football for example. If a statistician were to invest a lot of time into trying to predict the outcome of Arsenal games exclusively,  surely the statistician might be able to do this more accurately on average with enough time invested?",statistics
mxgc2w,1619255582.0,"[Q] Choosing between a Mann-Whitney test, Linear regression or both","Currently I am in the process of writing my master thesis, for which I have conducted a survey. The variables that I have are as follows:

* Independent variable: A Yes/No question (determining two subgroups)
* Dependent variable: A interval variable (7-point Likert scale)
* Moderator: Continuous variable

For these variables, I am curious how you would approach this. A Mann-Whitney test (similar to t test but for non-parametric variables) makes sense for comparing two groups. However, it seems odd to use a Mann-Whitney test for the main variable and subsequently use a linear regression for the moderator.

&#x200B;

In this case, would it make the most sense to use a linear regression for both the main relationship (using dummies for the independent variable) and the moderating relationship, to have consistency? Would it make sense to use both tests to strengthen your findings? I'd appreciate some input in this.",statistics
mxeig9,1619247127.0,"[Q] [E] STATA, SAS, or R certified courses?","Hi all!

I'm looking to learn more than my very limited experience with R (I was not overly talented) as it seems like it's going to be required for any job I do in the future. I'm wondering if there are any online courses (free or paid, I'm in Canada if that matters) that grant a certificate of completion or something along those lines.

Is one of the three better to learn for biostatistics/public health-related uses? I've seen all three mentioned fairly equally so it would be great to have an idea of the best place to start!

Thank you!!",statistics
mxcq47,1619239017.0,[D] Automatic Feature Engineering during Deep Learning,"I have often heard that one of the reasons that deep learning methods are preferred over other machine learning methods is because algorithms like deep neural networks do not require the analyst to spend as much time ""selecting variables for the model"" (i.e. feature engineering, feature selection, feature extraction).

Apparently, deep neural networks are able to ""intelligently"" (in the background) consider and create many different combinations of ""features"" that are ""conducive"" to the modelling problem.

Naturally, I was curious about this claim. Intuitively, I understand that through the hidden layers, weights and activation functions, neural networks are making ""new combinations"" of features that are passed forward and are ultimately used for making predictions on new data.

Beyond this, I am not sure what to think - are there any references/papers that have documented (either theoretically or empirically) that deep neural networks are able to largely ""take care"" of the task of ""feature engineering"" compared to traditional algorithms like regression models, decision trees and random forest? Have any experiments been done where many irrelevant features were added to a dataset, and a deep neural network was able to ""ignore"" them?",statistics
mxcll9,1619238448.0,[D] What do we know mathematically about statistical analysis?,"Got kinda burned by my college recently. Long story short: All statistics courses available are applied statistics, and they don't have a statistics course for mathematics students. We just have to pick from the engineering ones. We don't learn any math, no analysis, no proofs, no theorems, no abstraction, nothing. The phrase ""memorizing formulas"" appears in the one-paragraph course description, and ""MEMORIZE THIS"" appears all over the lecture notes. (In their defense, they *don't* rely on memorization for the applications. They really do want us to understand experiments and how to come to a meaningful conclusion based on the numbers that *pop out* of formulas.)

I asked my academic advisor about this, and they said they would mention to the board that they might consider a class for mathematics students.

Does that mean it didn't even occur to them someone might be interested in how statistics *works* beyond how you *use* it? Surely ~~leonhard euler~~ scientists didn't just ""figure out"" all this stuff a long time ago and then forget about it forever, right?

I almost feel a little frustrated, because I don't know where to go from here. I have to have a statistics course, but part of the reason I became a math major in the first place is because, in general, I find myself much more interested in how mathematics works and less interested in how we use mathematics.",statistics
mxbkrq,1619234153.0,"[Q] New to regressions, and I need to pick correct variables.","Hello, I'm new to Econometrics and this is my first term taking an applied Econometrics course. I have a few question regarding running regressions, and I'm given a practice data set.

First off, I'm trying to measure the demand for biking conditional on pollution and weather. There are multiple variables such as weather, humidity, windspeed, bushfire,  rain and air pressure.

My question is how of many of these variables am I supposed to include in my regression? isn't temperature correlated with humidity, air pressure windspeed? I noticed when I include those 3 variables + temp the effect of temperature increases, What does that imply?. Would including temperature only and not the rest yield in biased estimates? since the covariance between error term and Xi is bigger than 0? .

I'm sorry if I'm all over the place I'm just trying to understand how could I efficiently pick my variables.",statistics
mx75mx,1619218271.0,[Research] Which research areas are currently hot in statistics at the moment or upcomming ?,,statistics
mx6hoe,1619216168.0,[R] Do you agree with this statement,"I came across the following statement when reading a paper : "" Various researchers have provided an indication how to interpret Bayes factors (e.g. Jeffreys, 1961; Raftery, 1995). For completeness we provided the guidelines that were given by Raftery (1995). These guidelines are helpful for researchers who are new to Bayes factors. We do not recommend to use these guidelines as strict rules because researchers should decide by himself or herself when he or she feels that the Bayes factor indicates strong evidence. ""

Do you agree with that last sentence ? Because from my understanding until you choose a loss function, you can't say anything about the difference between two Bayes factor. I know that it is not always feasible but if this choice belongs to the researcher then it is subjective and arbitrary like the 0.05 or 0.01 thresholds when using p-values.",statistics
mx1d6b,1619201345.0,[Q] How do I set up my data for linear regression if I have multiple observations for one sample?,"I have a dataset that I need to do linear regression with to find the residuals.  It is gene expression data for multiple genes for a cohort of people.  I am using their health data as covariates.

The problem I am running into is there is 1 point of data per person for, lets say, sex.  M =1 F = 0.  There are multiple observations for each person for gene expression. Do I repeat the sexfor the patient as many times as there are observations?

If patient A is male, and there are 3 different genes expressed that I have data for, does my data look like this:

&#x200B;

|Patient|Gene|Expression|Sex|
|:-|:-|:-|:-|
|A|z|5|1|
|A|x|6|1|
|A|c|5.5|1|

&#x200B;

Thanks in advance",statistics
mwzc39,1619195841.0,T TEST HELP!! Which tail and type [Q] [R],"This is probably a super easy question but im struggling to get my head around it.

I'm currently investigating the effects of a strain on fungus on plant growth.So I have tested the same species of plant under 7 different conditions. 1 = Control (no fungus). 2, 3, 4 = Fungus A at 3 different concentrations. 5, 6, 7 = Fungus B at 3 different concentrations.

I am going to undertake T-Tests to compare my results.I just want to make sure I have the tails and type of T Test correct.I have undertaken a 1 tailed paired T - Test.(because I want to know if the mean of 1 strain is statistically greater than the other).

Is this correct? I ran an unpaired unequal variance T Test to see if the results are different and it gives me massively different results so I want to make sure I've picked the right test before I start my full write up.

Asking reddit because my dissertation supervisor is scary and doesn't like simple questions LOL

&#x200B;

EDIT: I know ANOVA is suitable for comparing multiple but I have been specifically told by my supervisor to use T-Tests to compare the cons against each other separately.",statistics
mwx2vr,1619189706.0,[Q] Beginner question: what are good resources for learning about the robustness of a technique to its assumptions?,"I’ve been learning the rudimentary stats procedures (ANOVA, regression, etc) and that these procedures have varying assumptions for the data you are using (e.g normal distribution, linearity). My professor keeps saying some procedures (with varying degrees) are robust to certain assumptions they have depending on sample size. When I ask for guidelines in this regard he tells me to find literature on the topic.

Ive looked long and hard but cant seem to find guidelines for understanding how much I should expect my data to meet assumptions for various procedures before choosing an alternative one. Any help or suggestions would be appreciated.",statistics
mwv19c,1619183818.0,"[Q] Anyone who is attending/has attended Colorado State’s Master’s in Applied Statistics, do you recommend it? What are some good and bad things about their program?","They’re one of the schools I’m strongly considering, but I want to make sure people have enjoyed the program. I’m told the first two courses in fall are some of the toughest and most theoretical courses in the program. Do you agree with that?

Do the 8 week courses feel rushed or are they designed well enough to not feel overwhelming?",statistics
mwudw9,1619181751.0,[Q] Seeking help with ANOVA formula and bootstrapping,"Thanks for the help on my previous post!

I've refined things a bit:
- Ten participants in two conditions, some movements were bad, so unequal sample sizes, and measurements are 'related', but not 'paired'. I.e. movements in one condition don't match with a movement in the other condition.

I think the formula would look like this:

```
dv ~ condition * montage * phase + subject/condition)
```

And I think to bootstrap this, it would look like so:

```
bsaov <- function(formula, data, indices) {
  d <- data[indices, ]
  fit <- aov(formula, data=d)
  return(<<something>>)
}

results <- boot(data=nfvf, statistic = bsaov, R=1000,
                formula = mean_power_abs ~ condition * montage * phase + subject/condition)
```

I'm not sure what to return from bsaov() to be summarized (so to speak) by the bootstrapping.
I could also be completely wrong about anything here.

Reasons for bootstrapping:
- unequal sample size
- non-normal distribution (Shapiro-Wilk p<0.001)
- heterogeneous variance between conditions (F test (var.test()) p < 0.001)
- Two groups, multiple IVs, so no Kruskall-Wallis

I appreciate any suggestions!",statistics
mws6p1,1619173397.0,[Career] MSc Statistics vs MSc in Business Analytics ?,"Hey guys  I am a recent graduate of statistics and economics and I am wondering which masters program you would recommend .

My undergrad curriculum  was very intense(like 20/125 graduated) and  included
All maths prerequisites for calculus(up to III) and linear Algebra ,

- Econometrics

- Stochastic Models

-Time Series (not Economics based)

-Survival Models

-Multivariate Analysis

-Statistical Machine Learning

 -Predictive Analytics

- Survey Sampling  and

- Bayesian Statistics   -  all at masters level .

Our undergraduate classes were the same level as the masters programs (same resources /classes attended  just slightly different assignments)

The only  important  modules in the MSc Statistics that  I haven't done are

-Data Mining

- non- Parametric statistics and

-Data programming in Python/SAS.

 I can only code proficiently in R but I am currently  learning Python ,SQL and Tableau on my own .


The business analytics  Msc is much more qualitative with an emphasis on visual analytics,data  management,operations  research and  Business Intelligence.

I am not sure if it would be worth it getting a an MSc  in Stats if I  have already covered so much   already .

 Which degree do you think would be the most versatile   for obtaining  a high paying  interesting job ?

I am interested in consulting, ecological statistics, finance   and data science .

Would it be more worthwhile doing a conversion degree for computer science ?


Thanks",statistics
mwrdq5,1619169809.0,[Question] Statistics Applied to Hotels?,"I have always been interested in statistics and recently I found out about hedonic regressions and used to to perform a 16 variable regression analysis to determine what features increases the guests’ willingness to pay for a room.

I am sure there are more statistical analyses that I am missing out on. I am looking to learn more and if anyone has suggestions/any readings, please let me know :)

It could be to perform sentiment analysis on reviews, predicting occupancy rate, optimising room price etc. Anything to do with hotels!",statistics
mwqil1,1619165806.0,[Q] Control (SPC) Charts Question: Non-normal Distributions and Time series.,"I am trying to measure process time in relation to material that is being processed by various different machines at the company I work at. I may also be interested in doing the same, but with the combined wait time before moving on to the next machine, i.e. dwell time.

In almost all cases there is a non-normal, positive skewed distribution.

So, my first question is how do I handle this without further transformation in the context of SPC charts. First because the average lay person will be confused when they see numbers that don't represent the actuals, and second because most text book examples assume the underlying data is normal.

What choice of SPC chart should I pick, and should I only show the upper and lower control limits given that the data is not normal? I read somewhere that an individual chart with only these two control lines accommodates non-normal distributions relatively well.

My other question is how and what kind of SPC chart might offer the ability to see process time month by month. Some further questions here might be around sampling, grouping, etc.

Thanks.",statistics
mwp32b,1619159315.0,"[D] | How thin is the line, in terms of work, between statisticians and data scientists? How do these two figures differ and what do they have in common, it both work with data?","I am a statistics student from Italy, and what I did notice is that the job market of positions which require data-handling skills here is still at its first phases: many companies are looking for statisticians when what they have to do is work with machine learning algorhythms, and many search for data scientists, when what they're looking for is someone able to focus on exploratory analysis or clinical tests etc.

Are these two figure almost identical or are the job recruiters which in most cases don't know who they need to looking for?
I am aware that these two figures share similar patterns but tend to have different approaches, would like to hear what you think on this matter, and if, where you live, during your job search, you stumbled upon similar situations.",statistics
mwoqds,1619157808.0,[D] importance of neural tangent kernels,"Has anyone heard of the ""neural tangent kernel""? I originally had thought this was an activation function for a neural network.

Looking here:
 https://en.m.wikipedia.org/wiki/Neural_tangent_kernel

""the neural tangent kernel (NTK) is a kernel which describes the evolution of deep artificial neural networks during their training by gradient descent. It allows ANNs to be studied using theoretical tools from Kernel Methods.""

Can someone please help me understand what this means? Why are neural tangent kernels important?

Thanks

https://rajatvd.github.io/NTK/",statistics
mwo63f,1619155558.0,"[D] can someone please explain the ""representer theorem"" in simpler term?","https://en.m.wikipedia.org/wiki/Representer_theorem

Can someone please try to explain the ""representer theorem"" in simpler terms?  Why is it considered important in the realm of machine learning?

Thanks",statistics
mwkbph,1619142182.0,[Q] How to calculate the average time to a place within a country?,"For a paper on international trade, I'd like to calculate the average distance to a port within a country.
Is there a way to do this?

Ideally it would be the average distance by road and adjusted for population but that seems like it'd be much harder.",statistics
mwjz2q,1619141035.0,[R] A Bot That Plays Battleship Using Probability,"I recently built a bot in python that can play the Battleship board game using probability. The bot is able to guess where all the ships are in 54 moves on average. This average was found by placing ships randomly and seeing how the bot does.

The bot builds the probability of where ships might be based on the hits and misses that have been on the board so far. In this bot, I didn't include the option for the bot to know which ship was sunk.

I feel like the code could be optimized more. If you would like to take a look at the code and give me some comments, here is the link to the GitHub repo:  https://github.com/challengingLuck/youtube/tree/master/Battleship

I also made a YouTube video if you'd like to check it out: [https://youtu.be/aCj8Ajc1yUU](https://youtu.be/aCj8Ajc1yUU)

Let me know what you think!",statistics
mwe3jg,1619123631.0,"[Q] What is ""burning data""","From Rishi Narang's inside the black box:

""The world finds new and interesting ways to confound our understanding. As such, to test our current best thinking against competition that existed in the past is a form of wishful thinking. This is a subtle and nefarious form of look‐ahead bias, which is a critical problem in research. As researchers become more and more familiar with the out‐of‐sample periods they use to test their ideas’ validity, it becomes more likely that they are implicitly assuming they would have known more about the future than in fact they would have known had they been asking the same questions historically. This practice is called ***burning data*** by some quants ""

&#x200B;

I'm unclear what this means.  Does it just mean that every time you iterrate your model based off the OOS test results, you are engaging in sort of lookahead bias?

&#x200B;

An earlier paragraph states this: ""By learning from the out‐of‐sample data and using that information to train the model anew, he has effectively used up his out‐of‐sample data and has caused them effectively to become part of the in‐sample data set"".  So basically, everytime we learn from our results and make some adjustment to our initial model, are we effectively using **a form of data creep?**",statistics
mwdgvf,1619121945.0,[Education] Grad School Course Recommendations,"Hi Everyone,

I'm going into my second year of a MS Biostats degree with the goal of getting a statistician/data scientist role in a health-related field after graduating.

Here are some of the courses I could take next semester:

* Statistical computing (fundamental algorithms, RNG, MCMC, EM implemented in R)
* Techniques for working with big data (hadoop/spark, unix programming, databases, version control, programming best practices)
* Clinical trials
* Longitudinal data analysis
* Survival Analysis
* Python + Pandas, Numpy, SKL, Pytorch
* Advanced Applied Stats (Mediation Analysis, ML, Bayesian techniques)

Which of these would most help me get a job/be a good statistician/data scientist?

I see many job postings ask for SKL, so perhaps taking the class on that would be good. But...I think I could probably teach myself SKL outside of school. I think it would be much harder to teach myself statistical computing or survival analysis, for example. It seems the more methodological courses would have a longer-term impact on my abilities and understanding of the field, and the more applied courses would have the short-term benefit of helping me get a job. How do I balance these needs?",statistics
mwc4uu,1619118343.0,[Question] Popularity of blackhat tools. What does the graph mean? (Interpretation),"Can someone tell me the behavior of the graph as shown in this image:

[https://ibb.co/Mn0h9cD](https://ibb.co/Mn0h9cD)

Does this mean blackhat tools are popular or unpopular (according to the graph)?",statistics
mwb3rl,1619115559.0,Do I need to run a regression before checking for structural breaks? [Question],"What I want to verify is, if certain stocks experienced a structural break in 2021. As variables, do I need market return (the return on an index for example) and the stock return? Do I need to run a regression on them first, for example, Dow Jones and AMC returns, AMC being the dependent variable? (I guess I don't entirely understand what structural breaks are)",statistics
mwaryr,1619114693.0,[Q] Which 2x2 correlation test to use - Chi Squared or McNemar's?,"I have a research data set that consists of a number of videos, which we've manually coded using Themes and Sentiments, i.e. ""Positive"", ""Advertisement"", ""Authority (gov. official, medical professional, etc). Each video can have any number of themes and sentiments coded to it.

We then, for each theme, did a pairwise, binary comparison with each other theme, to see if a theme has correlative value with another theme. In different terms, we took the set of videos that match a theme and the set of videos that do not match a theme, and paired them with the same binary sets on a different theme. Here's a made-up example matrix for one of these comparisons:

&#x200B;

||Authority|Authority'|
|:-|:-|:-|
|Positive|20|60|
|Positive'|30|240|

&#x200B;

My understanding is that we can find either the Phi Coeffecient, or the McNemar's Test Statistic to compare this data. I'm confused on which to use. My understanding is that:

Phi Coefficient is appropriate for unpaired, nominal data.

McNemar's is appropriate for paired, nominal, dichotomous data.

The comparisons above are nominal and dichotomous, but are they considered paired data? I'm having trouble reasoning about why they might considered be paired or unpaired.

As far as results go, McNemar's is giving results that match our hypothesis -- for instance, ""Positive"" and ""Advertisement"" show strong, positive correlation. When we take the phi coefficient, we are getting much weaker results (values closer to zero). The direction of the correlation is not different between any of our sets for the McNemar's and Chi Squared (Phi Coefficient) test.

&#x200B;

p.s. McNemar's gives a directionless value from 0-1, and Chi Squared gives a directional value from -1 to 1, but we were able to multiply the McNemar's result by a direction derived from our results to show positive or negative correlation. I can explain how we did that if that's relevant to any answers here.",statistics
mwa2ee,1619112766.0,[Q] how to interpret bidirectional causality in the case of Granger causality,"Hi all,

Im currently writing a report that utilises Granger causality tests to check the influence of numerous factors on the price/returns of bitcoin.

In the case of the volume traded, I've found bidirectional causality. By this I mean:

> Y granger causes F(X)   -> p-value = 0.00005

> F(X) granger causes Y   -> p-value 0.05

I would regard these as both significant and therefore bidirectional. I am unsure though of how to even comment on this, what can be said and what cannot? The two other cases where one value granger causes another, or no causal relationship, are relatively straightforward conceptually. I am not sure how to interpret this result.

Any advice/guidance is majorly appreciated!

edit: sorry forgot to add the p-values are the result of an F-test. There is also significant terms from the exogenous variable in VAR analysis",statistics
mw7xji,1619107061.0,[Q] Interaction term in regression,"Hi, I made a correlation matrix of gender and a variety of clinical outcomes. However, I was told that I needed to also consider weight status (either continuous or categories like obese/not obese) as a cause for the clinical outcome and in particular an ""interaction term"" between gender and weight status and how that ""interaction term"" relates to the clinical outcome. My original approach was correlation matrix but I've only heard of interaction terms in context of regression. It would be so complicated to include many factors in a regression. What are my options to see if there's an interaction between gender and weight status on the clinical outcome? Could I do an interaction term of gender x weight, weight, gender in the model  (nothing else) and see how they all relate to clinical outcome in a regression? Or do i just do  the interaction term alone at first in univariate regression?

What kind of regression and does inserting the variables need to be ordered a certain way? How would i interpret the results regarding interaction? and how do i create an interaction variable w a binary such as male/female? thanks!",statistics
mw7tar,1619106752.0,[Q] Updating Time Series Posterior distribution,"I have a distribution of probability densities by Hour and Minute of the day. I want to be able to update the distribution based on new information. The question that I am ultimately trying to answer is: The estimated wait time at 5:00 PM is 30 min what is the new posterior distribution if 5 people had a wait time of 38 min?

If the density for exactly 5:00 PM is updated, I would expect it to update the density for times in close proximity to 5 PM and decay as the duration increases.

The end goal would be to estimate the posterior distribution for each mapped location. Is a Bayesian approach the right way to approach this problem? If so, could you point me to some resources that would allow me to research how to update the posterior using feedback?",statistics
mw4tpa,1619098357.0,[Q] Is there a regression method that can estimate the beta of a stock that takes into account its debt/equity ratio over the period?,"The formula for estimating the beta using linear regression is:

*R\_j* = *a* \+ *b(R\_m)*

That is, you have the stock returns versus the market returns over many years and want to estimate the linear relationship. The slope *b* is therefore the estimated beta.

But as the textbook points out, the beta estimated this way reflects the average (financial) leverage of the company over the period. So if you simply use the formula Levered bata = Unlevered beta \* (Tax rate) \* (debt/equity ratio), the obtained unlevered beta does not represent the current leverage.

Is it feasible to find the best fitting slope if I rewrite the relationship like this?

*R\_j* = *a* \+ \[*b*\_unlevered \* tax rate \* Debt/equity ratio\]*(R\_m)*

So, you have one more column in the data, debt/equity ratio.",statistics
mw3iuf,1619094088.0,[R] I calculated an iota coefficient of 0.899 when comparing scores of two judges. Is that good or bad?,"What are the cutoffs of a ""good iota coefficient""?

In this study, we have several trainees performing surgery. One surgeon is assessing each trainee in the operating room, and another surgeon is assessing them through a video recording and reviewed later on. They assess them on around 5 points, with a single digit indicating their score for each point.

With the help of /u/ticketstothepunshow I got an iota coefficient of 0.899 between the two judging surgeons on all 5 criteria. Is that a ""good iota"" that indicates the two judges were similar in their scoring?

Also:

When I compared the means of their scores on each task, a particular task scoring jumped out as the cause of the reduced iota. How do I ""prove"" that it's the culprit?

But when I calculated the iota coefficients 5 more times, but without one task each time, the coefficient went up and down. Is this a better way of knowing which task ratings were the most and least overlapping?

Thank you!",statistics
mw1x3v,1619087860.0,[Q] What is the process to correctly compare the popularity of items over time?,"I have a list of items which were published at specific times going back a decade. These items have been downloaded many times each.

For each item I have the total number of downloads over their entire life.

Downloads do not occur evenly spread out, they are bunched towards the beginning of availability.

How do I compare the ""popularity"" of a recent item with that of an older one?

If I divide the downloads by the period that they were available, I'm assuming that downloads are evenly distributed and I end up with the most recent item being extremely popular, when this is clearly not the case

How do I do this?

Background: I publish a weekly podcast and I am attempting to determine if it's being listened to more or less. I have the actual server logs.",statistics
mvz6e0,1619074536.0,[E] Seeking intuitive books or papers or resources to learn the backend of the widely statistical tools in research," With this SPSS or any other software/programming that research people use to analyze a sample data, I don't understand how the final number reveals the relation, what does it? how does it work? I know we have these wiki pages, but the notations are so tedious. Is there any intuitive guide or books or papers that can, you know get the heart of the tools out for a better understanding??",statistics
mvwgsu,1619062551.0,[D] math theorems behind machine learning,"Can someone recommend a source (e.g. website, blog, book, youtube channel) that discusses the math theory behind machine learning - but in such way that it's not ""pure math""? Something detailed, but not heavy in pure math?",statistics
mvweth,1619062348.0,"[D] decline of traditional ""state space models""","It seems that Recurrent Neural Networks have overtaken traditional ""state space models"" for time series models. Is this because traditional state space models require the analyst to make certain assumptions about how the system transitions between different states - whereas a recurrent neural  network can consider a wide combination of states through hidden layers and deep architecture?",statistics
mvvvfj,1619060370.0,"[Q] Different statistician picked up project, changed t-test, p no longer significant. Quick Q","Working with a dataset of ~2000 patients that was initially analyzed by 1 statistician then again by another. Our primary outcome is regarding how much of a drug was used during hospitalization before and after an intervention (updated guidelines). A group of patients pre-intervention, and a different group post-intervention.

So just a difference of means, aka report two-tailed unpaired/two-sample t-test of means assuming unequal variances, right? Anyway, the 2nd statistician got a different p-value, enough such that our difference before and after intervention was no longer significant, so just trying to figure out why.

He explained it as, ""First statistician was doing mean1=mean2=0 and not testing for what you want, now it's mean1=mean2 or mean1-mean2=0.""

I know mean1=mean2 is what we want (is there a difference between the means?), but what is this mean1=mean2=0 test? In layman's terms, what's mean1=mean2=0 asking?

Appreciate any help - thank you!",statistics
mvqy5z,1619043561.0,"[Q] Given the current longevity data on people’s life span, could statisticians be able to accurately predict the year that we’ll reach the longest age of 150 human years (on Earth)?","At what year will the first human ever reach 150 years of age, given they still remain on Earth?",statistics
mvqvos,1619043361.0,[Q] How do Bayesian statistics work in the case of consumer reviews?,"Suppose there are 2 restaurants:

* Restaurant A with a 4.5 star rating and 5 total reviews
* Restaurant B with a 4.0 star rating and 100 total reviews

How could a Bayesian formula help show that Restaurant B's rating of 4.0 is actually more ""legit"" than Restaurant A's rating of 4.5 because of the sheer quantity of total reviews.

Apologies if this is vague.",statistics
mvppm0,1619039908.0,[D] Intuitive Explanation As To Why Some Models Can't Handle Categorical Variables with Too Many Categories,"I am working with an example similar to this: https://stackoverflow.com/questions/46914490/r-random-forest-and-more-than-53-categories

I am using a random forest model, and one of the categorical variables I am using has too many categories (around 80). When I run the model, I get the following error (I am working in R):

Error in randomForest.default(m, y, ...) : Can not handle categorical predictors with more than 53 categories

However, this error goes away when I remove that variable and everything works fine.

I was wondering - why does this error happen? Is it because the software is unable to handle this problem, or does it have anything to do with the math behind the random forest algorithm?

For example, random forests are made up of many decision trees - decision trees themselves use the ""Gini Impurity"" or ""Entropy"" to make these splits (e.g. https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) . Is it possible that the mathematical formulas ""don't work"" when there are too many categories ?

For example, maybe too many categories lead to a sparse matrix, or one of the intermediate calculations results in a ""division by zero"", or results in all possible splits becoming statistically identical to each other?",statistics
mvpotj,1619039843.0,[Q] Trying to remember the name of a strategy for reducing the overall error of multiple estimates,"For the life of me I can't remember name of it, but there's a strategy that allows some metric of improved accuracy / lowered error when making multiple estimates, like some kind of regularization technique. Whereas intuition would suggest that squared error is minimized by using the mean of each variable, there is a strategy that lowers the overall squared error by slightly adjusting each estimate - even when the variables and estimations are otherwise independent. Does anybody remember the name of this technique?

Edit - it's the [James-Stein Estimator](https://en.wikipedia.org/wiki/James%E2%80%93Stein_estimator) I was looking for!",statistics
mvotoc,1619037392.0,[C] Sales trends,"[C] I have a list of registration years of vehicles that are bought and reregistered as used vehicles. I am using the initial registration date and the used registration date to find the amount of time customers are holding onto their vehicles.

I am sorting the data to only give me N>20, and I have data going back 20 years. If I project that most customers hold onto their units for a period of five years (trying to extrapolate this to conquest customers based on average financing options) what would be the best statistical test to use to determine this?

I want to be able to cross reference this with my known accounts to conquest accounts so we can use marketing money to throw at them when we can predict roughly their purchasing period.

Sorry, I haven’t taken stats since college and figured I’d ask here before start digging into my old notes or watching YouTube videos.

Any help would be appreciated. Thanks.",statistics
mvosb0,1619037285.0,[Q] Whats the difference between individual fixed effect model and two-way fixed effects model?,"My dataset is a balanced panel with 290 individuals all observed in 3 different time periods, 2010, 2014 and 2018.

I want to measure the effect of x on y with a fixed effects model. When I include both time and individual fixed effects my regressor x, and its lag interacted with a time dummy for 2018 (x_2014 * dummy2018) is not significant. However, when I remove the time effects from the model, they both become significant and their estimates increases by a lot.

Is a FE model with only individual fixed effects called an individual fixed effects model?

Is a FE model with both time and individual fixed effects called an two-way model?

Is the year dummies from my FE model with both time and individual fixed effects ""consuming"" the effect off x on y? x does vary over time and is not constant.

Any help is greatly appreciated! Thanks.",statistics
mvnu15,1619034598.0,"[Q] Relationship between data, Stat final project","Hey everyone,

For my final project in my statistics class, I have to determine the relationship between online learning and GPA. I understand that I will be asking other college students what their numerical GPA is since the start of this academic year (because last year online learning started late in the year). My question: Should I also inquire about their GPA prior to online learning so I have something to compare it to?",statistics
mvnmw0,1619034046.0,[Q] Demonstrating relationship between data,"What kind of analysis would I need to perform to see if there is some kind of relationship between the following data?

I have a data set where I have daily EMS visits, Maximum patients in the ED on a given date, Maximum number of patients boarding in an ED on a given date, and average boarding time for a given date.

I would like to see whether there is a relationship between number of EMS visits and the other data listed above -

Ie: when there are many patients boarding in the ED, there are fewer EMS visits. Or when there are many overall patients in the ED, there are fewer EMS visis, or when admitted patients are boarding in the ED, there are fewer EMS visits. (and whether there is a statistical significance to this relationship)

I have limited formal stats background (i like data and extracted this data manually on excel from some clnical data) - but am stuck in terms of making further use of this data due to my limited knowledge of stats. I don't have any special stats software beside excel. Can I do this analysis on excel?

Thank you",statistics
mvk16m,1619024166.0,How to forecast human population? [Q],"&#x200B;

Hello everyone !!!

The final work I'm doing for my economics degree is about rural depopulation in a tiny region of central Spain. I'm writing a chapter about future perspectives on demography, in that chapter I want to put a forecast of the population on the region.

So, which kind of model or technique do you recommend to me for it?. I've thought on an ARIMA model or a exponential smoothing one, because I only have data about the population.

Sorry about my english, thank you for your attention and have a good day !!",statistics
mviosq,1619020455.0,[Q] Can you get a r squared and p-value for a non linear regression?," Let's say I plot a graph between two variables and the y-axis is linear scale whereas the x-axis is log scale. The regression line would be y=a ln(x) + c, with a being the slope and c being the intercept.

I can get an R-squared value in excel for this regression line, but not a p-value in Excel.

Furthermore, I read online that there is r squared and p-value are not valid for non-linear regression.

Am i correct in saying this? I don't really understand the reason why. If the r squared and p value are not valid, what ways can I get a measure of how good the regression is?

Thanks in advance",statistics
mvhfda,1619016909.0,[D] using math to justify the performance of machine learning algorithms,"Suppose we look at the mnist digit recognition problem: referencing the mathematical properties of these algorithms, how could we try to justify that for this problem - random forest performs better than linear regression, and neural networks outperform random forest?",statistics
mvggm2,1619014110.0,[Q] How to justify taking these courses in a Statistics program?,"I just got accepted into a Math MA program with a statistics concentration as my university doesn’t have a Masters in statistics. I have already been assigned an advisor and we were discussing the courses I should take.

Per the guidelines I am able to take up to 12 credits outside of the Math department. Speaking to my advisor he is not very fond of that. He wants me to take all the courses in the math department.

Well I don’t want to, I want to learn stats but that’s not all I want to learn. My intentions were to take a grad course in machine learning and a course in micro and macro economics.

Well he is very much against that, we have a Data Science program and he stated if I wanted to learn machine learning I should have applied to that program and he also believes the Econ courses are useless. I personally don’t see it that way, I want to learn whatever I wanna learn and I don’t wanna strictly focus on math courses which is allowed.

So he states I need to justify a need to take those courses and I honestly can’t think of a much better answer than the fact that I want to learn them.",statistics
mvg73h,1619013335.0,[Q] Continuous Covariate on Chi-square test of independence,"I am currently doing a chi-square analysis on 2 categorical variables: ASD group (high trait, low trait), and anxiety change (no change, worsened, improved). I found age to be significantly different between ASD group levels and I want to control for that in this analysis. How do I do that on SPSS?

&#x200B;

Thanks,",statistics
mve4j3,1619006412.0,"Weekly /r/Statistics Discussion - What problems, research, or projects have you been working on?","Please use this thread to discuss whatever problems, projects, or research you have been working on lately. The purpose of this sticky is to help community members gain perspective and exposure to different domains and facets of Statistics that others are interested in. Hopefully, both seasoned veterans and newcomers will be able to walk away from these discussions satisfied, and intrigued to learn more.

It's difficult to lay ground rules around a discussion like this, so I ask you all to remember Reddit's sitewide rules and the rules of our community. We are an inclusive community and will not tolerate derogatory comments towards other user's sex, race, gender, politics, character, etc. Keep it professional. Downvote posts that contribute nothing or detract from the conversation. Do not downvote on the mere fact you disagree with the person. Use the report button liberally if you feel it needs moderator attention.

**Homework questions are (generally) not appropriate!** That being said, I think at this point we can often discern between someone genuinely curious and making efforts to understand an exercise problem and a lazy student. We don't want this thread filling up with a ton of homework questions, so please exhaust other avenues before posting here. I would suggest looking to [r/homeworkhelp](https://www.reddit.com/r/homeworkhelp/), [r/AskStatistics](https://www.reddit.com/r/AskStatistics/), or [CrossValidated](https://stats.stackexchange.com/) first before posting here.

**Surveys and shameless self-promotion are not allowed!** Consider this your only warning. Violating this rule may result in temporary or permanent ban.

I look forward to reading and participating in these discussions and building a more active community! Please feel free to message me if you have any feedback, concerns, or complaints.",statistics
mvdmae,1619004479.0,[Q] Course recommendations?,"hi!

I'm looking for recommendations for online courses that cover some advanced statistics for social sciences. I'm pretty good at regressions (multiple regressions, mediations, moderations, etc) and Factor Analysis (including multigroup stuff), but would love something like quadratic regressions or OLS or even introductory machine learning stuff. I'm also proficient in R, so the course could be taught on R.

Alternatively, an introduction to Python for statistics (focusing on the Python bit and not the stats bit) could also do, so that I could learn one more language haha.

I would also prefer audit-only or free courses. Mainly because I'm not from the US, so the cost is too high, generally.

Some background: I'm planning to apply for Psych grad school and have a lower GPA due to stats, but in the years since my last degree, I have become compareitively proficient with applied stats, as I'm in a research position currently.

tldr: recommendations for advanced stats online courses with R
+ introduction to python for people in psychology/social science",statistics
mvbmhy,1618995749.0,[D] Possible U-shaped distribution,"I am looking for some U-shaped distribution in higher dimension .For single dimension Beta distribution (with alpha,beta <1)  is a reasonable choice .Is there some known distribution in higher which can act like Beta(with alpha,beta <1).

I am basically looking for some thing like a U-shaped quadratic function but which is rather almost flat in most of the space but increases rapidly as it approaches the boundary.

PS: I am not looking for dirichlet which increases rapidly only towards the corners

Thanks in advance",statistics
mvb2zd,1618992966.0,"[Q] I run 100 simulations, and I record the wait times of every entity in each simulation. If I want to know the median wait time, do I take the median of all wait times combined, or the average of individual median wait times?","Edit: some context.
I am simulating patients in a medical clinic. Patients arrive (a random number of them at mostly random times), and depending on if the necessary staff are available, the patients have to wait for the next step of their appointment, then leave. I am interested in if the wait times are below a certain threshold (i.e. if the xth percentile of wait times is below y minutes).

For example:

Simulation 1 returns wait times [1,5,6,2,3,4].

Simulation 2 returns wait times [2, 3, 7, 1]

...

Simulation 100 returns [10, 3, 5, 2, 3, 3, 3]

If I want to know the median wait time of the system, should I combine all of the wait times into a single list and take the median, or should I take the median of each simulation, and average those 100 medians? What about the median of the medians?

Would it matter if I wanted the 90th percentile instead of the median? What if I wanted the mean wait times (I believe this is called the ""grand mean"").

The number of samples might not the same in each simulation, but the number of samples should be around the same (they come from the same distribution).",statistics
mv8dvg,1618980104.0,[D] least absolute deviations (to a power?) and robust regression,"I've been thinking a little bit about least squares and how one method of getting a robust regression alternative is to use Least Absolute Deviations.  One of the things that seems to be potentially problematic is that there could be multiple solutions, with the example on wikipedia given as such:

https://upload.wikimedia.org/wikipedia/en/8/89/Least_absolute_deviations_regression_method_diagram.gif

Linked from: https://en.wikipedia.org/wiki/Least_absolute_deviations

Would a fairly simple solution to this be to use a near-1 power?  That is, instead of minimizing ABSOLUTE(residuals), you could instead minimize [ABSOLUTE(residuals)]^1.01 or 1.1 or 1.0001 or some other value less than 2?  When you get to 2, of course, you're at least squares and no longer reducing the effect of outliers, so I'm thinking of values between 1 and 2, but most likely near 1.  Is this common and I'm just not aware of what this is called?  Would this be a reasonable approach to robust regression while getting unique solutions vs the LAD approach?",statistics
mv7bf0,1618975762.0,[E] Engineer looking for advice for learning predictive modeling,"I am a civil engineer who will be starting a master's in geoinformatics engineering focusing on geospatial data science in the near future. I took a probability and statistics for engineers course in undergrad, a very practical course without much focus on theory and the math behind concepts.

I know I will eventually have to grasp statistical learning and predictive modeling. My question is: should I bother reading a more theoretical book like Mathematical Statistics by Wackerly or can I jump directly into books like Introduction to Statistical Learning and Applied Predictive Modelling?

Thanks!",statistics
mv6he0,1618972539.0,[D] Complexity of Time Series Models: ARIMA vs. LSTM,"1) When it comes to time series analysis, I am trying to understand what makes newer models such as LSTM's capable of capturing more complex patterns in the data compared to older modeis such as ARIMA? In statistical learning theory, there is something called the VC Dimension of an algorithm (https://en.m.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension) - the VC dimension is apparently what describes the relartive level of complexity a machine learning algorithm can capture. Does this concept of VC Dimension carry over to models in time series analysis? Is it possible to show that LSTM's have a higher VC dimension compared to ARIMA style models? Supposedly, neural network based time series models were developed because modeols like ARIMA was unable to provide reliable estimates for bigger and complex datasets. Mathematically speaking, what allows a LSTM to capture more variation and complexity in a dataset compared to ARIMA?




2) Lately, I have seen many people starting to suggest that Convoloution Neural Networks (CNN) can also be used for the purpose of time series forecasting. Just as a general question: in what instances would it be better to use a CNN for time series forecasting compared to an LSTM?

Thanks",statistics
mv5uxo,1618970293.0,"[D] ""no free lunch"" vs neural networks","I read that there is a theorem called ""the no free lunch theorem"" that states : there is no single algorithm that is better than all other algorithms. This is somewhat obvious: complex algorithms should perform better on complex problems, and simpler algorithms should perform better on simpler problems.

This being said, why have neural network based algorithms been accepted as the main type of algorithms for solving complex real-world problems? Apart from the simple answer, that they ""from observation, they simply perform better on these problems"" - if we were to look at neural networks (e.g. mlp, lstm, cnn), reffering to the mathematical properties of neural networks, how/what could we attribute their success to? Why do we use neural networks instead of regression models? From a certain prespective, are neural networks defying the ""no free lunch theorem""?",statistics
mv2x4h,1618960071.0,[Q] Do the size and critical value of a test depend on the sample size?,"The power of a test depends on the sample size.  Similarly,

- Does the size of a test depend on the sample size?

- The critical value of a test for a significance level is computed from its size. Does the critical value of a test for a significance level depend on the sample size?

My guess is yes to both questions. But in statistics books, I found that the size and critical value of a test is calculated once for all, without referring to sample size, and then the power of the test is calculated with sample size involved, in particular, for estimating the required sample size for achieving some power.
Is sample size not important in calculating the size and critical value of a test?

Thanks.",statistics
mv1q8k,1618956499.0,[D] Computational Costs of Machine Learning Algorithms,"https://stats.stackexchange.com/questions/73944/what-are-the-limitations-of-kernel-methods-and-when-to-use-kernel-methods

Can anyone recommend any sources that discuss why kernel methods (e.g. SVM) are ""computationally cheaper"" compared to neural networks?",statistics
mv1o8f,1618956330.0,"[D] Why do ""polynomials"" (e.g. polynomial regression) have a bad reputation of overfitting?","We all must have heard by now - when we start learning about statistical models overfitting data, the first example we are often given is about ""polynomial functions"" (e.g. see the picture here: https://ardianumam.wordpress.com/2017/09/22/deriving-polynomial-regression-with-regularization-to-avoid-overfitting/) .

We are warned that although higher degree polynomials can fit training data quite well. they surely will overfit and generalize poorly to the test data.

My question is : Why does this happen? Is there any mathematical justification as to why (higher degree) polynomial functions overfit the data? The closest explanation I could find online was something called ""Runge's Phenomenon"" (https://en.wikipedia.org/wiki/Runge%27s_phenomenon ), which suggests that higher order polynomials tend to ""oscillate"" a lot - does this explain why polynomial functions are known to overfit data?

I understand that there is a whole field of ""Regularization"" that tries to fix these overfitting problems (e.g. penalization can prevent a statistical model from ""hugging"" the data too closely) - but just using mathematical intuition, why are polynomials known to overfit the data?

In general, ""functions"" (e.g. the response variable you are trying to predict using machine learning algorithms) can be approximated using older methods like fourier series, taylor series and newer methods like neural networks. I believe that there are theorems that guarantee that taylor series, polynomials and neural networks can ""arbitrarily approximate"" any function. Perhaps neural networks can promise smaller errors for simpler complexity?

But does anyone know why polynomials are said to have a bad habit of overfitting, to the extent that neural networks have largely replaced them?

Interesting paper: https://www.nber.org/system/files/working_papers/w20405/w20405.pdf",statistics
muzma2,1618950586.0,[Q] Machine Learning Reading Recommendation,"Hey!

Today  I realized that even though I have been using statistics for work and  research for more than 5 years, I have literally no knowledge of machine  learning and classification algorithms (Neural Networks, Random  Forests, you name it). Is there a book that introduces machine learning  and the most frequently used methods in a practical,  application-oriented ""cookbook"" style? It would be even more amazing if  it included examples with R code. I am mostly interested in Random  Forests and Neural Networks, but I appreciate whatever. I consider myself fairly advanced in terms of my knowledge of applied statistics, so it does not have to be a book written for complete dummies, but I lack the mathematical sophistication to appreciate the finer intricacies, so I would prefer something with less formalisms.

Thanks!",statistics
muz98h,1618949587.0,"[Q] Is the relationship between power, significance level, sample size, and effect size representable by a formula?","1. Power, significance level, sample size, and effect size are related to each other. Given three, we can calculate the other. Other than   some power tables and sample size tables, is there a closed form or formula that represent their relationship? The books I searched in have kept this vague.

2. Is their relationship derived in a completely deterministic way without calculating any probability? (I suspect their relationship might be purely deterministic and can be derived without referring to probability.)

3. The power is a function over the alternative hypothesis. So what does a ""power"" (which I guess is a scalar) mean in relation to effect size?


In mathematical statistics books, I don't find they mentioning effect size and the relationship between the four concepts. But instead, I find the definition of power function is the closest but still different. The power function can be defined from level alpha, test statistics T, sample size n:

> For each theta in set Theta_1 of alternative hypotheses, beta(theta) := P_theta [T_n(X) >= c],

> where c is computed from sup_{theta in Theta_0} P_theta[T_n(X)  >= c] = alpha

Thanks.",statistics
muxssj,1618945577.0,[Question] Statistical Test for two sets of coordinates,"I would like to run a test to estimate if two sets of coordinates are coming from the same distribution.

In  my case one set of coords are measurements of an underlying process and  the other set are possible values coming from my own model. I know that  this can be achieved with a Kolmogorov Smirnov in 1D, but I don't know  how to translate this into 2D.

[Example Image](https://imgur.com/a/m91i3uh)",statistics
mutvhv,1618935144.0,"[D] Data before models, but problem formulation first","[https://www.crosstab.io/articles/formulation-comes-first](https://www.crosstab.io/articles/formulation-comes-first)

Formulating business tasks as data science/machine learning problems is the hard  part of statistical modeling, not training and knob twiddling. It's also where the magic happens, and what distinguishes a senior data scientist from a junior data scientist.

What do you think?",statistics
muqit3,1618925941.0,[Q] Calculate appropriate but practical bin size?,"Hello people!

First post here, please don't hurt me :D

Here at work I have a set of \~330K observations (user consumption levels) and I need to visualize them in a histogram first, then construct a customer base model. Both hinge on the bin size.

If I'm not mistaken\* Sturge applies to normal distributions so it can't be applied here, but what other choices do I have? I tried a few more rules, but apart from the Freedman–Diaconis one which gave me a realistic 53 bins to work with, the rest give me a huge number of bins I simply can't deal with - in their thousands, in some cases.

Any help would be greatly appreciated - I can try and provide any further info that's needed.

&#x200B;

\*obligatory statement: *not a statistician*",statistics
muola2,1618919469.0,[Q] Looking for GP kernel,"I am looking for a GP kernel. I have a series of populations with binary features I want to predict, and I have latitude and longitude information. Additionally, I have population size estimates for each population. I want to fit a 2D Gaussian Process with the latitude and longitude information, but also take into account the population sizes. The idea is that the large population sizes should reduce the absolute distance between two populations, while small population sizes should increase it.

I think that a 3D approach or multiplying kernels would the wrong approach because I do not expect population size to have any direct impact on the features themselves, only in the amount of covariance between two points.

Thanks!",statistics
mum8lt,1618909302.0,[Q] How can I predict the probability of winning based on data of wins and losses?,"Okay so I'm playing a video game and I'm trying to figure out which character I should play based on data about wins and losses on that character. So I want to estimate the probability that I will win given I picked a particular character.

It seems intuitive to consider % win rate, but clearly this isn't enough. If I play 2 games on ""Brand"" and win both of them, that doesn't mean there's a 100% chance that I will win the next game. Likewise it seems like I should be more confident I will win if I have 15 wins and 5 losses on ""Soraka"" than if I have 6 wins and 2 losses on ""Thresh"" even though those are both 75% win rate.

I know that one of the possible methods is to play as many games as possible on each character and then just observe their %WRs, but this would be very time consuming and the point of doing this in the first place is so that I spend as few games as possible and characters I'm bad at and as many as possible on characters I am good at.

So yeah, what's the best way to get the probability I will win given data of wins/losses? Also, is there a better way to figure out which character I'm best at without needing to do calculations like that?",statistics
mum8ag,1618909260.0,[Q] How to identify the upper threshold of a skewed plot?,"Sorry for probably my bad use of terminology, I work in biology and I'm learning statistics as I go.

I have a distribution plot of data, plotting genes with different p-values, which looks like this: [https://imgur.com/Q8MKx9y](https://imgur.com/Q8MKx9y) (y-axis is counts of genes, x-axis is p-values per gene)

I want to select the upper threshold of genes with very high p-values (so insignificant genes), but I don't know how to best methodically do this. For example, I know it would be best to get a final gene group of a few hundred genes as that number works best in downstream gene analysis tools, but I feel it's biased of me to set a p-value cut off that gives me the gene number I want but isn't actually completely the upper gene group in the total distribution, if that makes sense.

Based on a skewed plot, how can you select thresholds in the plot methodically to view upper and lower quartiles of genes?",statistics
mum0l1,1618908213.0,[Question] What is the essence of Combining AR and MA models into ARMA or ARIMA ?,"

I have always wondered why AR and MA are combined to form an unified ARMA or ARIMA model.

My thinking is that a time series comprises of the below.

Yt = signal + noise (eq1)

The AR part models a lagged version of the dependent variable (there by increasing signal of finding any correlation structure (perhaps a weak casualty too)). Thus AR amplifies the signal in the above equation eq1.

The MA part models the error or white noise i.e. to predict a future value it kind of 'course corrects' by factoring in previous errors. Thus MA reduces the noise in eq 1.

Is my intuition or thinking correct ?

If not, why are the AR and MA terms merged to form a unified model.

Would be grateful for the comments or clarification.",statistics
mukqkh,1618901945.0,[D] The population of earth is more than 7 Billion. Is the sample size to do any statistical study concerning entire world should be big enough ?,"I will explain here.

As the population is 7 billion.
Some studies come out saying this thing causes that thing in humans. But their N size is like 100-200 or even 1000. Is that size good enough to make a statistical decision about 7 billion people. Or should N be bigger comprising of people from different countries to have a better statistical understanding of the entire world ?

I haven't conducted any study but my general opinion is N size should be bigger.",statistics
mugyj9,1618886776.0,[C] Honestly? Just a Rant Post Regarding the Post-Bacc Analytics Job Hunt,"Hi, everyone. I'm just a bit frustrated, to be honest. A little background - I have a bachelor's and I graduated just over a year ago. I didn't major in statistics, but I was exposed to it from research with a professor in an applied field during my senior year. It was fun! We coded in R, got a few studies going, and I still coordinate with him to this day to do work on some hobby projects, despite not taking classes anymore.

After graduation, I also wound up tutoring stats and R programming at a large company and taking on some extra responsibilities; got into a role hiring new tutoring applicants, etc. Part-time, but between this and a simulation project or two that I still work on with my former mentor, I enjoy things. But that's where the buck seems to stop in terms of professional development.

I get it. I don't have a phd or master's. That's perfectly fine; it'd be absurd to expect anything more than running analyses or managing data under the supervision of a statistician. I don't mind that, and I'd welcome it! But I'm just disappointed in how hard it's been trying to nail a job in statistical programming. That's where I wanted to lead things from here. But despite studying up on SAS, getting a certification in my spare time, and coding a lengthy project for github that involved base SAS, SAS/STAT, IML, SQL, and macro programming, I struggle to get noticed given the few entry-level positions I seem to find.

I'd like to conduct a quick post-mortem and settle this once and for all: Honestly, is SAS a no-go for a college graduate? In terms of roles even at CROs, is hiring mostly for those with a master's or with experience? As you might be able to tell, in terms of statistical programming, I'm interested in the clinical area, as that's where a lot of this sort of work seems to be performed. Some pretty old resources seem to say that CROs are a go for recent graduates, but at this point, more than likely for the best, it's time for me to move on to a technology that's more widely used.

Does this seem to be supported by your observations?",statistics
mufb1t,1618881052.0,[Q] Does increasing sample size increase test size as well as power?,"Power and test size of a test procedure are  computed in the same way: based on the probability of rejection under each parameter value.

Increasing sample size can increase power. Does that also increase test size, and therefore increase the risk of test size exceeding the level of significance?

How do people manage to increase power without risking test size exceeding level of significance?

Thanks.",statistics
muf3ry,1618880358.0,[education] YouTube StatsExamples playlist," I've made a [YouTube channel](https://www.youtube.com/playlist?list=PL4i1LGTIpScqnqq3MX8FL7aQuj_C78QR2)  (and website) with statistics videos that I'm hoping will be useful for  people. Check it out if you're interested and feel free to post some  constructive advice or suggestions. My target audience is AP stats and  college students and the intention is to include lots of step-by-step  examples:
[Most recent video](https://youtu.be/diRX_NesFkA)",statistics
mubxpf,1618870244.0,[Q] Rules of thumb for effect size of interaction coefficients in mixed effects logistic regression?,"Lets assume all continuous predictors are standardized, and all categorical predictors are binary. Are there rules of thumb for what interaction coefficients would be small, medium and large in mixed effects logistic regression?

I been shown [this](https://www.meta-analysis.com/downloads/Meta-analysis%20Converting%20among%20effect%20sizes.pdf) resource when has a formula for converting Cohen's d to log odds ratio. To answer my question, could I simply convert a small effect (by Cohen's d standards) to log odds ratio and use that as a small interaction coefficient in mixed effects logistic regression?

This doesn't have to be very precise. It is just for the purpose of ball parking number of participants using a simulated power analysis.",statistics
muakp0,1618866413.0,[D] Efficient ways of choosing number of layers/neurons in a neural network,"I have been reading more about the theoretical backgrounds of neural networks (e.g. ""universal approximation theorem"") and have seen several authors demonstrate that even a simple (few layers, many neurons) neural network can (theoretically) approximate the variable of interest (i.e. the response variable) to a ""decent"" level of precision.  However, the implication being that to use simple neural networks in order to achieve good results, this would require a very large number of neurons. Therefore, deeper neural networks have been developed over the years, which attempt to provide good results with more layers but a fewer number of neurons.

This brings me to my situation: I have never been able to successfully fit a neural network to any real-world data that I have used. I have always gotten really bad results with neural networks (after trying all sorts of combinations of number of neurons, number of layers, learning rate, activation function, ""drop out"" regularization, etc.). This seems to be a hyperparameter-grid search problem.

(Ironically, models like CART decision trees have good results on the same data (supervised binary classification) and random forest has produced even better - this data is not ""small by any means"", contains around 30 columns and over 300,000 rows of data).

 Does anyone know if routines have been written (e.g. in tensorflow keras) that can assist in this problem of deciding the number of layers and the number of neurons? Is there a ""ground rule"" for deciding how many layers and how many neurons to begin with? Is there something around that can ""intelligently"" point you in the right direction for how many neurons/layers to choose?",statistics
mua07o,1618864836.0,[Q] What is the definition of effect size in statistical theory?,"What is the definition of [effect size](https://en.wikipedia.org/wiki/Effect_size) in statistical theory?

I have searched in many mathematical statistics books, but haven't found one that mentions the concept. They do clearly define power  level of significance. Is effect size not a well defined concept?

I was curious that how the minimum sample size for a test is computed from a desired power, level of significance, and effect size.
In mathematical statistics books, the minimum sample size is computed from desired power and level of significance. So  how is effect size involved then?

Thanks.",statistics
mu9psh,1618864025.0,"[D] Has anyone ever heard of a ""scissors plot""?","https://imgur.com/a/d2t6gII

I came across this interesting graph called ""scissors plot"". I have never heard about it before - has anyone else heard about it? Is this a well known plot?

It would be interesting to know if there was some way to roughly approximate the ""N-o"" point, perhaps the ""N-o"" point could be used to decide if it makes more sense to use ""complex"" models or ""simple"" models.",statistics
mu9o17,1618863892.0,[E] How important is graduate level Probability Theory?,"Hi all.  During my undergrad I took Probability Theory 1 and 2.

In Probability Theory 1 I learned the principals of counting, the axioms of probability, random variables, fundamental limit theorems, concepts relating to conditional probability and independence, discrete and continuous random variables, how to compute their moments, the law of large numbers and central limit theorem.   In Probability Theory 2, I learned about Discrete and Continuous Markov Chains, Stochastic Processes, and Brownian Motion.

Both of those classes had some theory, but it was mostly understanding concepts and solving problems.  None of those classes dealt with Measure Theory.  My grad program has Advanced Probability 1 and 2.  I was told that I can forego taking both those classes because of my stellar grades in the undergrad Probability Theory 1 and 2 courses.  I'm a bit hesitant to forego taking them.

What do you guys think?  Should I take Advanced Probability Theory 1 and 2?

Thank you.",statistics
mu7uxf,1618858975.0,[Q] Randomized Tournament Style Survey,"My team is looking to create a survey that identifies people's preferences amongst a set of words by making direct comparisons between two options.

For example, let's pretend that we were asking people to determine their favorite ice cream flavor out of `chocolate`, `vanilla`, `rocky road`, `strawberry`, and `mint`.

They would be presented with a randomly generated choice between two of the options:

`chocolate` OR `strawberry`

And asked to select their preference (`chocolate` being the clear winner here in my heavily biased opinion). At this point, either both options are replaced or the loser is replaced:

`chocolate` OR `vanilla`

This process continues for either a set or arbitrary number of times.

Two questions:

* Is there a name for this style of survey? I have seen them and participated in them before, but cannot seem to be able to find it.
* Are there a particular set of techniques utilized to analyze the output of these surveys?
* Are there tools that people have already built to administer this type of survey? What are they?

We've discussed building a quick R Shiny app to do this for us, but I'd really prefer to utilize a tool that someone else has already built. Please let me know if there is a better place to post this!",statistics
mu6u4i,1618856232.0,[Career] Can you guys recommend me some good statistic textbooks that touch upon the syllabus below (preferably by Indian authors)?,"

* Exploratory Analysis

   * Design of Experiments, Sampling, Sampling Error, Sampling Bias
   * Measures of Central Tendency and Dispersion
   * Statistical survey and Presentation of data
* Statistical Inference

   * Confidence intervals
   * Correlation
   * Formulating Null & Alternate Hypothesis, Type I and Type II errors
   * Regression
   * z-test/t-test, p-value
* Probability

   * Basics of Probability
   * Probability density function (PDF) and Cumulative distribution function(CDF)
   * Standard distributions",statistics
mu619m,1618854094.0,"[Q] Quick check: is the coefficient in logistic regression for a binary variable synonymous with the ""log odds ratio""?",I have been suggested a paper that lets me convert Cohen's d to a log odds ratio. Am I right that this latter term is synonymous with the coefficient in a logistic regression when the predictor is binary?,statistics
mu60m7,1618854045.0,"[D] assumption of ""normally distribution"" for gaussian process","Gaussian Process (https://en.m.wikipedia.org/wiki/Gaussian_process) seems to be an important topic in machine learning and statistical modelling. But in many topics involving Gausian Process (e.g. gaussian process regression, bayesian optimization for the cost function in neural networks, etc.), when I come across tutorials for how to implement these methods using statistical computing software (e.g. R, python), no one seems to test if the data being analyzed follows a multivariate normal (i.e. gaussian) distribution.

Based on the fact that no one is doing this - is it really necessary to verify that the data you are using follows a multivariate gaussian distribution when using methods that involve Gaussian Process?

Thanks",statistics
mu4xq6,1618851127.0,[Q] - is it possible to sample from any probability distribution?,"I was going through some materials about generative models and it was said that we cannot compute the likelihood for all the generative models. I was wondering if it was possible to sample from any probability distribution?

Thanks",statistics
mu4ush,1618850906.0,UCLA vs UCSB vs SDSU [E],"Can someone please help me decide between these schools?


UCLA - MS Biostats

UCSB - MA statistics

SDSU - MS statistics


I am still planning on getting a PhD after completion of masters. Not partial to biostats, despite extensive life science research background. My biggest worry is: if I go to a lower ranked MS, like SDSU, will I be shooting myself in the foot if I want get into an elite PhD program afterwards? 





UCSB Pros

-funded

-UC system

-strong faculty focus in financial statistics, but still diverse faculty in terms of other research interests

-degree is in stats rather than biostats, so more opportunity to go into a biostats or stats PhD?


UCSB Cons

-small town (<100k)

-MA instead of an MS (not sure if this matters)
 


UCLA Pros

-will likely be funded

-highly regarded school in UC system, and might help application when applying to PhD programs

-located in LA

-less theoretical program than UCSB


UCLA Cons

-located in LA

-biostats in instead of plain stats
 


SDSU Pros

-located in SD where I live, and would ideally like stay

-likely funded and/or very cheap

-option to concentrate if Biostats if I want, but still an MS in stats

-located in massive biotech scene


SDSU Cons

-not well known state school, and I want to go to a good PhD program afterwards

-very small faculty, but they are diverse in research interests",statistics
mu2ty2,1618845391.0,[Q] Best resources to learn basic statistics?,"Hello all!

First, I apologize if this question has already been answered. I couldn't find a useful answer through Google, so I'm here. A link to another thread would be awesome if such a thing already exists.

I'm wondering what some good resources are for learning basic-to-intermediate levels stats. I took a basic stats course about 3 years ago and I have more knowledge of Excel than the layperson, but very little knowledge relative to most (all?) of the people in this sub. Lately, I've become interested in sports data, mainly NBA, MLB, and NFL.

Fast forward 3 years, I'm graduating in about a month and I have the summer to just work and study for the GRE. I'd like to learn more about statistics with the end goal of creating various statistical models for the major sports that I enjoy watching (and occasionally betting on). Right now, Random Forest models and Neural Network models are very intriguing, but I don't know where to gather the requisite knowledge to create those. I've read that I'll need to learn how to code, which is a welcome challenge.

TLDR: Any resources you have (YouTube channels, blogs, etc.) which can help me understand concepts that can be applied to creating statistical/analytical models would be greatly appreciated! Thank you all so much!

DJ",statistics
mu1s4w,1618842430.0,[Q] Transforming interaction to proportions,"I have a question about interactions. Imagine X is only marginally insignificant at M(-1SD) p = .051 and strongly significant at M(+1SD). Can I *roughly* transform this to proportions according to a normal distributions. In other words, the effect is significant for roughly 85% of the sample? I'm asking so I can more easily translate an interaction into words for practitioners.",statistics
mu0awr,1618837950.0,[Q] Scaling variance in multivariate normal model,"I have a bivariate regression model where one variable is a predictor for both outcomes (there are other predictors as well).

I want the variance of both outcomes to scale with the magnitude of that predictor variable. When the variable gets larger, Sigma for both outcomes should be larger as well (while keeping the correlation constant).

Is there a way to do this? The model is coded in Stan, but I think potential solutions to this should be software-independent.",statistics
mtyoyr,1618832236.0,[Q] Is it bad to leave outliers in when you have different measures and different outliers for all of them?,"I had to conduct an experiment and do a write-up for my undergraduate degree, so it doesn't really need to be scientifically valuable.

I have around 8 measures and some of them have 3-4 outliers, but all of the outliers are different between them. I already have a small sample size (N=16), so removing them all would leave me with half of that when I try to run an ANOVA.",statistics
mtxhii,1618827211.0,[Q] Non-parametric outlier test on Gaussian data - why?,"I am reading an academic study re: data cleaning of high frequency data in finance. As HF data is very noisy and not normally distributed due to fat tails, the author uses a standardization procedure to normalize the data. In his words, the transformed data is “virtually normal”

The author then uses median absolute deviation tests to detect/purge outliers from his data. My question is why? If the transformed data is now approx normal, why use robust statistics? Why not use a parametric approach? What was the point of the transformation in the first place??

In case the reference is needed:

[https://virtusinterpress.org/IMG/pdf/cocv12i3c1p1.pdf](https://virtusinterpress.org/IMG/pdf/cocv12i3c1p1.pdf)",statistics
mtskov,1618804644.0,"[D] Does anyone here study/use models from ""functional analysis""?","https://en.m.wikipedia.org/wiki/Functional_data_analysis

I came across this wikipedia page on functional data analysis. Are these kinds of models still being used nowadays alongside deep learning models? Does anyone use them in their work/research?",statistics
mtpqug,1618794106.0,[C][D] Where have PhD Statisticians ended up in tenure track academia?,"They say a statistician can play in everyone's back yard. I'm curious, statistically speaking, where do stats grads end up aside from the pure and (bio)stats departments?

That is, if you or you know of someone who got a stats phd and is now at a tenure track position abroad or in the US, which other departments have you or they gone to, aside from statistics/biostatistics?",statistics
mtp91a,1618792338.0,[Education] Need help deciding if Health Informatics is for me!,"Sorry for the weak title, not sure what else to name this but I have handful of questions if anyone could help answer them. Just need help gathering my thoughts and I want to see others input based on their experience,etc.


I graduate for my undergrad (Healthcare Technology Management) in 1 year, but I am interested in a masters and I am looking around and feel as though health informatics or something similar is something that interests me a lot.

Currently I feel like i want to further my statistics knowledge and solidify what i know so far, I have been thinking of doing an online stats course/certificate during the summer; This could be free YouTube videos, or a something like coursera (suggestions?) and whatever i choose worth it?

Anyone in health informatics or something similar, could you give me insight of that field and your experience?",statistics
mtnsv2,1618787306.0,[Q] Specs in computer for master in Statistics,"Hello, everyone. This is my first post in the sub, sorry if I make any mistake.

I would like to get some recommendations on what to look for in a new computer (laptop) to use it for R mainly. Next autumn I will start my master in Statistics and coming from an Economics degree I have not really needed a specially fast/powerfull computer till now. My knowledge in hardware is also very limited.

Right now I have a surface 4 which I bought for university and mainly use it for my studies and normal things like checking email and so. However as I have been working on my degree's thesis I have noticed that it is not fast at all when working with a larger data size... So I think its time as a R computer is definitely coming to an end (for reading, underlining documents and doing an average use of internet still works perfect).

I have read that the more RAM I have, the better. But apart of that I know nothing else. Any advice would be helpful. I'm also in Europe if that matters. Thank youuu",statistics
mtmefw,1618782779.0,[Q] How do people even come up with neural net architectures?,"As a beginner to DL coming from stat, I find the conceptual and math understanding of how stuff like dense/ conv layers, activations, dropout, regularization pretty straightforward.

But these architecures like ResNet, LeNet, UNet, *insert whatever*- Net, the latest greatest transformer how the hell do people come up with this stuff? It seems like total shooting in the dark. There are infinitely many possible architectures and hyperparameters to try like how do you just stumble upon these?

Im also wondering bc I am taking a DL class but the project throws you on the deep end (no pun intended) and you have to do something novel applied to a dataset. That includes modifying the architecture and im like I don’t even know where to start.",statistics
mtkumo,1618777992.0,[Q] Question about analyzing results from Stata,"My advisor has asked me to further analyze some results of a regression in my dissertation. I have two IVs that I need to compare, one is a count variable, the other is a percentage variable. I need to find out what a one unit change in the count variable is equivalent to in the percentage variable.",statistics
mtdfpp,1618754786.0,[Q] What's the correct test to analyze my data?,"Hello,

I would like to know your opinion about what test(s) I should use to analyze the data from my experiment. I want to compare the differences in a specific exercise between two different sub-phases of the menstrual cycle.

Let me know if you need more details, I am a MRes student with limited statistical knowledge, trying to learn.

**Sample size**: 5 subjects performed the exercise in both sub-phases of the menstrual cycle.

**Exercise protocol**: 5 sprints with a short recovery. (6"" sprint, 24"" recovery).

**Design**: every subject had to perform the exercise protocol in two different phases of the menstrual cycle, in randomized order (someone started in phase 1, someone in phase 2). Before this, they all did a familiarisation session.

**Parameters**:

1. *Sprint parameters*: those are parameters analysed during/after every sprint, and therefore for each exercise session I have 5 values. For example: power, velocity
2. *Anthropometric data*: parameters collected once, before the exercise protocol (height, body mass, circumferences)
3. *Post-exercise parameters*: collected immediately after the exercise, 3 minutes after and 5 minutes after the exercise ended

&#x200B;

What tests would you use to compare familiarization, sub-phase 1 and sub-phase 2 in these parameters?

My supervisor suggested a **two-way ANOVA with RM** for the *sprint parameters and the post-exercise parameters*, with a **Tukey's multiple comparison** to then see if there are significant differences between sub-phase 1 and sub-phase 2. Due to a few missing data, the software (GraphPad) suggested to use a  mixed-effects model (restricted maximum likelihood (REML) to take care of the missing data.

For anthropometric data, a **one-way ANOVA with RM** and **Tukey's multiple comparison** was suggested.

&#x200B;

Do you agree with these choice? I think the idea is correct, but I would use the non-parametric versions of these 2 tests. I would use Friedman instead of the one-way ANOVA with RM, for example, but I am not quite sure what to do with the two-way ANOVA.

Any help?",statistics
mt81ju,1618729638.0,[D] Can anyone please recommend an algorithm that can solve this kind of problem?,"https://imgur.com/a/kegQPiw

Suppose you have data on bank fraud in graph/network format. Each node is a customer, and for each customer you have information corresponding to their account (e.g. var1, var2, var3). The edges represent a family relationship (e.g. brother-sister, wife-husband, parent-son, etc.). For simplicity sake, let's say that that each customer in this data set only has 1 bank account.

Case 1: Suppose you have a dataset in which nodes are either ""group A"" (fraud), ""group B"" (no fraud) or ""unknown"". You are interested in predicting whether the nodes labelled as ""unknown"" are ""fraud"" or ""no fraud"". What kind of algorithms can be used to predict this?

Case 2: Suppose you now have point-in-time data. You have a graph from an earlier time point (T-0) and a later time point (T-1). Many things could have changed between these two time points. For example, new edges might exist between previously unconnected nodes (e.g. two customers are now married), existing edges between connected nodes might no longer be present (e.g. two married customers are now divorced), nodes that existed earlier might no longer be around (e.g. they decided to leave the bank and switch to another bank), or new nodes might have appeared (e.g. new customers) and might form connections with other nodes. You have information for each of these nodes (e.g. var1, var2, var3) from time T-0 and time T-1. You are now interested in predicting which customers with the ""unknown"" label are ""fraud"" or ""no fraud"". In this situation, what kind of algorithms can you use?

In general, are their common algorithms that can be used for ""node classification""?

Thanks",statistics
mt7mxi,1618727516.0,[Question] University Statistical Genomics Courses?,"Can anyone recommend any free/open-source courses offered by universities on statistical genomics? I don't really like platforms such as edX because I do not feel that the resources are deep enough and everything is like an introduction. I was looking for something hosted/presented more like these courses:

[https://stanford-cs221.github.io/spring2021/](https://stanford-cs221.github.io/spring2021/)

[CS229: Machine Learning (stanford.edu)](http://cs229.stanford.edu/)

[CS230 Deep Learning (stanford.edu)](https://cs230.stanford.edu/)",statistics
mt1q3z,1618702583.0,[D] can someone please help me find a reference/source that explains this?,"""Neural networks are weird in the sense that they both are and are not impacted by the curse of dimensionality dependent on the architecture, activations, depth etc. So to reiterate the curse of dimensionality is the problem that a huge amount of points are necessary in high dimensions to cover an input space. One way to interpret deep neural networks is to think of all layers expect the very last layer as doing a complicated projection of a high dimensional manifold into a lower dimensional manifold, where then the last layer classifies on top of. ""

""The next part: So for example in a convolutional network for classification where the last layer is a softmax layer, we can interpret the architecture as doing a non-linear projection onto a smaller dimension and then doing a multinomial logistic regression (the softmax layer) on that projection. So in a sense the compressed representation of our data allows us to circumvent the curse of dimensionality. Again this is one interpretation, in reality the curse of dimensionality does in fact impact neural networks, but not at the same level as the models outlined above.""

Source: https://stats.stackexchange.com/questions/186184/does-dimensionality-curse-effect-some-models-more-than-others

Cab anyone recommend any sources/papers/articles where they explain how/why:

""All layers expect the very last layer as doing a complicated projection of a high dimensional manifold into a lower dimensional manifold, where then the last layer classifies on top of. ""

In all the readings I have done, I have never read any interpretations that describe how when data passes through layers, a natural projection from high dimension to low dimension is taking place.

Thanks",statistics
mt1bj9,1618701128.0,[Q] Has anyone pivoted from statistics / DS to finance?,"I have a statistics education and when I started earning money, I researched the best way to invest. Today, I max out my tax advantaged accounts and put a little bit of each paycheck into index funds.

As I do this, I’ve learned that I really enjoy investing. I think the stock market is one of the most interesting data sets there is. This led me to consider taking up financial advising or investment banking as a side hustle, or even a future career.

Has anyone done this? I fear that without an education in accounting or a relevant cert (like CFA), the transition would be hard to muster. Also, I hear the hours are some of the most brutal in the corporate world. Then again, hard to compare a venture capitalist with a fiduciary who has a handful of clients.",statistics
mt18cp,1618700841.0,[D] Could you recommend some standard books in statistics that use R?,"I found some standard text books in statitics, and some in R, both at introductory and theoretical/advanced levels.

I was wondering if you could recommend some standard books in statistics that uses R at introductory, and comphrehensive or advanced levels?",statistics
msyzcd,1618693097.0,"[D] Is this the equivalent of the ""what came first, the chicken or the egg"" in statistics?","https://en.wikipedia.org/wiki/Probably_approximately_correct_learning

I am learning about this concept in statistical learning called ""Probably Approximately Correct"" (PAC) - although the wording of this can seem complicated and technical, (if I understand correctly) the essence of PAC is to show that if a ""target concept"" (e.g. the set of all possible input points corresponding to a certain output), then the error of a machine learning algorithm can be probabilistically bounded with a certain range. I think all this is intended to show, that a machine learning algorithm is useful for making predictions, instead of basing your predictors off which color socks your neighbor is wearing.

1) PAC framework was developed in 1984 - yet prior to this, many statistical models were being used for making predictions (e.g. regression models). Once PAC was developed, did researchers have to examine all statistical models they were using prior to this, and confirm if these models were compatible with PAC framework?

2) Now, the same question for modern models. When newer machine learning models are developed (e.g. LSTM models, developed long after PAC framework was established) - are these new algorithms tested to make sure they are compatible with PAC framework?

3) Can someone please confirm if my understanding of PAC framework is correct? (source: https://stats.stackexchange.com/questions/142906/what-does-pac-learning-theory-mean , https://machinelearningmastery.com/what-is-a-hypothesis-in-machine-learning/ )  A ""hypothesis"" (in the context of PAC) seems to be a general term for a machine learning algorithm, the ""hypothesis space"" is the space of all possible such algorithms (e.g. a linear regression model with specific beta parameters is a individual hypothesis and all possible linear regression models are the hypothesis space), ""D"" is the distribution of the data, and a ""Concept Class"" - but Im still confused about the differences between target concept and concept class. Can someone please clarify this?",statistics
msyj9o,1618691635.0,[D] Differences between Univariate and Multivariate models,"Hello. Suppose you have an outcome, Y, and covariates i, j, and k. And you create four models: Y=β\_1i, Y=β\_2j, Y=β\_3k, and Y=β\_1i+β\_2j+β\_3k. If β\_1 is not significantly different from 0 in the univariate model, can it be significantly different from zero in the multivariate model? My experience is that variables often become non-significant when going from univariate to multivariate, but I don't think ive seen the opposite.

Except It did occur in a Cox regression model I found in an article.PMID: 31838169, figure 3a, Histology. [https://imgur.com/poXsumz](https://imgur.com/poXsumz)  Is this more common than I thought, rare and not often seen, or should it be impossible and I should suspect there is something wrong with the reported model?

Thanks",statistics
o71xtm,1624544708.0,Do any of you actually regret not doing a PhD in Statistics/Data Science,"
Hello, my goals are to work as a data scientist in industry. At this point I’m just kind of unsure if I should pursue a PhD or not. My goals are to just be a data scientist in the industry. For any of you in industry, and I’m sure this is also based on the specific industry type, do you guys regret not getting a PhD in statistics for your job? My plan is to get an MS in stats and work, but for any of you, did you regret not finishing through after your MS? If you do have regrets what are they, and how had the MS limited you if any?",datascience
o71l8m,1624543613.0,"So, uh -- What do you guys actually do?","I'm studying data science and machine learning while working as a data analyst for a digital consulting agency. I have the flexibility to experiment with what I'm learning at work -- but machine learning is just a hammer for which I can never find a nail.

I understand how machine learning is used for voice and image analysis, but I keep seeing data scientists say they ""create predictive models to find business solutions.""

But what does that mean?

I'd love to apply what I'm learning at work, but I can't never see a way that creating a predictive machine learning model would help me better solve a business problem.

What kind of projects are you guys actually doing at work?",datascience
o70jsy,1624540184.0,Are there publications you can write for other than TDS?,Just curious if TowardsDataScience is really the only publication you can write for nowadays.,datascience
o70cyx,1624539535.0,How to perform churn analysis for a business that does not have recurring revenue and is not subscription-based?,,datascience
o702qa,1624538463.0,Very interesting data scientist job vs. highly paid data analyst job,"I'm a software engineer that is trying to go into data science.  I received two job offers.





One is for a data scientist position doing work that I find very interesting, such as working with cloud technologies, deploying ML models, and working closely with data engineers on the data pipelines.




The other offer is for a data scientist job that pays a lot more than the other company's salary, but where the job responsibilities align more with being a data analyst.




I'm more interested in the software engineering side of data science, so I'm wondering if it would hurt to take the higher paying offer?  Since that company is well known, I think I could still take that job and always internally transfer into a data or ML engineering role in the future.",datascience
o6ycn7,1624531347.0,Is there such a book about data science that covers the numericals of algorithms?,"https://www.youtube.com/watch?v=t6wFp0CGupg

https://www.youtube.com/watch?v=2A8AGfxs0D8

For eg-: Like the one in above video.

Is there a book or some notes made by some teachers available in the internet or even paid udemy courses, that give examples of these solved numericals like in video? I am asking this because these videos by Indian guys are very inaccurate and I am not sure if I have learnt correctly or not.",datascience
o6w79i,1624520930.0,How to learn to analyze business data - LOGIC/THINKING not only tools!,"In the field of data analytics, there's a lot of learning materials out there covering the tools, libraries, or visualization techniques. What I couldn't find is a guide on the logic or thinking process.

&#x200B;

For example if I have sales data, what to look at? What business questions to ask? How to make compelling business recommendation from my findings etc.

&#x200B;

Do you know of any online resource/course/book/video on that matter?",datascience
o6qxgo,1624499047.0,Similarity between datasets,"Suppose you have two datasets: each dataset contains continuous variables (x, y, z) and 1000 rows. Let's say the first dataset is from a hospital in California and the second dataset is from a hospital in New York.

Are there any common ways to measure how ""similar"" the two datasets are?

Another application:

If you train an ml algorithm on a dataset....and then the you get new data. Then, if the new data is really similar to the old data, you can be more confident about the performance of the ml algorithm on the new data.

Thanks",datascience
o6p823,1624492860.0,Object detection from scratch resouces,"For fun I'm playing around with image classification, segmentation and now detection.

I've done some basic object detection projects with transfer learning using Mask R-CNN and YOLO which worked great. However the point of this is to learn how they work and write my own terrible versions.

I understand the basics behind object detection, cutting up the image into patches and running image classification on the patches, I was just looking for a resource that walks through this without using transfer learning or pre-built networks.

Like I said I expect this to be terrible I just want to try it out for myself.",datascience
o6os3s,1624491299.0,Are data science interviews still a work in progress??,"I was recently on the job hunt and did not encounter a single interview that was alike. For a bit I thought I was unprepared but then I realized some of these teams weren't sure what they wanted to hire. What do y'all think?? Are data science interviews still in the works mostly? Or do you know of a good process that will get adopted throughout the industry??

I made a video about my experience taking and creating an interview..... Didn't go well

https://youtu.be/XsgQPC7PGco",datascience
o6od47,1624489862.0,"Are BI, and Data analyst roles so similar that one could use the ""same"" resume for both positions?","I'm asking because I am six months away from going back into the job market after graduating. I am starting my search now to get feedback and hone my resume. I will be targeting both BI and Data analyst roles. I was wondering for those in the field. I could not notice a vast difference between BI and Data Analyst roles to warrant creating a separate resume for both.

Is this valid or is there something I am missing?",datascience
o6nmo6,1624487402.0,Id like to draw and create better visualizations.,"I'm working as an intern data analyst till March of 2022 at a big tech company and I want to learn how to draw better and more unique visualizations of data.

I'm currently using python in Jupyter, pretty much standard from what I've seen here, but I know that there is Rstudio available in my company, what is better and how would you go about it?

This is just a little context, maybe it helps. I've worked as an intern full stack dev (6 months) before using java and doing some docker + database stuff. From then I worked as a part-time backed developer untill I got this job as a data analyst intern.

I'm still defining if I like it more than dev to make a career out of it, but until about a month ago was pretty fun and challenging to play with data and try to extract value out of it. Now I'm a little bogged down with stakeholder management, meetings and having impostor syndrome feeling like q model fitting monkey.

So to address that I wanted to try and do something different, like more ad-hoc visualizations or even drawings using plotting. I feel like the math is there for it and I know a few libraries I haven't been able to test during my free time. So I figured that the people who share things that inspire me (YOU), might want to share a few tips, recommendations, dos and Don'ts.

(Sorry if the English is weird. Stll learning, corrections are appreciated)",datascience
o6lqvi,1624481569.0,New sub for honest feedback on your data analysis (r/DestroyMyAnalysis),"r/DestroyMyAnalysis was created to help data scientists (and students) find pitfalls in their analyses.

I've found it extremely helpful to have someone else look over my work and provide honest feedback for my sources, methods, conclusions, etc., so I thought it might be a good idea to create a sub just for that purpose.

Anyone can post a link to Colab, Binder, Github, blog, etc. to get ideas for improvement, find pitfalls, and anything else to help you improve and make your future analyses more robust.",datascience
o6lado,1624480124.0,Thoughts on Approaching Multiple Time Series,"I have the order dates of a 100 different products going back more than a decade and want to do forecasting to the best of my ability. The data is clean and consistent, though some items aren't ordered very often.

The two approaches I've thought of is

1. To do a monthly aggregate of how much product was ordered across all items and do a basic SARIMA with 1s for all values and a time lag of 12 months.
2. To use the prophet library to predict the future, though these results have been poor due to the items having a greater volatility and growth as of late due to covid, product output, and other outside factors.

Avenues I'm considering:

1. Hyperparameter tuning for SARIMA.
2. Using the monthly aggregate of all items to help forecast each individual item, as building SARIMA models for each individual item may not be as useful due to a lack of data, as some items may not be ordered at all some months.
3. Read more of the prophet documentation to try to adjust for the extreme volatility in my data.
4. Try messing around with ML time series forecasting libraries and see what can be done.

Thoughts? Anything else I should try? Links or topics I should look into for finding the best solution?",datascience
o6l9jz,1624480053.0,Question on control/variant testing,"Non-data scientist struggling to find the “right” way to set up populations for control vs variant testing, and am wondering if my methodology holds any ground.

We’re targeting our best customers with a campaign and want to see how much incremental revenue it generates.

To find the control and variant populations I’m simply ranking the customers by their recency, AOV, order count and other order economics to get to a weighted rank. I’m doing this in SQL, which is the primary language I know.

Then once I have every customer assigned a unique rank I choose only the odd numbered ranks and keep the even ranked customers as the control that is excluded from the campaign.

My thought is that this would provide an even distribution of our best customers in the control and variant groups.

When I plot the distributions for the different kpis the control and variant do look aligned but am not sure how confident I can be in the results.

Does this methodology for selecting control/variant groups seem ok?",datascience
o6hij9,1624468874.0,What's your experience as the first data scientist in the company?,,datascience
o6gvn2,1624467193.0,"What do you do when you are stuck on a problem? I'm up against a deadline, and freezing up.",I have a massive dataset and feel like I can't organize it properly to get any insight..much less answer the questions posed by the stakeholders. Any advice out there??,datascience
o6grje,1624466936.0,"Can anyone list a successful project that was actually DS/ML, and fully delivered in their company?","Having one of those days where it feels like every project we attempt fails or fizzles out. Seems to be that 90% of the time there is a lower tech solution/analysis that would deliver most of the value that hasn’t been explored yet.

Looking online, much content is toy box example of projects/algorithms, kind of showing how they work. But not much content is around about things that have actually been production used or provided REAL value.

I sometimes feel as though the interesting ML/DS things people think of when you say ML or DS have already been done and an out of the box solution would suffice. Bespoke solutions are not reached again because the low hanging fruit hasn’t been explored, or the data doesn’t exist.

Plus where do people even go to learn about developing the useful stuff? There’s the same content in 1000 different forms explaining the basic stuff we all know, but where to go from there?

I feel as though this has turned into a bit of a rant (sorry about that). I suppose I’m just looking for confirmation that DS is still relevant and useful outside of the walls of Amazon/google etc.",datascience
o6gclz,1624465742.0,How much log loss is good enough?,"Basically the title.

I'm working on a project using a Random Forest Classifier, and it performs pretty well on the classification task (precision and recall). However, we will also use the probabilities of being 0 or 1 in some situations. In order to assess the performance of the model in a context of probabilities, I performed a log loss evaluation, getting a value of around 0.5. How do I know whether this is a bad or good cost? I know that the lower the better, but how much lower does this value need to be?

I've read that it depends on other parameters, like proportion/balance of 0 and 1 on the dataset. In my case, it's about 10% of 1. Is there a proportion between the log loss and any other parameter that I can detect whether this is a good or bad performance (for example, an ideal ratio of log_loss/proportion of 1)?",datascience
o6dzyp,1624458751.0,Python Developer Role Disguised as Data Science,"I'm a CS student and i've recently been interviewing for several Data Science Internships, one of the companies was a walking red flag. Keep in mind that this wasn't a small startup, this was a huge Company (> 10k employees).

It started when I applied for the position online, they responded after over a month, once I already had several offers. What was interesting was that they were the only company that called me as their first response and did not send a mail, which was a surprise but not a deal breaker to me. They wanted to make a short Teams interview, which I accepted since I wanted to have the Interview Training, but would only consider them if they would be a really great fit.

So far so good, we arrange an interview for the following Monday at 1 pm in the call.

About 3 Hours after the call, they send me a Teams link via Mail, which was written pretty unprofessionally, and looked like they they hadn't put much thought in it. What I immediately notice was that the Teams Link they send me was for 11:30 am on Monday, not 1 pm like we had agreed upon, which was really strange. So I send them a mail asking when the Interview **really** is, and that I would be fine with both timeframes, but would like to know when. I get a response back about 2 hours later, saying that the other employee that would be present can't get to it at 1 pm, so they decided to move the Interview. I immediately see the red flag, they had just moved the Interview, without talking to me first, and didnt even think of telling me. I shrug it off and told them it was fine, since I was not planning on taking the job anyways.

Fast forward to Monday 11:30 am:

I join the Teams Meeting, they start out with a little small talk/chit-chat. And we proceed to the Interview. They talk a little about what they do (at max 2 minutes) and then ask me to introduce myself, which I do and then we just do a standard interview which goes great for the most part. What they really emphasized at multiple points, was that they wanted to have an Intern for ""A long time"" so they were really straight forward, asking me for how many years I will study CS (probably so they can know for how long they can get away with paying me less), and proceed to talk about how they ""Keep their Interns for a long time"".

Then one of them starts to list all the people in their branch, which was weird, since he didn't list a single Data Scientist (The role that the internship was for), which made me suspicious. Then, in the middle of the Interview I get to ask some Questions, so I ask what they will expect from the intern and what kind of task he be responsible for. When they answered I immediately thought ""Wow, that sounds alot like a Python Developer Role, not Data Science"", which made sense since they kept asking for my python skills, which as itself is not a problem since I am very comfortable with my Python knowledge, but it made me really sceptical, so I keep asking more specific Questions until im am certain of it. Since I was 100% sure that this wasn't a DS Role and I was not worried of not getting the Job, I ask ""Why did you call the Job listing Data Science when it sounds alot like a Python Developer Role?"". The answer was not what I thought, one of the Interviewers straight up told me to my face that they ""knew it was not a DS role, but decided to call it that anyway since its such a great buzzword, and they would get a lot more applicants that way"" (this is as close to a 100% quote as I can recall, so this is not exaggerated) , which really made me speechless. After that I just decided to play nice until the Interview was over, but had already decided that I was not going to take their offer, if they would make me one.

Fast Forward 2 Weeks:

After they had told me that they would get back to me by the end of the Week, they didn't, and after two weeks I receive an Email that they had decided for another applicant (that poor dude). My guess is that they smelled that I didn't want to take the job anyways and if I did, I would not stay for long since it became pretty clear that I knew they were full of shit.

&#x200B;

Has this happened to any of you? How common is it that companies try to disguise a Python Dev role as DS?",datascience
o6d52h,1624455993.0,"Maybe this question has been asked before, but how important is it to have a gitHub account with your independent (out of work) projects ?","I am in the market right-now and I see that many companies are asking for gitHub url information- I'm assuming it is so that the interviewee can provide some work that they have done on the side in ML (outside of work requirements) , so how important is that? Because I enjoy ML and data analytics as my job but after work I enjoy other activities, not necessarily doing data analytics and projects in ML. So is not having a gitHub full of ML projects something frowned upon by employers now?",datascience
o6cp1u,1624454458.0,Tidying time-series & behavioral experimental data [Question],"Hi all,

I recently came across the original [Tidy Data paper](https://www.jstatsoft.org/article/view/v059i10) (if you haven't read this, check it out- I wish I had a long time ago) and have been thinking a lot about how to best reorganize data from my experiments to make analyses and visualization easier. However, my datasets seem kind of unconventional and I haven't found great examples for how to best tidy them.

Basically, I continuously collect rodent behavioral data in sessions that span 60 trials. I collect **timestamps** of events of interest (e.g. lever press, trial start). So my data looks something like this currently (I've been playing with both Matlab structs and Python pandas.dataframes). For simplicity I shortened this example to just 3 trials.

&#x200B;

|subject|group|date|trialType|trialStart|behaviorA|
|:-|:-|:-|:-|:-|:-|
|1|0|20210601|\[0,0,1\]|\[10,40,60\]|\[8,12,42,65\]|
|2|1|20210601|\[0,0,1\]|\[10,40,60\]|\[15,22,26,48,53\]|
|3|0|20210601|\[0,0,1\]|\[10,40,60\]|\[12,42,80\]|
|1|0|20210602|\[0,0,1\]|\[10,40,60\]|\[4,22,45,63\]|
|2|1|20210602|\[0,0,1\]|\[10,40,60\]|\[30,44,68\]|
|3|0|20210602|\[0,0,1\]|\[10,40,60\]|\[12,29,43,63,68\]|

&#x200B;

Notice that the events contain arrays of multiple values, which makes it ""untidy"". Currently I have one row per subject per date (this corresponds to my raw data files). While this organization is intuitive to me, it seems to make it harder to conveniently plot and analyze the data using readily available packages.

In order to have a single value, I was thinking of reorganizing it so that each row corresponds to a time bin in every file. Instead of event timestamps, the events would be binary coded so that a 1 would be placed at the corresponding timestamp and would be 0 otherwise. It would look like:

&#x200B;

|subject|group|date|timeBin|trialStart|trialType|behaviorA|
|:-|:-|:-|:-|:-|:-|:-|
|1|0|20210601|1|0|0|0|
|1|0|20210601|2|0|0|0|
|1|0|20210601|3|1|2|0|
|1|0|20210601|4|0|0|0|
|1|0|20210601|5|0|0|1|
|1|0|20210601|6|0|0|0|

My event timestamps are sampled at 10ms resolution and I have a few hundred files so this could get huge but I guess I could downsample by rounding the timestamps.

This dataset is pretty much the ""template"" of most of my datasets but I also have more complex datasets where I am continuously tracking a variable over time (e.g. I have video recordings I can use to track position & velocity) so I think organizing things by timestamp may effectively translate to those in the long run?

An alternative would be to have one row for each trial, but this wouldn't be effective if I am also collecting a continuous variable.

I'd love any feedback & ideas about how to best organize these data! That includes coding resources and packages if you have recommendations.",datascience
o6c06f,1624452053.0,Need some help on best practices to build up a small scale solution,"Hey, I haven't been getting long, solid responses from this sub in overall, but I'm gonna try again. Hope someone can shed some pointers anyway!

So we don't have a system in place for data, and I'm tasked with setting it all up. There's a few mariadb servers that have to be piped to a centralised data store for BI. There's also data from Facebook Marketing API that I'd ideally like a pre-built connector for.

Several criteria are: No vendor lock-in if possible, low volumes of data, but needed in real-time and incrementally sync'ed. Not using cloud db's since our volumes don't justify the need for it, plus prefer to keep things local.

What's the best way to go about doing this? Some of the options I've considered:

\- use a pipeline like Stitch (but that's rather expensive for this use case) and so I've considered Airbyte but this open source software is still very immature, despite some help from the nice people over there.

\- Tried using Clickhouse replication but it doesn't work for mariadb

\- considering something hybrid with Airflow (or the newer [Prefect.io](https://Prefect.io)) to schedule and pipe data. This probably also means using some manually-coded connectors?

Data warehouse DB is not selected yet either. I'm thinking, for this use case, something simple like Clickhouse or Postgres (though this one isn't exactly an OLAP).

Preferably, I'd use pre-built solutions, since code is not my forte, but I am open to considering simple, easily debuggable code solutions.

I have many more little big questions like these so if anyone is willing to share more directly with me, I'm very happy to connect!",datascience
o694bs,1624439315.0,Common mistakes in the industry,"To everyone in the industry:

What are some of the most common or surprising data science related mistakes you've encounters at the workplace?

For example: mistaking correlation for causation; only looking at mean numbers without checking for outliers.",datascience
o68ian,1624436146.0,I wanted to create a project using the instagram follower and following lists. How do i extract list of followers and following of public accounts from Instagram?,Don't want to use any third party apps,datascience
o676fd,1624429648.0,Dealing with paperwork aspect in new project,"I recently joined a new software company. The boss wants to build a recommendations system engine for an e-commerce platform. My background is machine learning so most of the previous job, I received the requirements and implement algorithms and systems to process data. This time I was required to build up a product solution, include various paperwork like advantage features proposals, business model, use scenarios,... I have a feeling that this is not my job but a business analysis one. Is this normal for an ordinary software engineer to handle this one, if so, how can I do this effectively?",datascience
o63xss,1624416593.0,Should Proprietary Clinical ML Algorithms be Subject to External Review?,"Some [recent](https://www.fastcompany.com/90641343/epic-deterioration-index-algorithm-pandemic-concerns) [events](https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2781307) have spurred discussion around if or how clinical ML tools should be regulated. Some suggest FDA regulation, others peer review. The vendors claim to be transparent, but just with their customers.

What are yall's thoughts on the matter?",datascience
o5y960,1624398677.0,Is WGU masters in data analytics program any good (Reviewing an applicant),Long story short have a candidate for a jr DS job he has a BS in CS from a state school (Respectable one) and MS in Data Analytics from WGU. Personally idc but I know a few others on the decision team are concerned. Anyone have thoughts on WGUs program?,datascience
o5wjpv,1624393885.0,data literacy at your company,"I was wondering if some companies 'obliges' most of their employees to learn to code (basic skills) or for example dashboarding, advanced data analysis skills with excel or ... through training periods \[one week of full training and no actual work...\].

The purpose would be to make everyone data literate. So that everyone at the company can provide the data team with +- good datasets or so that they can handle their dashboards once they are published (how to filter, refresh data, ...)

If so, please share your experience and what are the best ways to discuss that with the managers.",datascience
o5wjmn,1624393878.0,Python courses for experienced R programmer?,"I'm a mid career data scientist and have somehow managed to stick to R the past 7 years. I'm going to be looking for a new job in the next few months and would like to be able to put Python on my resume. Basically just have it down enough that I can still work if I get hired by a Python shop. I feel like once I have to use it I'll become proficient pretty quickly.

I progressed halfway through a Coursera course only to find the rest of it is using IBM Watson studio. Since this is not industry standard it seems like a waste to put energy into. Can anyone suggest some other Python for data science courses?",datascience
o5wfp2,1624393574.0,Can someone help me understand Horizontal vs Vertical Scaling?,"I've been learning about Apache Spark, and got into the topic of horizontal vs vertical scaling.

My company uses MySQL, and I've read that MySQL can only be scaled vertically in terms of ""Master"", and can be scaled horizontally in terms of ""Slaves"".

My question on two different topics are:

Is the idea of distributed computing with Apache Spark similar or the same as the Master Slave relationship? It sounds like to me, both are just using multiple servers for different purposes.

What makes it so that MySQL can only be scaled vertically in terms of the ""Master""? and other databases able to be scaled horizontally?",datascience
o5vuf1,1624392006.0,What file format do you like to save your Python/Numpy/Pandas data?,"I'm just wondering what people like to use for saving data. Typical conventions I've heard of are:

* pickle
* python shelve
* csv
* sqlite3 / SQL -- Why not throw it into a database?
* hdf5
* json
* Numpy's npz format.


Just wondering, for fast reading & writing what options do you like to use?",datascience
o5vbsg,1624390632.0,Game development - how to structure data?,"Hi! I'm a game developer, and I have a question about how to best structure my data. As a former hammer (accountant), everything always looks like a nail (spreadsheet) to me. I'm wondering if there's a better way.

Here are a few actual examples of the desired output (in Lua format). Apologies if the formatting isn't right - I did my best. These are a few lines describing maps in an RPG:

    M.map_info[hash(""forest_tree_h1"")] = {script_require = ""maps.map_codes.forest_tree_h1"", display_name=[[]], biome = ""forest"", max_level=10, min_level=1, store_level_cap=false, player_tint_add = vmath.vector4(0,0,0,0), player_tint_subtract = vmath.vector4(0,0,0,0), cloud =vmath.vector4(0.15, 0.20, 0.10, 0), border = true, map_zoom = true, music = {id="""", force=false, ambient=""indoor_empty"", ambient_multiplier=1, rest_time=120}}

    M.map_info[hash(""rusty_fortress_h1"")] = {script_require = ""maps.map_codes.rusty_fortress_h1"", display_name=[[]], biome = ""rusty"", max_level=10, min_level=1, store_level_cap=false, player_tint_add = vmath.vector4(0,0,0,0), player_tint_subtract = vmath.vector4(0,0,0,0), cloud =nil, border = true, map_zoom = true, music = {id="""", force=false, ambient=""indoor_empty"", ambient_multiplier=1, rest_time=120}}

    M.map_info[hash(""rusty_huts_h1"")] = {script_require = ""maps.map_codes.rusty_huts_h1"", display_name=[[]], biome = ""rusty"", max_level=10, min_level=1, store_level_cap=false, player_tint_add = vmath.vector4(0,0,0,0), player_tint_subtract = vmath.vector4(0,0,0,0), cloud =nil, border = true, map_zoom = true, music = {id="""", force=false, ambient=""indoor_empty"", ambient_multiplier=1, rest_time=120}}

Here are a few lines from a space game about alien genetics:

    {skill_name = ""LOG-LOG-4"", skill_id = 1089, race_ids = {4,4}, category_hash = hash(""4-4-""), texture = hash(""skill_icons""), flipbook = hash(""4-4-""), description = ""add 97 crew limit"", is_mutation = false, is_variant = true, can_combine = true, show_in_skillcheck = false, texture_string = ""skill_icons"", flipbook_string = ""4-4-"", default_unlocked = false, },
    {skill_name = ""LOG-LOG-5"", skill_id = 1090, race_ids = {4,4}, category_hash = hash(""4-4-""), texture = hash(""skill_icons""), flipbook = hash(""4-4-""), description = ""remove 38 damage"", is_mutation = false, is_variant = true, can_combine = true, show_in_skillcheck = false, texture_string = ""skill_icons"", flipbook_string = ""4-4-"", default_unlocked = false, },
    {skill_name = ""POW-POW-POW-1"", skill_id = 1091, race_ids = {1,1,1}, category_hash = hash(""1-1-1-""), texture = hash(""skill_icons""), flipbook = hash(""1-1-1-""), description = ""add 21 damage"", is_mutation = false, is_variant = true, can_combine = false, show_in_skillcheck = false, texture_string = ""skill_icons"", flipbook_string = ""1-1-1-"", default_unlocked = true, },
    {skill_name = ""POW-POW-POW-2"", skill_id = 1092, race_ids = {1,1,1}, category_hash = hash(""1-1-1-""), texture = hash(""skill_icons""), flipbook = hash(""1-1-1-""), description = ""add 68 crew limit"", is_mutation = false, is_variant = true, can_combine = false, show_in_skillcheck = false, texture_string = ""skill_icons"", flipbook_string = ""1-1-1-"", default_unlocked = false, },

This ends up being sometimes hundreds of lines of data, with a lot of stuff (strings, numbers, tables in tables, etc). Since the data is live during development, I end up wanting to change it a lot, add and remove things, etc. It obviously gets unwieldy doing it right in the editor, editing hundreds of lines. Previously I’ve made Google Sheets to handle it. I love spreadsheets but even I will admit this is cumbersome:

    =""M.map_info[hash(""""""&B3&"""""")] = {script_require = """"maps.map_codes.""&B3&"""""", display_name=[[""&E3&""]], biome = """"""&C3&"""""", max_level=""&P3&"", min_level=""&Q3&"", store_level_cap=""&R3&"", player_tint_add = vmath.vector4(""&S3&"",""&T3&"",""&U3&"",""&V3&""), player_tint_subtract = vmath.vector4(""&W3&"",""&X3&"",""&Y3&"",""&Z3&""), cloud =""&M3&"", border = ""&N3&"", map_zoom = ""&O3&"", music = {id=""""""&H3&"""""", force=""&I3&"", ambient=""""""&K3&"""""", ambient_multiplier=""&L3&"", rest_time=""&J3&""}}""

Generally speaking, tables might look something like this:
{a_number = 2, a_string = ""string here"", subtable = {3}},
{a_number = 4, a_string = ""another_string"", subtable = {}},
{a_number = 8, a_string = ""yet_another_string"", subtable = {3,5,7,11,13,17,19}},

The main stumbling block ends up being the subtables, which can have none, one, or multiple values. I haven't figured out a good way to handle this in a spreadsheet. I can either begin entering comma-delineated values manually (this is bad because it’s manual, makes it hard to keep track of the data, and eventually begins resembling the reason I implemented the spreadsheet in the first place), or I have x number of columns for each individual data point in the subtable (this is bad because it is cumbersome to set up and implies a maximum number of entries in a subtable).

Does this make sense? Is there a better way to handle this? Some kind of tool (free is great, but I'll pay to make my life easier)?

Thank you in advance, and please do let me know if anything needs to be clarified.",datascience
o5s9oc,1624382386.0,Best way to summarize text?,"I am looking to create a website, including a function similar to [TLDRthis](https://tldrthis.com). What would be the best way to approach the summarization part of development?
It would mainly be used for longer messages, news or articles.",datascience
o5rrl7,1624381061.0,"The Data ""Cleaning"" vs ""Analysis"" Conversation","Seeing posts/threads on this topic and I have a hot take: The cleaning is the more interesting of the two.

So many posts on this topic and all seem to have an underlying premise that data cleaning sucks and that the modeling is what's interesting/fun. But the cleaning takes up so much time precisely because it's very challenging, ambiguous. It's the part of the process I think will be last to be automated (if it ever is). I get that modeling can provide deep insights and/or value and so are certainly rewarding, but I *really* think many of our conversations on this topic miss the point. Mapping the real world to noisy data is an inherently ambiguous task. Best to embrace that; If it were otherwise there'd be a lot less demand for data professionals in the first place.",datascience
o5qiab,1624377693.0,How to pipe data efficiently?,"I have a mariadb that I need to pipe data from, and into a clickhouse database. It appears that clickhouse does not have mariadb replication available - only mysql.

What does it take to do this in a budget friendly way? (no vendor lock-ins or proprietary software licenses as much as possible)

It has to have automated, scheduled replication (using CDC/bin log).

Alternatively, can you suggest an easy to manage olap dwh other than clickhouse?",datascience
o5qhbd,1624377626.0,What is the difference between the coding skillset of a data scientist and that of a SWE?,"I honestly think that the line of difference in coding skillsets is blurred. For instance, are you supposed to be grinding leetcode to become a data scientist or is that only for SWEs?",datascience
o5pizc,1624375051.0,For those living in Japan/for those who would know: What is the state of the data science field in Japan like? I heard there is a huge demand for data scientists there.,"Hello guys,

I saw from [this post (two years old)](https://www.reddit.com/r/datascience/comments/94pf2u/data_scienceanalytics_in_japan/) that robotics, NLP, and AR/VR were quite big in Japan.  I was wondering if that is still the case?  What other additional data science/AI fields are picking up over there?

Additionally, I read that there ""aren't many good formal educational opportunities to learn data science. "" Is that still true?

Lastly, would people in Japan be interested in data science presentations by speakers from Canada and/or the states?

Thank you for your time!",datascience
o5pfv7,1624374811.0,Can someone explain use-cases for Apache Spark?,"So I vaguely understand what Spark does at a high level.

Right now, I'm working as a data analyst. All I do is write SQL queries, conduct exploratory python analysis, build tools, etc.

I don't really do heavy analysis, ML, etc.

If my company transitioned to Spark, what would be the impact for me? I would have faster processing times for my SQL and Python Scripts? Access to real time data, rather than waiting on ETLs?",datascience
o5ohhi,1624372278.0,Powerpoint graphics visualisations tips?,"Are there any recommended tools/templates for presenting my data neatly in my presentation slides?

I can produce neat Python and R graphs and plots and paste them on my slides, however, I have seen many presentations by companies where they use nice and fancy layouts for graphs and also other graphics and icons. I would like to ask the fellow data scientists in this sub how they produce elegant designs and how much time and effort it takes from them.

I am working in research, so presentations are not as important as the methods and the results for me. Nevertheless, generating nicer presentations would be a great skill to acquire.",datascience
o5octp,1624371923.0,What should I expect for the first week or so at a DS consulting firm?,"I am starting in a new role as data scientist at a fully remote consulting company next week. This will be my first full time position as a data scientist (previously worked as an independent contractor doing DS work for a couple of different startups after my PhD).


Does anyone have any tips for starting out in a role like this/anything you wish you had known before starting?",datascience
o5o7ec,1624371488.0,California Consumer Privacy Act - Interview Request Graduate School,"Hello, I am writing a paper on  California Consumer Privacy Act  or more specifically  TITLE 1.81.5. California Consumer Privacy Act of 2018 - 1798.110. I need to interview someone in the workplace that has experience on this act/statute? How this statute has impacted your work, etc. Let me know if you're interested for a 30 minute zoom/skype interview on this topic. I can send questions beforehand. TIA.",datascience
o5lbvu,1624362841.0,Retrieve Similar Images,"I am trying to build a similar image retrieval system where given an image, the system is able to show top 'k' most similar images to it. For this particular example, I am using the [DeepFashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) dataset where given an image containing say a shirt, you show top 5 clothes most similar to a shirt. A subset of this has 289,222 diverse clothes images in it. Each image is of shape: (300, 300, 3).

The approach I have includes:

1. Train an autoencoder
2. Feed each image in the dataset through the encoder to get a reduced n-dimensional latent space representation. For example, it can be 100-d latent space representation
3. Create a table of shape m x (n + 2) where 'm' is the number of images and each image is compressed to n-dimensions. One of the column is the image name and the other column is a path to where the image is stored on your local system
4. Given a new image, you feed it through the encoder to get the n-dimensional latent space representation
5. Use something like cosine similarity, etc to compare the n-d latent space for new image with the table m x (n + 2) obtained in step 3 to find/retrieve top k closest clothes

How do I create the table mentioned in step 3?

I am planning on using TensorFlow 2.5 with Python 3.8 and the code for getting an image generator is as follows:

    image_generator = ImageDataGenerator(
        rescale = 1./255, rotation_range = 135)

    train_data_gen = image_generator.flow_from_directory(
        directory = train_dir, batch_size = batch_size,
        shuffle = False, target_size = (IMG_HEIGHT, IMG_WIDTH),
        class_mode = 'sparse'

How can get image name and path to image to create the m x (n + 2) table in step 3?

Also, is there any other better way that I am missing out on?

Thanks!",datascience
o5kyx8,1624361645.0,40k time series,"I have 40k time series from roughly the same distribution (daily product sales over time) and I need to forecast how each will behave.

How would you approach this? Retrain a really basic model 40k times? Or have a huge model that is trained once with all the data?

How fast would the prediction work? I mean if it takes 10 seconds for each of the time series, 400k seconds is... a few days :(",datascience
o5i8ws,1624351021.0,Books/blogs suggestions for feature engineering," I am working on a data science project in the banking domain. It would be helpful if anybody suggests books/blogs for feature engineering for the same.

Thank you in advance",datascience
o5d59y,1624332251.0,What made you feel like data science was right for you?,,datascience
o57qq3,1624315631.0,Mentorship?,"I am a current college senior with several internships and research fellowships under my belt. I am currently working for the summer for a large insurance company in my area as a data science intern, but we have no practicing data scientists in my organization. I am looking for someone who can serve as a mentor to me during the end of my education and into my career. Does anyone know of any US groups or resources that connect professionals who are willing to mentor to mentees. I know just enough to know that I don’t know a lot, but I just lost my mentor to an international job. Thanks for reading!",datascience
o546nv,1624306044.0,Given a hopelessly awful data project. Made no progress in 3 months. Is it time to give up?,"I've been working on an incredibly simple yet absurd and stupid data project for 3 months with my 30 minutes or so of free time I have per week outside of my current business analyst duties. We use this program called Anaplan which has a power bi API to get data... But the API of course is garbage and doesn't work if your organization uses single sign-on... Which basically every single organization does, so the API is therefore useless and you have to download massive text or CSV files with all the data that you want and important manually into power bi...



But here's the real issue with the data. It has a stage or process step column that duplicates every single primary key five times, to capture data about each step in the approval process. So you have five different rows for each and every single primary key where the approval date or the date that it moved into that specific stage is located.... Meaning that if you try and pivot the columns so that each stage is its own column, now you have literally five different columns where dates are not all in the same row neatly like they would be in Excel. I have tried to figure out how to get them all in the same row in power query or power bi. But it's hopeless. It's like there's no way to do it. It's senselessly stupid.


I'm expected to be some sort of data scientist even though I'm just a regular business analyst with no data science education, training, working on this absurdly stupid dashboard that I have to manually pull the data for instead of using the API that they worked on to develop that doesn't work because it's single sign-on",datascience
o518jf,1624298401.0,I'm looking for a simple tool that i can color 100 dots/symbols that represent 100 people.,"I'm not a data scientist so sorry if this is inappropriate. I want to have 100 symbols(small circles?) to visualize demographics. I can't find such charts in Excel or other simple chart tools. What's the easiest way i can achieve this?

And if this is inappropriate here, which sub should i ask for it?",datascience
o505c1,1624295558.0,Do you respond to cold emails offering jobs? How was your experience?,"For example, here is the subject line in an email (to my personal address) that I recently received.

> $222K - $276K Cash/Year + 10-20k public shares -- REMOTE Principal Machine Learning Engineer

Goes on to explain that the shares are worth ~$200K.

*Then* it starts telling me about the actual role. Explaining that they just raised all this money and blah blah blah. I'm not currently looking to change jobs, but for those of you who've responded to similar emails, how'd it go? Would you say that you had a positive experience?

**Edit:** I am surprised at the number of you saying that you respond at all. I almost uniformly ignore them.",datascience
o4z4pm,1624292938.0,Using Python Classes to Streamline Data Modelling/Cleaning,"I work as a Data Analyst and I often have downtime between assignments, so I'm trying to practice OOP and make my work more efficient. Does anyone have success creating a library of Python classes to then call methods on Pandas DF instead of writing out the same lines of code? I'm trying to figure it out, but haven't yet. Below is a simple Class for string cleaning, although it isn't finished yet.

    class PhoneNumbers:
    """"""
    This class sanitizes phone numbers and appends any digits beyond 10 to a separate column
    """"""
    def __init__(self, pandas_obj):
        self._obj = pandas_obj

    def sanitizephonenumbers(obj):
        obj.replace(r'[^0-9]+','')

This is the code I'm trying to replace

    # sanitizing phone numbers
    df['phone'].replace(to_replace='[^0-9]+', value='', inplace=True ,regex=True)

    # adding extensions to seperate column pt. 1
    df['phone_main'] = df['phone'].str[0:10]

    # adding extensions to seperate column pt. 2
    df['phone_ext'] = df['phone'].str[11:]

    # removing original `phone` column
    df = df.drop(['phone'], axis=1)

If anyone could point me to a resource, help me with my code, or show the code that you used for this task, it would be much appreciated.",datascience
o4yq3l,1624291869.0,Graph Databases for Data Science,"Neo4j just raised a huge $325M Series F. In this [article](https://www.wfmz.com/news/pr_newswire/pr_newswire_technology/neo4j-announces-325-million-series-f-investment-the-largest-in-database-history/article_50b00fb1-ac7c-5008-ba98-4594735e0103.html) covering the announcement, there is a very striking quote:


>According to Gartner, ""By 2025, graph technologies will be used in 80% of data and analytics innovations, up from 10% in 2021, facilitating rapid decision making across the enterprise.""

What are your experiences with graph databases? Do you also see this trend?

We're currently using it as a PoC to combine POI with population data. You can find it on our [GitHub](https://github.com/kuwala-io/kuwala).",datascience
o4xsri,1624289476.0,Is there any difference in operational definitions between predicting vs. forecasting?,"Is one a subset of another other? Or are they fundamentally different? I have heard forecasting is different than predicting primarily due to forecasting having a time component, but I am not sure if this is true.",datascience
o4wu05,1624287008.0,No Idea How to Train Using a Custom COCO Format Dataset?,"First off, I'm really, *really* new to (practical data science). I've taken a course in ML before, but this is my first time doing any DL, and I don't even remember half of what I did in that course.

In any case, I'm trying to t**rain a model on the pklot dataset**, obtained from [https://public.roboflow.com/object-detection/pklot](https://public.roboflow.com/object-detection/pklot). The problem is, I have no idea how to train the model on a custom dataset. I wrote this code, modified slightly from [https://towardsdatascience.com/mask-rcnn-implementation-on-a-custom-dataset-fd9a878123d4](https://towardsdatascience.com/mask-rcnn-implementation-on-a-custom-dataset-fd9a878123d4). I uploaded it as a notepad, trial1.txt:

&#x200B;

\[trial1.txt\]([https://github.com/matterport/Mask\_RCNN/files/6687411/trial1.txt](https://github.com/matterport/Mask_RCNN/files/6687411/trial1.txt))

&#x200B;

&#x200B;

I also tried (emphasis on tried) to modify the actual [coco.py](https://coco.py) file, thinking that would make it easier. It's uploaded as trial2.txt:

&#x200B;

\[trial2.txt\]([https://github.com/matterport/Mask\_RCNN/files/6687429/trial2.txt](https://github.com/matterport/Mask_RCNN/files/6687429/trial2.txt))

&#x200B;

Any help is appreciated, thank you! I don't even know what I'm looking at half the time, haha. Note that both obviously didn't work :/",datascience
o4w3v5,1624284995.0,Are statistical models theoretically designed to make predictions about individuals?,"Are statistical models in theory able to make predictions about individuals? Suppose you have an individual with observed covariate information (x = a, y = b, z = c) : in theory, can a regression model (trained well on some data) predict the expected value of this individual's response variable?

I heard today that statistical models are not designed to make predictions about individuals. They are only designed to predict the average behavior of a large group of individuals - and in theory, should not be used to make predictions about individuals.

Is this correct? Does this mean that any time statistical models are used to make individual predictions, this is going against the intended use of statistical models?

If I understand correctly: this means that when a statistical model makes a prediction about an individual with observed covariate information (x = a, y = b, z = c) - it's making a prediction for the behavior of ALL individuals in the universe with observed covariate information (x = a, y = b, z = c) . Is this correct? Does this mean by definition, the idea of  making predictions for individuals is a fallacy?


Thanks",datascience
o4vqom,1624283936.0,Sensitive Data,"Hello,

I'm working on a project with a client that has sensitive data. He would like me to do the analysis on the data without it being downloaded to my computer. The data needs to stay private. Is there any software that you would recommend to us that would make this done nicely? I'm planning to mainly use Python and R for this project.",datascience
o4v2f5,1624281850.0,Linux for data science,"Hi. Some data science job ads, mostly of data engineering type want ""at least basic knowledge of linux"" or ""user knowledge of linux"". A while ago I read a post somewhere on reddit describing what that could be but now I can't find it.

Looking at https://linuxjourney.com, the most recommended linux tutorial on reddit, will I be fine after completing the ""Grasshopper"" level, or is it more like that I should finish the whole course and then I have basic knowledge since I have 0 experience? Thanks for everyone's opinion and personal experience.",datascience
o4udw3,1624279874.0,Help Scraping Web Map Data?,"Hi all!

I'm hoping you can help me scrape data off of this web map: [https://fortress.maptive.com/ver4/66ac434516a4ac2808f0c63f1469ac50](https://fortress.maptive.com/ver4/66ac434516a4ac2808f0c63f1469ac50)

I haven't gotten too far, but it looks like the data are loaded by POST requests and come back as JSON. I think a local web server might be needed to do this, and it's a little above my paygrade. If anyone could point me in the direction of some resources, or is able to say ""Oh this will take two minutes, do this!"" I'll be so grateful.

Thanks so much!",datascience
o4tjvs,1624277138.0,Digitizing Printed Archives of Data Tables,"Does anyone have advice or ideas on how to digitize several hundred pages of printed tables of data (engineering measurements)?

Table headers are a mix of English, French, and German. Data is mostly measurement data (imperial measures) and fractions, in a courier-style font of the typewriter era.

I know I have to OCR all this but I can’t find a tool well suited to tables of data. Let alone engineering notations.

What’s an efficient way to scan all this? Kinos or OfficeMax perhaps? But then how do I get this into something like Excel?

Am I really going to have to hand key all this? It could take me months if I can stay sane long enough.

Any advice welcome.",datascience
o4s4o4,1624271370.0,how to filter data fast,"hello, I have a data science/machine learning question: I have raw data, how can I filter it? problem is: there might be irrelevant data, duplicate values (i am working on images now), or any other edge case, so how can I detect outliers and irrelevant images?",datascience
o4mv0k,1624249102.0,Python? R? Nah. Here’s a TypeScript KMeans implementation!,"Worked on this a while ago for a few different projects, basically just a free open-source typescript version of KMeans. It may be of use to you!

[https://github.com/GoldinGuy/K-Means-TS](https://github.com/GoldinGuy/K-Means-TS)

If you appreciate it, feel free to star the project! If you don’t, I guess keep scrolling lol.",datascience
o4jkni,1624237633.0,Designing a seminar for undergrads,"Greetings!

I am working on my PHD. I have the opportunity of doing a seminar and wanted to introduce the fundamentals of Python for ML.

The situation is, that I have no experience developing course content for bachelor students.  I have been guest lecturer for [M.Sc](https://M.Sc). but rather on applied modelling.

I received most of my education via ""on job"" trainings (such as bootcams, one-on-one, trainings paid by the project, or by jumping in projects)
I have the Idea to  \*ejem\* let me be inspired from the famous udemy Tutorials, but I am unsure if the content can be fit for engineering undergrads.  Anyone has any other suggestions?

I will do this as volunteer and will (nor want to ) not receive any compensation. I want this on my resume.",datascience
o4fpgh,1624224980.0,What kind of education do you need for AI drug discovery?,"I have a bachelor's in chemistry and I've been learning python to try to get into data science. What I generally see on this sub is that a master's in statistics or DS is a good education for this field.

Would this also be true for AI drug discovery, or is that a different animal? Is this something that requires a PHD in, say biochemistry + programming experience or does it fit more into the purview of general data science?",datascience
o4cwry,1624216877.0,1 month of free time - Looking to utilize it well,"Hi!

I have an upcoming month where I will be completely free and want to build up a strong foundation for Data Science in the future.

I have a month free in the upcoming weeks before I start my postgraduate degree and would like to utilize it fully. I have a fairly good understanding of Logistic Regression, Decision Trees, Random Forest, SVM etc. A course which does a deep dive though of these would be amazing.

I am primarily looking to enter the field in terms of Neural networks & Deep Learning. Here, please treat me as a total novice.

I don't mind paying for courses, if they're worth it. Should I go for free courses or certified courses? Which ones would you recommend?",datascience
o4b14t,1624211400.0,Pandas query not giving the same results as the same query in SQLite,"EDIT: I'll post this in stack overflow: I forgot about the subreddit's rules.

&#x200B;

I have made a query  with the file ""Sample - Superstore.csv"" from [https://github.com/mikemooreviz/superstore](https://github.com/mikemooreviz/superstore) that will give me the count for each case that contains some type of criteria for strings, as well as a count without any of the previous criteria for the other counts.

The column with the strings that will be analyzed is ""CustomerName"".

&#x200B;

Basically: count for number of clients where the full name starts with an upper case ""A"", number of clients where the full name has a lower case ""t"", number of clients where the full name finishes with a lower case ""n"", then the number of clients where the full names don't have any of the previous criteria.

&#x200B;

This is the query in pandas:

&#x200B;

    import pandas as pd;import numpy as np;import re;

    df = pd.read_csv(""path_of_csv_file"",sep="";"");

    pd.set_option('display.max_rows', None);pd.set_option('display.max_columns', None);pd.set_option('display.width', None);pd.set_option('display.max_colwidth', None);

    df['strings_conditions'] = np.where(df['CustomerName'].str.startswith(""A""),
    				    'Starts with a capital A',
    				    np.where(df['CustomerName'].str.contains(""t""),
    					  'Has a non-capitalized t',
    					     np.where(df['CustomerName'].str.endswith(""n""),
    						      'Finishes with a non-capitalized n',
    						      'Something else')))
    df_new = df.loc[:,['strings_conditions','CustomerName']].drop_duplicates().dropna()

    df_new.groupby(['strings_conditions'])['strings_conditions'].count()

&#x200B;

which gives the following results:

&#x200B;

&#x200B;

|strings\_conditions|count|
|:-|:-|
|Finishes with a non-capitalized n|100|
|Has a non-capitalized t|288|
|Something else|341|
|Starts with a capital A|64|

&#x200B;

but the same query in SQLite:

&#x200B;

    SELECT 'Finishes with a non-capitalized n' AS strings_conditions, count(*)
    FROM
    (
    SELECT CustomerName
    FROM mag_correction
    WHERE mag_correction.CustomerName glob ""*n""
    GROUP by CustomerName
    )

    UNION ALL

    SELECT 'Has a non-capitalized t' AS strings_conditions, count(*)
    FROM
    (
    SELECT CustomerName
    FROM mag_correction
    WHERE mag_correction.CustomerName glob ""*t*""
    GROUP by CustomerName
    )

    UNION ALL

    SELECT 'Something else' AS strings_conditions, count(*)
    FROM
    (
    SELECT CustomerName
    FROM mag_correction
    WHERE mag_correction.CustomerName NOT glob ""A*""
    AND mag_correction.CustomerName NOT glob ""*t*""
    AND mag_correction.CustomerName NOT glob ""*n""
    GROUP by CustomerName
    )

    UNION ALL

    SELECT 'Starts with a capital A' AS strings_conditions, count(*)
    FROM
    (
    SELECT CustomerName
    FROM mag_correction
    WHERE mag_correction.CustomerName glob ""A*""
    GROUP by CustomerName
    )

&#x200B;

gives me:

&#x200B;

&#x200B;

|strings\_conditions|count|
|:-|:-|
|Finishes with a non-capitalized n|187|
|Has a non-capitalized t|313|
|Something else|341|
|Starts with a capital A|64|

&#x200B;

Would anybody know why this happening? Two of the count results are the same, but I'm don't know where I have gone wrong for the other two.

&#x200B;

If any clarification is needed, I'll happily provide more.

&#x200B;

EDIT: creating a view in SQLite exactly like df\_new in pandas with the following query:

    SELECT
    CASE
    WHEN CustomerName glob ""*n"" THEN ""Finishes with a non-capitalized n""
    WHEN CustomerName glob ""*t*"" THEN ""Has a non-capitalized t""
    WHEN CustomerName NOT glob ""A*""
    AND CustomerName NOT glob ""*t*""
    AND CustomerName NOT glob ""*n""
    THEN ""Something else""
    WHEN CustomerName glob ""A*"" THEN ""Starts with a capital A""
    END strings_conditions,
    CustomerName
    FROM mag_correction
    GROUP by CustomerName

Then querying it:

    SELECT df_new.strings_conditions, count(*)
    FROM df_new
    GROUP by df_new.strings_conditions

Gives once again a bunch of different results (except for two rows compared to the other SQLite query):

&#x200B;

|strings\_conditions|count|
|:-|:-|
|Finishes with a non-capitalized n|187|
|Has a non-capitalized t|234|
|Something else|341|
|Starts with a capital A|31|

&#x200B;

I'm so confused.

&#x200B;

&#x200B;",datascience
o4a0kp,1624208451.0,Prospects of becoming a Chartered Data Scientist (CDS) offered by ADaSci?,"https://www.adasci.org/cds-program

I came across this Certification where you become a chartered data scientist. Aimed for the working professional, any person who successfully passes the exam (MCQs) and has prior 2 years of work experiences is bestowed this charter.

What I wished to know is whether it is recognized enough in the industry like the Tensorflow Developer Certificate and other exams like SAS, etc and whether it offers exclusivity in terms of an increase in pay range in the Data Science Industry and what benefits could one avail holding such recognition?

Your views?",datascience
o48pik,1624204707.0,Job Hopping: do it,"I consistently see/hear people advice others - especially early in their careers - not to job hop.

""It will look bad on your resume""

""No one will want to hire you""

""No one becomes VP if they can't show they can stay at one place"".

That may apply in other careers (and honestly, I don't think it does, but whatever) - but ***especially in data science*** it's just terrible, terrible advice.

*Unless your current company is giving you 8% yearly raises and 20%+ comp increases with each promotion, you should be looking for another job within 2 years.*

EDIT: To be clear, if you're not getting 20% increases in comp you should be looking for opportunities that *will* offer you *at least* 20% increases in comp. I'm not saying you should take lateral moves just because you're not getting big enough increases. Make every move count. And you should be able to.

There are 4 core reasons why:

**Experienced Data Science talent is in incredibly high demand**

If you have 1+ years of legit data science experience, you likely won't have trouble finding companies to offer you a job. I was trying to hire a guy recently who ended up with 4 offers on the table, including one that was 50% higher than the one I gave him. That is what the world is looking like right now.

Which means that even if you're flagged as a ""job hopper"", the reality is that most companies don't have the candidate pool to get picky enough to reject you. They need people. They don't have leverage.

**The fastest way to get a higher-ranking role is to change companies**

This is just basic probability + the previous point. Your company may or may not have a higher role for you to move into (and that's assuming they would even be interested in promoting you). In contrast, there are 100s of companies out there with openings at levels higher than you. Waiting for a role to open up at your company is just a bad gamble.

When I look at people that joined my first job at the same time as I did - and mind you - people I thought were just as if not *more* capable than me - I am now 2/3 titles above them. And it's all because I was able to get bigger titles as I switched jobs.

**The ""job hopper"" red flag is self-correcting**

Say you jump jobs every 6 months 3 times in a row. You would *surely* become a ""job hopper, do not hire"" candidate after that... until you weren't.

See, if no one hires you for a new job for 2, 3, 4 years... eventually someone is going to look at your resume and say ""hey, they job hopped a bunch for a bit, but now they've been at job X for like 3 years... we should give this person a chance"".

For every hiring manager, there is a number Y of consecutive years at one job that will undo whatever previous job-hopping behavior there was prior.

**Internal compensation increases are lower than external ones 99% of the time**

Listen, if your company is giving you 10% yearly raises and 25% promotion raises - by all means, stay. That's a great company.

If you're like the rest of us, getting 2-4% raises and 10-15% comp increases when you get a promotion, and you're getting promoted every 2.5 years on average (or less), then the math just doesn't work out.

Here's some very real data from my 8 year career:

Average total comp increase (without promotion): 2%

Average total comp increase (with promotion): 12%

Average time-till-promotion: 2 years.

Average total comp increase (changing jobs): 28%

If I had stayed at one job for 8 years, my current comp would probably be somewhere around 50%-60% of what it is now - and that is in large part because I took a new job for a 25% raise after being with one company for only 6 months.

Was it risky in that some employers may look at that 6 month tenure as a problem? Probably. But it hasn't stopped at least some substantial number of companies to continue to pursue me.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Now, let's pause here. Some of you will say ""well, I applied to one job once and didn't get it, so I know that no one wants to hire me"".

I had a roommate in college that gave me great life advice disguised as terrible dating advice.

His dating advice was ""listen, the reason I get so many girls is that I go out and I hit on 30, 40 girls every night. And every one of them but one will tell me ""no"", but as long as one of them says ""yes"" that's all you need"".

So I never followed that advice for dating, but you should 100% follow it for job searching. There are 100s of jobs out there for which you're qualified. If you're currently employed and in no rush to leave your job, continuously keep applying to any job that you would consider an upgrade over your current one. Obviously make sure the effort is worth the payout - don't go doing week-long take-home assignments for jobs that suck, but pick and choose jobs that are good fits, pay well, look cool, and put some effort into applying for them.

You will get told no a *lot* at first. And then you'll get better at cleaning up your resume, better at interviewing, better at take-homes, etc. Because the only way to get better at those things is to practice.

And then eventually you'll start making it to the final rounds of some interview processes. But probably still get rejected. And then one day you'll get an offer that represents a 40% increase in comp and you'll be sitting there thinking ""wait, what the hell?"".

**TL;DR: job hop aggressively, especially if early in your career. Don't let blanket advice about how job hopping is bad deter you from doing what is going to almost surely be substantial leaps in your career and comp.**

EDIT:

If it wasn't obvious (and maybe it wasn't) there are certainly cases where this advice won't apply.

u/MichaelKamprath pointed out that this may not apply in tech, where you can climb the ladder as an individual contributor and deep expertise may be much more valuable than climbing the management ladder. And I think that is a fair assessment - however one must also recognize this is *not* the case outside of tech where the big salaries are going to come from management roles.

I think it's also fair to say that if compensation isn't a big driver for you - and the quality of the work matters much more, then this may not apply either.",datascience
o47vll,1624202209.0,Interpretation Result from Market Basket Analysis (MBA),"This is the first time I did analysis in MBA, I got the result something like:

SUPPORT    |     CONFIDENCE   |   LIFT  |   RULE

1                                  85                    1.2           A==> B

 Does this mean if A is being bought then 85% confidence C will be being purchased too?  If the Lift = 1.2 in the output, then 20% more likely B is to be purchased if A is purchased?

However, based on mathematical formula, I feel high confidence and support does not imply cause and effect. It's possible that *without A* are more confident likely to have B

This also means LIFT should be the main metrics (LIFT > 1 to indicate the intention correlation). For support and confidence, we just simply need those numbers surpass some small enough threshold. Is that corrected?

What can we say to business guys with this rule?",datascience
o47ks5,1624201313.0,Can you please come up with SOTA methods and approaches for time-series forecasting?,"Recently, quite surprisingly for me but the main focus of my work shifted to time-series forecasting.
I have read a lot in the great book by Hyndman, but I still have a feeling there are a lot of approaches and methods I haven't tried. Currently, my baseline approach is Facebook Prophet to which I add a few custom regressors and try to find the optimal values for the hyperparameters mentioned in the official documentation.
There are some special traits in the data I work with. Due to how billing is implemented, there are some significant spikes on the 28th of each month and then there might be a sudden drop in the next few days (29-31). Adding regressors helps, but not that much because those values (28-31) might be unexpectedly high or low.

I have also tried Greykite by Linkedin. This library is quite new and is supposedly better than Prophet at least according to their own blog post. I find it much more challenging and confusing to work with though, and their documentation has yet to be improved in order to be coherent and readable.
As far as I know, the fancy deep learning models are cool on paper, but because of their non-existent interpretability, high probability of overfitting, and relatively mediocre results in practice, are not used very often.


What should I read, try, pay attention to in order to maximize the prediction quality? I should note that I am a Python guy so I use everything written in/for Python. Thanks in advance!",datascience
o46g5j,1624198055.0,Will I be disappointed in my first industry job after I do a PhD?,"Hello, I’m an undergrad student whose considering a PhD in statistics. My goal is to go into industry after, ideally as a data scientist or in a research data scientist position. I would do an MS but I personally would feel as though I should have gone all the way to do a phd and have regret if I just got an MS. However, there’s a lot of people with MS who have jobs in industry. My question is, if I get a PhD, will I be disappointed by my actual job in industry? Will I feel as though I could have just gotten a job with an MS? It’s a complex question I guess because I first need to figure out if I want to do one or not, because from reading this you guys may feel I’m not entirely sold on a phd. But what I’m asking is that doing all that research in a 5 year program, will the opportunities I get in industry be not what I expected to be?

My expectations: cool ML projects, statistical analysis etc.",datascience
o468ms,1624197509.0,"Hi! I just expanded the Data Science Cheatsheet to five pages, added material on Time Series, Statistics, and A/B Testing, and landed my first full-time job","Hey all! You might remember me from the Data Science Cheatsheet I posted a few months ago ([here](https://www.reddit.com/r/datascience/comments/ljftgi/i_created_a_fourpage_data_science_cheatsheet_to/)). The support from that was incredible, and I thought I’d share an update.

Since then, I’ve gone through a dozen interviews, ranging from FANG to startups to MBB, and updated the cheatsheet with topics I’ve seen covered in actual interviews.

Improvements include:

* Added Time Series
* Added Statistics
* Added A/B Testing
* Improved Distribution Section
* Added Multi-class SVM
* Added HMM
* Miscellaneous Section
* And a bunch of other small changes scattered throughout!

These topics, along with the material covered previously, are all condensed in a convenient five-page Data Science Cheatsheet, found [here](https://github.com/aaronwangy/Data-Science-Cheatsheet).

I’ll be heading to a FANG company as a DS after graduation, and I hope this cheatsheet is helpful to those on the job hunt or just looking to brush up on machine learning concepts. Feel free to leave any suggestions and star/save the repo for reference and future updates!

Cheers, AW

Github Repo: [https://github.com/aaronwangy/Data-Science-Cheatsheet](https://github.com/aaronwangy/Data-Science-Cheatsheet)",datascience
o45iaj,1624195130.0,Scraping Twitter with Twint questions from a total newbie,"Hey guys, if anyone of you has experience with twint, I would greatly appreciate a few tipps here. I tried for like 2 days now to get this working (trial and error, youtube vids and medium articles mostly... I knew nothing about coding before and I might add that I still have no clue)

I have this written down, it describes my main problems:



### Command Ran:

import twint
import pandas

import nest\_asyncio
nest\_asyncio.apply()

c = twint.Config()
c.Search = ""EURO2020""
c.Since = ""2021-06-19""
c.Until = ""2021-06-20""
c.Custom = \['time','username','tweet','likes','link'\]   ## <-- This is the problem line
c.Store\_csv = True
c.Output = ""Test\_EM2020""

twint.run.Search(c)

### Description of Issue

I am very new to all of this, lets just say that as a disclaimer. I  want to scrape all tweets that happen during specific EURO 2020 football  games. I tried my best to get everything working, but I have no idea  what I am doing to be honest. the pandas, and asyncio line I got form a  YouTube Channel, it doesn't seem to be working if I leave them out, so I  kept them.

The general Scraping seems to work fine, but there are several things that I want to do that give me error messages:

&#x200B;

1. When I try to slim the csv down by only scraping for the stuff i need  (not much, see my c.Custom), I get the message  ""CRITICAL:root:twint.output:\_output:CSV:Error:list indices must be  integers or slices, not str list indices must be integers or slices, not  str"". I have no idea what that means, but I am confused because I am  not asking anything new by my wanted parameters - they are in the csv  when i do not filter, so it doesn't make sense to me why I get an error  message when I look for less attributes.

2. I really want to keep only Englisch and German messages, but the  c.Lang = ""de"" line doesn't seem to be doing anything, same as the  Englisch one. I also do not know how I can combine the two, so looking  only for ""en"" and ""de""

3. Right now what I still need to do is go into Excel and re-format the  first column with the seperators. That does work, but is an extra step  that I am shure can be automated somehow - I just don't know how.


Any help on this would be greatly appreciated. I don't know if this  is the right place to ask, but I found no ""discussion"" forum or  something of the sort. Thanks for reading anyways!

### Environment Details

>Windows 10, Anaconda and Jupyter notebook",datascience
o452fr,1624193581.0,"Do you guys, with all honestly, love your job and this occupation in general?","I'm interested with becoming a data scientist or something very related ever since I was 15, but to be completely honest, 90% of the posts here are ranting about the profession, about how it's not like what everyone's thinking and how much 99% of your job basically isn't fun.

Are you happy with what you do? Would you take this profession again in hindsight? Is it worth it? Or is it just the big money that's driving it?",datascience
o444nk,1624190431.0,Weekly Entering & Transitioning Thread | 20 Jun 2021 - 27 Jun 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
o43uwb,1624189483.0,How hard is it to switch from data science to software engineering?,"Let's say someone mastered python out of necessity for the data science field, wouldn't it be too easy for them to just learn other frameworks/technologies software engineering related, which would eventually land them software engineering jobs?

Edit: I'm not moving to or from anything, I'm really interested in data science and technically I only have the basics in both fields (SE from my university courses), it's just that I saw a lot of people saying how data science is becoming so saturated, and in my country the opportunities for SE far outweigh the Data science/AI/ML ones so I was kinda worried that if I didn't find something data science related abroad  (that won't be the case, hopefully) I would be able to switch to SE easily.",datascience
o42gfn,1624183747.0,help needed,"Has anybody here have bought the udemy course 'the complete machine learning 2021 : 10 real world projects' . And if you have done, can you guys lend me the course.",datascience
o40pui,1624176780.0,ML Optimizers from scratch using JAX,"Github link (includes a link to a Kaggle notebook to run it directly) -  [shreyansh26/ML-Optimizers-JAX](https://github.com/shreyansh26/ML-Optimizers-JAX)

Implementations of some popular optimizers from scratch for a simple model like Linear Regression. The goal of this project was to understand how these optimizers work under the hood and try to do a toy implementation myself. I also use a bit of JAX magic to perform the differentiation of the loss function w.r.t to the weights and the bias without explicitly writing their derivatives as a separate function. 

This can serve as an excellent tutorial for beginners who want to explore optimization algorithms in more detail.",datascience
o3zdd3,1624170989.0,"What tools, language and technologies to learn as a beginner in the field of data analytics?","I am a beginner and have learned Python, Pandas, Excel and the Basics of Hypothesis Testing and wanted to know what should I learn and what certifications I should prepare for If I want to get a Career in Business Analytics or Data Analytics so please can anyone tell me what should I do and also what type of projects I should do?",datascience
o3z9j9,1624170453.0,Full Data engineering/ Data science Pipeline on stock market idea,"Hey guys. Hope you are doing good today.

I am a python developer and I have very little experience in ML and Big data. I am also a professional stock trader.

So I want some technical advice or an idea  from the redditors here.

I wanna a build a full stack data science project something related to the stock market.

When I say a full stack I mean right from the start from getting data or extracting data and going through all the big data pipelines and building a predictive model and deploying it.

I mean I have some ideas but I am not able to technically produce it in a way like you guys could do. I am asking you because with experience you know something compared to me

I want answers like

""Scrap financial data from a website, live stream process it using spark and setup in airflow and then take the data do a reinforcement learning algorithm and deploy it showing something in the frontend""

Forgive me if I am demanding too much,but please do your best. It would be helpful for others too",datascience
o3ybbf,1624166422.0,"Starting my masters in DS this fall, any advice on my first class?","After much thought, I have decided that getting a masters in data science is the correct career choice for me. I begin my studies this fall, and my first class is python for data analysis.

Does anyone have advice they’d like to share? I know the basics of Python and I took an online udemy course for Python with data analysis back in 2019.

My goal is to maximize what I learn in this course because I’d really like to increase my use of Python (for data science and just in general)",datascience
o3u9v8,1624151317.0,Sales pitch for DS,"Within Australia, large companies have something called grad programs. These grads rotate through the business 3 or 4 times in 6 months stints. These grads have to apply to an area of the business to work.
I need to write a pitch to get these new grads to apply to my area of the business.

Question is, if you are new to analytics/data science, why did you want to get into it? What did you hear about it for you to think yeah that’s what I want to do?",datascience
o3u1dn,1624150503.0,"Python or R, which programming language is better for data science and which has better scope in the future?",,datascience
o3sjcm,1624145317.0,Crossvalidation using Facebook Prophet,"Hi,

I have a dataset containing the monthly number of shipments for the years 2014 to 2019. I used the Facebook Prophet algorithm to fit a basic model. However, I am not sure how to implement cross-validation on this data. I could not find any blogs/GitHub files that perform cross-validation on monthly data. Is there a workaround for this?

Thanks in advance",datascience
o3rbc2,1624141353.0,Can the prediction of gradient boosted decision trees be parallelized?,"I know that GDBT model cannot be parallelized during training because the trees are built sequentially. What about its scoring / making prediction phase for one single sample?

As far as I understand, we can evaluate the outputs of all trees at once (hence parallelizable), and the final prediction is just a linear combination. Is that correct?",datascience
o3oppz,1624133344.0,Some tips on how to go from academia to a Data Science position,"I read a lot of posts about how to land a data science position and what the biggest differences are between doing research in academia and working as a Data Scientist. Since I did the same journey myself, a couple of years ago, I thought it might be helpful if I summarised my experience and my thoughts about how to successfully do the transfer. My first post on the subject is here: [https://ml-joe.medium.com/from-ph-d-to-research-data-scientist-the-journey-from-academia-to-industry-part-1-2d29200dc5c1?sk=1dc4115b6bc3213377e3e75667d6f25e](https://ml-joe.medium.com/from-ph-d-to-research-data-scientist-the-journey-from-academia-to-industry-part-1-2d29200dc5c1?sk=1dc4115b6bc3213377e3e75667d6f25e)

&#x200B;

Let me know what you think! Thanks!",datascience
o3ofbu,1624132518.0,MC2: A Platform for Secure Analytics and Machine Learning,"(Disclaimer: I'm not affiliated with the project)

[https://github.com/mc2-project](https://github.com/mc2-project/mc2)

MC2 is a project that aims at helping data scientists and engineers collaborate and process collective data without sharing the content of the data with one another, not even the cloud provider. I think the project is very interesting and I'd like about the use cases and what you will do with it.",datascience
o3o5lm,1624131702.0,Mentorship or a discord to ask questions?,"I’m a 2 year decision scientist and I’m on my own. I went from knowing little excel, let alone python or sql, to writing code all the time. But there are still things I don’t know. I was wondering if there was someone who wouldn’t mind being friends on discord or something where I can ask questions when they pop in my head. For the most part, I think Google answers the base line of my questions, but it would be nice to be able to tailor my question based on my role.

An example is something like: it’s me, my laptop, and the company’s SQL server. Should I get Hadoop? Should I run pyspark for these pesky, longer operations when I don’t have multiple machines to run operations on? How can I grab weather data  for all US zip codes and store it, as it’s over 25-50 GB of data?

Being the sole guy for these kinds of developments is challenging. But anything to make my life easier would be a blessing.",datascience
o3l9o0,1624123981.0,What are some exciting new tools/libraries in 2021?,"Hi Everyone, I am an industry data scientist. One of the problems that I find is that while working at a large company,  there is some adoption lag with some new tools + libraries. Could anyone help point me in the right direction for software tools + libraries that are picking up steam this year? I remember hearing stuff about the Julia Programming language a couple of years ago but not sure if that has risen in popularity",datascience
o3iwh1,1624117494.0,Data Science for Computer Networks. Where should I start?,"My boss wants me to do computer network analysis. However, I have never done it before and I only have a math background. I have a good command of R and Statistics. Please help me with ideas and learning material.

I just bought the book Network Security Through Data Analysis: From Data to Action, by Michael Collins. You can check the index with Amazon or Google. ***If you go to the index of the book, Part 3 is Analytics (Starts on page 199). The index shows a list of all possible analytics for computer networks.***

My only experience was with delay analysis, jitter analysis, UDP vs TCP.. In other words, not too much.

***I would say that the general question that we are trying to answer is if our computer network is healthy.***

I have time to learn. And, I am planning to subscribe to O'Reilly that give you access to millions of books and videos. I have seen that they have an area called cybersecurity analyst. Please let me know if EDX, Coursera, or any other MOOC that can help me.

 ***One example about how to do it with R, would be the hrbrmstr/crafter: Tools to Analyze and Visualize Network Packet Capture ('PCAP') Files, Here is the link:*** [***https://rdrr.io/github/hrbrmstr/crafter/***](https://rdrr.io/github/hrbrmstr/crafter/)

 In advance, thank you for your help!",datascience
o3g1q0,1624109112.0,How often do you find yourself performing analytics engineering duties?,"Not necessarily data engineering (ETL/ELT) work, but architecture and development work inside of the database/DWH.",datascience
o3d3jm,1624098623.0,Create a model to improve a business issue,"I have a great opportunity in a company, it's a B2B company. The CEO of this company really want to hire me but he wants to test me one day to be sure. This company use a call center and the CEO ask me to find a way to increase the pourcentage of people accept to take the call. In this moment the call center get 30% of people taking the phone call. The compagny wants an increase of 5%. So i need to build a model. What kind of variables should i take according to you to build it (sexe, age, professional activity,...) ?  I have no work experiences but just theorical knowledge.

I need some advices.
Thanks

Ps: Sorry for my Frenchglish",datascience
o3brf2,1624092955.0,Where to find good Quality DS project examples?,"Hi all,

I was just wondering, is there a good place to read some good quality actual data science projects end to end?

Ideally, I think it would be good to just have a place with a good set of Jupyter notebooks of varying length and complexity that I could read to get a better understanding of the whole end to end process of a 'typical' data science project.

I understand that that code can be found on Kaggle and GitHub, but it feels like it is kind of hard work to be able to find them all organised in one place. Its hard to discern the good from the amateur, and a lot of the time its just small little 'tricks' and tutorials, with not much descriptive text of what the problem is and what they are trying to carry out. I'm kind of looking for some 'gold standard' data science projects I can read to get a better understanding of what is required and what to strive for.

Maybe I am just doing it wrong, but does any one have any suggestions?",datascience
o3ajx5,1624087406.0,Admitted to the Master of Applied Data Science (MADS) - Online at the University of Michigan - Thoughts?," Hello all,

I have been admitted to the Master of Applied Data Science (MADS) - Online at the University of Michigan to start in Fall 2021:

[https://www.si.umich.edu/programs/master-applied-data-science-online](https://www.si.umich.edu/programs/master-applied-data-science-online)

Does anyone have any insights on the program? If I understand correctly, the program is very new and the first cohort of students must be about to graduate now. I would love to read the experience of some people that have taken the program and whether they thought it was worth it as well as any objective opinions in general.

I have found very few first-hand opinions on the MADS at Michigan out there, and the opinions that I have read (mostly here on reddit) were on the negative side. Given that other schools such as Georgia Tech have tons of overwhelmingly positive opinions -both on the quality of the classes as well as the price-, I am scared this is not the right move for me. It is a big investment in terms of time and money after all.

My background:

&#x200B;

* Bachelor in Economics (10 years ago)
* 5+ years of Data Analytics work in large tech company in Bay AreA
* Obtained 2 professional certificates at UC Berkeley Extension: 1 in Programming, 1 in Data Science
   * Medium Proficiency in Python, SQL + Statistics/Probability
* I intend to take degree in 3 years (while working full-time)
* I can afford the tuition (\~$45k before employer contributions) if program is worth it. It won't put me into hardship or debt.
* What I want to get from the degree: applied knowledge that I can use at the workplace to move onto more technical roles.
   * Also, a degree that will 'officially' open the doors to the mentioned roles, as many positions state that a Masters Degree is the minimum required qualification.
* If I were to decline the offer, my current options are not many:
   * Master of Science in Data Science at Colorado Boulder (everyone is 'admitted' through their Introduction courses that take place every 3 months): https://www.colorado.edu/program/data-science/coursera-overview
   * Apply to other schools for the Spring 2022 semester (Georgia Tech would be the first target; any other recommendations?)",datascience
o395o5,1624081060.0,Any Actuary transition to data scientists?,"Hello.

I am an undergraduate student looking for more potential career opportunities.

Are there data scientists here from actuarial background who can share more experience on it?

Thanks in advance.",datascience
o36yvp,1624072823.0,What jobs and sectors can I get with a data science degree?,"Hey guys so I’m undecided yet on what I want to major in but data science has caught my eye. I was just wondering what specific entry level jobs could I get out of college? Is it so in demand that you can work in pretty much any sector? Is there such thing as an associates  in data science?

Im not very good at math but I plan on taking remedial math in college, assuming they have that; will I be fine?

What kind of internships can benefit me to set myself up for success?",datascience
o36h26,1624070970.0,survey for data scientists: issues faced around documentation / on-boarding / KT,"Hey all!

I setup a short survey **print(**[https://forms.gle/2XGL3q8RGpZjmLi78](https://forms.gle/2XGL3q8RGpZjmLi78)**)** to learn more about problems that other developers (data engineers, data scientists) face when it comes to documentation. It would help me out if you'd be willing to give some feedback about the challenges that you face. This is a problem that I face when working on new projects and on new teams and something that I want to build and solve for.

Challenges could include like: time that it takes to create, knowledge transfer of what you work on, having to explain to non-technical people vs. new developers.",datascience
o360o3,1624069222.0,Do pandas and other Python data science libraries change a lot?,"I took a data science with Python course on Udemy that was created in 2017. I’m wondering, how much do pandas and other classic DS libraries change (matplotlib, scikitlearn, seaborn etc.)? Should I take a refresher course?",datascience
o35vgb,1624068678.0,FAANG interview prep: A/B testing - please be merciless in your reply,"Here's the hypothetical from the interviewer:

FB launched a Zoom-like feature. It was generally well-accepted and its usage is growing.

You work at Instagram. How would you evaluate if IG should add that Zoom-like feature?

(in other words, a synchronous communication app within a heterogeneous network (FB) is being evaluted for launch in an otherwise asynchronous homogenous network (IG).

My response:

Clarifying questions:

\- Can some people use the FB Zoom feature with a higher / different  access level than others?

\- What requirements, minimums, or thresholds must be achieved in order to obtain higher access (such as:

o a Facebook business page,

o a Facebook business page with  >1,000 followers

o a Facebook user with >500 edges (relationships since [Facebook can process one trillion edge graphs)](https://research.fb.com/publications/one-trillion-edges-graph-processing-at-facebook-scale/) which the people (nodes) desiring higher access must have people

\- Higher access might include: the ability to invite more than 20 people (20 being the number the hypothetical provided); the ability to place other companies’ advertisements in the Zoom invitation, the Zoom meeting, and/or the Zoom follow up notification; the ability to place advertisements of the host’s company in the Zoom invitation, the Zoom meeting, and/or the Zoom follow up notification; a longer Zoom meeting time (>60 minutes for example)

(clarifying questions partially answered but  mostly deferred)

I would review the data from the A/B experiment on this feature's usage and adoption at FB. I imagine this A/B test would have a dependent variable / control group / training set in machine learning (ML) (user behavior before Zoom feature) and an independent variable / test group / test set in ML (user behavior after Zoom feature).  user behavior here would include the following variables which would be available in SQL tables for further analysis: frequency (did it increase or decrease after using this feature; in what ways did it increase or decrease (likes, comments, shares, marketplace (buying or selling), direct chat w/ other nodes (users), creation or removal of certain edges (relationships).

I'd also analyze datasets which tracked:

\- how many invitees became hosts and set up their own FB Zoom meeting within 1,2,3,4 and +4 weeks;

\- How many invitees purchased one of the host’s products that were advertised in the Zoom meeting?

\- How many invitees purchased one of the non-host products that were advertised in the Zoom meeting?

The A/B experiment I'd design at IG:

Dependent variable / control group / training set: IG user behavior before Zoom feature

Independent variable / test group / test set: IG user behavior after Zoom feature

user behavior here would include the following variables which would be available in SQL tables for further analysis: frequency (did it increase or decrease after using this feature; in what ways did it increase or decrease (likes, comments, shares, marketplace (buying or selling), direct chat w/ other nodes (users), creation or removal of certain edges (relationships).

Last, I'd run an SQL inner join of the networks of people who used FB Zoom  and the networks of those same people on IG. I'd use clustering ML (entropy weight k-means) to then look for trends or patterns which might explain why the Zoom feature was used more (or less) on FB than IG; which gender uses the Zoom feature more; which network (IG or FB) leads to more Zoom invites being sent out; do IG or FB Zoom meetings lead to more purchases? What type of purchases (category)? What price range? How does price, category and frequency of purchase vary based on GIS or location data of Zoom host and location of invitees? Do the data suggest this might be growing into something like the Influencers feature?",datascience
o34mzt,1624064117.0,How many people is data science are introverts?,"Untill college, I was kind of extrovert who eventually with age started becoming introvert. I started my career in sales but one thing after another made me switch to Data science. After 5 years of job, I'm mostly introvert and data science actually helps me this as many other career options do indeed need extrovert characteristics.
To break down on how it helps 2 major examples are:
•Communication:
Its mostly through email, this helps me avoid unnecessary talking. Moreover any verbal meeting mostly translate into me listening to the person and identify the problem statement and then let my work speak.

•Technology
Working on laptop, pushing code on git for collaboration etc all further helps me with least human interaction.

Things were it hurts me most.
•Switching job
Terrible time at interview since now you have to speak and make eye contact

•Office friends
Many a times it had happened that I'm the last person to get to know of office gossip. In my past jobs it was kind off necessity since it helped me know if company will shutdown or not. My last 4 company where I worked all shutdown and in 2, I was among last to know that it was going down.",datascience
o347ji,1624062565.0,What Are The Best Data Science Bootcamps?,"Hi All!

Could I get your opinions on the best value data science bootcamps out there? It's something I've looked at for a long time, but I've been hesitant to pick one because there seems to be so many of them.

The first one that comes to mind is General Assembly, and I also see Springboard. Let me know your experience with these and any others out there.

Thanks in advance!",datascience
o33taz,1624061165.0,How to start preparing for AWS cloud practitioner certification,"I’m a beginner and I’m planning on creating a career in cloud services. I currently have little to no knowledge on cloud platforms and I am wanting to learn more. As a first step I’m planning to prepare for the basic certification offered by AWS I.e. Cloud Practitioner.
It would be great if anyone can provide me resources to begin with. I’m more of a video person than book person so if you have any online MOOC course that will be perfect for my goal. Thanks!",datascience
o33nut,1624060687.0,"Data Scientists who switched to Data Engineer, how is it going?","I’m considering a switch to data engineering as I really enjoy the engineering side of things I’ve had to do as a Data Scientist.

As a Data Scientist what were you doing before? How do you like it? Any regrets?",datascience
o32wxx,1624058338.0,ML Visualization Software,"What software did the author use to create the wonderful visualizations in this Transformer writeup? I would love to recreate his work.

[https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)",datascience
o32fsq,1624056873.0,Is it really possible?,"So, for the past 3 years, I have worked in multiple dead-end jobs due to having no goal or career in mind, leading to not going to college or university, which I really do hate myself for. Worked in a bar, two warehouse jobs, and now work in an apprenticeship in a financial services company as a Quality Assurance Analyst.

As part of my apprenticeship, I take part in courses where they are relevant to our jobs and I was introduced to Data Science which caught my attention. We get told what it is, it’s purpose, the jobs that come under it, and I don’t think I ever felt in love with such a thing before in my life.

Fast forward three months, I have signed up for online courses, been reading articles, programming languages, and it’s never gone away, and that’s rare for someone like me with Autism and ADHD. But one thing I keep seeing is articles and people saying “How to Become a Data Analyst with No Degree or Experience”.

This has me interested but also very wary due to the current work climate and strict job requirements. So, I want to ask everyone: Is it really possible to land a job as a Data Analyst with a portfolio background, with no experience, and no degree?

I’m happy for the job I am grateful to have kept since pre-pandemic but I know I wouldn’t like to stay in a job like that, or in the same company which is pretty terrible to staff.

If any advice or knowledge can be given as well, it would be much appreciated in my career path. Thank you.",datascience
o31p08,1624054681.0,Resources for Learning Data Engineering?,"Hi,

I have CS Bachelors and am interested in going thru a curriculum or learning the core fundamentals of data engineering and gaining practical experience doing projects. I'm at stage 0 right now. Have reasonable familiarity with python, pandas, basic experience with sql (relational).

Does anyone have any resources (articles, online classes/courses or tracks, books, etc..) they can share so I may learn the core fundamentals for data engineering starting as a beginner? A lot of what I've seen online is like cloudera, google, aws, etc.. offering some classes tailored to their proprietary systems but idk which softwares/programs are most relevant in Data Engineering. So its hard to tell what is a good resource for learning core fundamentals versus Company A wanting to grow users in their proprietary ecosystem (which may not be used much by many companies).

**In short, I'd like to know what the most widely used skills/softwares/programs are for data engineering and what the best resources are to learn & apply said learning pragmatically.** Ideally cheap/free but is not necessarily a requirement.

I appreciate any help in advance. :)",datascience
o31fkc,1624053873.0,‘Primer’ for leetcode?,"I have 0 SWE background and my coding skills include SQL, R and Python (pandas, numpy etc). My work is on the analytics side so I rarely think in terms of OOP, and I dont do a lot of functions.

Even looking at the most basic leetcode problems, I get stuck with even where to start.  Terms binary trees, hashes, sorted lists etc is very foreign to me.

I want to start doing leetcode, but is there any other resources I should start with first just to kind of get the basics of the basics down?  The idea is that if I see a leetcode problem, I want to have some sort of reference of where to start.",datascience
o319vj,1624053392.0,What is the random_state parameter for DecisionTreeRegressor?,"I'm a newbie who just started to learn data science via Kaggle courses and the above-said parameter was used when defining the model.
e.g - `data_model = data_model.DecisionTreeRegressor(random_state=1)`

They mention that this was to get the same results every time. But even after I changed values, or just completely removed the parameter, the same results were generated, or at least that's what it seems like, looking at the `predictions.head()`

So what's the use of that parameter here? Why do we even use it when it brings no change?

.

Also, please give me any advice you'd liek to as I've only started learning like a week ago.",datascience
o316ni,1624053110.0,Conferences for 2021 - Disney Conference,"With \\things starting to reopen my company is restarting training and conference travelling.

I was taking a look at the Disney Conference on Data and Analytics. I know that most people find the Disney conferences very useful and I was wondering if anyone in DS had attended this conference and if so, what they thought of it.

[https://disneydataconference.com/](https://disneydataconference.com/)

FYI - not affiliated in with Disney in any manner, just a Canadian looking for a winter trip to somewhere warm ;)

Or are there any good ones looking to be in person in the fall? I know a lot of this may be still be subject to cancellations depending on what happens again in the fall.",datascience
o2x2me,1624041657.0,What are your top things that are usually being overlooked but super important and can save lots of time and money,"My list:

1. Documentation
2. The summary of code logic as flowchart/diagram format
3. Code convention
4. Grab some general significant number to check if each step output is making sense
5. Prepare some common preproc function for the task with similar procedures.
6. Put the date/time as prefix for each simulation testing",datascience
o2wsh8,1624040932.0,Is this a data science job for real?,"Hi, I am a CS major. I graduated in 2019 and have been working in a company since then.

When I joined, they had just started an AI team. In fact, my manager was the first data science hire and I was the second one. We have been working on creating an MVP, and don't have any customers for it yet.

My manager is more inclined towards the business side of data science (so he's good in storytelling in demos, working with Sales and Product Management for the requirements etc.). We don't have any expert for guidance on ML product pipelines, algorithm improvement etc. so anything I have implemented so far has been by taking help from the internet.

As a college fresher, I got this job through a Python interview. I even left an offer of 2.5x pay in software development because I wanted to pursue data science.

I haven't interviewed for any other company since then. I don't really know what is usually involved in data science jobs. Have I gained any useful data science experience in order to get the next job?

My work involves:

\- setting up internal products on demo servers and preparing a story through dummy data/insights for customer demos or security conferences (40%)

\- designing database tables and creating reports and dashboards for the product (initially it was in PowerBI, then Jasper Reports and now in an internal product framework) (25%)

\- developing and maintaining Python jobs and integrating model training/detection with the main Java product through Flask (20%)

\- exploring, drawing analogies and implementing unsupervised ML/DL algorithms that can solve the use cases provided by Product Management. (15%)

 Is this what is usually involved in a real data science job?

Also, I read that you should add in your resume how your work helped in making business value. But since we don't have any customers, what should I add?",datascience
o2w4qb,1624039241.0,There has to be an online tool for text generation right?,"Friend of mine wants to import a list of names and generate fake names that are similar based on the input training data. He's been having trouble with installing tensorflow on his M1 mac. I was sure there would be an online utility to do something like that without the need to train locally, but I can't seem to find a decent resource for him to use.

Any suggestions?",datascience
o2vm51,1624037938.0,Conferences - paying your own way,"What are others’ thoughts on paying your own way to attend conferences directly related to your job? Is it common practice?  Are there salary ranges or other criteria you consider when making this kind of choice?

Back story: I used to work as a government contractor and we were only allowed to attend one conference per year. On that salary, I really couldn’t afford to pay my own way so I only went and presented at one. I recently changed jobs to a small startup, with a 25% pay increase but no real benefits to speak of yet (VERY small and new startup). There’s a conference that is squarely in line with my job description and potentially really important because of both the subject matter and the focus.  The boss is leaning towards only sending one of us and having that person take screenshots. Honestly, I don’t think this is functional for two reasons: 1) if I’m at a conference I want to focus on it and not be taking screenshots like crazy for 4 days, and 2) if I’m not at the conference, screenshots are not going to be useful to me really.  So I’m considering just paying for it myself ($500).  It will mean I can’t get (right away) the new computer I also need for my job, but this conference is really important for both me and the person who signaled it to the boss (and would get to go...that’s only fair and I’m totally ok with it).  However, paying my own way also sends a signal that I’m happy to do this going forward - which I am not. Conferences are expensive, and as a W2 employee they are not tax-deductible. What would you guys do?",datascience
o2u9dy,1624035800.0,How does your team deploy models?,"I work on a ""Data Science"" team that does work that is hybrid of typical DS/DE/DA work.

Some days it's simple SQL and Tableau, other times its building pipelines through real time ingestion with kafka or batch ETLs using Airflow, sometimes it's hard statistical analysis and occasionally we do actual Machine Learning...

We are all Data Scientists by title but play the hybrid of just being good with data, regardless of specifics coming to DA versus DE versus DS..

Recently I've felt like I've been missing the DS side of things. I get the occasional one off request for building data models but don't ever really deploy anything with them... Usually just local models and then sharing the results.

I am wanting to start putting some models ""in production"" as a way to show my usual stakeholders the value that ML can have for the business and I'm curious in all the ways you guys do this on your team? I specifically am curious about two scenarios...

**Scenario 1: Model only needs to be running when the ETL runs.**

Most of our work is batch processing data at some interval. I typically utilize airflow with kubernetes pod operators to spin up python containers that have the code I need for the ETL. I figured a super simple way to do this was to just store a trained model in the container itself and have the scripts run the models the same way I would locally whenever the airflow job is triggered. This seems simple, but I'm sure my idea is flawed. I know a major limitation here is that to retrain the model, I need to pull my container back to my local machine, retrain the model locally, rebuild the container and push it back to artifactory so the ETL can now use the updated version. There's also the limitation that other people can't use the model since its only present ""in production"" when airflow triggers the pod to spin up.

**Scenario 2: Model needs to be available and running at all times**

I often utilize kafka triggers deployed in kubernetes pods to listen to topics of interest. While they usually just write data to a db or send notifications to stakeholders about the event that occurred, I see a lot of potential in being able to point data from an event into a classification or regression model in real time and then store the results of the model for later use. To do this, I think my approach would be to build a flask API that is deployed in the same kubernetes cluster that I could point my kafka trigger towards... I have played with flask before, but am not as great with the whole devops side in terms of configuring IPs and making sure my flask API is available for other ""apps"" to use...

I would love your feedback on how your team deploys models and code, especially if you run into the above two scenarios :)",datascience
o2qr6i,1624027552.0,"can someone please explain what the ""white color shades"" mean in this picture?","[https://martin-thoma.com/images/2016/01/ml-classifiers-2.png](https://martin-thoma.com/images/2016/01/ml-classifiers-2.png)

These pictures are supposed to show the decision boundaries of different machine learning algorithms on a binary classification task. There are two classes for the response variable: ""red"" and ""blue"".

Shouldn't all the decision boundaries either be fully red or fully blue? What do the shades of white mean? Does this mean ""an overlapping decision boundary""?

Thanks",datascience
o2q9o8,1624026210.0,Can you guys help me understand what data science is?,"PLEASE TELL ME IF THIS VIOLATES RULE 9 AND ILL REMOVE IT THANKS

So I really don't get what data science is, and how its different from statistics. I've read a bunch of websites but still can't come up with like a simple explanation of what it is. From my understanding, you get the meaning from data, while in statistics you make the data? Also, I don't get why coding is needed for data? What does an average day look like for a data scientist? Do you like to make the data and then say what it means or something? Sorry if I sound really dumb.",datascience
o2q05f,1624025495.0,Tips on how to properly mentor and train junior data people?,"My company hired a junior BI analyst a couple of months back to handle the backlog of dashboarding/analysis demands I was not able to juggle in a timely manner due to more pressing data science/engineering concerns (I was the sole data person in the team at the time).

She's done a great job, but now that most of the overdue demands she was given are done, she has expressed interest in gradually transitioning to a more broad data role within the company. Most of her previous job experience is in a strict BI role (dashboard building, reporting, etc) but she has done a few python courses on her own.

Under my supervision, she has begun working on a few basic tasks like data cleaning, pipeline building, etc. I can tell she's interested, but her progress has been remarkably slow and underwhelming.
People who have more experience with mentoring juniors, what are some things I can do to be a better mentor and help her develop in the field? I try to give detailed feedback in each of her deliveries but as I said progress is slow so far.


\-------
EDIT: I didn't expect this many good responses, thank you so much! Starting next week I'll try to come up with a more active plan of mentoring based on the input you guys gave. Here's hoping this post can help more people who are or might eventually be in a similar situation.
",datascience
o2p1cp,1624022708.0,Is the occupation of a Data Analyst and Database Analyst same or are they different? Under what occupational group does a Data Analyst fall into?,"Non-native English speaker here.

What is the difference between a Data Analyst and a Database Analyst?

Is the occupation of a Data Analyst part of occupation unit group [2172--Database Analysts and Data Administrators](https://noc.esdc.gc.ca/Structure/NocProfile?objectid=xYpcSE6sKP672q64fVjEXwuRuW7o0pqx1PT2WTqtRT1u0YlGq3so6qLpM%2FO7M0Ic4ZDQ9YoZIGfvucsB9Lr7ohU%2BkbKG85oz8uuocyqCXV0%3D)? If not, which occupational unit does it fall into in the Canadian National Occupational Classification System?",datascience
o2jtgd,1624003072.0,CDP / XCDP for beginner data scientist,"Hi everyone,

Did anyone work as a Data scientist in ecommerce industry? I am currently working with Bloomreach, which can provide full customer experience without really knowing advanced programming.

I am looking for something cheaper alternative tool for data science in ecommerce - tracking, data analysis, predictions, single customer view, omnichannel communication, recommendation etc. What tools/combination of tools are best for you?

I tried almost all CDP demos, but i want to know some experiences from e-commerce segment. For info, we are small agency focused on automation and data.",datascience
o2i7b9,1623996408.0,Modern Time Series Models,"Does anyone know what are the most modern statistical models being used for time series analysis? I have heard of transformer and attention mechanisms models that are used for modelling sequential data - but these seem to be more relevant for modelling data from the NLP domain. When it comes to classical time series modelling (e.g. a vector of temperature measurements) : does anyone know what are some of the more modern models being used for this? I did some searching online : it seems like ARIMA style models were some of the first ones, followed by state space models/hidden markov, and the more recent ones being RNN and LSTM.

Are LSTM and RNN the most modern models that are being used for classical time series problems?

Thanks",datascience
o2hiye,1623993939.0,What course/book/talk etc. added the most value to your career as a data scientist?,,datascience
o2gg88,1623990025.0,Has anyone had any experience selecting priors for Bayesian Models in real life?,"I often see in textbooks and blogs, when dealing with Bayesian Models, popular choices of priors seem to be well-known distributions (e.g. the gaussian prior). But how would you go about selecting priors for a specific model?

For example, suppose you are interested in making some bayesian model (e.g. for causal inference) on some medical data. One of your variables - 'smoking status', you have knowledge that patients who smoke vs patients who don't smoke have different life expectancies.

Using historical data, how would you choose a ""prior"" for this model?

Thanks",datascience
o2ew30,1623984870.0,Offered managerial role for likely a big hit on QOL,"I am currently a sr. analyst doing research on business questions and support our DS team as a SME. It's a fairly relaxed but unsatisfying job. The pay is ok but enough. We will have hybrid model when going back and the commute is only 10 minutes.

I went to my (grad) school networking event, pitched myself to a company, and got offered a managerial role. My responsibility is building out data solutions such as dashboards, analytics, and ML models, in addition to overseeing a small data process/ETL team.

Asides from the increased workload, this role requires 5 days in-office and the commute is 40+ min one way. There's no plan to move to hybrid in near future. I also have no experience in managing a team, let alone doing that while building out data functions from scratch.

Now the plus side is, it's a 20% increase in total comp. I have a lot of say in how the data analytics will run. Lastly, the chance of managerial experience seems to be valuable and rare.

I'm not too worried about delivering the technical aspect of work. I have experience building out dashboard, db, and pipeline. I have also delivered 1 ML model into production and currently delivering another one, granted they are off-the-shelf models. I'll essentially be repeating what I had been doing, given that new company is in the same business.

I think the company is sincere in matching my ask and trusting me with a managerial role. That said, would you consider this a good move? Do you think there's a high chance of failure considering that I had no prior experience in managing and have to build a new function at the same time? Do you think it's worth the quality-of-life drop for advancement in career?",datascience
o2eq7y,1623984337.0,Multiple stock predictions,"Most of the stock price prediction tutorials use a single stock as example with LSTM models. Although stocks have been proved to be random walks and containing to use LSTM for real time predictions is ""not recommended"".

Say that you stuck to LSTM, how does it happen in real world for 10 different stocks (it could be 20,50, etc.)?

Do you train 10 different LSTM models? Or use a different approach?

The Idea is to tell which amongst these 10 stocks would rise and which ones will dip.

Thanks",datascience
o2cr6e,1623978014.0,Anyone interested on getting together to focus on personal projects?,"I have a couple projects I’d like to work on. But I’m terrible at holding myself accountable to making progress on projects. I’d like to get together with a handful of people to work on our own projects, but we’d meet every couple weeks to give updates and feedback.

If anyone else is in the Chicago area, I’d love to meet in person. (I’ve spent enough time cooped up over the past year.)

If you’re interested, PM me.

EDIT: Wow! Thanks everyone for the interest! We started a discord server for the group. I don't want to post it directly on the sub, but if you're interested, send me a PM and I'll respond with the discord link. I'm logging off for the night, so I may not get back to you until tomorrow.",datascience
o29mq6,1623968703.0,How do you create storyboards?,"Hi all. I’m working on a project that requires a story or vision. I don’t want it to look crude but don’t need to spend a ton of time on it. What’s a good compromise to start with?

I figure a good starting point is a step up from PowerPoint. No disrespect to PPT but…

Thanks!",datascience
o271l3,1623961853.0,What would be the best workflow for this image dataset use case,"Hi all,

The project that I’m working right now is about image recognition. For the data pipeline we are using the following pipeline:
- Take photos with our cellphones
- Divide them into batches of 100 (called tasks), Upload them into CVAT (hosted in a aws machine) and label them
- Download the images/labels to our local machines
- Add some additional metadata to the labels and upload them to a aws s3 bucket.

This has some manual labor as there is label happening all the time and it would be desirable that the s3 bucket would have the updated information without much of an hassle.

What would you suggest in this case? What tools that you would think to automate this process?

I think that the bottleneck here is CVAT which only works with the creation of “tasks” and each one of them can’t have a lot of images since it will make the application slow.

Much thanks.",datascience
o233zs,1623951994.0,Recent graduate in Data Science," I graduated with a degree in ML/dataScience 2 years ago and since then been working for a small company as a ML Engineer in their R&D team. Unfortunately, I’m not getting the growth I expected I would in this role. It could be because I’m the only ML engineer, no other data scientist or anyone working on the things I’m working on.
 Additionally, there’s also no data engineers and no data pipelines, no cloud, the data is all scattered in files and folders. As mentioned, the company is not in Cloud yet, so no computing power either. Working as an ML engineer right out of bachelors and not having a team or even a mentor has been kind of rough to say the least.

 So here I am asking for advise- I really am not sure what to do next. Whether to get an MS in a similar field (data analytics/ML) and then switch my job or to switch first and get some more experience and then think about doing MS.

I can tell you where I want to be though- currently I’m doing core algorithm building and prediction modelling on moving parts but I think I want to venture towards the customer facing stuff – more on the lines of Market analysis or Product analysis.

I guess I’m here because I need some advice- any advice helps. Tell me about your journey into ML/ data analytics- what has worked for you what hasn’t. Any certifications or online programs you recommend to thrive and get noticed for more opportunities and grow in the field. Any MS programs that are good and worth exploring. Any advice that allows me to figure out what to do next helps.

Thank you for taking your time reading this and leaving a comment!",datascience
o22b58,1623949957.0,"40s Mid Level Manager in FinTech with Interest in DS, should I do a part time MS Degree?","Mid Level Director in early 40s working in large Financial Data company making a decent living responsible for Change an Risk for a product within Operations Group.  Also have a small team of 3 Data Scientist/Engineers and double the headcount next year with focus on New Data Integration, Data Source/Scraping, RPA, AI/NLP Modeling and Advanced Analytics/Visualization with Tableau/PBI.

While this is 1/3 of my responsibilities, its where my interest and curiosity lies.  My background is more Finance and Operations, intermediate SQL.  My involvement in all this is more around coming up with ideas, push on execution, project manage it all while tasking my guys on execution etc.  But because I know nothing about python, the different packages etc.  I always wanted to learn more.   Since I'm on an operations team and not Technology, are use cases are fairly basic etc but it's still fun to find opportunities to apply such tech to automate and reduce risk etc.   Our company offer tuition reimbursement of 20k per calendar year.  So I can pick any MSC degree over 3 calendar years but in 2 full years and it would be free.  I wouldnt do it for the ""starting Salary"" since I make above any MSC or MBA starting salary.  It's more for trying to further my career (sharpening the toolbox) in prep for any potential career/company changes if at all and staying relevant.

Question for you guys who have done such degrees and are working in such field.  Would this make sense for me?  Should it be Data Science?  Or would Data Analytics make more sense based on what I do and what level I'm at?  Is DS too nitty gritty?  Too close to the actual work?  Would it further it further my career?  Considering I have a team of Data Scientists or Data Engineers etc, does it make sense to learn it all from the group up?  Thoughts?",datascience
o1ulr0,1623927931.0,"So, being fired after 4 month","So I come from different industry (\~5 years experience working in energy) and then move to the new company in eCommerce since February (so technically I'm like a grad in eCommerce). I'm the first data scientist in the company, so there is no team and I likely spend a lot of time working with business guys. Before that, the company hired external consultants for analytics. And, the best I can have from them it's only Excel file, code, without any official business or technical documentation. So the only way to find out the logic calculation is to look at the code.

The business lead I usually reported to also take a maternity leave since April.

The company are in rush to produce Annual Customer Report on the my first day, which even after 4 months I hardly knows anything. Today this morning the top manager reviewed my performance, and they are not quite pleased with what I'm delivering. Then they decide not to extend my contract. They expect a data scientist to lead them to the place they want, coming up with ideas, questions and making decision. This is in my opinion a little bit more for business analysts who are already in the company for years, and also a little bit unrealisitc if the company do not have a proper technical team. (The good things is that the company uses SAS, and if they terminate then I can come back with Python.)

I wonder what's your thought in this situation? Usually, do you think 4 - 6 months are good time enough to onboard data scientists (if he didn't have any relevant domain knowledge before)?",datascience
o1abco,1623864519.0,Grappling with the social impact of data-related careers,"I’ve been working in this field at a consulting firm for 2 years now, and a question that always rests heavy on my mind is whether I should be applying my skills to a sector that has more direct social impact. The need for data analytics/science seems to follow the money trail, as larger corporations have been able to collect massive amounts of customer data and thus are willing to pay top dollar to help make sense of it.

There are definitely options to do data science in a more impactful way (e.g. non-profits, environmental data, life sciences data), but I have the overall impression that these fields pay less. More importantly, it can be frustrating to do DS for due to the lack of work done previously, leading to messy and lots of unclean/scattered data. In other words, because the majority of people take the higher paying jobs over the ones with higher social impact, the high social impact data roles and ecosystems remain underdeveloped.

My question is: how do you grapple with this reality?

Do you grind at a corporate job and donate part of your income? Do you teach on the side? Answer a lot of Stack Overflow questions? Invest it in your children’s future? Some pro bono DS work for non-profits in your free time?

Or just ignore all of it, because life is short, and you worked incredibly hard to get to where you’re at?",datascience
o18wu3,1623861017.0,Data Wrangling - Multiline Python Statements? Trying to learn best syntax for Python coming from R,"Hi,

I have worked with R as my primary language dealing with everything from econometrics/ML applications, GPS analysis using APIs, NLP contract analysis and dealing with unstructured data. I would say if I have a problem and can use R then I can likely devise some way to solve it.

&#x200B;

However, I want to move into a new role and I am finding despite my 5+ years with R as my primary language that Python is more preferred when I talk with recruiters, so I have picked it up and I was hoping to get some guidance with good examples of code. In R it is very easy and code 'flows' between statements using the pipe operator, but python I am finding it less intuitive from trial and error to do multistep aggregations, data summarization, etc.

&#x200B;

Anyone have a good guide of how to use python for complex data summaries? I want to be able to something like ifelse(col1 %in% \[""phrase1"", ""phrase2""\], Col2, NA) and get a count of how many unique values pass that logic. And I might have a half dozen conditional things like this as I have to evaluate many similar statistics for different time periods quite often. Kaggle has some data cleaning, but that data is perfect compared to some of my sources as a consultant.

&#x200B;

&#x200B;

Obviously this below chunk of code should be broken up across multiple lines, correct?

`df_BorState = df[df.BorrowerCity==""San Francisco""].groupby( [""BorrowerState"", ""BorrowerCity"", ""BorrowerZip""] ).agg( Tot_Amount = ('CurrentApprovalAmount', 'sum') ).sort_values(""Tot_Amount"", ascending = False)`

&#x200B;

Is something like this standardized?

`df_BorState = df[df.BorrowerCity==""San Francisco""].groupby(`

`[""BorrowerState"", ""BorrowerCity"", ""BorrowerZip""] ).agg(`

`Tot_Amount = ('CurrentApprovalAmount', 'sum') ).sort_values(`

`""Tot_Amount"", ascending = False)`",datascience
o17b6n,1623856720.0,When to update models?,"Suppose you have a predictive model that has been used for a few years - at what point do people decide to make changes to the model (e.g. add new variables, retrain the model with new data)? Is there a standard procedure for doing this? Are old and new models often run in parallel?

I would be curious to hear how this problem is being handled across the industry.

Thanks",datascience
o13xow,1623847263.0,Euro 2020 Predictions Update,"EDIT:  /u/pedrosorio Makes good points.  I've changed the prior rankings to reflect the team ELOs from the start of qualifying, and have also included UEFA nations games.  What I really should do is model the team ability as a random walk in time, or add some sort of competition/tournament effect.  The model is good enough for me for now.  I appreciate all your comments though, so please share.

Last week, I posted some predictions for the 2020 Euro.  Now that the first round is over, we can examine some of my performance.

My predictions and results for the first round are shown in [this](https://i.imgur.com/qkY6SQc.png) table (sorry it isn't prettier).  I achieve an average log loss of 0.92, where assigning all outcomes as equiprobable yields an average loss of 1.1.  My multiclass ROC for predicting the outcome is 0.77.  In short, in the first 12 games I perform slightly better than random guessing (which is honestly fine for me).  However, most people who have watched international football wouldn't assign all match events as equally likely (is Italy drawing Turkey really as probable as Italy losing to Turkey?  No).  Its hard for me to measure against a ""reasonable guesser"".  My work pool records all our guesses, and so at the end of the group stage I can use that as a sort of ensemble method to compare against.  We'll see.

[Here](https://i.imgur.com/mZaivJY.png) are match predictions for the remaining group stage games conditioned on the results of the first games.  The model is not perfect, and still makes some weird predictions.  For example, Portugal is given higher probability to beat France than they are to beat Germany even though France beat Germany in the first round.  If you subscribe to some sort of sports law of transitivity, this may sound weird.

My predictions for the second round and the results of the first can be found [here](https://github.com/Dpananos/Euro2021Predictions/tree/main/predictions).",datascience
o12a74,1623841517.0,How good at R or Python do you have to be before you add it to your resume?,"So I'm actually applying to Data Engineering jobs, so may not even be relevant.

However I'm never sure when it's okay to actually add something to your resume.

In the case of R, I only spent maybe a couple months on it. I learned the Tidyverse package, including Dplyr.

I also created a single project which included various graphs, along with decision trees, linear regression, and clustering algorithms using the caret package.

But I wouldn't say I'm proficient I don't think (I'm just good at Googling stuff).

I don't know if it's still okay to just stick it in with my list of skills.",datascience
o11rn9,1623839511.0,remote work,"Do you think that remote working for data science or analytics roles will be a thing post-covid too? I know that it cannot be like the past year that every job was remote, but will many jobs keep the remote status in the following years regardless of covid?",datascience
o0ztez,1623831063.0,How to remove data from a scatterplot,"I have a list of x,y coordinates  that represent the location of cells in a slice of tissue.  I can generate a scatterplot of that data and make a map.  Now I want to remove a bunch of those points because they are not trustworthy.   I know how to do that 1 point at a time, but I have thousands of points that need to be removed on each of hundreds of scatterplots.

Do you know if there is any way to highlight a lot of points at once on a scatterplot and then just delete them from the data set?

It doesn't matter what program/platform is used to do this.

It seems like a straightforward question but I can't find any way to do it, nor anyone who does.",datascience
o0p64q,1623792799.0,Choosing a combined title? E.g. Data Scientist & Engineer,"If given some say in setting a job title, for someone who does both (and will be expected to do both in the role), would you go for a merged title like ""Data Scientist & Engineer"", or just pick one? Context: data scientist roles are already on the resume, so goal is to highlight the additional skill/responsibility, if appropriate.",datascience
o0oz27,1623792235.0,Ramping Up Help from Coworkers,"I've started a new job as a Sr. Data Analyst. I am ramping up and am about a month into the position. Ramping up in the pandemic is a different experience than when I ramped up in a previous role in the office (obviously). The most notable part is knowing when to reach out to others and seek out that sort of 'whiteboard' session.

I feel that I am missing that now and don't have a great feel for my team. I have a project now but ultimately I feel disconnected. I am looking to do more catch ups and understand that with time rapport builds. Slack is part of the culture, but the group chat isn't too active.

When I have ramped up other individuals in the past I try to meet often and be available for their questions. I try to also have specific times to check in to help facilitate communication and let the person know there isn't a 'quota' to their questions.

What are ways others have been able to ramp up in the pandemic or fully remote? Any tips?

Edit: grammar",datascience
o0oxpm,1623792132.0,Finding Freelancing Opportunities,"I'm pretty happy with my full time job as a senior model developer (but I do a lot of analytics on model results as well), including the steady paycheck and job security it comes with. But sometimes I don't get to do the most interesting work so I think about getting into part-time freelancing. I had one person in my network pitch me an app idea for his small business. I had a conversation with their ceo, he seemed super interested, pitched me some requirements, answered some questions. I then roughed out the specific work required, how much time it would take, and used $50/hour as my baseline pay needed even though that's below what my regular job pays. Normally I'd need more for working beyond my full-time job because it would require sacrificing my social life, but the project was extremely interesting and could have led to a good relationship and more work down the road. But when he saw my estimate that it'd take 200 hours to complete aka $10k he said my estimates all made sense but thanks but no thanks. The fact that he didn't even attempt to counter makes me think he was expecting to pay like $1k for it, even though the guy who pitched the idea to me said that for $10k they'd recoup costs in a few months because they paid contractors to manually do the work my app would have automated, plus they lose money on mistakes the contractors regularly make.

&#x200B;

So my question is what's the market like for work like this? Are people actually able to build custom data-driven apps where they're paid 5 figures for completed projects? Or is my experience more typical where there's just a sticker shock? What kind of clients are paying this? How do you get your foot in the door? Would a good github or personal page with personal project examples be valuable?",datascience
o0neg0,1623787782.0,Does knowing R instead of Python makes you unhireable?,"Hello!

Sorry for another R, Python post.

Recently I got a task at work in which I had to read through multiple sheets of excel, clean, transform, reshape it and make it into a single dataframe. I hadn't done this type of task in either R or Python. Since, it was not really a time constraint task, I decided to do it in both and learn how to do it in both languages. I am better with R than Python. I barely know Python actually. So I started doing it in R and comfortably (with google) did it without taking much time. After that I tried it in Python but I'm still struggling to finish it. I will be able to do it but it's taking me significantly more time than R.

Is that just the learning curve of Python since I barely know the language or some things are just easier in R and I should just do it in the language I'm comfortable with? I'm afraid that that I'll never be able to learn Python like this and won't getting any interviews since I don't know how to do stuff in Python.

Thanks! Sorry for the long post.",datascience
o0m6w9,1623784526.0,Is it worth taking a lower tier DS internship after mid tier SWE internship if I’m interested in DS?,"I’m a rising senior currently interning at a decent company as swe, but I recently got offered a fall internship at a lower tier company in data science. I’m really interested in data science and haven’t really been exposed to it, but I’m worried this will look like a step down resume wise. The pay for the ds role is about half as much as my current swe role too for context. If I took the ds role, I would have less time on school as well since it’s in the fall. So would it just be more worthwhile to focus on school and maybe research there than this internship? I would still apply to data science jobs in the future regardless. Any thoughts would be appreciated!",datascience
o0koo8,1623780567.0,How does one become a better communicator?,"Hi all,

As the title suggests, off late, I have been struggling to communicate with non-technical stakeholders efficiently. For example, there was this one time where one of the stakeholders asked me to explain what a model did and I ended up combining a few technical terms together in a sentence which ended up confusing the stakeholder even more.

It is not that I suck at communicating in general. If I were to have a conversation regarding a simple analysis/explaining some viz, I do it pretty well. But, when it comes to explaining something more technical to someone with a non-technical background (like the inner workings of the model), I mess up big time.

My initial thought was that I might be messing up the explanations because I don't understand the models well enough, and I have been reading up all the basics from scratch in hopes that it would help me become better at explaining concepts.

While I do continue my re-reading of the basics, are there any other ways that I could improve my technical explanations? Thanks!",datascience
o0fxws,1623768060.0,Recommender System for Medicines - Code Example,"I am looking for Python coding example for - recommender system for medicines. The closest I have come to is [this](https://www.kaggle.com/chocozzz/recommendation-medicines-by-using-a-review).

Can you suggest something better?

Thanks!",datascience
o0exje,1623765311.0,Dealing with imbalanced datasets,"Suppose you are working on a supervised binary classification task. You have patient medical information (e.g. age, weight, gender, height, blood pressure, etc) and whether they have a certain disease or not (this is the response variable, ""yes"" or ""no""). Let's imagine that determining if patients have this disease is time consuming and costly - so a machine learning approach is being considered.

Let's assume that this disease is very rare. In your data set, only 1% of patients have this disease. Thus, the dataset is imbalanced.

Intuitively, we know that any machine learning algorithm trained on this data will likely perform poorly. That is, the performance will likely be deceptive: you might get an accuracy of 99%, but misclassify all of the patients who have the disease.

Mathematically speaking: is there any mathematical explanation for this very logical concept?

 E.g. if only study 1 hour for a chemistry exam, I might only learn how to solve 2-3 types of problems - thus, on a true/false style chemistry exam, there will be many questions that I don't know how to answer because I never saw them before, and I will be likely to perform badly on material that I have not prepared for. Do machine learning models work the same way?

For popular algorithms like neural networks, xgboost and random forest - can it be shown that for classification problems, you need a minimum number of observations or a minimum proportion of the minority class to probabilistically achieve a certain model performance?

On a more abstract side, I have heard that researchers are interested in trying to make machine learning models generalize without seeing thousands and thousands of examples. E.g. a 5 year old child can ""learn"" what is an ""elephant"" after seeing a few pictures of an elephant (e.g. it's perfectly reasonable to expect that a young child would see a picture of the cartoon character Dumbo and identify Dumbo as an elephant after coming back from a zoo), but a machine learning algorithm would likely need thousands and thousands of pictures of elephants (and likely require to see the same pictures upside down, inverted, with added noise, different color scheme, etc) prior to be able to generalize and learn the concept of an elephant. Perhaps the same analogy applies to machine learning models struggling to correctly classify patients with a rare disease, since there are so few of them?

Does the above concept have anything to do with the ""bias-variance tradeoff""? Or is it just logic - if there is not enough variability and information within the data, the machine learning model just learns the ""noise"" within the dataset? I am really curious to see if such a threshold for measuring ""minimum level of variability within the data"" has ever been studied?

PS: in a 1 dimensional sense, on a number line, if you have a ""point"" at 3 and another ""point"" at 5 - you could consider all inferences outside of 3 and 5 as ""extrapolation"" and all inferences between 3 and 5 as  ""interpolation"". When dealing with higher dimensional data, could you simply consider observations from the test set that have a smaller euclidean distance to other observations from the training set as ""interpolation"" and observstions that are farther away as ""extrapolation""? In reality, can you just consider all prediction as extrapolation - small scale extrapolation for closer points, large scale extrapolation for further points?

Thanks",datascience
o0e56q,1623763064.0,Generating New Data Points with SMOTE,"

There is a well-known algorithm in statistics called SMOTE (Synthetic Minority Over Sampling Technique) which is often used to ""balance"" and ""imbalanced"" data set:

[https://en.wikipedia.org/wiki/Oversampling\_and\_undersampling\_in\_data\_analysis](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis)

[https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python](https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/#:~:text=SMOTE%20(synthetic%20minority%20oversampling%20technique)%20is%20one%20of%20the%20most,instances%20between%20existing%20minority%20instances)

[https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)

If I have understood correctly, the premise of the SMOTE algorithm is as follows: Suppose you have a dataset containing information for medical patients that are ""healthy"" and ""not healthy"". But, let's assume that the majority of the patients within your dataset are ""healthy"" (the composition of healthy: not healthy being 95:5) . If you want to make a statistical model for this data, the data does not contain enough information for ""not healthy"" patients, and it will be very challenging to build a reliable statistical model that can make accurate predictions for ""not healthy"" patients. Thus, the SMOTE algorithm can fix this problem by:

1. ""rebalancing"" the data set (e.g. after SMOTE, your data set can have a composition of 70:30)
2. creating ""new"" data points from the ""existing"" data : as I understand, this is done by multiplying a given vector corresponding to a randomly selected individual observation, by some random number between 0 and 1.

This leads me to my question: Suppose you have already have a balanced dataset (e.g. the healthy: not healthy has a composition of 60:40), but let's assume that you have a relatively small dat set to begin with (e.g. 500 rows). Can you use the SMOTE algorithm to create new data points so that your dataset is bigger? I understand that no algorithm can magically compensate for data quality issues, but at the same time I don't see any major flaws with using SMOTE on already balanced data?

For reference, I illustrated this process below using R:

I would be interested in hearing a second opinion - Thanks!

    #load and install libraries
    remotes::install_version(""DMwR"", version=""0.4.1"")
    library(DMwR)

     #create some fake data and put them into a data frame called ""f""

    var_1<- rnorm(100,1,4)
    var_2 <-rnorm(100,10,5)
     var_3<- c(""0"",""2"", ""4"")
     var_3 <- sample(var_3, 100, replace=TRUE, prob=c(0.3, 0.6, 0.1))

     response<- c(""1"",""0"")
    response <- sample(response, 100, replace=TRUE, prob=c(0.3, 0.7))

     #put them into a data frame called ""f""

    f <- data.frame(var_1, var_2, var_3, response)

     #declare var_3 and response_variable as factors
    f$var_3 = as.factor(f$var_3)
     f$response = as.factor(f$response)

    #SMOTE algorithm
    #simulate new points from the first class

     smoted_data_over <- SMOTE(response~., f, perc.over=100)

     #simulate new points from the second class
    smoted_data_under <- SMOTE(response~., f, perc.under=100)

    #combine everything together into a final new data file
    final <-rbind(f, smoted_data_over, smoted_data_under)",datascience
o08ue4,1623743243.0,"I have a large dataset (100 mil rows) in Russian, I want to translate it into English. I was using Googletranslate API, which was showing error coz of a high number of requests. Is there anything else I can do??",,datascience
o07hrm,1623737973.0,Convincing SME depite good result model,"I'm in the situation where SME refuse to believe the model I created despite the good score (>70% f1 score). Now Im clueless on how to convince them.

As a background, I did my degree in the related field.  So, I have good understanding about the input data. Plus, via EDA, I can clearly see the seperation between classes in output. So, I'm not using Deep Learning to develop thr model, just simple logistic regression, hence the result is pretty easy to intepret and present.

Have you encountered this situation? How you go about convincing SME?",datascience
o06z5u,1623736063.0,Is linear programming part of DS?,"at a first glance LP seems promising...but honestly the techniques seem really dated....there must be modern tools vs using a simplex method to optimize.

appreciate any insight, and experiences shared

thanks",datascience
o01iho,1623717915.0,Can I set a language preference?,"I’m very much a beginner and learning R and Python but goodness do I prefer R. In future roles, will I be able to say that I prefer to use R over Python or is there not that kind of flexibility?",datascience
nzyady,1623708165.0,Suggestions for BI visualization tool that supports live feed connection from BQ?,"I was looking into tableau online which seems fantastic, but is a little expensive for my needs.  Ive been using google data studio, but its fastest data freshness is 15min, which isnt good enough.

Anyone have another suggestions?

&#x200B;

Thanks",datascience
nzxqxm,1623706694.0,How do you improve analytical thinking/writing?,"Hi

Recently I'm doing my EDA and I found that my analyst is my weaknesses.

My friend said textbooks are the best and I can read more articles published on Towards Datascience, etc secondly.

Just wondering how you guys improve analysis

I'd like to model some great analysts or collect those best analytical writings.

Would you like to share any best analytical articles or your favourite authors?


Thanks",datascience
nzsoi4,1623693335.0,100% Turnover on Data Team,"I joined a new organization in January, and I am now the only member of the data team remaining.

The bad - My boss, the data engineer, and two analysts (the whole team besides me) have all already resigned or are going to be leaving by the end of the month.  Some senior leaders in other departments have also resigned in the last few weeks. Retention has apparently been an issue here for many years, although I have had a pretty pleasant experience working with my colleagues and stakeholders so far. I have only met lots of bright, motivated people, so maybe they are all just getting poached by other companies. My pay is below market-rate.

The good - We have an embedded consulting group that handles a lot of our project management, data engineering, and data analysis, and they are staying, if not expanding in the short-term. We also have a new team lead and department director starting soon. I interviewed the team lead, and have seen the resume of the director, and am confident I can learn a lot from both of them. The work we do here is incredibly interesting and meaningful and I am motivated to build great data products.

Obviously this situation is a cause for concern. Has anyone weathered a similar situation that turned out for the best? Or is this likely going to be just miserable plodding along for the next year or two if I stay?",datascience
nzqoeo,1623688015.0,Any good personal blogs that has quality data science content?,Do you have any favourite bloggers that are professionals and have high quality content that you love reading? Would love to add them to my reading list. Cheers.,datascience
nzo5lk,1623681209.0,What do you use to version control Jupyter Notebooks?,"I\`ve been struggling to maintain version control of Jupyter Notebooks through pure Git because of all the issues of git dffing detecting cell output changes and stuff.

&#x200B;

Do you use any specific tools to keep up a good gitlfow-like version control scheme of your data science jupyter notebooks?",datascience
nznbfn,1623678874.0,Is it possible to use (S)ARIMAX to predict multiple time steps ahead?,"Topic. Given the lack of future covariates, can one use (S)ARIMAX to predict *k* (instead of just one) time steps ahead?

Another related question: Can we use SARIMAX to predict non-negative integer series, such as count of item sale? If yes, how? If not, which alternatives do you recommend?",datascience
nzmrwc,1623677248.0,Why does this linear transformation produces any eigenvector,"Supposed we have a linear transformation
A = [[2,1], [1,2]]
Why does when i use linalg in python and input this matrix it produces eigenvector and eigenvalues when this linear transformation has both changed the direction(amplitude) of the default coordinate system?",datascience
nzlzih,1623674799.0,How many projects are you able to work efficiently on?,"Hey everyone. I'm currently working actively on 2 projects, with 3 more coming up in the next weeks. I've been working with SQL trying to define patient cohorts for later statistical analysis in R. The SQL work has been slow to my liking but I only started working here in January and on a new database, of which I had to move out from after the first 2 months, to another database (same data source but different structure) so I had to redo a good chunk of the initial progress. I would say I've been only making real progress during the past 4 months. Add to that that I have at least 2 meetings a week.

My current contract is supposed to expire by the end of this month, and they'll extend it for another 3 months for me to deliver the first 2 projects, but they still expect me to work to some degree on the other 3 that are coming.

My question is if you feel like they're setting me up to fail on this position or working on 5 projects is actually doable? Obviously I'm going to focus on the ones that they're going to evaluate me on, but considering I'm the first data scientist here I think they're not used to having the vast majority of the time defining the data extraction parameters and cleaning the data, and only a small portion on the actual statistical analysis or ML modelling.

At the time of starting this job I had 9 months of experience, but this is my first job after getting my MSc. I already had some SQL experience but mainly from internet tutorials and some simple joins from my previous position.

What do you think?",datascience
nzkpwk,1623670304.0,Cluster Analysis for Customer Segmentation,"What do you think about a cluster analysis to segment customers? I feel like a manual segmentation is often times better, especially when it comes to more personalized marketing.

I think that clustering makes sense when there are distinct groups in the population. However, I think that these groups can easily be identified by EDA (finding thresholds of certain variables) in most cases. There is a possibility for identifying relevant groups only through cluster analysis, but I think that a) those cases are rare and b) the identified clusters are more complex and not suitable for a segmentation with the objective of a more personalized communication.

Does anybody have a success story where unsupervised clustering led to a customer segmentation that offered a business value (e.g. because of more personalized communication)? I am struggling to imagine a scenario where unsupervised clustering comes up with better clusters for personalized communications compared to manually building clusters by thresholds/criteria for clusters.",datascience
nzigaa,1623661030.0,Is going from a data science job to people analytics (corporate human resources) in the same company a demotion?,,datascience
nzie21,1623660747.0,Alternatives to Cross-Validation,"Hey Guys,

I am currently working on my thesis. In this thesis I work with time series data and use a model based on fused regression estimated on a rolling window. Unfortunately I do not habe enough obervations to utilize cross-validation or even any kind of validation. If someone here could point me on something I could use instead to choose my hyperparameters I would be incredibly thankful.

Thanks in advance and have a nice day.

Edit:
To clarify a little

The task is basically to evaluate penalized regression models against a standard factor model (essentially linear regression) in hedge fund replication.

At every point t I estimate a model based on the data in the rolling window abd use the coefficients as portfolio weights in t+1.",datascience
nzi1lx,1623659149.0,Is there a name for this simple Machine Learning Method? Or a similar one?,"Hello everyone,

for a university project we were given the following simple algorithm and I was wondering if it has a name or is similar to an existing method. I'd be glad if you could leave some comments.

So we have data points with 2 features in 3 evenly distributed categories. One can easily see 3 clusters but there is quite some overlap.

The suggested method wants us to determine 3 centres, one for each category, and categorize data points by determining the closest centre. These centres should be optimized so that the number of wrong categorizations is minimized. (Any optimization methods recommended? There seem to be a lot of local minima so we used scipys dual-annealing and most likely found the optimum but maybe there is a faster way?).

So is there any name for this categorization Method? Or a very similar one? All the methodes we looked at (sklearn) are much more sohphisticated.

We wanted to also use knn as an alternative method and compare the two using cross-validation.

If you have any other ideas I'd be very happy to hear them.

Thanks for reading and have a nice day!

P.S.: Cool to see this subreddit exists. subscribed!",datascience
nzhzxq,1623658940.0,"Data scientists in leadership positions, what are your strengths?","What do you focus on now, and how do you approach new ideas?

Do you have a framework to protect yourself and your team from risky work?",datascience
nzf1fb,1623646625.0,When did you know the data science was for you?,What made you realize that you wanted to pursue data science? Did you go to school for it or did you wind up the field by accident? Was there a certain class you took the sparked your interest?,datascience
nz22z5,1623607313.0,How would you go about building a content based recommendation system with reinforcement?,"Let’s say we’re a company like Spotify and want to recommend songs to you based on songs you’ve listened to.

Say we have a constraint that we don’t want to funnel all of our impressions to a small % of songs (which is likely to occur with user based collaborative filtering), but rather would prefer broad coverage of viewership across our whole library.

We want this to be personalized to each user and we want to iteratively learn as you continue to listen to new songs.

How would you go about building this architecture? What does it look like? What models do you opt to use?

Everything I’ve thought of seems to have some sort of hold up so I feel I’m missing something. I assume we can’t train an RNN for every user due to likely limited sample data (they’ve only listened to so many songs themselves) and computational cost of maintaining hundreds of thousands or millions of NNs. Traditional content based recommendations using like simple cosine similarity may not be able to capture some of the more complex nonlinear relationships without exceptional upfront feature engineering (e.g. I like electronic songs, but only if they’re between X and Y BPM, with female vocalists).

What am I missing? Do we have a good solution for this type of problem?",datascience
nyxfbk,1623594334.0,Tabular sequential and image data. Is there any other type of data?,"Are there any other types of data that we interpret with programming?

I assume theirs multiple different types of tabular data.. sequential is anything with a time series such as audio, & image is a 2D picture is that all their is?


Thankyou",datascience
nyussm,1623585632.0,Weekly Entering & Transitioning Thread | 13 Jun 2021 - 20 Jun 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
nyses8,1623575181.0,Is there a comprehensive overview of ML ranking + recommendation system techniques?,"I am looking to study recommendation system techniques (such as collaborative filtering), and how to build + evaluate machine learning models for ranking (instead of classification) problems. Google search results have been messy so far.

Does anyone have a good overview for these two topics?",datascience
nyj11a,1623538857.0,Julia has rendered Pandas obsolete,Change my mind.,datascience
nyizb5,1623538722.0,Using Jupyter Notebook vs something else?,"Noob here.  I have very basic skills in Python using PyCharm.

I just picked up Python for Data Science for Dummies - was in the library (yeah, open for in-person browsing!) and it looked interesting.

In this book, the author uses Jupyter Notebook.  Before I go and install another program and head down the path of learning it, I'm wondering if this is the right tool to be using.

My goals: Well, I guess I'd just like to expand my knowledge of Python.  I don't use it for work or anything, yet...  I'd like to move into an FP&A role and I know understanding Python is sometimes advantageous.  I do realize that doing data science with Python is probably more than would be needed in an FP&A role, and that's OK.  I think I may just like to learn how to use Python more because I'm just a very analytical person by nature and maybe someday I'll use it to put together analyses of Coronavirus data.  But since I am new with learning coding languages, if Jupyter is good as a starting point, that's OK too.  Have to admit that the CLI screenshots in the book intimidated me,  but I'm OK learning it since I know CLI is kind of a part of being a techy and it's probably about time I got more comfortable with it.",datascience
nyhh3s,1623534366.0,Any successful 1 man end to end stories?,"Hello all,

there is certainly a lot of hype still about Data Science and Machine learning, as somebody who tried ""sour side"" as well (few failed projects because quality of data, not really significant results)

I was wondering if somebody had any success stories, with quick ML projects that had real business impact and were set into process to bring value. Also if it was worth to go down Python way (I have experience doing my master thesis where I used ML) or much quicker way with ""pre-defined"" tools, like Power BI, or those online engines.

Now I got promoted to Business Intelligence manager position, only successful part of ML I did so far was with engine inside of Power BI. Down the line there are certainly some ideas I have, with speech recognition, better assigning employees to customers, finding right time to contact right customer.


But uncertainity of ML and its timing to get it done scares me (for some thing I know I can bring 50-60% of value by doing visual analysis, solving the big chunks of decisions in 10% of the time).


So generally I am advocate of ""ML is hype that is not worth it, and it will stay like this until we have done majority of analysis visually first"". I can see how they are failing in other business unit, where they hired niche data analysts and data scientist, before even having data in db, so it only enforces my thinking.


Also if somebody has in mind employee churn project, thats a no-go with quality of data in HR (not updating positions, wrong assigned managers, not standardized position names...)

tl;dr: is e2e ML deliverable by single person in company as side project, with bringing real value (relatively quickly)?",datascience
nyegax,1623526339.0,YoE to go from entry-level/MS data scientist to mid-level/senior data scientist? (USA),"I'm a new grad MS working as an entry-level data scientist. Most of the PhDs at my company are either at the senior level or managerial, but most also have a few years of experience too.

In general how much years of experience do you need to go from my current level to a senior data scientist and then to the principal/managerial level? I know a few new grad colleagues in SWE who got to senior engineer shortly after one year, but it seems like that trajectory is not exactly the same for DS.

I know this will also vary by company (with some tech companies requiring a PhD for data scientists at the lowest level).",datascience
nye9ya,1623525845.0,Should I take this Data scientist job offer,"I am offered a data scientist job at a budding health startup. As per the CEO job is ""not just about prediction"" but helping them to make a better product. At this new start up: i would be involved in deciding which product would fit vertically/horizontally with the current product, finding and discussing with right stakeholders out side the company, finding/buying data, making models. I sense the CEO is keen to license other models to integrate within the product.

I am fine with product development part but I would like to build model myself. I am afraid if the CEO just lincense other model then i would be end up setting infrastructure to use the models within current products.

Another key point is I am currently working in non mathematics/physics academic lab (where i do not do any modeling), and would like to transition to data science, learned data science through bootcamp/personal projects.

 My concern is would I get stuck within product infrastructure without making my hands dirty!

Edited: for clarity",datascience
ny7wy5,1623507906.0,Anybody using a M1 Apple product for local modeling work?,"Hi,

Not sure if this post violates the on-topic rule, it is DS-related in the applied sense in terms of being a practicioner, sorry if it is considered OT.

I usually work locally on my machine, which has always been a laptop with an i7 or i9 with a lower-end nvidia GPU for small to medium-sized modeling tasks.  I'm going to start a new job soon and will have my choice of work laptop. Big compute tasks can be performed on the cloud, however for prototype/POC work with limited datasets that don't require very intense hyperparameter searches, I typically work locally.

I've been reading some interesting things about the performance of ML libraries on M1 machines and it looks like deep learning packages as well as low level vector libraries and libraries built on top of them such as numpy are very quick these days with the m1.

Is anybody using an M1 machine these days for DS? I won't have time to mess around with complex builds and such, I'm generally somebody who just relies on anaconda to install what I need and make sure all of the packages work nicely together. Is the M1 ""There yet"" in terms of being ready to hit the road for DS work with minimal fuss?

My other question/concern is memory allocation for the gpu cores when using DL libraries. Since the memory is ""unified"", if I have 16 gigs, how is that split between general system use and GPU use?

Thanks!",datascience
nxru9w,1623450020.0,Steps when working with a new database,"What steps would you take to make sense of a large new dataset that has been sent to you?



Had the above question pop up in an interview. So from a data science perspective, what would you do?",datascience
nxn6we,1623437162.0,"Can we begin to understand possible mathematical reasons as to why algorithms like ""xgboost"" and ""random forest"" win Kaggle Competitions, instead of neural networks?","Could there be any mathematical reasons behind why algorithms like random forest and xgboost are known to win Kaggle competitions (i.e. perform well for medium sized tabular datasets) compared to deep neural networks and linear regression models?

Heuristically, here are my general conclusions:

1) GLM (general linear models) perform best on smaller sized datasets, provided certain statistical assumptions are met.

2) boosting and bagging algorithms (e.g. random forest and xgboost) perform best on larger tabular datasets, and do not require many statistical assumptions.

3) deep neural networks perform best on very large datasets, preferably on non tabular datasets (e.g. tensors, pictures, audio, computer vision, text/nlp).

But can there be any mathematical reasons that try to explain these general conclusions (provided these conclusions are correct)?

For instance, suppose there is one response variable and one predictor variable, and when graphed together they look like a sine wave - it seems unlikely that a linear regression model could perform well. Perhaps this is because a linear model can only capture a linear trend? Perhaps it is too hard to understand the exact assumptions required for GLM models to work on real world data, or they are too prone to overfit on complex data?

The same way, is there any math that explains why alphaGO, self driving cars and Google's BERT NLP model are all based on neural networks - and not using random forest and xgboost? Is this because there is some mathematical property of random forest and xgboost which severely hinder their performance on very big and complicated datasets? Perhaps it can be shown theoretically that random forests require an exponentially large amount of trees to model complex data, which is just not computationally possible ... or would surely result in overfitting?

And the same way, is there any math that explains why deep neural networks aren't as successful as random forest and xgboost on medium sized tabluar datasets? Do deep neural networks simply require too much effort to select the right combinations of hyperparameters, and its just not worth it for medium sized datasets when random forests work well given significantly less effort? Are deep neural networks to prone to overfit medium datasets?

Of course, all of this comes to down to trial and error: if a certain model fits the training and test data well - then use that model. But just using mathematical logic and intuition, can we develop some general guidelines that tell us which conditions and types/size of data are favorable for specific algorithms? This could potentially save us a lot of time by directly trying better suited models for the task at hand (e.g. not even trying to use logistic regression for alphaGO).

So in the end: Beyond empirical results, could there be any mathematical reasons behind why random forest and xgboost are chosen in kaggle competitions compared to deep neural networks? And beyond empirical results, could there be any reasons why random forest and xgboost are not chosen for the ImageNet competition?

Thanks",datascience
nxlv5l,1623433624.0,Data Analytics with java,"Currently I’m working for a customer, which only allows visual basic and java. The project I got is to make visualisation, create a report in powerpoint automatically. This should be done easily in python if using matplotlib and pptx-python. Has anyone done data analytics in java like this before?",datascience
nxkfwj,1623429927.0,Question about Data Product,"Hello guys, I'd like to discuss about data product concept or situation in a growing company.

So here is the situation. I am is a one of the data lead in a fast growing company in southeast asia. I bet in this year, we've doubled our MAU and getting the attention of market.

But, right now, in our data team, there are a lot of different spectrum that need to be achieved, ranging from data warehousing, data collection (ingestion), government, into creating data product like recommendation system, fraud detection, etc.

The problem here is, the data team, doesn’t have the skill like project management or PM skill related like scrum or agile methodologies to perform those wide ranging tasks.

Does anyone in this Data Science forum has a problem to integrate your expertise into your product ? Or even doesn't have any idea to breakdown your analysis or model creation into several part of tasks?

Cause, I feel that we are a bunch of experts that having no strategical or tactical solution for managing project.

Does anyone here has a same experience when serving data for product team or your company?",datascience
nxk4vu,1623429137.0,Can someone please help me understand these graphs?,"https://www.nature.com/articles/s41467-020-17280-8/figures/2

These graphs come from the following article on covid-19 and statistical models: https://www.nature.com/articles/s41467-020-17280-8

These graphs show the ""30 Day Risk Probabilities"" of ""critically ill patients"" vs ""other patients"". In these graphs, is a value of ""1"" supposed to indicate ""very high risk that a patient develops covid-19 symptoms""? So basically, these graphs are showing the day-by-day risk that (different groups of) patients develop covid-19 symptoms after their last hospital visit?

Thanks",datascience
nxjdcb,1623427185.0,Are mobile neural nets still relevant?," Is  there any good idea of a mobile app which would require on-device  inference? I can't think of any. In my opinion, MobileNet times have  passed. Now, creating mobile-efficient models are only useful to surpass  some benchmarks. A weird flex and that's all in my view.

It  seems all useful ML-based mobile apps have already been implemented:  face recognition, image filters, sound classification, voice  recognition...

Is there any need for deploying a ML model on a mobile device and not using an external server + API?",datascience
nxi5db,1623423985.0,Is it common to feel like you have no idea what you're doing in an internship?,"I'm a senior at university and I got a pretty nice internship somehow. I keep getting assigned work with nlp stuff that I don't know how to do. I read the theory behind it some time ago and I watch youtube videos, but I haven't had the opportunity to practice yet. Is this feeling of not knowing what you're doing normal? I've mainly worked with basic machine learning in the past, not much deep learning.

&#x200B;

EDIT: Thanks for all the responses guys. I had some anxiety coming in this week and its settling down. Lots of great advice here as well.",datascience
nxc78c,1623405197.0,Comparing a data analyst intern (Bank) offer with IT project analyst (Consultancy) offer,Hi all. I have two offers. One is from a big4bank for a data analyst internship (pays less) but I believe they use state of art technology and there is a lot to learn; The work is all for internal stuff.  The second offer is to work as a project analyst in which I will be working with clients. The company is big but not in the top10 or anything. The advantage of this company is that I’ll be working with clients which means more exposure and connections. They also use near top tech. I'm not sure which one will provide most growth. Any advice appreciated,datascience
nxbx5g,1623404087.0,Neoj4 books,"Hello there I'm a data science student and I was looking for the Neoj4 book for graphs databases and machine learning, being a student I can't get the free copy.
Can someone pass it to me or suggest another book.

Thanks for the attention.",datascience
nx72ro,1623385007.0,"I am looking for a personalization project, can you suggest what new things we can do with some open source data?",,datascience
nx3q3s,1623373978.0,Project lifecycle,"I am still in academics and most of my activities and projects have had limited scope and it's nothing like what I may work like in industry. I would really appreciate if someone can share their experience of working as a data scientist in the industry.

How do you go about finding a problem/challenge/idea of what to work on? What steps does a project go through? Do you follow SDLC kind of methodologies for a DS project? Do you participate in model deployment? What tools do you use?

I know this is not a structured list, but even though I am working through school it is really difficult for me to absorb anything without actually understanding industry practices",datascience
nx1guv,1623367106.0,Euro 2020 Predictions,"I remember Andrew Gelman had a nice little Stan model for the World Cup.  Since the Euro starts tomorrow, I thought I would try my hand at forecasting some of the games.  I'm not a sports data scientist (I'm more of a biostats guy), but I do like Bayes and I do like international football, so I thought what the hell.

To keep myself honest, I'd like to post a few predictions here.  To keep in the spirit of the sub, I am willing to discuss data, models, critiques of either, with you all.

[Here](https://github.com/Dpananos/Euro2021Predictions/blob/main/predictions/predictions.csv) are my predictions for the group stage.  Since its on github, you can see if I cheat and push predictions after the fact.

I plan to make predictions for each major stage and then update the model after that (so the group stage will pass, I'll calculate my Brier score and cross-entropy loss, I'll refit the model, and go from there).

But the real point of the post is to let you all know you're free to piggy-back off my efforts.  Clone the repo and try your hand.  I'd love to learn a thing or two about these sorts of modelling problems from the community.",datascience
nx0ygv,1623365652.0,neural network optimization,"&#x200B;

Hi, I used a feed forward neural network on Keras to approximate a concave one dimensional function , I would like to find the argmax and the max of my neural network, what would be the easiest way to solve this ? Should I implement something myself or does Keras already have some buil in function for that ?

Thanks!",datascience
nx0v79,1623365384.0,What server configuration should I get for Organisational data analytics applications?,"I head a BI department for a startup; well not much of a startup; We are almost a small enterprise now.

Currently, I run a suite of BI applications from my machine. My main applications that are run regularly are:

* MS Office
* Alteryx
* Database (PostGres)
* Python
* Power BI
* Tableau

Its quite capable for what it does however, we are looking to make the access for these tools organisational and hence, we are going to invest in a server where all these applications will reside.

Can the community please help me with the best server configurations for running the above applications seamlessly?

Of course, we are looking to have Windows Server as an OS.",datascience
nwww2s,1623355081.0,What do you do to combat the afternoon slump?,"There was some good discussion in a previous post about not ""working"" the full day.  Im curious to hear for days when there is work to do that isnt entirely motivating, what do you do to keep energy up?  Since I've been with jobs that involve sitting all day, I usually hit a slump around 2pm and am trying to find more techniques for picking up my energy and focus.

Sometimes I'll take my dog for a walk or give myself a 10 minute Reddit break, but what works for you?",datascience
nwv0ve,1623350395.0,Analytical uni project: can't use certain terminology in research paper?,"Hi guys! So I'm enrolled in a university course called Legal Analytics for which I had to do a group research project on a dataset of case law metadata. So our group basically made dictionaries to map existing metadata values to a new label (i.e. apply label x if y exists in metadata).

In order to improve our dictionaries we repeated a certain exploratory exercise multiple times to discover additional values and add those to the dictionaries and after each update of the dictionaries we repeated the labelling proces as well. Ultimately, we visualized this process and the difference in labelled cases between each repetition of updating dictionaries and labelling cases in some line charts. In our draft research paper we referred to each repetition as an 'iteration' and to the process as a whole as 'classification'.

Now, this is where my question and confusion comes in. We've got some PhDs tutoring this course and grading our research projects. A part of their feedback on our draft research paper was about our use of terminology; they basically said that terms like iteration and classification are reserved to machine learning and we shouldn't use those terms in our paper.

This left me not entirely convinced, because while machine learning is all the fuzz these days these terms are surely not limited to the field of machine learning? So, are my tutors right? Are more simple solutions suddenly excluded from using this kind of terminology? I'll be looking forward to your responses!",datascience
nwuzir,1623350303.0,What kind of freelancing jobs can data scientist do?,"Hi all,

I'm building my project portfolios, aiming for banks, advertisement firms..

I have a serious question: what's our competitive advantage as data scientists comparing to those software engineers/web developer?

This question has been wandering back of my head.

For SE, they can find jobs quite quickly even freelancing jobs. More demands for it in the job markets

For DS, you have to be really competitive across mathematics/statistics, software engineering, the domain knowledge. Fairly saying researchers could be data scientists.

My daily frustration is there are more demands for senior DS rather than juniors...

Is there any freelancing jobs for DS?

Cheers!",datascience
nwuckk,1623348732.0,How do you guys approach a new data science project?,"I’m a newbie in data science and I haven’t worked on any real life projects till now.
The projects I’ve completed have been part of some online course where the instructors either give away the solution/approach to the problem or give you a big enough hint so that you don’t think about the approach but just code whatever they say.

I’ve been trying to solve a couple of projects of my own and it’s been hard to build that ds intuition.
Normally, how do you guys approach a new problem? What kind of preprocessing do you do to your data, which model to fit, which metrics to choose? How do you guys decide it? I’d really like if you could help me develop some intuition on this",datascience
nwrtvs,1623342436.0,Time Series for 125 distinct products: Suggestions,"I have north of 100 products with a request to build more accurate forecast for them. For a 1-2 month turnaround, what are folks thought process on the approach: 1) go for each distinct product and determine best model and parameters, or 2) find a higher level hierarchy to reduce cardinality from 100 plus to let’s say 10-12 models which is more manageable.

First time working on a ts project and would appreciate your thoughts. Ty!",datascience
nwrrb2,1623342252.0,Explaining results to the business side,"How do y’all go about explaining results to the business that aren’t what they expected to be? For example, I have a model that is using variable B as the most important for predictions. The business is very upset because they believe that variable A should be the most important for predictions. We’ve showed them numerous examples within the dataset that was used for training as to why variable A is not the most important but they’re still dead set on hard coding that into the code regardless if it doesn’t improve the results. Any pointers here??",datascience
nwnlc4,1623331506.0,Recommender System Advice,"I have a problem statement of designing a recommender system for a pharmaceutical company which also produces healthcare products (vitamins, body care products, etc.). But they don't have an e-commerce website similar to Amazon, etc. Therefore, data collection is incomplete and dodgy to say the least.

Their current approach involves placing adverts on social media platforms like Facebook, Instagram, etc. and then getting/gathering user data from such platform by either using platform specific APIs and/or web scraping.

To design a recommender system for this company, can you suggest:

1. what data/features I might need?
2. which system to use- collaborative/content based filtering

I am new to recommender system domain and this will be my pilot project.

Thanks!",datascience
nwlc2r,1623324765.0,Need some advice on tracking specific words on a website over time,"Hi guys, hope you can help me out with this one!

I'm looking to do some research I've never done before; to track / visualize how many times a word has been mentioned on a website and on what dates they were mentioned.

So for example, lets say I want to get data on how many times the word ""Covid-19"" has been mentioned on a specific news website on each date over the past 2 years. I don't have a clue on how to attach a date to each mention, how could I do this?

Thanks in advance!",datascience
nwkfcf,1623321604.0,Is real-time processing worth it for your analytical use cases?,"Real-time technologies are powerful but add significant complexity to your data architecture.

Find out how to reap the benefits of real-time processing with the least architectural changes and maintenance effort: https://dashbird.io/blog/real-time-processing-analytical/",datascience
nwjmc1,1623318329.0,Imposter Syndrome kicks in for next week interview (Data Analyst),"I hope this is allowed here because the interview I am about to have is Data Analyst instead of Data Science.

&#x200B;

So I have been doing python self-learn. I even took IBM certificate on Data Science. Sadly enough I did not have much experience in doing it. My only IT experience is an Web Developer internship that I just recently ended.

&#x200B;

I am determined to give Data Science/Analyst a try. Now that I will be interviewed for one, my imposter syndrome just kicked in and feels like I might not qualified for the job. What are the good advice for the interview? I have python and SQL skill myself. The company I applied for listed required around 1 - 2 years of analyst experience, also needed work on Azure. This could be my very first data related job, and I wish to overcome my imposter syndrome...",datascience
nwj24j,1623315957.0,How do you remember all the data science/machine learning terms?,"Been studying data science/machine learning for about a year now and struggling to remember all the terms and information like what each model does, validation methods, statistics etc. How do you remember all these terms, what they do and when to use them?",datascience
nwhghp,1623309094.0,Super Basic Question: Filter & Grouping Tool for Mac?,"Hi there, I have a super basic/amateur question and apologies for it being elementary. But I figured that this group would be the right set of professionals to ask. (PS - did I use the right flair?)

I have some basic grouping (sums) and filtering needs for a large CSV data set. (500K plus records). Excel on the Mac is abysmal for such tasks, even though a basic pivot table would accomplish what I need.

Is there any tool out there (could be web-based or local) that fits the bill, and sits between Excel and a full-fledged database? (I’d rather not import to SQL and query it back out.)

Any thoughts/suggestions would be appreciated!",datascience
nwfvo3,1623302727.0,Ways to make money using tech/data skills outside of a regular job?,"Outside of a job working for a company or freelancing online as an employee or contractor.

What other options are possible for a software developer to make money using their programming/computer science skills/data science background?

Any of you using your technology/data skills to make money outside of your regular job?",datascience
nwf2wq,1623299654.0,Shooting for Kaggle Competition Prizes - is it worth it?,"I am thinking about joining Kaggle competitions to try and win money prizes, however I am unsure about the time and money (cloud compute?) it would take to get a real shot at it.

Did you try to join a competition with the specific goal to win money? Any advice?",datascience
nwbzk3,1623289424.0,"Professor cuts me off mid presentation and dismissed my idea, how common is this in industry with management?","Hello, I’m an undergrad student whose been working with my college team doing baseball analytics work. Current role with a few other students had been to look at their pitch sequencing data and to find insights. I had an idea today that I was presenting to them, and I made sure not to overwhelm them with technicals, provided insight into methodology, (didn’t state a value proposition, which is where I probably messed up), but as I’m going, midway through my 30-45 sec breakdown the professor cuts me off and starts talking about another students idea. Doesn’t even let me finish. I was pretty disappointed because I was pretty confident in my idea, but he didn’t want to continue listening.

My question is, does this happen a lot in industry when presenting to management? Do they sometimes dismiss your ideas like this?

Also maybe give me some advice on how to pitch something too, I am planning on scheduling a meeting with those two professors again to give them a full run through of my idea and why it’s useful.",datascience
nw9zkt,1623283212.0,Is it normal to feel guilty when you don't work much on a work day?,"Hi!

Work from home has been wonderful ever since it has been implemented but I've found myself not working much on days like today. I just wasn't feeling like it. I'm not sure if it's a good thing or a bad thing about work from home.

Do you guys have days like this too?

Not sure if it helps but I'm not missing out on any targets, deadlines. Manager is quite happy with what I'm delivering and I might even get promoted next year.
But today I didn't have much to do and I just felt like relaxing and listening to a podcast instead of upskilling or working on left over small tasks at work.
Also, I'm a junior. Just finished my first year after grad school.

Thanks!",datascience
nw9slt,1623282612.0,Association model used as causal models,"Hi,

Now I’m sure I’m not the only one but - although causal models are the holy grail, due to time and cost and laziness constraints all my models are just association models, not necessarily causal but observational in nature.

Easy, so I then communicate the associative nature of model and no DO operator or intervention has been modelled at all.
E.g. recently and elasticity model i modelled observed price % change against qty sold %  change.
But then business takes a mental leap and wants to use they models as if they are predictive of ‘doing’ something e.g. promoting a product in a given week.

So my main question - how do you manage to internally reconcile the somewhat illogical leap from associative model to that model being used as if it is instead a causal model?

Obviously if we say ‘oh no you can’t do that but it sure was a fun model to generate’ we probably wouldn’t have jobs. But then creating causal models can range from impossible to very slow and costly when business isn’t prepared to wait this long.

Do we just accept the mental leap from association to assuming some causal relation at times (in that intervening now will somehow get similar results as merely observing did) and keep collecting our pay checks with a smile?
I’m interested to hear more on this by the ds reddit community as it seems like a pretty large gaping logical hole in our day to day lives.",datascience
nw5ptn,1623271088.0,Predicting when a product will be sold out - is survival analysis appropriate?,"**Use-case:** *A particular product has X remaining items in stocks. Predict when the product is sold out, given both time-invariant and time-varying covariates.*

Is a multivariate Cox regression model appropriate for this problem, where the ""event"" is the product being sold out? What about if the items can be restocked (i.e. by users issuing returns), effectively increasing the stock in the process?

Is there a more sensible approach? I tried to look up something like ARIMAX for non-negative + discrete forecasting to predict remaining stock, but it seems unnecessarily complicated.",datascience
nw4wxh,1623268921.0,"Question: when (if ever) is ""bivariate regression"" useful??","I am retooling and revisiting STATA and came across my old notes on when to use each regression type.

&#x200B;

For when to use bivariate regression, my notes read:

&#x200B;

*""Don't. It's trash. Bivariate (one independent and one dependent) models don’t tell you much other than confirming if there is a strong correlation.""*

&#x200B;

I don't recall ever actually using it, and I started googling - but now I am puzzled.

&#x200B;

Is ""bivariate regression"" just a measure of correlation between independent variable X and dependent variable Y??

If so, when would it ever be useful?",datascience
nvz9f7,1623254305.0,Dynamic model that predicts the best next input variable to ask based on the first two/three inputs,"Hi, I'm trying to construct a model that takes in the first two/three input values from the user and based on those values, decides the best 4th independent variable to ask the user to optimize the time needed to bucket the user into one of the 5-6 different buckets (supervised clusters). The initial approaches that I was considering were bidirectional LSTM/RNN's.. but after reading up on these two, I'm now thinking there may be more suitable/clever approaches to tackles this. Thank you, the deep learning gods of Reddit xx",datascience
nvylxh,1623252560.0,Data project you’ve never worked on before,"If someone at work approaches you to consult on a type of analytical project that you’ve never worked on before, what’s the best way to respond?

A. Sorry, I haven’t done this before and can’t really help you.
B. While I’m not familiar with this kind of analysis, I’d be glad to take a look and provide my input.
C. Send it my way and I’ll make magic happen.
D. ?",datascience
nvvid4,1623244011.0,"Sell me on your physical input set up - keyboards, mice, accessories",,datascience
nvup3x,1623241600.0,What is the correct terminology for this type of survey?,"I have a survey where users rate a number of recommendations. The user does not know that half the recommendations are made by system A, and the other half are made by system B.

I initially thought this was called A/B testing, however, that does not seem to apply. What is the correct name for this ?",datascience
nvs6nt,1623233158.0,Calling out Excel Pro Users,"Dear Excel Geeks, we do have it ExcelTips group, but the mode is not active anymore. So I have created [another one](https://www.reddit.com/r/ExcelTips_ActiveGroup/).

If you are a pro-Excel user, [**you can share Excel Tips and Trick in this group**](https://www.reddit.com/r/ExcelTips_ActiveGroup/). If you starting with Excel you can join as well to follow the pro-users.

Reson I created because if it wasn't for the people who share their knowledge absolutely free, I wouldn't have survived and able to make a career as Data Analyst.

I still remember vividly, when I first got a job as Social Media Analyst in Shanghai, hardly had any knowledge about Excel, [Mike Girvin channel on YouTube name ExcelIsFun](https://www.youtube.com/user/ExcelIsFun/channels), absolutely saved my ass. If you are an absolute beginner in Microsoft Excel, I would highly recommend checking him.",datascience
nvrxp6,1623232196.0,Predicting who someone may want to send a message to,"How would you predict who someone may want to send a Snapchat or Gmail to?

I cant really think how to approach this interview question, can anyone help me get started with it?",datascience
nvn42p,1623212647.0,"This is going to be a rant, so sit back","So, I started my engineering journey with Electrical Engineering but somehow got interested in data science, I learned most of the things on my own, I studied about things required to be in the CS field but felt like I knew nothing and hence asked a few of my CS students to do a project with me so I can learn, they weren't that motivated so I did somethings myself. I was learning and going good doing my own project.

Though I didn't get any jobs in the field because I wasn't having a CS degree to be sitting in interviews plus due to pandemic, the company wants better at a lesser price, understandable to me. Somehow I got some research projects in the field of NLP and work independently suggesting my own ideas depending on the problem statement and Data peovided.

Now, I am in an MNC as a data science and analytics intern, with two other young team members, who are very excited, giving ideas and just TALKING, they don't know how to DO it, ultimately increasing my work because they don't need the job as they are just students and I need it, I don't want any bad impression from my side. On top of that, the project they gave us is of making a recommendation engine, they are not giving any idea, everything is on us.

I can make a recommendation engine like that, item-based, user-based anyone, and can try to build a hybrid one, depending on the data we have. They asked us to look for the domain yourself, it should have a unique feature too because, at the presentation, you have to tell that ""why the product is different"", I mean 8 weeks of time, no data nothing, need an MVP in 2 weeks, data has to searched and it should have a unique feature. Plus this one intern irritates that heck out of me........

Now I am thinking I was better working alone, but I have seen some great teammates, Please advise me anything on this. I don't know the feeling is right or not, or is it the lockdown eating my head. I am willing to correct my thought process but I need some advice from someone in the same field without being judged.

Update: Just got the problem system even broader, they need a personalization system not specifically a recommendation sytem.",datascience
nvm9qj,1623209726.0,"[Q] currently working as DA, company doesn't have any cloud platform or servers","Hi, right now I'm struggling to pull data in order to make reports or any analytics. Everything is scattered around either in excel files or in a bunch of platforms. I just started so I don't have much working experience and I know, you guys, might be able to give some tips that could help me on this. Really appreciate it!",datascience
nviakd,1623196665.0,Advice on types of jobs,"I'm currently looking around for a different data science job and I'm not exactly sure what I'm looking for but I could roughly classify the *types* of jobs I'm hearing about into a few broad categories. I'll list them and give my current thought but I was hoping you could all weigh in with your experience and help me make the right decision.

&#x200B;

1) The BIG tech company. These are your FAANG+M's. I assume that they are the ones doing really cutting-edge stuff and I imagine the work is pretty fun. I also assume they pay really well. I'm not sure if I can get past one of those leetcode interviews though. This one is probably out of reach for me but I imagine I'd take it if I had the chance.

2) The small tech company. ""we just got XXXX Million in funding and just landed a contract with <big company that you've heard of>"". Yeah IDK this is the one that I'm most wary about. I think ""fast-paced"" and ""great for self-starters"" are just code language for ""shitty work-life balance"" and ""poorly organized"". But of course I could be wrong

3) The big retailer/non-technical company that has a whizzbang data science team. This sounds kinda fun but then other times I wonder if it's a little mundane. Anyone actually doing advanced statistical models and ML or are we just A/B testing all day long?

4) the huge non-technical company that doesn't yet have a data science team. ""Yeah we think we could find a lot of business value if we brought on a data scientist"". This is the one I'm most conflicted about. Some of the most fun I've ever had with data science is when I'm working with people who have absolutely no tech background and couldn't even imagine what was possible. I think in the right situation you could really be hot shit around there. The thing I'm most worried about is that you'd soon run out of things to do. With some of these places the work they describe sounds more like a 3-month project than a career.

&#x200B;

What are some of your thoughts?",datascience
nvhtly,1623195275.0,This one thing could be holding back your career in Data Science...,"Ever thought to yourself that even though you are perfectly capable at your job, or maybe even the most knowledgable person, you are often underestimated in your role. Or worse, you find someone else (even though less capable technically) making the decisions and telling you how the project should be handled. You want, ask and expect a new opportunity or an exciting project from your leadership, but you simply watch them go to someone else in quiet despair.


You feel under-appreciated, ignored, and mostly misunderstood. You probably have several great ideas for your company, but if only someone were to listen to you.


I work with several people in Tech, IT, and Data Science, and this is such a common problem that I encounter.


The reason for this is ‘Perception”. See, there’s a big difference between being an expert vs being perceived as one. Being an expert will help you excel in the opportunities you land in, but how people perceive you is what will land you in opportunities in the first place.


Almost everyone is focused on honing their technical skills, which by the way is a great pursuit. But most ignore the art of basic persuasion and charm which keeps them from getting truly satisfying roles and opportunities.


So how does one gets perceived the right way…?


It has to do with the way you communicate. Experts have a way of talking that automatically demands compliance, respect, and conviction from others. Think of your last visit to a doctor. Did you argue with the doctor, or just wondered in your head that they probably know nothing, or simply dismissed what they asked you to do? Instead, you complied with whatever you said.


Effective persuasion is a learnable skill. Once you make a few key changes to the way you communicate, the environment around you and the way people treat you changes dramatically. You will command respect and unquestionable trust that will get you elite opportunities in your industry. So you can later prove it through your capabilities.


When you present something, people will just tune in to your reality as you speak. In fact, they literally will come to help you with your work even when you don’t ask them. All of this happens subconsciously when you know basic charisma and persuasion.",datascience
nvhi9a,1623194366.0,How important is it to have a good grasp on scalable databases as a data scientist/ML engineer?,"I know that knowing databases is crucial in this area but what is about more advanced topics like scalable databases?

Keywords would be: Hadoop and MapReduce, Spark, parallel and distributed databases, Data warehousing

This is an advanced course on databases at our university so I wanted to know how important such knowledge is if some one is lets say working as an ML engineer/data scientist.",datascience
nvhd0j,1623193917.0,[Q] How do you version control datasets?,I am curious to know how everyone version controls their datasets in projects and research projects?,datascience
nvgbn4,1623190970.0,knuckle Dragger seeking advice - On what courses to take so that I can analyze data on the SP500.,"What I am looking to do:

1) Scrape data of SP 500 company names and prices at specific date and end date.

2) compile the data.

3) organize companies by return over a 10 year period.

my goal:

 see what % of all SP 500 companies end up with different returns.

For  example, what % of companies end up being 10x or being removed.

Thanks in advance. I haver zero skills related to this.",datascience
nvfy81,1623189997.0,Testing GPT-3 powered survey tool - feedback and thoughts?,"Hi!

I'm building a tool that asks personalized follow up questions in order to get detailed survey responses. It's powered in part by GPT-3 (created by OpenAI). If you're open to testing it, it takes a couple of minutes...and I welcome feedback.

It's imperfect, but that's why we're testing ;)  Please DM me for a link!

I'd also love to hear your experiences building standalone AI products like this.",datascience
nvcn3w,1623181695.0,Brainstorming a DS Case Study from a big pharma company,"Hello all, not sure if this is allowed here or not, but I received a DS Case Study from a big pharma company in USA. I just wanted to see if there is anyone experienced in doing case studies and might want to help me brainstorm the problem and discuss possible methodologies and aligning the solution.",datascience
nvafx3,1623175793.0,Data Science projects for local governments,"A friend of mine is going to make a presentation to an Indian state government on how it can better use data, and how data may be used to have more effective policy and decision making for government bureaucrats in the Indian state.

To achieve traction with the bureaucracy, the focus needs to be more on projects and topics that will lead to ""quick wins.""Show some quick results; make like for the bureaucrats/policy makers perform better; and enable a virtuous loop where they can see how data can help in an efficient manner…. rather than being long projects that rarely result in concrete measurable benefits.

What are some projects/ topics that you would suggest? Maybe you have worked on some for local govts in other countries or in India itself. Any links and suggestions will be helpful

Note that most of these bureaucrats/policy makers are not coders; and data they have access to is often not clean. Many data bases do not talk to each other and there are data inconsistencies as well.

Any ideas and suggestions are much appreciated!! Thanks in advance!!

&#x200B;

EDIT:   Also: My friend's NGO will support with some data science volunteers…they will do the data cleaning and analysis… looking for some initial ideas that you think may lead to interest from bureaucrats/policy makers ",datascience
nva6p2,1623175106.0,Open dashboards for app data analysis,Need to analyse app data for work and showcase it on a dashboard. Don't have a lot of experience in it and would like to see how similar data has been analyzed before. Are there any open projects/dashboards that you are aware of that I could use as a point of reference? Any other resources on the same are also appreciated. Thanks in advance.,datascience
nv9xlh,1623174416.0,How do you document your datasets?,"Sometimes I fell 90% of my time is spent in data wrangling/munging is on data exploration - and most of that is spent trying to make sense of fields created by some long lost business logic or trying to discover how that dataset came to be.

As a consultant, I cry tears of join when I see a team that keeps a data dictionary or a well-organized catalog. Even if on Excel.

What is the best documentation practice you've seen?",datascience
nv8fwf,1623170482.0,"Datacamp vs edx, which would you recommend and why?","As the title suggests, there are a lot of good reviews on Datacamp, however, i've taken courses on edx before and they are amazing. There are a few from MIT and IBM etc.

for a beginner, what would you recommend and why?",datascience
nv6d5y,1623165607.0,"Startup went bankrupt, need career advice","Good afternoon. I am facing a challenging situation on my career now and I would like some advice. I will provide a very brief summary of my experience.

First of all, I am based in Portugal, Europe. I have a a Mechanical Engineering Degree focused on Energy Systems  (With a bunch of optimisation, ML and numerical simulations mixed in, including the master thesis, as well as years in extra curricular activities revolving around Python and ML projects.). I have 2 years and a couple of months experience in Data Science in the following roles:

1- Data Science Consultant for 1y and 2m. Role included developing a genetic algorithm, time series analysis with LSTM, Prophet and Arima, as well as a Big Data project on Databricks and SQL. I started feeling like I wanted to be part of internal Data Science team, so that I could really own my projects and that is why I left for company 2:

2- Data Scientist for 7m in an Energy Related Company. Me and another person were brought in to start a Data Science team.  This company was not a technological company and, there was not much to do really. We were supposed to get Data to start working on some use cases, but after 7 months we did not have any data nor any indication that we would have in the future. During my time in there I explored outlier detection methods like Isolation Forests and LOF, did a local web page using Flask, Javascript and Bootstrap, and also worked on some data cleaning and process automation pipelines. I had an offer via a recruiter that contacted me on Linkedin that I felt would make my job much more meaningful, and at the time it was very hard for me to justify not taking it, so I took it.

3- 7m Fintech Startup. This was pretty much what I wanted in a Data Science Role. Build a model using H20 AI for client grading and well as lot of other analysis for managing client and portfolio risk. I felt like my job truly mattered and I was extremely satisfied with it and super excited for all the possibilities that I would have, but due to a very unexpected issue with financing we ended up closing after 7m on the role.

More and more I have been craving time to truly dedicate myself to learn and develop some personal projects, mostly related to crypto and financial markets. My question is, can I afford to have a gap on my CV, assuming I fill it with personal projects or do I need to start looking for jobs immediately? Also, since I left university  I wanted to start an international career and move to Germany, Sweden, Switzerland, Austria, UK... ( I have been learning German for 2 years). Would this be a good time to truly try to move? Do I even have a chance if I just send CV's from Portugal (I am wiling to reallocate) and get a job on any of this countries before I move or would I really have to move there before I start trying to get a job?

Thanks all!",datascience
nv5jk1,1623163128.0,CSO Option VAR model,"HI there all,

First time poster and so sorry in advance for misdemeanors. I work in a commodity trading company and have been tasked with building / sourcing a CSO option risk model, in this case the spread is a time spread between future contracts for Crude Oil.

I have a pretty good understanding on VBA and there are people at the company who can work with Python etc. We have a SQL database of future prices for the various contracts as well as the volatility / delta / price of each options contract, from outright contracts to the CSO options.

Is anyone able to give me advice  / help on how to go about building this? Seems to be a MC simulation, but my only experience with that is using Matlab (engineering degree) which I have been told is not an option due to licencing costs.

&#x200B;

Thanks,

&#x200B;

thpj20",datascience
nv589x,1623162309.0,Research or Internship in prep for phd applications?,"
Hello all, I’m currently an undergraduate stats major who will be a junior in the fall. My goals is to apply to PhD programs in senior fall. If I wanted to look at opportunities for the summer prior to it, should I look into doing research within say the stats dept? Or should I be trying to look for an actual internship at a company? My research interests are within statistical learning, so I was thinking a research role would be better suited for me than some data analytics position at a company.

I feel that it will be hard for me to get on any papers or do research because I won’t have a ton of theory knowledge, but I’m hoping I can get on something more applied.

So what do you think? I feel like trying to get a research role would be better when applying then doing SQL all day at a company for a summer, chances are even if I expressed my case as I want to do some more data science and quantitative sort of internship it wouldn’t be as good as if I did research with a prof.

I will be applying to stats phd programs.",datascience
nv4uuy,1623161320.0,Reccomendations on vulnerability scanners.,We are running a kubernetes based development environment where data scientists are free to work on anything they deem appropriate. We need to ensure they are not introducing vulnerabilities. Does anyone have any tools they recommend for continuous scanning and reporting?,datascience
nuxm2s,1623131460.0,"What benefits can I have as a Mechanical/process engineer, if I have knowledge/skills in data science?","Hello all,

Im working as a process engineer in a process equipment manufacturing company. I’m still in the 2-3 year experience category.

Most of the decision making for which equipment to select in my company is done through experience. They say it’s important to also develop a feeling for how the product runs and machine behaves. I feel like this decision making can be replicated by analyzing the past data.

So I’m interested to learn data science and statistical analysis, I have experience in programming in VBA, bash scripting and can implement algorithms in any programming language, thanks to stack overflow.

Does it help to have this skill in addition to my general process engineering background? What benefits can someone like me have with this addition.",datascience
nuwn27,1623127796.0,Tableau vs Amazon QuickSights,"I know Tableau very well and is my preferred tool. But, I noticed there's a cheaper option from Amazon. Any input from your experience is appreciated.",datascience
nuw45a,1623125883.0,People you work with,Just wanted to gauge how much data scientists like working with their colleagues? I've been interviewing for various positions and have been disappointed in the people interviewing me. Most of the time I'm not treated respectfully and subsequently haven't been able to see myself working with the interviewers. It's turning me away from joining the profession.,datascience
nusz8e,1623115592.0,[rant from a hiring manager] MS in Buzzword programs are a waste of money,"I'm a first time hiring manager and I'm hiring a Data Analyst. I've reviewed hundreds of resumes and talked to dozens of people to calibrate myself on what people from different backgrounds are like.

Call me a purist, but I don't think it's possible to do good quantitative work if you don't understand how the models work from a basic mathematical perspective. For example, you should be able to answer the following questions about any given model you use in your work and mention in an interview: how should residuals be distributed in any given model you're using? What does a p-value actually represent in mathematical terms? What are the assumptions around independence of your predictor variables for any given model you're using? What diagnostic tests should you run for any given model and what hypothesis are each of these testing? And more. If you don't understand these things, then you are going to build an overly complicated model that is completely overfitted, as opposed to a more generalizable model that can be applied to multiple datasets.

The number of people I've talked to who have a MS in Business Analytics who say they're doing ML but then can't explain these basic underlying assumptions of the models they build is astounding and pitiful. It doesn't matter how prestigious the school they went to--I've talked to people with degrees like this from both Ivy League schools and from lesser known schools and it is all the same. I'm not trying to trick people with obscure trivia or anything; when I ask them to tell me about a project they worked on, they tell me ""I built \[insert model\] so I could \[solve whatever business problem\]"" and when I follow up with ""what are the underlying assumptions for \[insert model\]? What kinds of diagnostics did you run for that model?"", they get completely tongue tied, even for the basics like logistic and linear regression. The only things these people ever check for with diagnostics is ""sensitivity and specificity"" and ""area under the curve"", which barely scratches the surface in determining whether or not your model is good.

I've looked into the requirements on these programs (both when I was choosing a masters program a few years back and also more recently as I've been interviewing people) and none of these programs require people to take any courses that would actually prepare them to build models thoughtfully--just courses like ""SQL for Analytics"", ""Tableau for Visualization"", and super tool specific classes that (a) would be super easy for a reasonably smart person to learn on the job and (b) are not going to give them skills that will be longterm valuable because the tools we use change all the time--underlying mathematical principles do not.

So.... if you're thinking about getting an advanced degree to get more out of your career in this field, do yourself a favor and choose a program in a REAL ACADEMIC FIELD (ex: statistics, math, computer science, engineering) and not Some Buzzword That's Super Hot Right Now. No one will care about your bullshit buzzword degree 10 years from now. At the bare minimum, choose a program that requires you to take classes that are well founded in probability and mathematical statistics and not just plugging random shit into R or Python hoping that you'll be able to \~predict the future\~.",datascience
nus823,1623113210.0,Environmental Work,"Hello peepos,

I’ve started an internship with territorial bureau of statistics that has me doing broad statistical work. It is my intention to get into the environmental field with a strong statistical background when I’m done. I’m wondering if any of you beautiful folk work for Mother Earth and could offer some guidance. (Or any “green” company of sorts. :D) For now, I’ll be be honing my GIS skills, dashboarding, database management and intensive math, like survival rates and differential equations. Any big topics I should be studying as well?

Ty",datascience
nurs3c,1623111790.0,DS take home assignment requires building an entire project using skills I don't have,"Hi everyone! I have been a lurker in this community and it has been super helpful in more ways than I can count. Recently, I spoke with a company for a DS position and they sent me a take home assignment a couple of days ago.

It involves building an full-fledged ML web app from scratch. The steps include:

1. Loading tables in a SQL database
2. Training a model that predicts an outcome, and
3. Building a REST API that would receive data and post predictions based on the model I trained above

**In addition they state that it should take only 3-4 hours to complete this. REALLY????**

I do not have any meaningful background in building web apps and servers. This is pretty clear from my resume. Also, the job description did not mention any such requirements or skills for this particular position. Although, the company has an interesting product, I feel I would be wasting my time working on this assignment given my lack of skills. I wonder if I should rather spend my time working on other applications/assignments/interviews rather than doing this.  I feel really uncomfortable and honestly a little angry that they've asked me to build an entire project from scratch.

Would love to hear if y'all have any recommendations and thoughts about what I should do. Thank you :)",datascience
nukktk,1623092753.0,"Calling it now: a few years from now, ""data engineering"" will be just as overhyped and saturated as ""data science"" is now.","I see this on Reddit every single day: someone saying something to the effect of ""data science is over-saturated and not that interesting, I'm transitioning into data engineering where there are more jobs."" I don't blame people for being burnt out on data science and looking to go where the fields look greener, but we all see what's happening here, right?

Combine this with Reddit's (and the tech community in general) tendency to have a massive hard-on for anything ""engineering"" and I think we're seeing the beginning of a trend we've all seen before. In a few years we'll all be back here (or maybe in /r/dataengineering ) saying ""data engineering is oversaturated - that's why I'm moving into...quantum skunk wrangling"" or something.",datascience
nujq7q,1623090608.0,Reporting change of percentages.,"So you’re reporting out weekly kpis... you want to report out WoW change. The metric went from 4.7% to 6.3%. How would you show the change?

[View Poll](https://www.reddit.com/poll/nujq7q)",datascience
nufkw3,1623080422.0,Is it okay to forget a language if you haven’t used it in a while?,,datascience
nue01q,1623076428.0,"Data Science and Data Analytics is becoming ultra glorified / romanticized, and I don't think people are really told what they are getting into.","I honestly, don't think people wanting to break into Data Science really know what all it entails. It just sounds good, and sounds like it will make them lots of money.

No one tells people what comes with the job. There are a lot of headaches that come with it, and you have to be a very patient person.

When any person starts out in IT, they learn some psychology. How to manage users and their expectations. You learn what to say and what not to say. You learn how to appear confident and reassuring even if you're getting up to speed in the moment. The good ones do anyway.

Data Science, BI, DA - you have to have those skills multiplied by ten. You have to be better than the rest at managing expectations. You have to learn how to avoid support drains, and be thinking ahead all of the time.

The data science people are the only people I respect as much as the people in Systems. Because other fields, you learn one thing and only one side of it, call yourself an engineer despite knowing one side. Sys Engineers have to know a little about everything and base knowledge in all kinds of things/ They are constantly growing. Data Science folks are similar because they have to know a wide assortment of things, and they have to know all of the tips and tricks at their disposal to get their desired result. Which means they will know Python, multiple types of SQL, Pandas, Jupyter, and so on. They'll pivot in Excel in a pinch if they need to.

But the main reason I respect them is just because of how patient they have to be to want to work in their field for 30+ years.

Our DA left in 2018 and one of my roles was a senior DBA, so they just put her job on top of mine. I learned a lot and I got very good at SQL and streamlining and reducing task turn around for reports and data tasks. But I obviously didn't have the time to dive ultra deep into the rabbit hole, and I didn't want to. Because I knew it wasn't for me.

We were acquired, and I transitioned all of that stuff onto the BI team of the new company. I have so much respect for those people. I am still answering questions and taking one off requests. This morning I was just hit in the face with how much I dislike actually doing he DS/DA side. A Sales Senior Manager needed something with some data. I asked a follow up question. I needed a key piece of info to ensure I did the right thing and didn't have to do re work later. They said they would get it to me later.

They emailed it to me at 7:11am this morning, then messaged me before my shift - ""Hey, I don't see the data task with the blah blah being done. We needed it 6/3."" And I am thinking - then why wait until 6/7 to give me the info. We got the request 6/4, and I asked you on 6/4, then you waited the weekend to get it to me.

And those individuals who just keep coming back telling you the data wasn't what they expected or wanted when it is what they asked for.. I'm so happy to be just a senior sys engineer again working on large scale infra.

It's not for everyone, and I think they need to talk about and teach managing expectations so you don't shoot yourself in the foot. Luckily the BI team of the new company are phenomenal, and now I am out of the game.

But I am learning more Python at home in my spare time and things like Jupyter so I don't regress skill wise. Python is useful in what I do anyway. I've rewritten several PS automation scripts in it.",datascience
nubt22,1623070408.0,Best alternatives to 'shap' package?,"The shap package has been great when it works, but I would like an alternative package that has similar functionality. I mostly use gradient boosting, so any package that can use the tree-path methods (interventional is nice too, but not as important) would be a life saver.",datascience
nub8j8,1623068706.0,Visual Cleaning tool - Time Series,"Hi! Looking for a suggestion on a visual cleaning tool for time series (or any) data.

I am running my raw data through a time series decomposition to pick out some potential errors in the source, but ideally it would be nice to have something interactive to work with to validate the errors and add more.

Trying to avoid writing a bespoke thing in dash but I can ultimately do that if it comes to it.

Not bound to a platform but python is preferred, or even something electron based.

Thanks!",datascience
nu8eui,1623058907.0,"Apart from kaggle, where can I find data science challenges/projects?",,datascience
nu7uz0,1623056443.0,I was wondering about this problem and wanted to know if it makes any sense lol,"So suppose you have  different data sets that are not connected to each other via a ""primary ID, for example:

df 1:  Numerical data of medical records of patients (e.g BP, Sugar, etc)

df 2:  Objective and subjective records by the patient.

Now we have to match records from the df2 to that of df1. How can we match these two dfs without having any ID.

&#x200B;

It can be data of anything, website data or exam data, etc. Let me know how would you approach this problem.",datascience
nu52fh,1623044517.0,What tools are available for personal use?,"I have some data, mostly in excel that I would like to build some dashboards for and break down into understandable pieces.  But it seems like most tools like Tableau don’t have a free/personal tier/option.  Are any tools approachable for someone without deep pockets?",datascience
nu4deh,1623041943.0,Horn’s Parallel Analysis in Python: Am I doing it correctly?,"Hi all, been learning Factor Analysis for the first time using datasets from Kaggle. I’ve been using Factor Analysis to break down the dimensionality of the datasets, and want to justify the number of factors to keep with Parallel Analysis (other than Kaiser Criterion and Scree Plot).

There’s literally nothing I can find on Parallel Analysis (PA) in Python, so I read a paper called: ‘Parallel Analysis: a method for determining significant principal components’. It suggests generating a random matrix with the same number of variables and samples. After standardising my dataset, I randomly generated normally-distributed numbers with mean = 0 and dev = 1 for my random matrix, hoping to extract the eigenvalues of the random matrix and perform Parallel Analysis. My end Scree Plot  result of the synthetic data was very lackluster - almost a horizontal line with eigenvalues all close to 1 (basically I would be doing a glorified Kaiser Criterion comparison).

So have I done something wrong? Are there any resources on PA in Python?",datascience
nu1go7,1623031677.0,How much coding do data scientists do in a day?,"I'm planning to become a SWE but have been developing carpal tunnel syndrome symptoms, and I don't want to risk wasting my time learning software programming if I'll still always have recurring CTS in the end and can't code for hours a day. I'm also interested in DS but I understand that there is a coding aspect to this job as well.",datascience
ntxx3j,1623020033.0,Data Science Coding Standards,"I know there's a lot of different tasks people do, but I've generally worked on code bases that utilize many models, and our data has hundreds of variables. I've seen some guidance that if you've written any more than 10 lines of code it should be its own function, and that just seems insane to me.


Obviously it's a balancing act and you shouldn't have functions with thousands of lines of code, but I've seen plenty of \~100-200 line functions that generally define either a clean group of variables (say defining the \~15 inputs to a specific model), or a business process that's a bit complex but one clear process as you'd explain in English. I've seen code that follows the paradigm of keeping functions short and I've ended up trying to search for how a variable is defined and literally following a path of 10+ functions to find the answer.


I know it's a balancing act and you can say it always depends on details, but I didn't know if people could share their thoughts and whether in their actual day to day work they tried to follow the small function paradigm or whether the way I work is closer to how people handle their coding standards.

Edit:
Seen some posts about functions doing 1 thing and that's basically what I'm trying to figure out. Is ""prep data for model x"" considered one thing? Say you have 15 variables that all take 1-5 lines of code (and in my current project we have hundreds of models with ~15 variables each and not a ton of overlap). My opinion is that a function that defines those 15 variables is ""doing one thing"" and much easier to read/understand and maybe have to use the scroll wheel once or twice than to trace through different functions which are often factored into different code files. Do people tend to agree with this? If not how would you refactor such a function? Would you just have functions called prep_variable1, prep_variable2, etc some of which are one line long and called exactly once in your code base?",datascience
ntuj7e,1623010532.0,Which dimensions are you probing when talking to a company about a new job?,"Hi!

Interviews are not only a way for the company to test candidates, it is also an opportunity for the candidate to decide if the company can be a good fit or not.

I am going to have the first round of interviews next week with a medium-sized financial service company (they're opening a new medior/senior data scientist position).

Besides questions around the job content,  I am thinking about probing the following ""meta"" dimensions to detect potential orange (or red) flags:

\- size/seniority/background of the team

\- company culture

\- how mature is the organization in terms of data storage and management?

\- where does the data science team fit in the organigram / how close you are to key stakeholders?

\- Where does the company see the data science team in 5 years?

And you, what are the key dimensions that you are probing when you talk to a company about a new job?

&#x200B;

EDIT: Thank you so much for all the valuable answers. They are incredibly helpful!",datascience
ntptf0,1622997655.0,Standard Python Resources for Data Modeling,"Are there any mainstream python libraries which, given data from some source, suggest normalization schemes for data (e.g., recommended table structures for a 3NF or star schema in an RDBMS), profile relationships between fields for cardinality (x% of the time this field has a 1:1 relationship with this other field, the remaining y% are missing data and 1:many relationships), or complete other data modeling-related tasks?

I could cobble together some of this functionality using builtins/pandas/numpy etc. but am looking for industry-standard tools that data scientists use for the kind of “lite” data modeling that comes up on the job. (People’s personal GitHub repos for these tasks are OK but not exactly what I am looking for.)

Here are some sample cases to clarify:
1. You received a huge, raw denormalized extract from somewhere and will continue to receive incremental files on a regular basis. You want to create a profile of the initial data, use said profile to make some tradeoffs to “tidy” the data into an RDBMS-suitable format (maybe force 1:1 relationships where they exist 99% of the time for instance or fix overlapping datespans), and then monitor subsequent incremental files to ensure the underlying data profile had not changed drastically.
2. You received access to a new database with no documentation and little support from DBAs or the business on structures. Assume there are not keys or constraints defined in the RDBMS itself to leverage (perhaps the database was created/maintained by a skilled business user without DBA-level skills). You would like to create an ERD or some other documentation on this database quickly.

The focus on RDBMS as the endgame is because the goal here is to support analysis by a BI team that is skilled in SQL but no other programming languages.",datascience
ntnan1,1622990636.0,I got a DS related internship at HP!,"Hello all! So recently, I started working at HP as a product management intern. I know, that’s marketing, not data science, but I’ve spent the past two weeks learning all about it, and I find it very interesting.

So, for context, I’m a senior and this is my first PAID internship. I’ve done 5 unpaid internships over the course of 3 semesters before this in hopes it would land me a real one, and it actually did. I spoke to a HP recruiter which gave me a contact at another company. After 3 months of speaking to several people at the other company, just to result in my intern application being rejected, I returned to said HP recruiter. Their website had no internship that fit me, so I spoke to her directly, which led to two interviews and an offer. And after viewing my work profile, I saw that said internship was meant for an MBA candidate, not an undergrad. Therefore, I’m guessing my experience made up for what level of education they were looking for.

Thus, I signed on to be a marketing manager/product management intern for the Z by HP division. And Z makes computers for data scientists, like high gigs of ram, more core processors, and intel gold (and probably some other stuff, but my tech knowledge isn’t super expansive). And while working with them, I’ve interviewed a lot of DS professionals about their computer needs and what type they use. Also, about what SW stacks they like, and what language they code in. And there has been quite a consistency amongst their answers.

Therefore, if you are a DS undergrad/graduate looking for a job or internship, I have some advice for you:

1. Diversify your skill set. Most people I spoke to didn’t have a DS degree, rather they started their careers, something went wrong, and they made a career shift to DS. It was easy to switch to because from what I can tell, DS is growing, all companies are dependent on some sort of cloud, and python is their preferred code language. So with the influx of people entering DS, if you started in DS, learn for than one coding language, and make sure you can use a variety of SW stacks so that you can separate yourself from the competition.

2. Take an unpaid internship (only if it is worth it). Like I said, I’ve had 5, but I quit one early. The reason is if you aren’t going to pay me, I’m not going to perform work I believe a paid person should (which I know, is technically any work, but just watch where I’m going with this). I quit one because there was no way I was going to be at the stadium 3 hours before the game starts, run around setting every event table up and it’s accessories, miss the entire game because I have to help people the entire time, not have a break, get off at 11 pm, not have a parking pass, and on top of that only be fed a mini Jimmy John’s sandwhich.

But, there were others where I liked what I was doing, and they only required 10 hours or less work a week. I’d never advise anyone to work 40 hours a week for free, I wouldn’t advise even 15 hours a week for free. Just a few internships to pad the Resumé, but most importantly, actually provide you with some knowledge that will be applicable to your next job.

3. Apply even if you are not qualified. This applies to both internships and scholarships because I’ve gotten my way with both. These things provide too much for you not to try. I almost didn’t apply to the scholarship that takes care of all my tuition for my last two years of college, but I did. I almost reach back out to the recruiter that led to my internship now, at a company that will pay off the few student loans I do have. Hell, I almost didn’t apply to transfer to the university in at now after my freshman year at one I didn’t like, but was the epitome of “safe”. So believe in yourself and pull the trigger. This saying be be shot to hell but it’s true: you only live once (unless you believe in reincarnation, but you still only live THIS life once).",datascience
ntk7dk,1622980831.0,Weekly Entering & Transitioning Thread | 06 Jun 2021 - 13 Jun 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
ntj7md,1622977058.0,Thoughts on Julia Programming Language,"So far I've used only R and Python for my main projects, but I keep hearing about Julia as a much better solution (performance wise). Has anyone used it instead of Python in production. Do you think it could replace Python, (provided there is more support for libraries)?",datascience
nthz8k,1622971911.0,Is there any correlation between Supply Chain Management and Data Science ?,Edit: Thanks a lot for the people who have replied to this post. I now got a brief idea.,datascience
ntasnn,1622944067.0,Portable Laptop Wifi,"Hey, everyone! So I'm about to update my laptop that is long overdue to hit the trash, and I'm thinking about how, logistics wise, I do my schoolwork at work. The issue, though, is I can't use that laptop to connect to the internet. By go-to makeshift solution was to google or search stuff through the work computer and use my personal computer to do Jupyter Notebook stuff, which doesn't require the internet to work, but that doesn't work for things such as using StackOverflow, where they want screenshots or wanting to see the exact code used.

So my  question is, is there a way to bring Wi-Fi with you so that you can use your laptop on the go? Is there anything I can buy? Thanks!",datascience
nt8i82,1622936417.0,"I’m doing an excel project for a job interview, and I’m supposed to do a presentation that includes my “process and methodology.”","My methodology is just making lots of pivot tables. What do they want to see?

More info: they gave me a list of a dozen questions to answer. All of which were easily answered by cleaning up the data and then making pivot tables. I submitted a report in excel and now I’ve been asked to present my findings. They said my presentation should include my methodology and process. I’m kind of stumped for how to include it in a PowerPoint presentation.

Thanks for any insight.",datascience
nt8cg8,1622935898.0,"I got my first internship as a Data Scientist, at Amazon !","I'm graduating next year from a CS engineering school in France.

I was contacted by a recruiter on LinkedIn for a Business/Data Analyst role. I applied to it, had a few tests in SQL/Excel, and video interviews. Got the internship.

Then, I had my first call with my manager. He told me that we would be doing some descriptive analytics, but also predictive and prescriptive (basically ML) analytics if I was willing to. He then asked me about my expectations for the internship, and I told him that I would like to do a lot of DS/ML work, instead of BA/DA. Luckily, since he's the one responsible for DS in the team, he agreed and offered me to do a DS oriented internship instead of a BA/DA one.

&#x200B;

And that's how I got an Amazon DS internship, without even completing DS-specific tests.

I'm starting my project on Monday, I feel kinda scared lol. I don't have much experience and have only implemented a few clustering algorithms and linear regressions, but I have some theoretical knowledge on more complex stuff. Since it's going to be my first 'real' internship, I don't know how it's going to work, but I guess I'll just Google anything I don't know when I need it.

&#x200B;

I still can't realize the opportunity it is, and hope it's going to launch my career in Data Science ! All of my friends are mad jealous",datascience
nt85ct,1622935273.0,"Lifetime, reliability and performance testing","Looking for suggestions on either books, courses, websites etc. that cover things like:

* Survival analysis
* Reliability testing
* Lifecycle testing

Would be great if implementations were based on python/R.",datascience
nt7t2p,1622934203.0,How do you know if you're writing a good code or a bad one?,"Hi!

Few months ago, I started working on a project that requires me to use R to fetch, clean data, do some feature engineering. I'm able to do whatever is required but I'm not sure if my code or rather code snippets are ""good"" or ""bad"". I'm not even sure what good or bad means but I've seen these words thrown around.

Can more experienced people of this sub explain to me what qualifies as a good code?

Thanks!",datascience
nt3g36,1622921536.0,Deciding a classification algorithm,"I am new in Data Science so please excuse my limited knowledge. I am learning more about classification algorithms and how to appropriately selected algorithms for your task.

According to this website, [Classification Algorithms](https://blogs.sas.com/content/subconsciousmusings/2020/12/09/machine-learning-algorithm-use/), the author says, ""When the classes are not linearly separable, a kernel trick can be used to map a non-linearly separable space into a higher dimension linearly separable space."" So do you just check if your class is linearly separable or the entire dataset? In any case, I could not find a proper source that would explain clearly how do you go about checking linearity of the data, with actual implementation, can you help how to achieve this?

Further, a lot of blogs and tutorials mention that when you are selecting a classification algorithm you have to consider dataset size, distribution, computation time, data type of attributes etc. but I came across a notebook which was authored by a university professor wherein he used almost all algorithms, like SVM, AdaBoost, DecisionTree, Random Forest, Bagging, Boosting etc for the same project. Does it make sense to use all of them straightaway?

Is there like a resource that can help in making a decision, I did come across a few cheat sheets that have a flow chart but they don't seem to be in-depth.",datascience
nt1s22,1622916829.0,Salaries in Spain (yet another post like this),"Hi all, I'm interested in salaries in Spain for the mid-career to most senior positions (including managing/head of data science kind of positions) in data science/machine learning engineer/etc., specifically for Spain. Any information is welcome (and yes, I know they are much lower than in the US, and the post is not about that).
I'm asking specifically about mid-career positions and beyond because I get offers for more junior positions from time to time in Linkedin (so I have that salary range covered), but for more senior positions I don't have that information first hand, and I don't trust the numbers I see on Linkedin salaries or Glassdoor. They seem outdated and, more importantly, biased to people willing to answer. Kudos if you have information specifically about Barcelona and Madrid, where the salaries seem to be highest.


Best",datascience
nswxtw,1622903325.0,How to explain lack of meaningful work in your last job?,"My current work is very lax and although I was hired to do data engineering work, I have not done much of that. My position seem to be a placeholder and I am given random tasks (clean up data, check if some mathematics can be done with that data, image processing, extracting data from weird S3 buckets). And my work is not even very frequent, I can go on days without practically doing anything.

I need to switch jobs immediately for family matters. Can I use these experiences in my resume and switch to a data science position? My coding skill is nothing to brag about but my understanding of statistics, Analytics and model building should hold up.

Edit: Thank you everyone for your responses. I had some good ideas.",datascience
nsvihd,1622898941.0,Senior data scientist salaries in Eurozone,"What's the latest senior data scientist salary range in EU, especially countries like Germany, France and the Netherlands? In US tech companies based here, high end consulting such as BCG and also the average European company? Glassdoor is so outdated and anyway does not have sufficient data points for senior roles.",datascience
nsr2l3,1622881593.0,Authorization in streamlit,"I am working on a college project using streamlit for making a web app. Is it possible to get to this web app through some user authentication?
Moreover if possible to do so via a mobile application to take users credentials and verify it and then direct to this web app. Thank you in advance.",datascience
nsqj14,1622879272.0,How useful is knowledge of data structures and algorithms and how to learn them best?,"Disclaimer: not a data scientist but a policy and urban affairs researcher/consultant that uses DS/DA tools to do his job better. Thus, honest question, sort if it sounds stupid.
  The job I applied to required only Excel knowledge but right now I'm using SQL and Python (100% self taught) almost every day as my company is doing less traditional consultancy and more analytics stuff. Most of the times it's just data cleaning and wrangling and getting insights or designing the process when it involves geographic data so that the data engineering interns can do the proper ETL process. If I'm doing something more advanced (clustering, distance matrices, facility location...) I usually make do with out of the box solutions.
 I keep reading about data structures and algorithms in this sub and how important they are. However, I'm a bit mystified by the terminology and can't really see how it's useful. I know spatial indexing often uses trees and is used to make searching and performing operations faster (Union, intersection...). Other than that, I'm a at a loss and I'm a bit worried that whenever I need to do more advanced stuff or eventually interview for a more data-oriented role, I'll just make a fool of myself.

Thanks so much!",datascience
nsq3k6,1622877348.0,Will My Internship Influence My Career Trajectory?,"I got a data science internship and I've just started, I've been in the role for about two weeks. It's a research and development role for the company's product. I'm honestly really enjoying it. The role is capturing meta data from data science tech stacks like Google, AWS, Microsoft etc. We get to build projects with the technology so there's free reign to do whatever I want to which is a lot of fun. I get to use a lot of the new or popular tools data scientists use but I was wondering if it's detrimental that I'm not actually creating models for production.

I'll hopefully be very proficient with popular cloud services offerings but it's more of knowing how to create pipelines, setup services and a lot of the auxiliary things surrounding models. Like I previously said I do honestly enjoy the role. It wasn't what I was expecting but I get to learn a lot at a manageable pace which is nice.",datascience
nsplyp,1622875216.0,"CMU Researchers Propose RATT (Randomly Assign, Train and Track), A Method for Guaranteeing AI Model Generalization","**The Approximately Correct Machine Intelligence (ACMI) Lab at Carnegie Mellon University** (CMU) has published a paper on **Randomly Assign, Train, and Track (RATT)**. RATT is an algorithm that uses noisy training data to put an upper bound on a deep-learning model’s actual error risk. Model developers can use **RATT to see how well a model generalizes to new input data**.

The researchers demonstrate mathematical proofs of RATT’s guarantees and conduct experiments on various datasets for computer vision (CV) and natural language processing (NLP) models in their publication. **When a trained model gets a high error rate on randomly labeled (or noisy) data but a low error rate on clean data, the model is assumed to have a low error rate on new data.**

Full Summary: [https://www.marktechpost.com/2021/06/04/cmu-researchers-propose-ratt-randomly-assign-train-and-track-a-method-for-guaranteeing-ai-model-generalization/](https://www.marktechpost.com/2021/06/04/cmu-researchers-propose-ratt-randomly-assign-train-and-track-a-method-for-guaranteeing-ai-model-generalization/)

Paper: https://arxiv.org/pdf/2105.00303.pdf",datascience
nspls7,1622875196.0,Unseen data prediction,"I have a dataset for a bank where the objective is to predict whether a loan will end up as good where it's completely paid off, or a bad loan. The dataset has the target variable consisting of three labels: open (the loan is still ongoing), good loan and bad loan. The dataset is heavily skewed/imbalanced where majority of the rows/data points behind to good loan and the bad loans are a minority.

What I have done is filter the dataset for good and bad loans and trained different ML models on it which gives too good to be true performance. This makes it a binary classification. Accuracy, precision and recall are all 1.00 or 100% for the validation sets.

Then I want to use it to make predictions for the ""open"" rows/data points in the CSV file. But, the problem is that since these loans are still ongoing, we don't have the ground truth for them and therefore whatever predictions I get cannot be compared against the ground truth to get model metrics such as accuracy, precision, recall, etc.


Suggestions/help?

Thanks",datascience
nspktt,1622875080.0,choosing the best parameters in an optimization,"Hey Forum. I wanted to get some help and potentially collaborate/hire someone to help me find / come up with a solution to the below problem and the correct methodology on how to go about it. Here is the background:

&#x200B;

The use case is algorithmic trading. To make a simple example, I use indicators to trade forex/stocks / etc. I perform backtests on data (over 10 to 15 years) and my goal is to determine the best performing indicator input parameter combination. I do my backtesting using a process called ""walk forward analysis/walk forward optimization"" [https://en.wikipedia.org/wiki/Walk\_forward\_optimization](https://en.wikipedia.org/wiki/Walk_forward_optimization) . The goal is to determine how robust the trading algo is (the system) when it runs on ""out of sample data"". The goal is to select the best performing parameters (indicator parameters like stochastic, if that's what you are using), and carry that forward and use those input parameters on your out-of-sample data. so here is what a in sample results look like

&#x200B;

param1	param1	    CAGR/AvgDD

27	         140		10.661

27	        160		       10.236

29	         145	      9.633

31		 150	      12.927

33	        155	               3.952

35	       140	              3.214

37	        145	              5.977

&#x200B;

CAGR/AVgDD is my performance metric. It can be anything really, Profit, or profit factor, etc. Basically, parameters 1, 2, X are inputs to the system. During an in-sample optimization run, for each input parameter that I want to optimize, i pick a start, end and a step. So if there are 3 parameters and each has a start value of 1, the end value of 4, and a step of 1, then you have 4\*4\*4 combinations/passes and each pass will generate a performance metric value. My in-sample runs have a statistically significant amount of data. For example, a run over 4 years (in-sample period) will have at least 5000 to 10000 trades) for each pass/parameter combination.

&#x200B;

So here is the problem that I want to solve. How do I know which single ""pass"" / ""parameter combination"" to select to run on my out-of-sample data set? How do I choose the best-performing input parameter combination? I know it won't always be the one with the highest performance metric value. For example, my highest value can be 10, and the one right below it can be 4.3. Clearly here 10 is an outlier.

what algo or method should be used?

some people have said KNN. Is that true?

can this be done with more than just 2 parameter inputs? what if I am optimizing 3 or 4? is there a downside to optimizing 3, 4, 5, etc different parameters

&#x200B;

I'm also looking for someone to help automate this for me. Looking for someone in math/data science background to help me with this.",datascience
nsojd5,1622870865.0,"(I am self learning data science. I asked this question on every platform I can think of, but still didn't get an answer. Please help me out if you know the answer) Should I remove features such as gender and birth month before drawing the heatmap because they are categorical?","I am working on a dataset that has both categorical and numerical (continuous and discrete) features (26 columns, 30244 rows). Target is categorical (1, 2, 3) and I am performing EDA on this dataset.

My dataset is regarding hotel reservation status (Not cancelled(1), Cancelled(2), No show(3)) of customers in the span of 3 years (2015, 2016, 2017). Given data of the customer, my task is to predict if the customer will either cancel, not cancel or no-show for his reservation.

* The categorical features with numerical values (ex: gender has values 0 and 1) are also considered when taking the heatmap with seaborn. As per my knowledge, the heatmap is drawn to check the correlation between continuous numerical features right (correct me if I am wrong). Should I remove such features before taking the heatmap?
* The book-in date, expected check-in date, expected check-out date are given in the dataset. I extracted month and year for each feature separately. These month columns are also categorical right? (As they only have values between 1-12). I took screenshots of month distribution plots and uploaded them here.

[https://drive.google.com/drive/folders/1duayZBpuFrqLCEO9OYRgArtv1HVpVsBz?usp=sharing](https://drive.google.com/drive/folders/1duayZBpuFrqLCEO9OYRgArtv1HVpVsBz?usp=sharing)

* Should I do a test like the Chi-Square test on those features?",datascience
nsnzqe,1622868790.0,Any freelancer looking for an appretice/assistant?,"Hello everyone. I am currently self-learning Data Analysis and Data Science from scratch and I am really enjoying the process. I am still a begginer at the moment and still have a long way to go. I have just familliarised myself with python and the NumPy and Pandas Libraries. Just now diving deaper into data cleaning.

I was wondering if any freelancer out there would be willing to connect for the prospect of a future apprentice/assistant to help with freelance work. I could help by handling simple parts of projects at the start and escalate to harder ones as I go along, helping to speed up your work. I am not looking for any salary, just some mentorship and a reference in the future.

Anyone interested feel free to DM me so I can adress any questions.",datascience
nsiwd1,1622850895.0,Looks like the expected number of dating app matches one can get in Iceland is 187?,"I'm working on a dating app and was crunching some numbers and would love some feedback to see if there's any holes in my assumptions and calculations.

Thank you!

[https://docs.google.com/spreadsheets/d/1yB36IMgetTkYxoMtDmYiKaCmMFemFerLMpq5E6LHhDs/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1yB36IMgetTkYxoMtDmYiKaCmMFemFerLMpq5E6LHhDs/edit?usp=sharing)",datascience
nsi4ng,1622848378.0,Can I add University sponsored company Projects as experience in my resume?,"Hi, I am doing my masters in Data Science in Berlin, but my background is from automotive and have work experience as PMO for 2.9 years in Digital Transformation. Now to switch my career to Data Science, I took masters in Berlin. Now I have done 2 Company projects with the help of University and it was a part of University curriculum. Can I add this as experience in my resume or I need to add this only as a side project?

Will it be misleading the recruiter or the company I am giving Interviews. Kindly let me know.",datascience
nshjld,1622846583.0,So what's the point of having a Masters or a PhD in this field?,"We can all agree that most of the job is boring data stuff, collecting, cleaning, designing, transforming and the list keeps going. This takes like 75% to 90% of our time. The rest of the time is powerpoint, excel, meetings, building models, ML and ML-dev ops.

So my question is why so many positions require Master or higher education? do you guys have this kind of education?

Do you guys do actual complex stuff? What do you do that you need to have a PhD to do it?

I got 3 years of experience and i've never needed to know anything that couldnt be learned in a basic blog post of some random dude.

I guess some positions do need very complex knowledge of NPL or DL but the rest?? no way",datascience
nsf633,1622839822.0,Carvana lets you google while taking a coding test. Do you think more companies need to do this?,"Hi!

I recently found out that Carvana lets you use the internet while taking their technical test. They wrote something like this in the email invitation, ""We all know everybody googles the syntax on their job"". I'm sure there are many companies out there with similar mindset that I'm not aware of.

I found it interesting and was wondering what are your thoughts on this. Should more companies start allowing the use of internet in their coding tests?

Thanks!",datascience
nseegw,1622837759.0,On the quality vs quantity of job applications,"From your experience, is it worth tailoring resumes to job openings? Or is it a better idea to have a one-size-fits-all resume and cast a wide net?",datascience
nsda9k,1622834878.0,Do you like being a data scientist?,"I have the option to study two different courses, one is to become a Data Scientist Jr and the other one is the Google Project Management course. Right now I work as a
PM but I also know how to code, so I don’t know what path to pursue now, I mean I can improve my skills as a PM but in the other hand Data Science looks a very cool and interesting thing to study.

I have some experience coding with Python and Django, so I think my profile match, however I’m still wondering what to do... Do you guys like being data scientists? What do you hate about the role? Is there professional growth?  Do you consider that the demand for your profile is increasing?",datascience
nsd4m7,1622834473.0,Is upward of 1 hour in runtime a normal occurence when querying data from large tables using PySpark?,"I'm currently doing a SQL query (SELECT * FROM ... WHERE ...) using spark.sql() and then writing the results into a table using df.saveAsTable. However, this take upwards of an hour or more to run. The table I am querying from has ~1 billion rows of data and it is in Hive. Is this to be expected? Or is there something inherently wrong with my configurations of Spark that lead to the slow runtime?",datascience
nsc65l,1622831976.0,Question on Survey Data Results and writing,"My apologies if this isn't the proper group to ask the question - but any assistance would be greatly appreciated.

My company does weekly surveys to our membership base - we have approximately 4 years worth of data/results that we were looking for someone to assist in interpreting the data and possibly tying it all together for a comprehensive report sort of speak. I am struggling to find a company that offers this service or even what this service would be called.

Anyone here know of a company or consultant that could help?",datascience
nsbf1f,1622829894.0,"In the early stage of your career, how many hours per week should be dedicated to upskilling?","Hello!

I am about to finish my first year of a data job after grad school. In the past year, I've found myself not being able to upskill much outside of new things I learnt at work. Reasons or excuses could be wanting time for my hobbies, not wanting to study on the weekend.

I know I need to put some hours every week to learn new stuff outside of my job but I am kind of struggling.

I was wondering how do you guys go about your upskilling and what are some tips would you like to give to someone like me.

Thank you!

P.S. I can't say my skill set is the same as it was a year ago but not doing much outside of work makes me a bit insecure.",datascience
ns7l7m,1622819905.0,Should removing outlier be based on the specific data?,"I am new in Data Science so excuse my limited knowledge. I am studying an overview of the different stages that a DS project goes through.

Currently, I am learning more about outliers detection and removal. So, I have not found a resource that talks about real world application of outlier removal. Say you are working on a small project that has a data set that depends highly on other external factors. Let's assume the dataset that I will work on is economic growth in a particular state. In this case, economic growth depends on hundred different factors, growth in business, population, market, jobs etc.

Given that in your project you are just limited to the economic data, my question is should you perform an outlier removal (get a boxplot of different attributes in the dataset and and remove all the values that fall out of the 1.5 times interquartile range) or let go of the removal so as to assume the closest real world possibility?

In practice, what would be the ideal solution to work in this scenario?",datascience
ns5lwu,1622814677.0,"For most of the problems I try to solve using data science, the biggest challenge surprisingly isn’t really the “science” part but the “data” part","when you start a project with a problem and try to work towards a solution (which is what you should do to make sure your work is actually useful) then you arrive at this hurdle where you have the problem and an idea for the solution at hand, and they are your only lead to finding the specific data you need to train you models. Sometimes this data can be really hard to find using these search parameters. No matter how much I search, I don't find what I’m looking for

The data is probably out there and there is probably some search term that would make google put this data right at the top for you to see, but I've often found that the problem and prospective solution I have on hand is generally not it. Datasets online simply aren't indexed by their applications, they are probably most often indexed by their source. And that is something that I, in my experience, can’t really use to engineer a search term that gives good results (if the data even exists online).

I was wondering if you all had the same problem and whether you agreed with this idea. Is it the same case in your experience or am I just doing it wrong?",datascience
ns4sz8,1622812348.0,Transitioning from NLP to satellite and image based CV," I'm currently in a role where I've solely been working on NLP for the entire time. Recently I was offered an opportunity at a new company where I would be working with satellite and time series data with the goal of doing combining time series and CV. The thing is I have zero experience working with both time series and image data, the company are aware of this though, and they are fine with it.

My main reason for posting this is to try and gather some training resources so I don't go in with zero knowledge. Looking for any interesting projects/courses involving those types of data that would be beginner friendly and go through the processes that are generally required for this work. Appreciate any help you can provide",datascience
ns1l29,1622801310.0,"Text classification for item matching, best setup?","Hi  there, I am building a text classification model to match the name and  description of a customer's item (e.g. name: ""suction press nip"",  category: ""paper machine parts"") to a list of 10k basic items (name:  ""steel, unalloyed"", category: ""metals""). I have some initial matched  data to test and I will get more and more, hopefully.

I've build a sentiment analysis program in the past, this is a good example of what I used: [https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) (Spacy, Scikitlearn).

This  current problem is more complex though, it's 1 to 10k+ match and not  binary (or max 5, 6 values), the string for the item is short and  absolutely at the discretion of the source (client item log).

Which reads/tutorials/examples would you suggest to take a look at? (in Python please)",datascience
ns15kc,1622799612.0,Optimizing Based on all multiple counteracting factors,"Hi All,

I am working on a problem for a client wherein they want to streamline sourcing of their products based on 3 factors, Cost of goods, Lead Time & Risk Factor to fulfill the demand.

&#x200B;

I tried approaching it in the conventional Linear Programming model specifying constraints and minimizing Cost , but this method has a drawback that it is optimizing on 1 function i.e Cost and doesn't take it into account Risk/Lead , so I will get lowest value but my risk/lead time  is high I am looking for an approach which gives  balanced answer .

&#x200B;

I am thinking I should create a new objective function which is a mix of all the factors like

Objective = Qntity \* Country1 + Qntity \* Country2 + Risk\*Country1 + Risk\* Country2

But I cant understand if I should maximize or minimize this.

&#x200B;

Any thoughts on how can I proceed ?",datascience
nrzvrn,1622794464.0,ML advice needed!,"Hi, not sure if this is the right place for this, but just stressing cos I'm getting to the end of the sprint and I've got no results to show for my work.

&#x200B;

So basically, I started at my first DS job just over a month ago, and I'm currently working on developing a small object detection model to pick out various symbols in these complex noisy diagrams (crowded with lots of superfluous lines and text).

&#x200B;

The data set we have is pretty small, and I've had to label it myself. I've chosen to break the symbols into around 8 classes that are all pretty distinct from each other, and I've picked out \~600 data points of all symbols that we need, and \~400 cases of the general background cases.

&#x200B;

I've trained a CNN model to classify each case, and the confusion matrix looks pretty good, but when I run the model on the sliding windows it just performs terribly.

&#x200B;

Basically, it's OK at picking out these things in the small image sections that I've picked out but is terrible at picking them out in the random windows generated by the sliding windows technique that I'm applying.

&#x200B;

This is basically my first time building a NN model, and my first time labelling my own data. I think I have all of the implementations working fine, but I just don't know how to boost the performance.

&#x200B;

I feel like this is mostly just a lack of experience on my part, but it just feels like I've hit a wall in terms of what I can do with this model... I just don't want to have to say to my team that the project I've been working on all sprint is a no-go... I'd also mean that I'd have to come up with an alternative strategy to identify these things cos we kind of need this in the long run...

&#x200B;

Sorry for the rant.. Any advice or resources would be really appreciated!!

&#x200B;

Thanks!",datascience
nrzbg6,1622792134.0,Causal inference in Data Science,Does anyone have experience implementing causal inference in data science? What exactly did you use it for and how effective was it? Did it actually provide some value?,datascience
nryo30,1622789337.0,What’s the best source for raw medical data?,"I’m currently researching different prosthetic heart valve replacements and how they affect patient outcomes in a certain region of California. I want to get my hands on county specific data that shows which type of valve was used and then follow up on the patients outcome. Is this possible? I have no idea where to acquire these data.

Thanks for your help!",datascience
nrxu53,1622785862.0,Can anyone recommend a higher quality version of this picture?,"https://imgur.com/a/wz1Zwv3

I drew this picture - a regression model is being used to estimate the y-value for some points, and error bars that look like mini normal distributions are shown for each point.

Can anyone please recommend a higher quality version of this image? Something from google images, etc? I spent some time looking, but I couldn't find anything that exactly matches what I am looking for.

Thanks",datascience
nrwt90,1622782006.0,"Made an interview for a company, their project does not seem doable","This week I've had an interview with a company that manufactures wooden floors. They want to hire a data analyst / software engineer to digitilize  their manufacturing processses within their factory.

They told md which improvements they had in mine and some of them seemed completely okay, like installing sensors around the factory and gather data from those sensors yo atart building some big data bank.

The second is that they want to build applications for internal consumption for other workers to be able to better visualize what's going on in the factory.

However, their main focus was some other thing, they wanted to do was to build from zero a computer vision app in which you could take a picture of raw material and it wpuld predict its prone to failure or not.

The problem is that they don't hsve any data for that and I dont think they are well aware of the effort it would take, not to make the app itself (if possible) but to build a dataset large enough to be able to train the model.

The contract they are offering is just 6 months so I assume they need to see results within that time-frame.

I don't their degree of expertise in the topic, but to mind it seemed that they are not being realistic about this and the contractual relation wpuld end up rather bad.

What do you guys think?",datascience
nrs4r6,1622766114.0,Is learning web development worth it?,I have seen that sometimes the results obtained from the data science process have to be displayed to the end user in some sort of analytics web tool. Should I add web development to my data science toolbox?,datascience
nrpd22,1622758028.0,Advice On Resume Data Collection,"During this summer season, I hope to conduct a research project with my discord friend HonoredTarget. The goal of this project is to compile a giant database of resumes sent to FANG companies and compare those that were accepted/rejected to try and ""crack"" the screening process. In other words, we are essentially trying to figure out if there are certain keywords, phrases, or wordings that increase your chances of getting an interview. However, in order to do this, we need a large pool of resumes (then from this pool, we focus on the ""skills"" section of each resume).

Our initial plan was to create a form and post it on various subreddits but it seems that is not going well. I have spoken to various moderators of other CS-related reddits about permission to post the survey and they have flat out said no or just not responded, so it appears I am in a bit of a predicament. How do you guys think I should go about collecting a large amount of this sort of data? I have looked online and have been unable to find any public databases of resumes.

Let me know what you guys think I should do!",datascience
nrp373,1622757286.0,Hired at a Small Company. My Job is... Shaky.,"First DS job, working remotely, started about 3 months ago. It's a very small company in an industry that I was unfamiliar with, so there was a distinct learning curve in getting acquainted. There was also no onboarding, as is to be expected for very small companies.

I'm not sure they needed a data scientist and now I'm kind of scrambling to try and show value. Along with that, the part of the business that I'm working on does not generate any revenue, and has very little data (about 3000 sparse data points, maybe 1200 good ones, very few updates - maybe 5 per week, and very few insights that I am being asked to run on these actual data points).

With that, I'm being involved in the business development side of things (higher-ups do not know how this current 6-year old project should generate revenue), and every week my task changes. Usually it's about finding open-source datasets, but my boss has very little focus/patience, so each week is different. I struggle to maintain focus in my day-to-day data work as it becomes clear that what my boss wants is usually not doable within a reasonable time frame (i.e. investigate a causal question that would be great for an entire econometric paper), and will likely not generate revenue anytime soon.

Are there any other DS folk who have been hired into small places with very little data, being the only DS? How did you handle the situation? How long does it take you to do open-source data collection? I don't mind the field, the work, nor wearing many hats, but I'm worried that I won't be generating enough value to justify staying on the team.",datascience
nrou0l,1622756592.0,Best platform for a school data dashboard?,"I'm moving into a new role at my school next year--Data Strategist (yay!) and I will be responsible for managing the school's data. At the moment, data is not accessible and we have struggled as a result.

To my question, what do you think the best tool is for a dashboard that is easy to navigate/filter for many people that are not tech savvy and that will be easy for me to update on a weekly basis.

My first thought was google data studio since it's pretty straight forward, free, and easily works with sheets. However, I'm also somewhat proficient with python and will be utilizing seaborn (probably) for some of the visualizations.

Further information.. this is for a high school that has about 600 students and I need dashboards for the entire school, each grade level, and each content area.

Thanks!",datascience
nrnxka,1622754166.0,Is it legal to create images with an open-source NN implementation and sell them?,"I want to use the recently published VQGAN+CLIP implementation of transformers to generate images based on a text description, and then sell those images in any way I can, maybe through a website. I would use very specific seeds and text, so these images would be almost impossible for anybody to replicate with the same network. Is this legal? As I understand, [VQGAN](https://github.com/CompVis/taming-transformers) and [CLIP](https://github.com/openai/CLIP) are both open-source.

Thank you",datascience
nrmhcn,1622750425.0,Explanation of Enterprise Data Architecture vs tools," Hi all. I was hoping for some insight. I haven't worked with Red Hat or OpenShift before, and so I was wondering if you could give me the Cliffs Notes version of how the platform differs to a traditional enterprise data architecture? Or is it meant to slot in to the gap to provide cloud services for the other tools being used?

Would appreciate a bit of insight there. Hope that isn't too silly a question.

I was also wondering if there is an open source Enterprise Data Architecture system (with all the components) that I could play with as I develop a set of tools for my company, to get a feel for what the various components do and how they fit together.",datascience
nrj0i1,1622741487.0,Team with no data science infrastructure/knowledge (crawl/walk/run),"I'm in my first real data science job at a F500 med device company. The team I am supporting is looking to implement smart features for a web application. The team is all software developers with zero experience/understanding of data science. The previous work/proof of concept for the work was a bunch of Juptyer notebooks using static log data as inputs, and we are working through which features to implement.

I'm working to frame the steps of using data science/ML in production to crawl/walk/run (i.e. start small and work up from there, considering there is currently zero infrastructure). Anyone been in a similar situation and have advice on how to frame the crawl/walk/run steps for a team with zero experience?",datascience
nridri,1622739858.0,How much has probabilistic programming been adopted in industry?,"Hello, this just merely an interesting thought I’ve had. I’ve noticed there’s an interesting niche within the field of Bayesian statistics that goes into probabilistic programming, building Bayesian models, Bayesian deep learning etc. This area seems like a big topic in research as well. My question is more so geared towards industry, but what is the trend recently when it comes to using Bayesian statistics and probabilistic programming in a company? My intuition tells me that  Bayesian methods are really interpretable to stats/DS/math folks, but to those outside of that in industry, say stakeholders or upper level management it may not be as interpretable. With most baseline statistics classes starting off at the frequentist perspective, it seems that these are the methods which are really interpretable to management in industry, and thus there is not much of a use case for probabilistic programming and Bayesian methods other than research.

Can anyone speak to this? I’m curious to see how much of an acceptance there is to probabilistic programming  in the industry and if it is really only limited to research?",datascience
nrhzbw,1622738819.0,Tools for analyzing images,"Hello data scientists,

I am but a mere engineer, trying to pretend that I know what I’m doing. I have a small set of labelled greyscale images (2 classes), and a lot of unlabelled images. I want to understand what *qualitatively* differentiates the sets of labelled images.

My engineer brain understands how to train something to do a prediction, but absolutely fails to understand how to *analyze* the image data with the tools at my disposal. I would love to be able to tell someone, “*this* is the difference between these images”.

What’s the data science-y way to look at images?",datascience
nrgvaq,1622735922.0,Interest in a Puzzle-Solving Community?,"Hi everyone!

Many members of this subreddit want to brush up on data science or keep their skills sharp. Would anyone be interested in starting a community where we write each other challenge problems and get in the habit of solving problems daily? Think probability puzzles, coding problems, and questions about ML techniques. Research shows daily problem-solving can help you learn much quicker, boost recall, and prevent you from forgetting key concepts. Even with a small community of 20 members, writing 1 question means 20 questions to practice with every week.

Feel free to comment or DM me if you're interested!",datascience
nrecu2,1622729243.0,Is this a common problem?,"I tried fitting a GLM style regression model to some data and it resulted in all the regression coefficients being estimated as 0 (i.e. model failed). Yet when I tried a random forest model on the same data, the model worked well and I was even able to get 70% accuracy on the test set.

My dataset has continuous and categorical variables, as well as a lot of ""naturally occurring zeros"".

I was just wondering: is this a common problem? I spent a whole day trying to tweak the regression model to work, but the random forest instantly outperformed it?

Thanks",datascience
nr9b9x,1622712542.0,How to be taken seriously during a job interview when you don't have a STEM degree?,"NB: this is NOT a rant post, I swear. I want to be proactive.

I'm writing here to ask some advice on how to tackle my next interview processes, I have a problem about this.

&#x200B;

SOME CONTEXT, QUICKLY:

I am already a professional Data Scientist with almost 3 years of experience in a large company.

I have a PhD from a social science department. My main field of study has been application of statistical models. I spent four years studying (mostly) statistics and econometrics, and doing estimations. My final thesis was completely statistical in nature. Before that, I received good basics in CS.

I don't want to sound arrogant, but I think I'm good at my job. I have a good understanding of math, calculus, statistics, and algorithms. My colleagues with a background in STEM told me I'm good at Deep Learning. I am the reference guy in my company for the use of TensorFlow.

&#x200B;

HERE'S THE PROBLEM:

I like my current job but I don't have faith in the future of my company. I have seen countless potentially cool projects being supervised by corporate idiots that do nothing but speaking corporate jargon, that know nothing outside marketing. I'm sick of this and I want to leave.

However, every time I apply for a new job I feel that I'm not taken seriously because of my social science academic background. I can see how recruiters changed attitude when they found I come from a social science department. They believe I got there by mistake.

This is so frustrating. What can I do about this? How should I approach recruiters and companies when I apply for a new job?

&#x200B;

Thank you people, love this sub.


\-------
EDIT:
To make myself more clear, and give you an idea of why I wrote this post: I have JUST received an email (literally 1 minute ago!) by a company I applied for. They had cool DL projects, young data-savvy team, both interviews went great, we all liked each other. Now they just told me: listen, we liked you very much, but our company's policy is that no people with a social science background can be hired for this role. They literally told me that.

I hope you will now better understand the reason for this post, instead of calling my ""lack of humility"".

Again it's not a rant (partially now), but rather: tell me what to do to attenuate/bypass this problem.
",datascience
nqprvb,1622651217.0,Record Linkage - Supervised vs Unsupervised,Hey all. I've been tasked with figuring out the best way to implement record linkage between multiple data sources at my job. My suspicion is that supervised approaches will increase accuracy over unsupervised approaches as long as we are willing to do a clerical review to create a training data set that is large enough to be representative. Admittedly this would be very time consuming but I think it might be worthwhile in the long run. After reviewing many papers/blogs etc I can't seem to find many comparisons of current supervised vs unsupervised algorithms. Has anyone seen any work on this? Any links or guidance is appreciated. Or just general record linkage insight is appreciated also. Thanks!,datascience
nqnrs6,1622646072.0,I researched the origin of Unlimited PTO (at Netflix) and wrote up a case study :),"Unlimited PTO (paid-time-off). Some love it, others think it’s a scam.

But it’s worth exploring why this policy was implemented in the first place. And for that, we go back to the early days at Netflix.

It’s 2003. Netflix is galloping along in pursuit of Blockbuster. There’s a buzz around the office. The chase is on and an employee asks:

*""'We are all working online some weekends, responding to emails at odd hours, taking off an afternoon for personal time. We don't track hours worked per day or week. Why are we tracking days of vacation per year?""*

Reed Hastings, CEO of Netflix, doesn’t really have a great answer. After all, he’s always judged performance without looking at hours. Get the job done in 1 hour or 10 hours? Doesn’t matter as long as you're doing good work.

Hastings also realizes that some of the best ideas at work come after someone’s just taken vacation. They’ve got the mental bandwidth to think about their work in a fresh, creative manner. Something that’s not possible if you’re clocking in and out without any rest.

So Hastings decides to pull the trigger. He introduces Netflix’s *No Vacation Policy* which puts the onus on their employees to decide when and how much vacation they need to take.

In his book, *No Rules Rules*, Hastings describes getting nightmares when he first introduced this policy. In one of these nightmares, he’d drive to the office, park his car, and walk into a completely empty building.

Those nightmares, minus a few blips which we’ll get to in a bit, never really materialized. The policy was a success and soon other companies in the Valley started copying Netflix. Everybody wanted the best talent and implementing a no rules vacation policy seemed like a great differentiator.

Except that the same policy which worked so well for Netflix...wasn’t working for anyone else.

Other companies found that after implementing an unlimited PTO type policy, employees paradoxically started to take *less* vacation. They would worry that their co-workers would think they were slacking off or that they would get left behind come promotion time.

Hastings was surprised. After a bit of digging, he realized the reason behind why these policies had failed.

The leaders at these companies were not modelling big vacation taking.

Indeed, if the execs were only taking 10 days off, then the unlimited plan would deter other employees from taking anywhere near that amount or more than that.

As Hastings put it:

*“In the absence of a policy, the amount of vacation people take largely reflects what they see their boss and colleagues taking.”*

**Modelling others around you**

This concept of modelling others around us applies not only to vacation taking, but to all sorts of behaviors. As we continue to move towards a new distributed, remote-first workforce, there’s going to be a lot of ambiguity in the decisions that we need to make.

The companies that are able to best adapt to this changing environment will be the ones in which leaders model the right set of behaviors.

A big one will be written communication. As the ability to just randomly walk up to someone at the office and ask them a question subsides, we’ll need to document our practices much better and be able to communicate much more efficiently.

The more we see others, especially our leaders, invest in written communication and take the time to get better at it, the more we will do it.

And never mind us seeing them do this. Reed Hastings wants them to shout loud and clear just how much vacation they’re taking or just how much they’re investing in themselves, so as to encourage everyone else to do it.

An example of good modelling in practice is Evernote. The company, which also doesn’t limit employee vacation days, actually gives a $1,000 stipend to anyone who takes an entire week off in order to encourage vacation taking ([source](https://www.washingtonpost.com/news/on-leadership/wp/2013/08/13/the-catch-of-having-an-unlimited-vacation-policy/)).

**Other Things**

Okay, so there was one more thing that Reed Hastings found out. It wasn’t enough for leaders to just model the right behavior. They also had to set context and guidelines.

Reed realized this when it was the end of quarter and his accounting team was supposed to be closing up their financial books. But a member of the team, in an attempt to avoid the annual crunch period, took off the first two weeks of January. No bueno.

So Reed decided to put in place clear parameters and guidelines on what was acceptable within the context of taking time off. For example, it was imperative to mention things like how many people taking time off at the same time is acceptable and how managers must be notified well in advance of any such long vacations.

This would help prevent blows like the one above in the accounting department.

**Conclusion**

In the end, it seems like Unlimited PTO can work, but it also needs to be supported with strong management. Individuals need to model big vacation taking and put into place the right guidelines.

But I think the lessons here go beyond just vacation.

The behaviors we see and notice from those around us eventually have a strong impact on the type of people that we become. This is especially true at the managerial level, where the impact is 1 to N and can result in considerable [cultural debt](https://www.careerfair.io/reviews/cultural-debt).

So just like this question of unlimited vacation, the answer usually lies in its implementation. Context is king. But that does't always make for good headlines, now, does it. 

\--------

Hope that was useful.

*If you liked this post, you might like* [*my newsletter*](https://www.careerfair.io/subscribe)*. It's my best content delivered to your inbox once every two weeks. And if Twitter is more your thing, I would love it if you* [retweeted the thread](https://twitter.com/OGCareerFair/status/1400161823299604481)*!!*",datascience
nqlcp6,1622639145.0,"Hired as a Data Scientist, not doing Data Science work.","I was brought on to pretty large multinational organization as a Data Scientist thinking I would do Data Science work right?

Now let me preface with, this issue might just be because the client really has no idea what they’re doing and has horrible data management and data engineering. And there’s just a lot of Pre-work that needs to be done.

But every time my group encounters a Data Science problem, the first though is “Let’s just throw it in one of the AWS Services (Reckognize, Comprehend…etc) and close out the project”. I actually don’t think any of the other “Data Scientist” on the team are doing any Data Science. More of Data Engineering perhaps.

I’m all for fast and efficient solutions, but I’m not doing any Data Science work. I get it, like why train an NLP model when AWS has already done that for you, and you can make slight tweaks to it. My last job I was able to build models, pass them off to the Engineering team and move on to the next.

Has anyone encountered this? What are your thoughts and how would you respond?",datascience
nqhdm6,1622624332.0,What is your preferred workflow for working with documents and code at the same time?,"I assume at least 70% will say Jupyter, probably mostly with Python, maybe a few with Julia. Another 20% will say R with RStudio, etc. A handful might say Spyder or something.

I just want to say that I've found nearly every stack, at least as a beginner looking to 'get started fast', is horribly convoluted. I say that as a software developer who writes JavaScript applications (a well-known convoluted platform).

I just want to find something as simple as basic markdown that also lets me execute code, and it doesn't require a special IDE or a command for the code to run (ie, it continuously runs, or it creates live updates on changes).

- I really like the R Markdown format, but I don't love R itself, and I hate having to use R Studio. It also doesn't seem trivial to set up live updates while editing.
- I like Python more as a data science language, and it's cleanliness as a language also has a similar philosophy as markdown, but there doesn't seem to be a document format that I like. I don't want to write in cells (a la Jupyter) or use an IDE that controls where my cursor can go. I want to edit raw code.
- I even looked into writing code in JavaScript. Yes, Javascript math is UGLY, but I thought oh well, at least I can easily write documents and upload it to the internet, if that is my goal. I tried MDX engines, and you can't even write JS in MDX. At most, you can write a component in a separate file and import it into the MDX file, which is super bloaty.

So, what are your thoughts on this?

Is there any stack that has:

1. Markdown as a base document (not cells). I could be persuaded to something other than markdown, but it would have to be something that is easy to write books and author blogposts with. Markdown seems like the best game in town for that.
2. uses a decent high level language (I'm pretty flexible) that can be executed within the document and ideally create visuals too
3. live updates to the executed code (not just the markdown code) whenever the file is saved (or by some other similar mechanism)
4. no major requirements on IDE (I am a big time VS Code user, and I don't want to change my IDE just to write a little math)",datascience
nqenba,1622612981.0,What is the best package for combined speech recognition and diarization on long conversation audio files?,"I have maybe 1000 hours of audio recordings I want to convert to text with timestamps to match diarization timestamps. Or at the minimum, at least convert to text without diarization. The files are a few hours each and add up to maybe 200 5hr sessions. Quality isn't always great but a human can clearly understand what is being said. Approaches I have tried:

Mozilla freespeech: convoluted installed, no diarization

Kaldi: also somewhat convoluted install, could revisit

SpeechBrain with Huggingface pretrained: got working, but attention model may need 30 second or less inputs, worried about splitting 6 hour session into 30 seconds and the information loss.",datascience
nqd3gh,1622607318.0,Setup for a Dashboard-based business,"I'm looking for a variety of opinions on the following:

&#x200B;

I'm looking to build a website that brings together a variety of data sources and presents them as dashboards. The business model is paid subscription for access to the dashboards.

&#x200B;

For the Dashboards I'm trying to decide whether to use Plotly/Dash or PowerBI.

&#x200B;

I feel that Dash gives me more flexibility but the time taken to build fully interactive dashboards is higher compared with PowerBI. Also the user authorization side is more complex (sticking to the free open source version).

&#x200B;

On the flip side, I don't necessarily want a business that is reliant on a product of another company like Microsoft.

&#x200B;

Anyone have any thoughts on this?",datascience
nqcl3k,1622605565.0,How do you handle large datasets?,"Hi all,

I'm trying to use a Jupyter Notebook and pandas with a large dataset, but it keeps crashing and freezing my computer. I've also tried Google Colab, and a friend's computer with double the RAM, to no avail.

Any recommendations of what to use when handling really large sets of data?

Thank you!",datascience
nqcfya,1622605079.0,How to finalize job offer?,"If a choice is given to work as a Data Analyst at a rapidly growing startup which would have responsibilities of an analytics+engineering as well as future progression into becoming second data scientist in the company, or to work as a Senior Data Scientist at an analytics and measurement company, what would you think would be a good choice?

If compensation is a factor in deciding, the data analyst offer could fetch somewhere around 80k+ (no data as the company was recently founded) and the senior data scientist would be around $120k (as per published data)",datascience
nq3kne,1622578896.0,What pros or cons have you all seen by centralizing data science and data analysis operations across your organization?,"My company isn't too large but there is starting to be a disconnect between different groups on what data is being used to make decisions, how it is being used, who knows what data exists, etc. As a result I'm working on putting a business case together for getting a centralized data team consisting of data scientists and analyst. I was hoping you all may be able to provide more insight into the benefits and drawbacks of doing this based on your experience.",datascience
nq1fj2,1622573420.0,"Relationship between no NoSQL, Hadoop and Data lakes.","Hi, I am going crazy trying to figure out the relationship between these big data technologies. I understand what they do but I cannot find anything that tells me the relevance of a particular one to a field or task.

Are they technologies used in combination? Is one better for a particular type of data? Are there limitations that means the choice is budget dependent? Or is it just matter of preference?

Many thanks to anyone who can point me in the right direction!",datascience
npzaky,1622568104.0,Have any of you taked the 'Qualified' SQL challenge as part of interview process for Zoom,"I got this assessment today and just wanted to get an opinion on the difficulty level. Is it similar to LeetCode SQL Easy/Medium/Hard  or is it a totally different level. Trying to get a feel for what to expect in the 75 minute period.

TIA",datascience
npyxks,1622567193.0,A checklist for professionalizing machine learning models,"[https://www.crosstab.io/articles/professionalizing-machine-learning](https://www.crosstab.io/articles/professionalizing-machine-learning)

I'm curious to hear what people think, especially about things I missed in my list. I'm sure there are some...",datascience
npwyg0,1622562179.0,Data streaming question,"Hey, I'm looking for a solution, open source docker deployable service.

What I need to do is stream data from several mysql db's to a central postgres db. Polling once every 30-min. So performance and query size should matter.

Some of the tables in the mysql db do not have a date on them.

Now initially I planned to join the 6 tables in one of the db's to make a view of 130 columns, in order to get the date data in. Then SELECT * FROM table WHERE date=last 1 day. This should give me an option to limit the query by filtering it.

One can quickly see how the massive view will lag the origin server, especially if I poll it every 30 mins. There are plenty of NULL values in there but that's beside the point. Its the best solution I can think of at the moment. Correct me if I'm wrong about the filtering performance and if its actually sensible.

Alternatively I can stream individual tables but as mentioned above, there isn't any date column to filter, so it'd cause even more of a performance bottleneck to select all rows for each table at every update.

I initially used airflow to achieve this, by writing the data to a csv as a staging area for loading on to pg.

I've also looked at airbyte but they seem to be pretty early stage, though correct me if I'm wrong.

Could be difficult to use a mysql slave db as the two db's are different types. I also don't think there's probably sufficient infrastructure currently to handle several additional slave db's.

What would you do with the scenario above?",datascience
npv75z,1622557420.0,Any advice as to how to best transition into a more advanced data science role?,"So I'm a data scientist with 2 years of experience, but I work only with traditional  ML, i.e., multiple regression, logistics regressions, regularized regression and clustering algorithms (kmeans and hierarchical for the most part.) I also don't have the opportunity to work with big data.

Since that is not going to change any time soon, I've decided to try to look for a better, less limited, DS opportunity. However, I'm struggling to find a role that doesn't require 5-10 years of experience using DL/AI and big data spec. I'm just wondering if anyone here has gone through a similar process, and if so, what advice would you give to someone in a similar position?

To add a bit to my background, I am currently completing my masters in computer science with a specialization in machine learning, have a lot of personal experience working with random forest (with boosting), SVMs, and some personal experience in DL. I am also currently completing the MLOps coursera course, which hopefully would give me some more experience in working in deploying ML models.",datascience
npurud,1622556223.0,I’m so sick of corporate morons,"[RANT]

Hey gang, stand back, it’s rant time.

Analytics is a new field at my work, and I’m here to pioneer it. I work In corporate at a large medical devices company.

I’ve had the luxury of an amazing boss, some amazing colleagues, and decent budget.

But for the love of fucking god... I am so sick of being thrown responsibility or projects because good ol mary in sales watched a video on “gesture recognition”. The ideas are a great, and I have a framework for filtering them, but the fucking pressure, the initiation of projects with 0 data, no aim at data collection, no quality assurance or risk management and the icing on the cake, “we should roll out an MVP in 2 months”. What in gods name is that shit?

I’m the asshole. I’m always the asshole.
“Here are my requirements if we wish to complete this project in the given time frame.”
“So... why can’t you develop it now?”
Bro... for starters, I’m not a full fledged software engineer / deep learning god.

I ask for resources or a relaxed time, and I get 0.


I don’t need advice. I know what I need to do. I just love this community and felt the need to rant.",datascience
npupwg,1622556076.0,"How important is knowledge of statistics, really?","Let me start this off with a disclaimer that I'm still a beginner in data science, and I haven't been exposed to many projects. So far, the real life projects I've worked on concerned time-series data (energy demand and price forcasting + supply optimization, quantitative analysis for algorithmic trading), which I imagined to be heavy on stats before I began.

However, after I've worked on those projects, I feel like knowing or not knowing stats doesn't really affect my ability to complete the projects. I'm still able to analyze the data well, gather actionable insights and build models around those insights to optimize processes.

For example, linear regression is constrained by its assumptions, so what? We want stationary time-series data for ARIMA-based models so sample statistics are not time-dependent, so what? Bayesian methods like MCMC allow us to sample a distribution similar to the actual distribution due to the law of large numbers, so what?

Don't get me wrong, I really like learning about statistics as it fills me with a wondrous sense of appreciation every time I understand the underlying reasons behind why certain models work. But I'm just really curious as to why statistical knowledge is so valued in this field when (based on my experience so far) it doesn't really affect the quality of your work as long as you know WHEN and HOW to use statistical tools/models (even if you don't know WHY).",datascience
npuger,1622555289.0,How do you feel when you have nothing to do at work.,"What do you do when you have finished most (all) your tasks for the day?

I have been wondering how much actual work data analysts do per day on their 9-5 job. I know that some days will be very busy, but do you frequently have calm workdays?

How should/do you feel about it when you're supposedly working but have nothing to do. Is that a bad thing or is it normal to most companies (average company, not a FAANG or something)?",datascience
npuamu,1622554800.0,How to find and draw a high dimensional bounding box,"Hey all! I am trying to draw bounding boxes on arrays I have. For a 2-D set it's pretty simple (I follow a process detailed here: https://stackoverflow.com/a/67784869/9345615). However, my problem is now I may have much higher-dimension data.

Is there an accepted method of drawing bounding boxes on N-dim data, that scales well to high N?

For example, if I had a 5D array, that was filled with 1's, but with 2 separate areas filled with 100's, how can I find and draw boundary boxes around them?

I'm really open to any idea. So far I'm using image filters for the 2D examples, but for the N-dim case I'm not sure how well this will apply? Or if those filters really make sense to be used on Dim>2. It's hard for me to imagine as well an NN-esque approach (think Yolo), since I will only have a few arrays, so training would be an issue.",datascience
nptfed,1622552404.0,How do you save and manage code for reuse?,"Hey everyone,

after doing online courses I'm working my first guided project and I hope that I can transfer to unguided ones in Anaconda soon. My current project for practising is guided I find myself not remembering some solutions which I had in the courses eventhough I know I've solved a similar issue before.

I know it's common to have some kind of library for code for different problems. How do you store and manage these? I was thinking to maybe make a OneNote (Windows) while studying but I can imagine there are better ways? Especially when I switch to Linux I will need a new solution.",datascience
npt96d,1622551855.0,Tutoring for Data Science,"Hi guys,

I'm curious what websites you guys have used in the past for data science tutoring? What has been your experience with particular websites/services?

-Andrew",datascience
npnf3s,1622528643.0,"Am I wasting my time learning ""R""","Hey guys. Outside of one statistics class for stem majors that I took which involves python/jupyter notebooks and the likes, the rest of my statistics courses have been using R as the main programming language for our homework and projects. I'm a senior majoring in applied mathematics. I constantly see here that python is the ""now"" and R is being utilized less.


Is this true? Should I just derp my way through the rest of these classes without much thought to learn it better so I can focus on getting better at python?",datascience
npa881,1622486419.0,continuous learning advice,"I've been using R, python for data science for about 10 years, and I have a phd in industrial engineering.

We all know this is a field requires constant learning.

For example, I am starting to work on a time-series clusterings project, which is totally new to me. Concept like dynamic time warping is so great, however I found it difficult to dig into the algorithm. I  ended up just calling some package to solve the problem rather than trying to understand it inside out.

Science is progressing fast and it's very difficult for me to stay on top of everything. What's your experience on keep yourself relevant on the latest and greatest things?",datascience
np8uqk,1622482681.0,What is your thought on SAS as a tool for data science," Cheer everyone,

I just moved from Python to SAS for 4 months due to new job requirements. I wonder how you think SAS compared with other languages, any future.

Mine:

\- SAS is not so complex. The only problem is we have to memorize weird syntax

\- Lots of problem can be solved with proc sql. Unfortunately, proc sql has some different characteristics compared with standard SQL (e.g. why row\_number is missing in proc sql????). I likely use SAS mainly for practicing SQL.

\- The syntax is unique and not transferrable. If you're in SAS industry for too long, then it's likely hard to move to other jobs with different tool. Unlike if you know MATLAB or Python, you can easily move to R, or even C/C++ (They're interconnected with each other very well, SAS is a standalone hero)

\- Company uses SAS likely for security purposes (need an organization who is responsible for the tool if anything bad happened)

\- Then SAS Visual Analytics is another story and if you program for Advanced Filter in SAS Viya, then again it's more or less different systax compared with SAS Guide.

What's your thought?",datascience
nompja,1622415198.0,What's the culture like in data science? Progressive?,"Currently I'm working in civil engineering, and it has a pretty conservative culture. I'm a young queer lady and I had been closeted at work but I'm about to get married and I can imagine uncomfortable questions.

I have the opportunity to get a masters in data science largely paid for. I'm wondering if a career pivot would increase the chances of having a queer friendly work place. What's the culture like in a data science career?

And yes I know this should be protected but with at will employment laws its harder to build a case. Also I think I'd enjoy working in an environment without racists, transphobes, climate change deniers and antivaxers.",datascience
noe1fg,1622390026.0,"Did anyone here get their company to pay for their masters in a field of data science? If so, where did you work and what did you do?",Just curious!,datascience
nobqjn,1622383078.0,Wrapping up a data-intensive PhD but most industry data science seems really boring. Are there interesting jobs?,"Title basically says it all. I'm wrapping up a PhD in [computational biology field] and starting to think about what's next for me. I don't really want to stay in academia at this point: the odds of getting the fabled tenure track jobs are low and I'm pushing 30 so I haven less interest in bouncing around post-doc to post-doc until getting a TT or burning out.

A lot of my friends who graduated before me went the Data Science route - they're making good money (much better then we made as graduate students or would make as Tenure Track Profs) but the work just seems so *boring.* Instead of wrangling with interesting data types and trying to solve interesting problems, a lot of it seems to be basically financial or behavioral user data, and the goal is to deliver ""actionable business insights"", which always seems to boil down to optimizing profit-to-cost ratio. Far less of the interesting questions about mathematics and inference that pulled me into computational modeling and a lot more focus on business, learning how to pitch ideas to managers, etc.

I don't give a d*mn about that, and kind of chafe at the idea of using skills I spent 6 years developing at the cutting edge of scientific research to help make already-wealthy investors in a company richer. For context, my thesis research involves developing a very niche kind of computational model to explore distributed information processing in biological systems that I know has absolutely no relevance to anything in the world of business or finance.",datascience
no9tq4,1622376400.0,When is it imposter syndrome?,"I've started working as a data analyst at a company where I used to work in a non-techical role. They didn't have an established data team. Instead myself and my manager (we both graduated last year). Great opportunity for me, but I'm being asked to write a pretty big app in Python and I'm really struggling with it from a technical ""know-how"" standpoint.
I feel like maybe I'm not cut out for data work, but also understand that imposter syndrome is a thing. Just looking for advice from people who have spent a longer time in the field. Are there moments where you're completely over your head? Do you just try and work through it?
Thanks team.",datascience
no9q3m,1622376031.0,Weekly Entering & Transitioning Thread | 30 May 2021 - 06 Jun 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
no7t46,1622368021.0,Data Science field is overwhelming,"So i am a beginner in this field and the amount of knowledge and work being done looks very overwhelming. In fact my peers too seem like years ahead of me when it comes to knowledge and implementation.

Curious whether anyone out there also felt this way and how did you manage to get out of this confusion to feel a little confident that you know something and can do something. Or if you still feel this way. I want to know your experience.",datascience
no7s9w,1622367918.0,Kaggle and burnouts,"I am interested to know how often do people participate in Kaggle competitions, and when do they get to work on the competition's code.

I have a full-time data science/research position so I am usually occupied during the weekdays. In the weekends I just like to take sometime off-the-screen and do outdoor activities (hiking, cycling, chilling out). I am keen on getting more engaged in Kaggle competitions so I can have a broader knowledge and more career opportunities in the future. However, I am concerned that I will burn out, having to stay coding behind the computer screen 7 days a week. My position is a priority for sure, and I don't want my work to be affected because I was not properly taking a time off when I am supposed to. How do other people handle such a situation?

Tl;dr: I am interested in becoming more active on Kaggle, but I am concerned that I will burn myself out. What are your tips?",datascience
no77f5,1622365285.0,Open-source work in data science for a newbie.,Is there any open source work for someone who has no prior experience in making tools or any contributions? Someone who welcomes beginners and helps them or guides them to get better in contributing and improve collaboration skills.,datascience
no33kc,1622347669.0,Recommended resources for designing an item rating system?,"Hi there.

I am building a website with a rating system and I was wondering if there are any highly recommendable books that could help with designing it.

I'm interested in anything ranging from details such as designing algorithms to deal with items with fewer ratings having higher average scores (as in, an item with a single 10 rating being ranked higher than an item with a thousand 9 votes) or the arguments behind different rating systems (10 stars, 5 stars, thumbs up/down, subcategory ratings, etc) to even more disperse topics such as adapting the math to the user psychology behind it all (such as how to adapt the system to  nostalgia votes or how to separate evaluating how impactful or revolutionary a product was when released from how good or recommendable it is today).

I am also really interested in the implications that those different rating system designs would have for a inter-user recommender/affinity system, but I understand that might be a tad specific \^\^

&#x200B;

I am ok with technical reads and know some machine learning (I've done the Stanford course on Coursera), but I am not a data scientist, so I'd prefer it if the books/resources were reasonably accessible (though if a dense book is an absolute staple it would be good to know about it as well).

Cheers =)",datascience
nnwyn7,1622324567.0,Applying ML/DS for cybersecurity vs finance,"These are two areas that broadly, I’m interested in applying ML and DS techniques and skills to. I was wondering if some people could shed some light on some of the pros and cons of working in a machine learning or data science capacity in either of these areas. Thanks!",datascience
nnqrta,1622305048.0,Finally graduated from computer engineering,"I've been lurking around this subreddit since I started my final year project, a facial recognition project. I fell in love with data science overall and the stuff I was discovering every day. I lost interest in software engineering and embedded engineering a year ago, and I've been looking for the field that I would be happy to go into, and DS was the one. I've started applying for graduate jobs to become a data scientist, and I'm starting on a side project soon to boost my profile a bit more. I wondered how hard it would be when looking for jobs in DS, primarily when you haven't studied the course directly.",datascience
nnlunt,1622289044.0,"What is your current process like to source, clean/prepare, and collaborate with datasets?","As part of a bigger project, I'm looking to put some effort into open sourcing a data sourcing and data collaboration cli tool.  The utility of the tool has been great limited enterprise and research settings as a sort of a shadow IT tool that replaces ""emailing CSVs"" around"".

Please note, I'm not a data scientists or engineer so I'm looking to understand this use case further.  Thanks.

Edit:
If possible, when commenting, could you include organztion context. For instance, enterprise, startup, tech, research or other.",datascience
nnfeb4,1622262179.0,Lowballed for FAANG DS Contracting as New Grad? Advice Needed,"Hi everyone,

I had an unusual situation happen in the past few days, and I'd like some advice.

A staffing agency in the Bay Area offered me the opportunity to interview for a DS role on a FAANG team that would directly impact a product that is popular worldwide (think 100m+ users). I like the role, but am hesitant about it being a contract position, considering I have a full-time job lined up post-MS in the Bay Area that is paying 135k (\~150k if you include benefits, 170k if equity options aren't worth crap) with a team I like, though at a much smaller scale (more relatively unknown) company with far fewer DS to learn from.

The staffing agency told me the team wants to bring me in for an additional 7 interviews, testing me on everything (statistics, ML, product sense, python, SQL, behavioral), but that the position would only be paying 120k. I told her that is ridiculous, since this is just a contract position, and it would need to pay at least 180k for me to waste my time preparing and interviewing for the role, considering I have a full-time offer already. I was told today they would match the 180k.

Was I being extremely low-balled initially? The staffing agency is well known, and I've heard decent things about it. For context, this team has been looking for nearly a year for someone and I'm the only person to make it to the final stage (as far as I know). Do you think it is worthwhile to continue the interview process? Would you?

Any advice is appreciated. Thanks!

Edit #1: I'd be a W2 employee of the staffing agency. They'd have the contract with the FAANG.",datascience
nn8v5a,1622239352.0,Working as a Data Analyst at a Big4 (Europe),"In hope that this post won't get removed, I will take you through the steps of getting an internship at a Big4 in Belgium (Yes, mentioning the country is important because some things aren't the same in all the countries). The position was in data analytics\*.\* (the [full blog](https://dataanalystlife.blogspot.com/2021/06/working-at-big-4.html) if anyone is interested)

**The interview**

I had three interviews to pass.

* Technical (with one of the nicest recruiters/Data analyst/scientist)
* HR (also a very nice person)
* Manager (very serious guy, he scared the shit out of me, but once I started working with them he was super nice)

***Technical***

1. SQL = What would you write to do x, y, z. (Small question to test if I know how to use SQL or not at all)
2. Business question to test my business acumen
3. Statistics questions regarding outliers and robust preprocessing, median and mean in skewed data

Yes overall, the interview was not that hard, because I am a Civil Engineer + Master of AI. I truly think that having a good educational gives a nice push. The interviewer will think, if he made it that far, he won't be a dumb fuck (unless i cheated all the way). Yes I know, good grades does not mean intelligence. But good grades/good education means hard work and that's what most company want (hard workers) in my opinion.

***HR***

1. Testing my French skills (I am supposed to be bilingual but once you start talking English everyday you start losing the French vocab, ""le science de data"" I said it like 30 times (FFS)) mainly because in Belgium the languages are French, English, Dutch and German.
2. General storytelling, my cv, why i came to europe, why i chose my masters, what i did before coming
3. Motivation: on why I found the position interesting. BTW Deals Analytics is one of the most fun position if you check the YouTube videos.
4. \*\*Me saying some jokes to gain points :p\*\*

**Manager**

1. Same as HR but with a lot more pressure. I got scared to death no joke (I bet many people know what I am talking about)

**First Week as an Intern**

Right away, I had to learn the software they use, which is **Alteryx**. Since I have already done my Pandas and SQL on DataCamp, I did not require lots of time to get used to it. **VERY** fun no code software for data cleaning and prepping.

**First Project**

I directly started working on an RED financial data. The goal was to create insight from the financial data to direct the next investments in the right path (most lucrative).

**Second Project**

Geospatial analysis. Oh boiii, Oh BOIIIII ! This one was amazing. I had no idea how good is creating a map and understanding the effect of the surroundings on the business. This one was huge! Learned how to webscrape, how to deal with JSONS and much more.

**Third Project**

Computer Vision project (what the actual fuck? are we still in the same internship?). Haha. Matter of fact, I had learned a course on CV and I was like: ""guys i studied this a few months ago, I can solve it with CV"". Everyone liked it so much (even though i copy pasted the code from my old projects \*\*evil laugh\*\*)

**Fourth Project**

Geospatial Analysis again. But this was one very tough and stressing.

**Fifth Project**

At that point I had to work on my thesis because I had an intermediate presentation. However, the project was about traffic analysis (traffic as in cars). A dream coming true because i am a civil engineer specialized in traffic engineering/transportation. We did amazing stuff but they were very limited :(.

**The End**

One thing to add, for however gets an internship at a big4, I hope you get a supervisor similar to the one I had. I loved him. Always supportive and encouraging. He cared about me on the personal level.

**To the readers**

I hope you benefit from this. Either motivates you to apply or to learn something new.

hope you enjoyed it♥",datascience
nn5z43,1622231296.0,What are your thoughts on Quantile Random Forest?,"Hello!

I am doing a project at work to predict On time delivery percentage in a manufacturing process.
I recently discovered Quantile Random Forest and I like the idea of it. I am thinking of using Quantile 0.5 as a point estimator and 0.1 and 0.9 quantile as prediction interval.

So far the results have been good but since I'm new to the real world project setting and new to quantile random forest, I was wondering is there something I should keep in mind while using this algorithm?

I read an article at Medium where they showed a use case of QRF at Instacart to predict On time delivery percentage but I was thinking why this algorithm is not so popular (maybe I just don't know about it).

What have your personal experience been using QRF?

Thank you!",datascience
nn5wfs,1622231080.0,Binary Classification with Pick-and-Choose Threshold?,"Let's say I have a binary classification model where one of the discrete variable has 3 values, for example, male, female, unidentified. Does it make sense to use different probability thresholds for each value?

It seems intuitive to me but I'm trying to think of potential downfalls.

To give more context, our model generates a lot of false positives but performs well on class 0 (TN/FN). Does it make sense to have one threshold optimizing for class 0 prediction, then accept class 1 prediction only if the probability score is high?

Since high here means class 1 precision, if I want to fix this (at say 75%), each gender would have a different probability threshold.

The rest of the predictions will have prob score above class 0 threshold but lower than precision@.75 threshold. These will trigger manual intervention and we won't rely on model prediction.",datascience
nn53za,1622228820.0,How does version control work for ML stuff?,"i'm a software developer first, so getting into AI it's hard to get used to handling so much binary data. how do people in this field do data and model versioning in general?

ninja edit: my first instinct is git LFS",datascience
nn4j8q,1622227204.0,How do I think of data science projects?,"I'd really like to learn more about data science through practice and maybe build a portfolio, but I'm really uncreative and can't think of any projects to try. Does anyone have a suggestion for how to approach this or project ideas for someone with intermediate python experience? Maybe something w a machine learning component.",datascience
nn210e,1622220436.0,Experienced data scientists....what advice could you give to a Junior data scientist working at a start up?,"I'll keep this short, the start up were impressed with me when I was a software developer for them. I have a mathematical background and my masters was on a data science working with AI PhD students. I have a lot of knowledge in algorithms, cloud and best CI/CD practises. And I was previously a PhD student in A.I (didn't finish for valid reasons).

&#x200B;

The company has asked me to take the lead on projects despite my lack of experience. And due to the nature of startups, there's not much structure and mentorship involved, but they believe in me.  I'm extremely motivated to do well and constantly learn for me and my company. So I was wondering the data science journey might be more smooth if I make this post.

&#x200B;

I know this is kind of vague so if you need more information about me...let me know!

&#x200B;

Thanks a lot everyone.",datascience
nn0f57,1622216000.0,what does the path to computer vision/OpenCV for text look like?,"Hey all. I'm working on a project to extract machine-generated text and table data from PDFs.

We got part of this using libraries such as PyPDF2, PyMuPDF, and extracting tables using Camelot.

But you know PDFs can be a pain to read, sometimes have weird encoding or are scanned so we need an OCR solution. I've been researching and playing with OpenCV, but most resources involve neural networks on images.

I need to learn how to read text via an OCR solution. Can you recommend any resources or methods? Do they require NNs? Any insights would be appreciated. Thank you!",datascience
nmyg3i,1622210376.0,First two weeks of my first internship,"Today, I got my first paycheck from my first internship and I am shocked about the entire situation. I come from a poor family, I am the first of my family to college (and grad-school) and the first to have a real professional work experience. I honestly feel blessed to be able to improve on my data science abilities and get paid for it!

I have been working with the lead data scientist and have learned so much in these past two weeks. I enjoy coming to work and even more so now that I saw the paycheck.

Sorry for the weird post, but I am just in a good mood right now.

P.s. My boss asked me if I want to continue my internship for the Fall",datascience
nmt4pp,1622190388.0,How to explain your projects?,"Hi ,

I am switching from PMO to a Data Science role and got one interview today for a part-time role.

The Manager asked me, are you working on any ML projects, I told them I am working on 2 projects one is with a company and another one is with a university.

Manager asked me what models you use and I told Linear regression to predict the values and we are still in Data preprocessing like cleaning the data, imputing the values and stuff.

Then, later manager didn't ask any question and asked me whether I have any question for them

then the interview was done in 15 mins. now I feel I screwed up

What to do in future to prevent this scenario?

Please help me.",datascience
nmn22u,1622166619.0,Data Science at a Big 4,"Sorry if this is not allowed in this sub -

Was wondering if anyone had experience working as a Data Scientist at a Big 4...What should I expect?",datascience
nmkw02,1622159286.0,"Technical interview timed task, no pandas?","Just had an interview task for a data engineer role where I had to filter by date, find some codes in different columns etc. I read after that I was not allowed to use pandas or any external library? Is this a ridiculous ask?  I feel like this doesn’t represent the working environment at all.",datascience
nmiq15,1622152596.0,"I used VADER sentiment analysis to track and invest based on WallStreetBets stock sentiment -- I'm up 33% annually $16k) -- here's source code, process, result, and an article","[Source Code](https://github.com/tstewart161/Reddit_Sentiment_Trader) (mine)

[Article](https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664) (not mine but it's an amazing look into how this works)

**HOW I DID THIS**

Scraped WSB sentiment, got the top + most positively mentioned stocks on WSB (for the better part of this year, that's been $GME and $AMC, recently some $SPCE and $NVDA, and about 13 other stocks. I have the strategy rebalancing monthly.

Right now I'm up 60% YTD, compared to the SP500's 13% (the recent spikes in GME and AMC have helped tremendously)

**Some stats (and a** [**picture of a card**](https://preview.redd.it/62exai0wik171.png?width=620&format=png&auto=webp&s=1f8ec63b65c84e0e28da6d9164edfbb618ff09d0) **I made giving more info about the strategy):**

\- The strategy is **backtested** only to the beginning of 2020, but I'm working on it. It's got an annualized return of 33% (compared to 16% for the SP500)

\- **Max drawdown of -8.7%** (thought this was pretty interesting - WSB would be a very cool hedge for financial markets at large. Rode COVID like a wave)

Happy to answer any more questions about the process/results. I think doing stuff like this is pretty cool as someone with a foot in algo trading and traditional financial markets",datascience
nmgfgb,1622146348.0,What are some good software engineering practices that all data scientists must know?,"We all know that a significant portion of the value added by data science comes from having good data infrastructure and model deploying, which are more related to software engineering than math/statistics. If one wants to be as well-rounded as possible, what are some of the best software engineering practices (things like version control) that are a must?",datascience
nmblj9,1622133694.0,"Paying for ""Personal"" Projects and Homework","In my spare time, I do some freelance work as a side hustle on some of the bigger platforms out there. The amount of DA, DS, Stat and etc. students that are posting their university homework and projects is preposterous. It ranges from basic stuff like running simple models and cleaning datasets to big capstone projects. I  decline every interview from these types of students that really ramp me up and beat the whole purpose of studying. They don't know the basics and have gone into the field just because they've heard that you can make money there. Not saying that they can't learn it, but going into a field without a deep interest or passion for it, on average, breeds bad practitioners.

Have you run into people like these? What is your opinion on this matter?",datascience
nmbicr,1622133461.0,"New to corporate, should you submit your task way before deadline?","Hello!

Sorry this might be a very stupid question but I've seen many people saying, ""Never submit your task before the deadline"". What's the thought behind this statement?

Asking this because, I'm a junior at a company and my manager often overestimates the time required to do certain tasks he gives me. And right now I happened to be in a situation where he gave me a task with a deadline of a week and I finished it within a few hours.

In your experience, what's the best thing to do?

Thanks!",datascience
nmaguz,1622130674.0,A lot of people entering this field are like over-fitted models,"No disrespect to Ph'd's,  just an interesting analogy.

lots of internal validation and creds,  but poor performance in the wild.",datascience
nm9155,1622126670.0,Forecasting Out of Stock items on a store-item level,"Hi all,

 I work for a large wholesale company, and I am trying to create a way to forecast when specific items will go out of stock at a specific store. I have access to sales data by store-item for the past 5 years as well the past 5 years of out of stock data (also on a store-item level).

How would you approach this?

FYI I code in Python mainly, and I'm pretty familiar with most ML tools and models.

Just trying to get a variety of ideas.

Thank you.",datascience
nm8k0y,1622125314.0,Favorite podcasts and other audio resources for learning and staying up to date?,"What’s everyone’s favorite data science related podcasts, YouTube channels and audiobooks?

I spend a lot of time in the car and would love to learn while I drive! Thanks.",datascience
nm0lab,1622094061.0,Will Palantir replace data science teams?,"I've been reading a lot about Palantir lately and how they are creating software that analyzes data and creates models for you. So naturally, i've been concerned that this new technology will eventually replace data analysts/scientists. I know right now they are only working with the government but from what i've read, they hope to eventually move into the private sector as well. Anyone have any thoughts on this and how this might affect the future of data science jobs? I'm worried the job will be made redundant by this tech and the more I read the more worried I get- it just makes me sad tbh",datascience
nm00ol,1622091737.0,"Is it normal to manually ""adjust"" forecasts?","I work at a data science consulting firm and there I was faced with the established procedure that, if the team presents some forecast to a client and the client thinks that the forecast is too high or too low, instead of changing hyperparameters or even changing models, the team basically changes the forecast values manually using ""market insights"" (they basically look for other specialists forecasts in the internet and subjectively choose a value close to those). This makes me incredibly uncomfortable. Is this a normal procedure to be used at data science consultancies? I never worked at another consultancy, so I don't know if this is normal or not.",datascience
nlwviq,1622079908.0,How was your first job out of college?,"Ive been at this job for about three months now and I feel like I’m not being challenged. I get assigned work that takes me about four hours to complete then the rest of the day I’m not doing anything except maybe 3-4 meetings that last 20 mins and then Im done.

I also spend most of my time just cleaning and pulling data in Excel. Which often makes me think why I’m being pay well when this stuff is so easy.

Is this the norm for a jr data analyst role or should i find another job?",datascience
nlwczv,1622078083.0,Data scientists who moved to ML data science roles: How did you get senior level skills?,"I've been a data scientist for a bit over a year and a half. But I don't feel ""Senior"" at all.

If anything, I feel like what I assumed data scientists who got entry-level roles felt like.

I look at the interview questions for Uber, Amazon, MSFT and others and I don't really see myself learning them from my peers. I'll need to study ISLR or other materials.

But it's the other materials where I'm a bit stuck.

Wondering if folks who made it to Senior roles or FAANG roles (not counting analytics/product roles) could share tips on how to learn to be a better data scientist.",datascience
nlryy8,1622064489.0,Forecasting employee turnover with circular reference,"Hi all,

I posted a question yesterday asking if anyone had any thoughts on how I could predict the rate at which employees in my would the company.

Thank you so much for the help! I've manage to get a working model that does it based on my current employee base, but when new employee's join, I haven't quite got it working there.

What my analysis showed is that, on average, 5% of all new employees we get will leave in the first week. Due to this, we should onboard an additional 5%. Here is where the circular reference starts. We therefore onboard 5% more and so our attrition rate increases, meaning we need to onboard more.

Has anyone come across an issue like this before?


What assumptions can I take to stop the constant circle?

Any thoughts/advice would be really appreciated all!",datascience
nlroo8,1622063631.0,Working on a project analyzing my Etsy sales data,"I'm not sure if this is the right place to ask but here it goes.

I started my Etsy sales dataset in the daily format:
https://imgur.com/CXmWQuE

Then I grouped them by 'year-month':
https://imgur.com/YFBODfA

I ended up with the following:
https://imgur.com/Lu0HlRa

For months where I don't have any sales for that specific listing_id, I want to have the month and zero next to it.

For example:
listing #902533496 from the last screenshot, I want to add these rows:

* 2021-01            0
* 2021-02            0
* 2021-05            0

Anybody has an idea on how to do this?

Thank you!",datascience
nlql25,1622060661.0,How can I practice finding data quality issues before an interview assessment?,"A recruiter has sent me a paper to review including “The six primary data quality assessment” before an online assessment I will go through with him, in which he will send me a dataset to find data quality issues using Python/Pandas within an hour.

- Where to find datasets to practice on?

- What do I expect to be doing in this hour?

- How to practice and be ready in the next couple of days?

Link to the paper: https://damauk.wildapricot.org/resources/Documents/DAMA%20UK%20DQ%20Dimensions%20White%20Paper2020.pdf",datascience
nlnpcx,1622053161.0,Most onerous data formats?,"Hello,

I am looking for some suggestions or ideas surrounding the most onerous and irksome data formats you’ve had to work with. Here’s the skinny: a very large, and in my humble opinion, just straight up malevolent company X is conducting retaliatory data requests at small public offices and institutions in a US state. One of my friends happens to work there. Now, I am all for free and open public data, 100%, but this is a nefarious attempt to drain and waste public resources and to intimidate. They are making entirely useless requests.

I am a senior data analyst with a few skills here and there and would like to help my friend stick it to evil corp while still operating well within the law and legal requirements. If you were tasked with handling hundreds of thousands of emails, meeting notes, minutes, powerpoints etc.. what would be the most onerous and cumbersome file formats or organization? Like, I was thinking of converting all text to binary and writing a little python program to generate folder hierarchies and compress every single email etc.. somehow scramble things up a bit while still ensuring the data has integrity etc.. any suggestions?",datascience
nlmcr8,1622049675.0,Grocery store purchase records,"I'm interested in a side project that looks at grocery store shopping habits and health outcomes. For the shopper history, I was hoping for loyalty number-based transaction data that would give me a good picture on how ""healthy"" their trips look. I'm not as interested in price as much as types of food (i.e. fruits vs candy). Haven't come across how to buy these data, but this [tweet thread](https://twitter.com/RobertGReeve/status/1397034344833748992?s=20) made me think a data aggregator may have it. Has anyone purchased grocery shopper transaction data before?",datascience
nlj5j8,1622041393.0,Classification/Regression just from a distance matrix?,"I have a dataset that is pre-computed into a distance matrix, fully connected between all points. This made sense as it was originally intended for clustering but now I am wondering if I could use it for classification, i.e. given unlabelled points and their distances to all labelled points, assign soft labels. Being able to do regression in the same manner would also be a plus.

I tried Googling this but I could not come up with the appropriate terms to search. The best I could find is graph-based semi-supervised techniques like Label Propogation in sklearn but I was wondering if anyone had any insight into additional models & techniques I could look into. Thanks!",datascience
nlh1wv,1622035733.0,"Ideal Text Analytics Data Structure -- One Document at a time, or one Row at a Time?","I just got tossed an interesting problem by management.   There's a lot of a certain type of document laying out agreements between labor/mgmt at the local branches, and a poor understanding at the top over what topics occur regularly in these documents.  It's over a thousand .txt documents, up to about 15k characters in each, so there's a lot to look through, and therefore, text analytics to the rescue.

I just got finished reading them all into Hadoop and turning them into a big table of the form:

Row = LineOfText,OriginalDocumentName

&#x200B;

Before I get too far into the modeling part, I'm wondering if this is the best form to have the data in, or whether I'd do better with a format of:

Row = EntireDocument, OriginalDocumentName

&#x200B;

My tools will be SAS Viya's text analytics primarily because I like the concept modeling part, and some R package like tidytext and whatever I can find for concept formation (R is my real go-to language, but I'm a bit of a noob in text analytics, and don't fully understand those packages yet.)  I've done some with Python's nltk and similar packages, although I'm expert level in R, and struggle some in Python.

Any thoughts about what's the best general format to use -- one line at a time, or the entire document at a time?   By the way, the documents come from a variety of sources like Word, PDF, and OCR input, and are pretty low quality in terms of misread or mangled words, white space, and weird control characters.  I'm not sure there's an obvious way to skip the line feeds in a Hive import to get to the second document-as-a-row format, but I can cross that bridge later, and have a few databases whizzes on my team that could help me figure it out if needed.",datascience
nlgnd6,1622034586.0,Data Scientists extinct within 10 years?,"I read an interesting article on Medium that claims the Data Scientist title will go the way of the dodo in a decade.

The TLDR is: data science tools will become as ubiquitous as MS Office products, and everyone will be expected to be skilled in using them. Titles will transition back to reflecting domain knowledge rather than skills will data.

What are your thoughts? Do you agree? Will this impact how you approach your career path?

It reminds me of Chandler making a lot of money for simple data entry. I never understood why something so easy would pay so well, but maybe the next generation will say the same of us...

 https://link.medium.com/hiXbXHrDzgb",datascience
nle5jq,1622026745.0,Data science job postings asking for both Python and R?,"I'm seeing this quite a lot, is this normal or are they just throwing in some buzz words they've seen for data science skills?

I've always been under the impression combing both is largely unnecessary and their use depends on the business or the individual data scientist's preference.",datascience
nl8wmt,1622005586.0,How many of you are in a Sales position but doing data science for your company?,"I'm head of sales for a relatively small company (~20m annual sales) and do all of the sales data analysis via Power BI and I'm learning Python.  Just curious how many other people in similar positions and how you're dealing with it.  Any insight or guidance is appreciated.

I love working with data but have 20 years of sales specific experience.  Previously wrote programs/whatever you'd like to call it in Excel VBA.  Currently pulling from SQL into Power BI realizing I can't do what I want without Python/Seaborn etc.",datascience
nl595z,1621992840.0,Data Augmentation idea help,"I've been wracking my brains on trying to do this efficiently.  I want to learn a probability distribution of a bunch of values and sample new data points from that curve

Given a numpy array/matrix of integers/floats, I want to be able to learn the probability density function of those values(per array in matrix) and sample or generate new values or columns for the matrix as per the probability distribution of that row

If possible, group similar rows in the matrix or pick a subset and then do a signal to noise kind of thing  to generate more data points as features or columns.

Is there any prebuilt package in numpy, sklearn or scipy that allows me to achieve this or apply it to a whole matrix at a time to scale quickly?  Even if some part of this is achievable through a package that would be a huge help",datascience
nl3j1f,1621987161.0,Visualizing Multidimensional Data... 128 Dimensions ---> 2D or 3D,"I am using programs like node2vec, graph2vec, doc2vec etc to build a knowledge graph. The output of all of them comes in 128 length vectors.

Is it feasible to try and compress the length to 2 or 3 dimensions so that I might visualize what any of the above methods have accomplished? If it it feasible than can I get pointed in the right direction for python libraries, packages, etc? Does not need to be perfect... just needs to give more than a csv file lol.

Thank you!",datascience
nl0fz7,1621977890.0,Marketing Analytics - how do I track where customers are coming from and how far on the website they go to?,"This is a little confusing, so I'll add all the details that I know so far. We have Facebook Ads running for a product that is displayed on Amazon, but my manager wants me to create a website for this product and then analyze which Ad people are coming from.

At the same time, there's Influencer Marketing for this product as well. Unfortunately, Adobe Analytics would be an easy way to track where people are coming from, but my company doesn't use that. There are a lot of clicks on the Ads, but no one is buying the product, so I'm trying to see exactly where on the website they stop and how to optimize the site layout. My manager really wants me to create a website in order to track all of the information instead of using Amazon, and I'm not so sure if that step is needed at all.

The product started out as really successful, but now almost no one is buying it, so it seems like a weird project.

The main issue is that I'm not sure how to even start collecting data. After I'm able to collect the data, I can then analyze it and make a model, but I don't have a background in marketing or marketing analytics, so I'm pretty lost. ",datascience
nl02h9,1621976876.0,What’s the deal with python becoming more popular in job ads?,"I graduated undergrad in late 2000’s, grad school in early 2010’s. I’m a statistician focused mostly in the social science, medical, health insurance, and public health spheres.

Around 2010-2012, all I heard was “you gotta learn R” so I did and I’m pretty proficient with it now. Then I heard you gotta learn SQL, and now I’m an intermediate SQL user, I mostly just use it in SAS commands.  It’s great with large datasets.

Then in the mid 2010’s you gotta learn Tableau, check easy enough. Then the tidyverse package,... which has a lot of overlap with SQL skills anyways. Then other packages then a few job ads wanted SPSS-Amos and/or Mplus.

Now almost every job posting for statistical / data analytics type roles I’ve come across wants me to know python. I’m sure I’ll pick it up eventually. But I can do most of what I need to do in R (and other tools). Hiring committees can’t explain why they want me to know python. I think they just stick it on there because it sounds cool. Wow snake programming language?

What’s up with these committees and job ads and their affinity towards python, yet they don’t know the value or applicability or necessity of it in these roles?",datascience
nkzz3e,1621976639.0,Roadmap / Plan Documentation for DS Projects,"I just started a lead role with my company and have was curious if anyone else has done something similar. Basically, I will be leading (and helping develop) efforts towards curating a use case list, choosing, of that list, what we'll be working on, based on business value, and executing those solutions. This effort started a couple of weeks before I began the new role, so I am catching up. Our executive leader has some passion around developing and using some tools we do not already have, so there is a bit of focus on graph analytics right now, but other ML and AI solutions are not out of the question, I just need work with my team to decide on the use cases and create a document for our plan.

I've done this for other projects that were not DS related, but was curious if anyone has any sort of template or guidance for a format that worked really well for them. Maybe even an outline of what should be included and how it should be organized. I don't have a lot of direction, since I am being asked to run with this, so I thought this community might have some good suggestions. Thanks so much!",datascience
nkyiwc,1621972512.0,How much to share in a public presentation,"Hi datascience,
My team at work has been asked to share some of our work at an upcoming event. from a best-practices perspective, how much of our methodology should we share?

My concern is that much of our data is publicly available and the rest can be purchased easily. Our models are largely off the shelf or require minimal tuning. Our innovations are really elegant and not hard to reproduce. Should I be at all worried that a larger, more experienced DS team will piggyback off of our efforts and compete for our lucrative contracts? What parts of data + model + configuration should be kept obscure?",datascience
nky62p,1621971570.0,Freelance experience as a DS you may share,"Hey there! Long time lurker, first time poster. I love this sub, I learned quite a lot and I am very thankful for all the interactions.
About my post, I work as a DS in the risk area of a bank, nonetheless, lately my boss has been taking away my projects and giving them to someone else, also cancelling my meetings and engaging less with me. I fear he is trying to make me quit, management has used this tactic to force other employees to quit before.
I decided to look for other jobs, no luck so far, and I read a bunch of articles suggesting me to do freelance work. My github portfolio is wanting and I am asking for any and all advice from the community:
What is your experience doing freelance? I am setting my account on upwork atm.
How may I get noticed? Any experience you can give a n00b like me? Can I get a living wage from freelance?
Much appreciated!",datascience
nky5ei,1621971520.0,Job frustrations (Data science/analysis),"&#x200B;

So I have been working overall for around 6 months as a data analyst. The first 4 months were a full-time internship at a big4 and the last 2 months have been a full-time position at a 6 years old startup. The experience at both firms is amazing and enjoyable. However, the tasks themselves can sometimes be frustrating.

**Problem**

The frustration comes mainly from hard to clean datasets (data inconsistency) or tasks that are not at my level of experience yet (aka challenges). We also receive in some cases datasets that are slightly modified (for no reason) which causes the script to give an error...

**Context**

We receive generally sales data from retailers, we clean them and push them to the database, so we can later on visualize, analyze, create predictive models.

**Discussion**

I would like to initiate a discussion on your personal experiences with similar problems and how you dealt with them (stackoverflow, asked your supervisor ...).

I wrote a [small blog here](https://dataanalystlife.blogspot.com/2021/05/data-inconsistency-in-real-life.html) about my thoughts  and stories so far (a 2 mins read). However, I would be much more interested in the real stories in the comment section than the traffic to my blog, because it will help me deal with the situations in a better way and with less frustrations on the long run.",datascience
nkwlgu,1621967359.0,How much of a role should assumptions for statistical methods of analysis play in data science?,"TLDR: As a data scientist how important are the assumptions for the statistical methods of analysis?

Currently I am working on my MS in data science, and I've been thinking a lot about how my data science CS courses practically ignore basic statistical practices that I was taught in undergrad as a stats major. For example: the last two semesters I have taken two courses offered through the college of computer science, taught by the same professor, one: data preparation and analysis, and two: data mining. Having taken a data analysis class in undergad (a different university and offered under the college of mathematics as a statistics course) I was very well equipped for this course but I noticed that the professor overlooked a lot of things that I was told is critically important to statistics and statistical analysis specifically assumptions and tests to see if those assumptions were met. I didn't think much of it, this course was designed for grad students and there are prerequisites that were needed that cover assumptions for various methods (though not all of the methods in this course are addressed in the prerequisite courses).

The next semester I take Data Mining, an undergraduate level course. Like I said, same professor, and a CS course. I understand that data mining might not be heavily as heavily based in stats as CS with its basis in machine learning and AI, but the stats is a piece. During our final project I was discussing with some friends the trouble I was having meeting assumptions with the dataset given (same project and dataset for everyone) and asked them how they were handling it. My friends, no stats majors, could not understand what my issues were. When I was explaining to them the assumptions for a principle component analysis (PCA) (a large part of the project) they said that I was making it a bigger deal than it needs to be, and I should just run the PCA with no check on the assumptions and move on like the example the prof provided us. Unable to get any help on my problem I did just that, turned in my project and to my surprise I got a 100%. I couldn't believe that I got no points deducted for not checking the assumptions. The previous semester I had a project too, my partner dropped the class in the middle of the semester so I did the project, assumption checks and all, on my own with little problems so there wasn't an issue.

As a statistician running analyses without checking assumptions raises huge ethical flags. How can I know that the method of analysis and resulting prediction responses were right without knowing the assumptions were met? I went on Kaggle to look at other people's code to see how they handle assumptions in their various projects and competition submissions and not many had the assumptions addressed. It made me wonder if in data science it was enough to run the analysis and predict, as long as there was a good prediction accuracy no need to worry about the steps to verify the method of analysis was the right method for the data.",datascience
nkurf1,1621962550.0,Predicting number of employees that will leave for a high turnover workforce,"Hi all,

At work, I am looking to predict how many employees will leave the company, on a weekly basis.

We contract a lot of our staff, so every week, we can have new joiners and those that leave (either due to their contracts ending, poor performance, etc).

Depending how work is going, we may be looking to hire 10 new contractors every week, with around 3/4 leaving. However in times when we get particularly busy, I want to be able to predict that more employees will leave and so we can tell HR to hire more contractors.

The data I have available (but can try and get more) is:

\- Total number of employees that have left every week

\- Total number of employees we hire every week

\- Current end of contracts/rating of contractors (those with particularly poor ratings, we will look to terminate).

&#x200B;

Can someone help me understand which direction I need to go in to do my forecasting? Just to confirm, I'm asking for you to point me in the direction, as I have never done this before!


I've read a few articles on Python that try and predict which of your current crop of employees will leave, but as there is a chance that our contractors can change, I need this model to be future proof.

&#x200B;

My initial thoughts were to create a basic model in Excel, where I calculate a baseline using the past 4 weeks actuals, then apply an uplift in weeks with a high end of contract, and when we see high number of low rated contractors.

This is quite manual though, so I was wondering if there was a more clever and robust way to do  this.

&#x200B;

Any advice/information would hugely appreciated.

&#x200B;

Thanks all",datascience
nkqyll,1621952661.0,Advice needed - PO for data science team,"Hey guys,

I recently got a position of a PO of a data science team. Previously I always worked with classic engineering teams. Needless to say, I quickly come to realize that 1) data science team != engineering team in terms of way of working and approach to work 2) I probably could use some development of how to be a better PO for such a team.

&#x200B;

What I would like to ask you guys about:

1. Could you recommend a good book / training / materials to become better in working with a data science team?
2. Could you recommend a good blog / web-site where I, as a PO can read updates in data science community that might be relevant for me? (by now I typically find resources which are more focused on tech issues / updates which would be more relevant for the ML engineers, data scientists)

Thank you!",datascience
nkptwy,1621949482.0,Visualizing graph2vec,"I’m a data science n00b and was recently asked to look into graph2vec... I ran the ex. program and it outputs a csv file with 128 dimensions... is their anyway to visualize this so that one can roughly see what is happening?

Thanks!",datascience
nkpidl,1621948544.0,Efficient Decision Tree Pruning in Python,"Hi,

I'm working on a project where I need to automatically create a large number of decision tree, and to prune them.

The only way to do that is a function like that :

    def do_best_tree(Xtrain, ytrain, Xtest, ytest):
        clf = DecisionTreeClassifier()
        clf.fit(Xtrain, ytrain)
        path = clf.cost_complexity_pruning_path(Xtrain, ytrain)
        ccp_alphas = path.ccp_alphas
        clfs = []
        if len(ccp_alphas) > 100:
            nb = 2
        else:
            nb=1
        for ccp_alpha in tqdm(ccp_alphas[::nb]):
            clf = DecisionTreeClassifier(ccp_alpha=ccp_alpha)
            clf.fit(Xtrain, ytrain)
            clfs.append(clf)
        return max(clfs, key=lambda x:x.score(Xtest, ytest))


So it take a huge amount of time, as it fit a lot of trees. See the

       if len(ccp_alphas) > 100:
            nb = 2

I added in order to divide by two the number of trees, but it still very slow.

Isn't there another way to do that ? For example by really pruning a single tree ? I'm not limited to scikit-learn, but didn't find anything that is doing that....

Thank you in advance !",datascience
nknmvd,1621942704.0,Does anyone else feel like an incompetent programmer?,"I'm currently an engineering student, and I started my data science journey about a year ago when I discovered my passion for data. Since then, I have been self-taught all the way from MOOCs and books. I tried to apply what I learnt through personal projects and internships, but the entire time I feel like I've only been searching up, copying code and modifying it for my own needs.

Most of the time I don't write any original code except for some simple functions or if I'm working on a platform with custom syntax. I am mostly familiar with the libraries I need, but only to the extent where I know which specific library can help me with a particular task.

I know it's still pretty early in my DS journey, but I can't help but feel incompetent sometimes. Does anyone else have the same problem? If not, how do I overcome this and become better at writing original code?",datascience
nkgeop,1621914580.0,Multimodal Deep Learning," Hi  Guys, I have a problem statement where there is a need for fire  detection which is usually handled by Computer Vision Object Detection  models - YOLO, Faster R-CNN, etc. However, I was thinking about using  Multimodal DL for this to take inputs from heat/thermal sensor, etc.  apart from video feeds.

Any practical blog/tutorial you can point me to?

Thanks!",datascience
nkg3d9,1621913484.0,Specialize in one area or be a generalist?,"I’m wondering if I should stay a generalist (there’s always stuff to learn) or if I should hone in one niche area (NLP, computer vision, causal inference or bayesian stats)

It seems like the ideal data scientist is an expert in all of those areas, even though in reality it’s quite difficult. We all sorta learn what we need depending on the problem we’re tryna solve

Update: seems like most of y’all are recommending be a generalist unless I’m passionate about a specific area",datascience
nkfa84,1621910863.0,"Do successful models defy the ""bias-variance tradeoff""?","In statistics, we are always warned about the ""bias-variance tradeoff"":  simple statistical models are reliable, but are generally unable to sufficiently capture the complexity within the data (i.e. high bias, low variance) ; complex statistical models are able to capture complexity within the data, but are generally not as reliable when generalizing to new data (i.e. high variance, low bias).

This leads me to my questions:

1) Are successful statistical models able to defy the ""bias-variance tradeoff""? As a simple example, consider the famous ""iris dataset"".  Kaggle competitions have shown us that statistical models can be made that perform well on both the training data as well as the test data. Are these statistical models defying the ""bias-variance tradeoff""? Now, let's imagine a far more complicated problem and dataset - but suppose that we are still able to create a statistical model that performs well on both the training data as well as the test data : are we again defying the ""bias-variance tradeoff""?

2) I have seen proofs that show how the MSE (mean squared error) can be decomposed into a ""bias term"" and a ""variance term"". Thus, for a given statistical model : for a fixed value of this model's MSE, if the variance is high then the bias must be low in order to compensate (and vice versa).

My question relates to the following : when people discuss the variance in the ""bias-variance tradeoff"", they are generally interested in the variance of a statistical model's performance when dealing with unseen data. Since this unseen data might not even exist at the moment, how is the ""bias-variance tradeoff"" able to make claims about unseen data? Is the ""bias-variance tradeoff"" a general idea with some theoretical foundations? Or is it mainly empirical?

3) Finally, how does the ""bias-variance tradeoff"" apply to real world models such as the ""self driving car"" , ""alpha go"" and computers playing tetris? Or in the case of reinforcement learning models, the ""bias-variance tradeoff"" does not apply the same way it does in supervised learning models?

Thanks",datascience
nkcehu,1621901870.0,Explain the need for non SWE ML pipeline vs existing SWE frameworks,"Hi , Looking at [metaflow](https://docs.metaflow.org/) tutorials and trying to see how different/ better it is from the setup below that can work in a SWE based pipeline; And if any reason to switch to metaflow , or all its features listed below are covered adequately by this setup:

&#x200B;

1. **DataWarehouse** \- Source of data (pumped in from dbt pipeline)
2. **Compute resources** \- Covered by autoscaling in aws;
3. **Job Scheduler**:

* Quartz/Spring application reads configuration from a job database with a UI for entering schedules & jobs;
* Schedules are decoupled from jobs; can evolve independently without touching code.
* Most jobs are to send a message to a kafka queue to kick off spring batch or python ML code.

**4. Architecture**:

* Orchestration handled by Java Spring cloud  stream / data flows plus kafka topics / producers/consumers.
* ML jobs are python classes /in-house python libraries so mostly in the ML pipeline only parameters are read from db and applied to the appropriate ML class;
* Emphasis on avoiding one-off ML python procedural scripts
* Data transfer between steps done using dbt (sql is understood by more folks). Only ML steps done in python

&#x200B;

5.     **Versioning/Inspecting Results & Organizing Results:**

* dbt  & python ML jobs  results histories  based on batch/run\_id are stored and can be queried in sql
* Micrometer&Prometheus metrics used to monitor success/ failed stages of all jobs.
* Sleuth distributed log tracing also used.
* Namespaces for development artifacts are simply git branches of each developer
* Namespaces isolation when inspecting results is based on run\_ids/user\_ids embedded in micrometer metrics and intermediate results of dbt & python ML job histories.

**6. Loading and Storing Data:**

* Intermediate steps data is stored in database/s3

**7.  Loading and Storing Data:**

* Again no need to reinvent the wheel ; gradle for java code , pip aand requirements.txt for python

In all these steps using a mature framework like spring boot & spring cloud stream makes life a lot easier

This setup will allow use common workflows that are already well defined in SWE rather than redefine new workflows in the existing infrastructure",datascience
nkbqx6,1621899844.0,I'm offended by having to scale my data,I find it demeaning,datascience
nkbfil,1621898885.0,What kind of mindset a person should shape in order to bocome a good data scientist?,"Some context, I'm gonna be speaker for a meetup and I want to touch the fundamentals for people who wants to start their career as data scientists.

Rather than talk about the usual stuff (develop math, biz and coding skills) **I want to people reflect on the mindset they need to build so they can become successful data scientists**.

Right now I have for things to share with them:

1. _Curiosity_: Data scientist are people with lot of curiosity and they are willing to research. If your stay curious you will have the mindset for ask questions, look for data, formulate hypothesis and test them.


2. _Perseverance_: Usually, Data Science is a rough path. There is no magic bootcamp or 6 month course to become a good scientific. You need to stay focus and practice your skills pretty often (even by just listening a podcast or reading a paper).


3. _Emphaty_: You have put yourself in other scenarios rather than just thinking inside the Data Science side. Often you need to collaborate with other disciplines and understand the context of unknown situations. You might analyze social events, business metrics, human behavior, etcetera.


4. _Participation_: As data scientists, we need to get our hands dirty. No better way to learn (imo) than building real applications, solve real problems.


**What other characteristics do you perceive in a successful data scientist?**",datascience
nka0nu,1621894795.0,Effective SQL for Data Science,"These last couple of years, I've spent a lot of time writing SQL. I put together some lessons learned to use it effectively for Data Science projects.

Small things like using CTEs, auto-formatting, and jinja have made a huge difference for me.

What other recommendations you have to master SQL for Data Science?

[https://ploomber.io/posts/sql/](https://ploomber.io/posts/sql/)",datascience
nk8t4x,1621891428.0,"Need pointers on where to start on how to model this data that is essentially ""arrival times"" or ""arrival delays""","The situation is like this:  We receive deliveries of data electronically, and let's say they are expected to arrive at 8 AM daily. But historically they can arrive at say 5-10 AM. So it's periodic but not really. The data is gathered only hourly at the top of the hour.

The data we're gathering now is basically ""time since last arrival""  which is zero when something has arrived in the last hour, and ticks up hour by hour until the next delivery.  What I've been doing so far is fitting this with a sawtooth wave and whenever a delivery is late, the ""time since last"" goes above the threshold and alerts us.  I researched time series data and such but it's not really what I'm looking for.

Here's the issue:  we have dozens of different ones of these per customer and hundreds of customers,  and my fitting works well most of the time, but there are still a large number of false alerts. Also, some of these are 7 days a week, others are M-F,  others are more than once per day.  All very different kinds of sawtooths, and a lot of manual adjusting.

What I've started doing is just collecting a histogram of when the arrival delay is zero vs hour of the day, this gives me just a set of times. I did this for one example of a reasonably well behaved data set and got a distribution that was rather skewed but fittable. (Is this a Poisson process?) I have enough history to look back 6 weeks. This gives only 6 data points for e.g. a Tuesday, but for 7-day-per-week systems there is no problem aggregating all the days and looking just at the hour of the day (42 total data points)  But knowing when to combine 7 days, vs 5/2 split etc is a manual decision. I would prefer it it could fit each arrival event separately.

(I'm actually looking at the data for 6 weeks plotted over 1 week timeframe of 168 hours per week, so I see the scatter plots overlayed and can guess at the amount of variation when I do these, so for example 8 AM Tuesday would be at T=56 hour and constructing the threshold sawtooth function on that axis.)

What I am looking for (perhaps) is a way to give say, based on the real history, give me the time of day that if the packet hasn't arrived by, there's a high % chance that it's late and set an alarm.

Since the history can and does contain some that were late (or absent) I know those should factor in with less weight. I don't know what kind of distribution these should fit or how to output a cutoff value for a given % chance it's out of compliance.  And the reason I'm trying is so I can script this to analyze hundreds of such data sets and set thresholds automatically.

Any suggestions where to look?    Online article?  videos?
I would be interested in suggestions for textbooks as well.

Thanks",datascience
nk7hs9,1621888060.0,What is a good answer for: Why use l1/l2 norms but not L0.5 or L3?,"I see this as an example interview question all the time.

But I never see great answers.

So far as I can tell, a good answer might be..

\- L2 norm is continuously differentiable
\- L1 has closed-form solution


\-L0.5 or L3 are possible
\-but L3 norm will tend to overregularize and bring coefficients towards each other.
\-L0.5 norm would induce some irregular sparsity; not even sure how to clarify this one.

&#x200B;

What else would people mention? I know there are answers involving Hilbert spaces with the L2 norm but I don't really understand that.",datascience
nk6noh,1621885940.0,Looking yo hire a Data Science mentor for career advice,"Next year I will start my MBA and after that I am starting a MSc in Data Science. I am 31 years old and have worked as Marketing Manager and eCommerce Manager. All of these positions involve lots of data analysis and data visualization but none of data science (prediction models, machine learning, etc).

I have experience using Tableau, PowerBi, Google Data Studio, Analytics, Ads... I have worked mostly on Analysis and Visualization. My biggest weakness would be the ""math"" side of data science.

My ultimate goal is to work at Google, it has always been my dream company. Other options are big companies such as Amazon, Facebook, Netflix, DiDi, Uber, or any other ""big"" company.

I don't know if I am the right thing by looking for a Data Science mentor, or if I should be looking for a different person, like a general career counselor? Any tips?",datascience
nk5dny,1621882657.0,"UPDATE: Just had my interview, was it an ""air raid"" style of interview that I was afraid it was going to be?","Prior Post for context: https://www.reddit.com/r/datascience/comments/nhi11p/has_anyone_here_had_the_experience_of_what_i_call/

Sadly I think it was an air raid for the most part... and I don't think I did very well.

I didn't really get many rapid fire trivia questions, although I got some, and I had to answer a couple with ""I don't know."" For example I was asked what is the mathematical equation to calculate p-values... I answered with ""I don't remember? I would have to consult my college notes from 11 years ago"". In my head I was thinking, why does it matter when scikit learn or R does that all under the hood? There was another trivia question I got which I answered I don't know but will not say what it was for the sake of not outing myself incase the interviewers are reading this.

I got some data engineering questions(not my strong suit) and I don't believe I gave good answers. Everywhere I have been I have worked along side with data engineering teams but have never actually done the data engineering work. When I got to the point of the interview where I could ask questions I asked if this role was more of a data science role or data engineering role and they said definitely data science, they have separate data engineering teams, so I have no idea why I was even asked these questions.

I think my strong suit was using my past work experiences to outline how I got things done, but even then I am not sure if my responses were good enough because I felt like I was on defense from the get go. I do better in interviews when I am ""on offense"", so to speak. For example I was asked for an example of how I segmented customers in the past and used that to drive revenue growth. I said I would look at various segmentation techniques and choose the best one based on model performance against test data, and how I determined that to be K-Means clustering after using PCA to reduce the number of features and using a scree plot to determine the number of segments. And how this segmentation approach allowed us to grow our revenue from 4th place in the market to 2nd place. I don't think I was precise or deep enough in this answer and was too vague and I didn't project enough confidence. But, in an hour long verbal interview, how deep am I supposed to go? I struggled with finding the right balance of depth and respecting the time constraints.

I'll be surprised if I don't get rejected... but I feel like this format was tough to succeed in. I believe I am a strong data scientist, but I am at my best when I know exactly what scenario I am facing. Questions like ""Here is what we want to accomplish, how would you do it?"" are what I do best, I didn't get any of those questions. It was more open ended broad questions such as ""What is your go to machine learning model"" and I literally could have given anything. It depends on the task at hand. I said Random Forest to go with the question and how I like the built in OOB functionality in R. Although if I could answer the question again I'd go with Gradient Boosting.

Another question I hated was ""How do you stay on top of data science industry trends"". I didn't really know how to answer that one. I said I stay engaged with publications and gave a personal example of what I do in my free time(that I won't say since I don't want to out myself incase those who interviewed lurk here) but I don't like this because I believe you stick with what works and you don't always need to be jumping to the new and shiny toy out there unless there is a good reason, and if there was you'd probably know about it without having to be proactive to learn about it.

Another question was ""Do you follow up on your own models performance against real world data?"". I didn't have a problem with this question because of course I do. Who doesn't? I said its one thing for a model to have high accuracy on train and test data, its another thing for it to actually perform on real world data that you collect after the training and testing process. Therefore you want to make sure its actually hitting the marks that you calibrated during the model building phase otherwise go back to the drawing board. Then they followed up with ""What if you gained more responsibilities on your plate and could no longer follow up on all of your models?"", which I think was a silly follow up, because I feel that is putting the cart before the horse. I said in a hypothetical scenario where my bandwidth was overextended to where I could not do such a thing, as I hope it would not get to that point, I would have to resort to being a leader and calibrating the bandwidth of my team and allocating resources to ensure it does get done.

I got asked ""How do you perform feature selection"" and I simply explained various ways to do it based on the model at hand(i.e. p-Values for linear regression, feature score for Random Forest, etc.). I didn't like this question because its something you would ask an entry level candidate, not someone interviewing for director. I answered it anyway but with only an hour, I feel like better questions could have been asked.

The interview was solely to gauge my technical abilities, not my leadership or management abilities, so I understand that the interview was aimed to do that. With that being said I don't think I answered the questions given to me with enough confidence or precision. I am good at gauging body language, facial expressions and tone of voice of those interviewing me and I don't think they were impressed. If its up to these 2 guys I don't have a chance. The only way I have a chance is if all I needed to do was show some basic technical competency and the hiring manager(who was on the call but was just there to listen) values my management/leadership attributes and track record more than my hour long call with these 2 guys.

Comparing this interview to the 3 bad ones I had before I think this one was definitely the worst of the bunch in terms of how I gauged my performance. I am starting to lose confidence in my interviewing skills, as I believe I have a hard time translating my actual 10 year track record into verbal competency. I know how to do things, I just have a hard time coherently explaining how those things are done.

Fortunately... I have another interview starting in 10 minutes... and 5 others lined up this week. But this was the job I really wanted out of all of them.",datascience
njyxnj,1621865638.0,"Completely and totally 'burnt out' at work, unsure if I should quit or just go rouge and do my own core data science based projects?","Edit: Disclaimer, not 'stress' burnout, more like, feels like a total dead end role now, can't go on much longer, like Peter Gibbons from Office Space, that's how I feel.

Ok, context in a nutshell, been at this tech company for about 4yrs in a mixture of roles from product to market research, but been working as a data analyst for the last 2yrs, nearly 2.5

My goal had been (and agreed with HR) to progress towards a data scientist role when I originally signed up to it. But this has not materialised.

Fast forward 2.5yrs, I've had absolutely nobody in the business to learn from(never had), everything has been self-taught, my day to day work has been much more BI related (dashboards, product stats etc) as opposed to core data science tasks. I really have to go out of my way if I want to write and code, even SQL (data is all maintained by gatekeepers, mostly inefficient ones, so I have to request it mostly, then it's just an out the box plug in to PowerBI/Tableau or similar)

I've absolutely maxed out my patience with this company and their talk the talk grand plans. My technical skills have totally stagnated, and if I was to compare it to when I left uni, my skills regressed in areas such as advanced mathematical/statistical techniques. My day to day tasks typically involve adhoc requests solved with Tableau (with absolutely horrendous data quality). There are some back end things involving SQL/Mongo/AWS but these are probably 10% overall if even that. When it comes to addressing the data, I'm more like a project manager, because I'm not allowed to fix or implement things myself. So I end up making requests for things and gathering requirements like a PO/BA/ProjMan hybrid role, but even that is a waste of space, e.g. simple request for consumer product usage? Dead in the water for over a year despite weekly meetings because the development team won't implement changes needed to track them (new POs can be seen mentally questioning life choices when the answer to 'so where can I see the usage stats' is, ""they don't exist"")

The only thing it has that appeals is a degree of autonomy with what I do once I finish the adhoc requests. I easily have 50% of my working hours to address anything I like (in my more motivated, enthusiastic days this was spent addressing the data quality issues, data warehouse etc, but the way these ideas and suggestions were valued/met just killed my soul; options and recommendations closed due to 'time', 'cost', 'effort' etc

I'm thinking of just self teaching the core data science content I wanted to initially learn (I'm already doing this, just not applying it to anything at work), and finding things to apply this to at work.

The problem is, I'm all alone. Nobody in this company has a data science background, so I can't learn from anyone here. I'll have no idea if what I am doing is good practice or even straight up wrong. Even if I did, the data is such bad quality and held in rigid, closed off systems (I am always refused direct access to it) that I'm not convinced there's a lot of real insight to get from it

Given that I have no real world data science experience, I'll be competing for entry roles in a competitive job market. So I'm really not sure if I should stick at this place and do my own thing on the job (flying blind, probably with low output) or just quit, spend summer selfteaching and practicing on projects I actually care about personally, while applying for jobs (have some master's degree offers in September if shit hits fan)",datascience
njxwij,1621862683.0,How to geo-cluster houses in a real estate dataset?,"I have a fairly large portfolio of houses (think thousands) that I want to cluster based on - proximity to neighboring houses and some house types (fuel source, detached / apartment ...).

The goal is to create clusters based on the distance to other houses and the types (e.g., cluster of 5 houses max. 50 meters from each other which are all on the same fuel source and are detached). Luckily, in my dataset it is most likely that houses next to each other will also be of the same type.

Do you have any tips on algorithms / approaches for this job? I am proficient in Python / R.

Thank you.",datascience
njqqpw,1621835224.0,Tools for error Analysis,"Are there any tools to make it easier to debug the model performance and evaluate the model errors? For example, I want to be able to able to dissect how my model is performing for certain classes etc",datascience
njihmm,1621807376.0,"Why do you think Data Science became this ""sexy"" job and what job was hot before this?","Happy Sunday!

I was hoping we'd have a light discussion before jumping in the week tomorrow.

I'm 26 right now, when I was in my undergrad, I remember Android development or some kind of website development were pretty popular among the college students. Today I was wondering that apart from money, what makes a job ""hot""?

Would love to hear from you guys, especially who have been in the market before Data Science even existed.

Thank you!",datascience
njen7v,1621796805.0,Online machine learning (or how to automatically update your model in production),"I'm trying to find resources to learn more about a new subfield in Machine Learning called online learning.

The idea is beautiful and powerful: your model in production trains itself with new latest data to react to changes faster. However the classic ways to build the MLOps infrastructure and algorithms' maths won't do the job here, so I'm eager to learn more:

* I've found [this post](https://huyenchip.com/2020/12/27/real-time-machine-learning.html) by Standford's ML lecturer Chip Huyen to be a great introduction to the concept of Online Learning.
* I've found [river](https://github.com/online-ml/river) to be a promising python library for online learning.

Apart from that, I don't know many resources out there, do you? Any blogs to follow? Any ""Titanic"" equivalents (a simple problem to get going)?",datascience
njd0ft,1621792294.0,What is a good technical interview machine learning question?,"I am giving a technical interview later this week.  My background is in statistics and I will be a question with coding on it.  But I also want to ask a machine learning question.

Our company usually uses machine learning algorithms for prediction as an alternative to logistic regression.  My own understanding is just that decision tree has a decent interpretability but less accurate than random forest or Xgboost.  I don’t think it is fair for me to ask the candidate their algorithms in details since I am not an expert myself.

Does anyone have any suggestions?  Thanks.",datascience
njcmm2,1621791237.0,Time Series Anomaly detection system,"Hi All,

So I recently joined a firm with massive operations in the logistics & delivery business. We are currently building a system that can automatically flag anomalous events based on the time-series nature of business KPIs across multiple cities & zones. We are facing multiple roadblocks & I feel completely stuck in a loop without any progress. Below are a few problems we're facing:

1. Prior to this system business never tried detecting anomalies manually, so they don't know what an anomaly is. This is my biggest concern as it makes the problem statement quite open-ended. Also, even after detecting an anomaly through time series models, we don't have any mechanism to evaluate them
2. While building a time series model, should we include the underlying variables as the predictors? Or just treat the target variable as a univariate variable and perform Root cause analysis on the detected anomaly events?

Please share any resources or case studies of a similar system that is implemented on a large scale. I know this problem is very business-specific but I assume the underlying techniques will be similar for such systems.",datascience
njbini,1621788090.0,Is cross-validation hyperparameter tuning sometimes not better than just setting reasonable values?,"I have noticed this in practice like in Kaggle comps. Sometimes I have done no hyperparameter tuning by just setting whatever seems reasonable ish in a ballpark or using defaults and it ends up performing better than doing computationally intensive and tuning every little hyperparameter.

In the real world I also wonder whether cross validation for hyperparams can result in being more sensitive to things like data and concept drift. Because well if the future data doesn’t look like your validation set then the CV would have resulted in you overfitting the hyperparameters themselves.",datascience
nja1gq,1621783785.0,What are methods that explain aggregated time series anomalies? For example what feature values contributes to number of Covid-19 cases at a given time interval?,"Let’s take Covid-19 global number of positive cases.

For each day, the global daily number is known by aggregating each country number. And each country cases can be further grouped into different variables like by virus variant, by country state, etc.

If someone looks at the global time series, it’s hard to know which variables are contributing to the number of cases without cutting and slicing the data.

Are there methods that allow us to surface the variable values that contribute to the number or cases for a given time interval?

This sounds somewhat easy, like I can calculate the contribution percentage of each variable value, and sort them.

Though I may also be interested in the contributing trend as well which can be positively contributing to the global number of cases and negatively contributing to the global number of cases.

From my cursory reading, I found topics such as aberration detection. Or generally anomaly detection. But these topics almost never explain what are the variable values that contribute to the anomaly. It max explain anomalous points due to trends and seasonalities but not so much on what are the explanatory variables given that we have aggregated time series.",datascience
nj9s57,1621783002.0,"LinkedIn Open-Sources ‘Greykite’, A Time Series Forecasting Library","LinkedIn recently opened-sourced [Greykite](https://engineering.linkedin.com/blog/2021/greykite--a-flexible--intuitive--and-fast-forecasting-library), a Python library originally built for LinkedIn’s forecasting needs. Greykite’s main algorithm is Silverkite, which delivers automated forecasting, which LinkedIn uses for resource planning, performance management, optimization, and ecosystem insight.

While using predictive models to estimate consumer behavior, data drift has proven to be a great challenge during the pandemic in 2020. In such a situation, predicting future expectations is challenging as well as necessarily helpful to any business. Automation, which allows for repeatability, can increase accuracy and can be used by algorithms to make decisions further down the line. According to LinkedIn, Silverkite has improved revenue forecasts for ‘1-day ahead’ and ‘7-day ahead’ and Weekly Active User forecasts for 2-week ahead.

Full Summary: [https://www.marktechpost.com/2021/05/23/linkedin-open-sources-greykite-a-time-series-forecasting-library/](https://www.marktechpost.com/2021/05/23/linkedin-open-sources-greykite-a-time-series-forecasting-library/?_ga=2.74959442.1924646600.1621739878-488125022.1618729090)

GitHub: [https://github.com/linkedin/greykite](https://github.com/linkedin/greykite)

PyPI: [https://pypi.org/project/greykite/](https://pypi.org/project/greykite/)

Paper: http://arxiv.org/abs/2105.01098",datascience
nj6cc2,1621771230.0,Weekly Entering & Transitioning Thread | 23 May 2021 - 30 May 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
niuauk,1621724222.0,What type of job would allow me to create useful tools for a data science/data analyst team?,"I am currently a data scientist/analyst. My current job has a lot of analyses and code that could be functionalized and used as an internal Python package. I am interested in working in a role that is focused on creating packages, tools, and other processes to help streamline and create efficiency for an entire DS team... and less so a role that is actually DS itself. Curious if anyone knows if there is a certain job title that fits this description?",datascience
nir1qm,1621714470.0,Questioning my qualifications for an Analytics Director position I have been interviewing for(and have advanced far in the process for),"I have 8 years of experience in data science, and was reached out to by a recruiter in regards to a Director of Marketing Analytics position for a company that is not a no-name company(many of you have probably heard of them). I have gone through the interview process and have advanced far in the process, so I would imagine I am coming to the end of the line.

The problem is I keep reading the job description and am wondering how qualified I truly am for this role. The last 5 years I have managed teams, with my most recent role managing a team of 8 as a senior data science manager(my team was laid off in December). I consider myself to be very well versed in data science and everything that comes with it.

HOWEVER... the job description(in terms of duties) has a lot of data engineering lingo in it. Something I really don't have experience in. Everywhere I have been, we have had a separate data engineering team that handles all of that, which I work parallel with. In all my roles I have been strictly data science, modeling, machine learning, deep learning, analytics and insights, client and executive presentations, and nothing to do with data warehousing and data pipelining. But, in the job requirements section, I meet all of the qualification criteria.

I can send the exact job description, qualifications and responsibilities in private message if anyone asks. But, I feel like my data engineering skills are lacking, and you think the recruiters and those I have interviewed with so far would have been able to tell that, but I keep advancing. In my interviews, I talk up my technical skills, but most importantly I talk up my people skills. As I have advanced in this profession, the one thing I have learned is the higher you go, the less important your techinical skills become, and the more important your people skills become. Those I have spoke with so far are really glad to hear someone say that...

But, I don't want to set myself up to fail. Should someone with my level of experience in this industry be expected to have data engineering experience as well? I've always viewed the two as two separate discplines, and I believe a position marrying the two would be overkill. I believe in specialization in that regard. I believe in terms of pure data science and analytics I am a home run for this role, but all of the data engineering mumbo jumbo in the job description is scaring the bejeezus out of me. Surely in my next interview this week I could ask if there is a separate data engineering team or if its something I would have to handle. Or am I worrying over nothing? Surely a company this size would have enough resources to split the two disciplines out?",datascience
niq3eb,1621711650.0,How does everyone share their models etc. across teams for re-use effectively?,"Does anyone know of any good tools for knowledge sharing post fact?

We've tried this but found it came up a bit short.

https://github.com/airbnb/knowledge-repo",datascience
nino7x,1621704728.0,"Need to go back to the basics, what's your favorite Stats 101 book?","Hello!

I an looking for a book that explains all the distributions, probability, Anova, p value, confidence and prediction interval and maybe linear regression too.

Is there a book you like that explains this well?

Thank you!",datascience
niljmw,1621698711.0,Does anyone use STATA?,"I have a Master's of Public Policy and I generally would do data cleaning / ETL in Excel, and then import it into STATA for multivariate regressions.

It was nothing fancy but it was insightful and I enjoyed it; now I want to expand my knowledge into SQL, but I am wondering if realistically so few people/places use STATA that I should start learning Python, or SPSS instead?",datascience
niieqi,1621689331.0,Your experience with Knime,"Hi everyone,

I was scrolling feeds of the group and did a quick search for Knime. It actually surprises me how unpopular as a platform is considering that the last post was a year ago.

I have started to learn more about Knime (required for job) and wanted to see your thoughts on the platform based on the experience you had.

Is there any substitute that does a better job than Knime and this is the reason why it is not very popular.

Any opinion is helpful.",datascience
ni7cix,1621645341.0,Data Scientist vs Senior Product Analyst,"I'm in the unique and fortunate situation of having the option of choosing between a data scientist (promotion in current company) or senior product analyst (offer from a new company) position for my next role.

Both would be significant upgrades for me, but the product analyst position at a new place will pay significantly more (I don't know by how much yet as I'm waiting for a formal offer from my current company). I have wanted to break into DS and get the title for a while, but I'm not sure if staying at my current company with lower pay is worth the title.

I know titles and actual work in our field really aren't well defined. I have some indication of what the DS work if I stayed would look like- some cool ML models, recommendation algorithms, testing, as well as more typical data analyst work with SQL and no modeling. My preference would be to do modeling and more DS long term, but I'm also kind of ready for a reset and new company.

There's certainly some factors I'm leaving out,, but which opportunity would you jump at? A DS role with the title and maybe more interesting work, but lower pay and company frustrations - OR a senior product analyst role at a new, exciting company with significantly more pay and more typical product analytics work.

Maybe ""which would you pick"" is too subjective- but what considerations would you make?

Any advice welcome, thanks!",datascience
ni5ptp,1621639581.0,"spark ml StringIndexer vs OneHotEncoder, when to use which?","Confused as to when to use [StringIndexer](https://spark.apache.org/docs/latest/ml-features#stringindexer) vs StringIndexer+[OneHotEncoder](https://spark.apache.org/docs/latest/ml-features#onehotencoder).

The OneHotEncoder docs say

>For string type input data, it is common to encode categorical features using StringIndexer first.

In what situations would I want to take the extra step of transforming StringIndex'ed output to one-hot encoded features? I can find a lot of resources on how to use which, but not in which cases the OneHotEncoder would be better.",datascience
ni2x2q,1621631225.0,"how ""interpertable"" are regression models?","I was recently reading some articles on the importance of ""interpertability"" when dealing with ""blackbox"" models. ""Blackbox"" models like neural networks are said to have a very low level of interpertability, because they don't allow the analyst to understand why the model is making a certain predictions for an individual observation.

On the other hand, models like decision trees and regression models are said to have much higher levels of interpertability. In a general sense, I can understand why models like decision trees are interpretable, because they literally provide the analyst with a set of fixed rules that explain how to classify an individual observation.

If you look at a regression model,

e.g. salary = 5.3 * height  + 2 * weight  - 15.8 * age

A regression model can allow the analyst to understand how much each variable contributes to the prediction (e.g. in this example, age contributes more to the prediction by a factor of almost 8 times), and you can also find out how statistically significant each variable is (e.g. indivudal p-value of each regression coefficient).

Is this what is meant by the ""interpertability of a regression model""?

Thanks",datascience
ni0xcu,1621625813.0,The best data science newsletters that you subscribe for?,,datascience
ni0b8j,1621624185.0,"Currently a Data Scientist... Want to increase my skillset to expand into Data Engineering... Any great resources, courses etc that you guys can recommend. Thanks",,datascience
nhzi43,1621622017.0,What is ONE single essential tool/program/skill that a new person absolutely must master when transitioning into a data science/analyst role?,"

[View Poll](https://www.reddit.com/poll/nhzi43)",datascience
nhxqrn,1621617329.0,"How do YOU pronounce ""epoch""?","I've always pronounced it as ""eeee-pock"" which is how my Comp Sci professor who first taught me neural nets said it. But I hear people say ""epic"" or ""eh-pock"" all the time and it really irritates me for some reason.

How do you think it's supposed to be pronounced in a data science context?

Edit: I've learned from some commenters that the American pronunciation is supposed to be ""eh-puk"" (like epic) and the British pronunciation is supposed to be ""e-pock"". But I swear I hear some people sort of meet in the middle and use ""eh-pock"" as well.",datascience
nhv5w3,1621610728.0,"Review: Statistical Rethinking, by Richard McElreath","[https://www.crosstab.io/articles/statistical-rethinking-review](https://www.crosstab.io/articles/statistical-rethinking-review)

I noticed a lot of folks recommending this book, so I followed the crowd and got a copy. It's oriented toward researchers in natural and social sciences, so I wrote up my thoughts about the book from the perspective of an industry data scientist",datascience
nhtcug,1621605990.0,Should I use Python at work if my coworkers don't have experience with it?,"I am working on a Data Science project at work and my manager gave me permission to use Python. However, he also said that my code should be clean and readable and I must explain it to my coworkers, since none of them have extensive experience with Python before. This is because I am an intern, so when I leave, my coworkers must be able to understand my code and maintain it. Because of this, do you think I should use Python? Or use something else like Excel to be safe cause everyone know Excel?",datascience
nhstoa,1621604517.0,I'm fed up of seeing continuous data from tests in the time domain. It offers very little value.,"This drives me nuts.

Unless you are looking for a relationship between time and your variable, graphing in time is useless.

I so often see: two parameters plotted on the same graph (x axis time) where people are trying to establish a correlation.

This isn't limited to the fresh faced grad who's just discovered R. But experienced technical experts in a field, typically engineering data in the fields I work (data logging etc.)

If you want to visually assess correlation between variables, plot them X vs Y, and then lets have a look.

* Where time is not a critical factor.",datascience
nhp2ui,1621592160.0,Securing Machine learning model,"Hey guys, I have a scenario where a ML model needs to be deployed on client's server. There exists the possibility that the model might be reverse engineered and therefore there is a need to protect it.

Suggestions for achieving this?

Thanks!",datascience
nhi11p,1621564466.0,"Has anyone here had the experience of what I call an ""air raid"" style of interview, where the panel of interviewers seem to be constantly trying to attack and poke holes in you?","I've been back on the job market for the last month since being laid off and I have what may be a final interview on Monday for a job I really want, its kind of a dream job for me, Director of Data/Analytics for a company I've always wanted to work for. I didn't even apply, a recruiter sought me out personally. I have the experience and qualifications. I've been in this business since I graduated in 2011, I have management experience, and a successful track record.

I've already had multiple calls with hiring managers, and those have all been great, hence why I have advanced so far. However my next interview they said they are bringing in 2 outside guys from a data firm they contract to ""gauge"" my technical experience.

This immediately brought in fear because I've been interviewing for many jobs over the past month and I've already had 3 interviews that I considered to be ""air raid"" interviews where it seemed like I was under attack from the panel rather than being interviewed by the panel.

The first ""air raid"" interview I was facing a panel of 3 in a final interview setting and all of a sudden we get to a part where it was rapid fire trivia style questions. I felt like I was on the fast money round of Family Feud because I was only given 30 seconds to answer each question. The thing is it was pure Python trivia, a lot of questions over stuff I'll automate anyway that I didn't know off the top of my head and would have to reference my work. The guy leading the interview, the entire time during this, had a smug, skeptical look on his face like that blonde dude from Napoleon Dynamite who is always making fun of Napoelon. Afterward the 2 other interviewers were trying to apologize without apologizing as you could tell they werent a fan of that part of the interview. I did fine on everything else, but that was a train wreck and I got the rejection email the next week.

Then about a month ago I had another panel style interview, going up against 3 guys who I felt were just trying to knock me down from the get go. Asking a lot of ""booby trapped"" questions that I was clever enough to ""figure out"" but there were a couple that got by me. Questions obviously designed to trip people up. It didn't help that the microphones one of the interviewers had was horrible and I kept having to ask him to repeat questions, but these guys were very smug and hostile and played off of each other as if it were some kind of game to ruin the dreams of anyone applying. I got rejected by these people too, and actually got a customized rejection email saying that my skillset was below their standards. No shit, if they are judging my skillset based on that interview they won't find anyone that meets their standards. Which is the case because I still get emails from LinkedIn telling me to apply for that job as they are still actively recruiting for it. Good luck!

Finally I had a take home task that took me about 5 hours and I had to present it to a panel, and they were really unimpressed, not because of my conclusions/findings/work, but because it wasn't ""visually appealing"" enough. They actually wanted me to present my findings in PowerPoint(I used R Markdown) with fancy infographics and such. I didn't realize I was being hired for a graphic design job. I did what I was tasked to do and infographics were not in the task instructions. It's not like my R Markdown graphs and charts were ugly or off, they told the story perfectly and accurately, but its clear they were looking for someone who wanted to be an artist as well.

Anyway, I feel like these 3 experiences have prepared me for what I may be facing, and I suppose there is a chance that these 2 guys they are bringing in to ""gauge"" my technical skills won't bombard me and will be totally cool, but I am not getting my hopes up. These two have already reached out to me and asked for my GitHub account, something I was not prepared for since I was never asked about it prior nor was it in the job description. I sent it over anyway but a lot of my code was written for a one man audience(me) and I wasn't able to save all of my work from my past job as they blocked access to my work OneDrive as soon as I was laid off so I could only save my work samples that I had on my own machine. Therefore I don't feel like my GitHub is truly putting my best foot forward.

I had a good panel interview experience 3 weeks ago, I made it to the final 2 but was not selected, but it was still a great experience, and I let the recruiters/hiring managers know it. They didn't try to pepper you with trivia or kaggle or leetcode, and instead just probed you about your conceptual understanding of concepts.

When I was a hiring manager and was hiring people for my own teams, I always hired on potential, not pure ability. I didn't hire them based on what they could do now, but what I felt like they could ultimately become. I feel like a lot of these interviews are structured around finding candidates with high floors, rather than high ceilings.

Anyway, just kind of ranting as I mentally prepare for what could be another air raid interview. Anyone have any tips in case it gets to that point?",datascience
nhfdr3,1621555833.0,What are some tools/best practices that Causal Inferencing teams use for experimentation?,"Would love some advice/recommendations from Causal Inference Data Scientists - We are trying to look for tools/frameworks/platforms that can help boost the productivity of Data Scientists in a causal inferencing team. Right now, the Data Scientists are just doing their experimentation on AI Platform Notebooks, but would like to try to standardize their methodology, automate processes whenever possible and  track their experimentation.

I believe the current workflow is:

1. DS writes SQL query to pull in treatments, outcome variables data from Snowflake.
2. DS uses ECONML or DoWhy libraries to get the causal estimate, statistical significance, etc.
3. DS tracks experiments and different variables used on Mlflow

I'm sure this current workflow can be greatly approved and was wondering if there are some established industry best practices  that we can learn from with regards to causal inferencing and experimentation. Also, we would love to leverage any open source tooling you would recommend that would help in this domain",datascience
nhbc7e,1621544350.0,"All else equal, would hiring managers rather have a candidate with all their experience in their industry or prefer someone with experience in multiple fields?","I would think it would be a bonus to have experience in various industries, but my encounters in applications and interviews makes me think otherwise",datascience
nh9tku,1621540509.0,Pro/Cons of Contract vs FTE?," I am weighing the pros and cons of taking a contract position, which I haven’t done before. What are things I should consider?

All I know about contract work is: -they don’t take any taxes out -no benefits, no health insurance -less networking -not a part of team/culture -may or may not turn into a job -less stable

This is for a data analyst role. They are offering 40/hr. But my current annual salary is 75k with great health coverage.

What factors should I consider? What do you wish you knew before taking your first contract role? Why do people generally look down on contract offers, I don’t get it...?

Any help would be greatly appreciated",datascience
nh9g9y,1621539586.0,"Has anyone worked with ""structural equation modeling"" or ""statistical process control""?","I recently came across these topics - they look very interesting, but also very complicated. Has anyone ever dealt with them before? What kind of projects did you use them for?",datascience
nh1as2,1621519963.0,"Data Scientists, what are few things that you wish you knew before starting your data science journey?",,datascience
nh19zq,1621519911.0,Accumulated Local Effects,"I recently came across a newer technique called ""accumulated local effects"", that attempts to explain the effect of predictor variables on the response variable :

https://docs.seldon.io/projects/alibi/en/stable/methods/ALE.html

Has anyone tried using this method on real data? Did you find it useful? Any stories/anecdotes/experiences/comments/reviews you would be willing to share regaeding this method?",datascience
ngzhno,1621515411.0,Should I get a new job?,"Background info: I was a stats major in undergrad and now I'm getting my masters in cs from OMSCS (Georgia tech). I've been working at a large fortune 500 company for a year now as a data analyst/data scientist.

My job consists mostly of building tables and metrics in SQL, and I recently started doing some python work involving solving the vehicle routing problem, so I've been introduced to a lot of machine learning models and libraries. I'm also familiar with cloud computing and use cloud technology in my day to day.

The problem is that this team has absolutely no guidance, no one checks on my work and no one cares about my work, it's really assigned to me as a learning opportunity. The team doesn't really need a data scientist at all. Also, I'm the only data scientist on the team, everyone else is a software developer. I've learned a ton but the lack of guidance really really frustrates me and I think it puts me at a big disadvantage when it comes to learning.

My question is: given my experience will I even be able to find another data science job or should I just stay at my current job?",datascience
ngv3ts,1621501077.0,Language-agnostic deployment setup?,"I'm in a situation where I need to ""productionise"" a large number of models written in various languages. We have a system set up for deploying Python models in Docker containers, accessible via API.

Currently our approach is to attempt to wrap any non-Python models in Python code and deploy using our existing framework. For example, we can wrap an R model to resemble a Python one via a library such as RPy2. However, this isn't particularly elegant, and new wrappers have to be written for each new language (or even for particularly different models in the same language).

Another option I'd considered was having the models kept in their own language-specific scripts, which can be executed from inside Python app via calls to the command line. This seems a better approach since we're no longer dealing with wrappers, though I'm concerned that having to run import statements/load the model for each inference could cause high latency.

A third option I've been toying with (though haven't managed to figure out the details for) is to have the web app run in one container, and the model in a second, with some very minimal model serving code. I think this might allow us to sidestep the issue of loading dependencies, though it seems we'd have to write the model serving code in the model's language (the original problem).

I'm interested to hear your thoughts on this - has anyone else found an elegant solution to this?",datascience
nguua9,1621500081.0,"It's crazy how effective it's to include ""Data Scientist"" in your job listing.","Example - at the company I work for, they had been trying to hire a analyst for quite some time. It was originally called ""technical analyst"", and the response was...lukewarm. 20-25 applicants, and some even withdrew their applications underway.

Then HR renamed the job to ""Data Scientist"", included that in the tittle of the listing, and slapped on some buzzwords on the new tools we use.

Result? Almost 300 applications. The shortlist included people with experience from big name tech and banking companies, prestigious schools, etc.",datascience
ngls7t,1621470448.0,How to explain to Management that Data Cleaning is a really important part of my job,"Hi all,

I recently started my first job working as an entry level Data Scientist. I’ve been working at this company for roughly 3.5 months now and was put on a project where I am to extract phrases and classification codes from PDF documents in different languages (there is more to it than that - I’m just keeping it brief without disclosing too much).

I had relatively finished most of the algorithm that is able to extract and compile these phrases/codes - however, the dataset that I am using has all been entered manually by multiple different people who work at the company (~100+ people). This requires a lot of data cleaning to process duplicate phrases that are mapped to different codes, categories of codes, etc. Additionally, it appears that many people have formatted their inputs drastically differently. I am currently only doing this for the English language and then will have to do it for French, Spanish, and German in the coming weeks. Each dataset is initially 250,000 records where I can automate roughly 90% of the cleaning - the rest are all either really obscure cases or the classification of the duplicate phrases are too close to call causing me to have to closely examine and google them online to determine which one shouldn’t be there.

I know all of this is all super vague - I am trying my best to explain what I can share (some things I can’t)

Back to my question - I have weekly meetings with management where some of them seem surprised when I tell them that I am still working on data cleaning (been working on it for 2 weeks now and will likely need more time than this as I haven’t even finished the English dataset). I would estimate that up to this point 70%-75% of the code I’ve written is for the sole purpose of data cleaning, preprocessing, and determining what belongs where (using fuzzy logic and embeddings). My question is how do I explain to them that the data cleaning process is most of the work a data scientist needs to do? Am I looking into this too much? Had I been given a perfectly clean dataset, I would be able to complete this in no time. Also, this is my first job out of college (bachelors degree in Data Science) and I definitely acknowledge the skill gap between me and the other members on my team who are Sr. Data Scientists. They are much more efficient than I am when it comes to things such as Deep Learning, the cloud, etc.

Any advice is greatly appreciated



TL;DR My first job out of college. Been working at the company for 3.5 months as a data scientist. Management seems to be surprised that data cleaning is taking me so long (2 weeks and counting) to complete which makes me feel like I am not working efficiently enough. Does management have it backwards where they think building the ML models is more intense than the Data Cleaning portion?


Edit: Thank you all for the input and advice! I have a meeting with management later this week and I will definitely be using the suggestions and advice provided here

Edit 2: Wow!! I really can thank everyone enough for all the advice and feedback I received. You all have gave me some great guidance as to how I can navigate this issue. Thank you!

Edit 3: Grammar + Formatting",datascience
ngg2su,1621455888.0,Question regarding freelancing,"I've been contacted by an acquaintance to do some freelance work, and I'm unsure how to bill it: should I just set an hourly rate and charge according to time invested until completion? They are interested in the final product (not on the code), and since I would be using some personal libraries of mine, on the one hand I feel that being too fast is counterproductive with an hourly rate (= little money). However if I just set a flat price and there's unforeseen issues, I might have to work more, ending up with an effective hourly rate that is too low.


How do you deal with this and what do you recommend?",datascience
ngcufb,1621447891.0,Paid NLP Tools vs Building Own Model,"I have started to work for a small start-up company. We are only 2 data scientists.

I am trying to understand consumer satisfaction by analyzing reviews. Sentiment Analysis and NER will be methods I will go for as initial step.

My company doesn't have an NLP pipeline yet.

I wonder which one is better: using Paid NLP Tools like Google Could NLP, IBM's Watson NLU or a self build NLP model?

I would be happy to hear what you think. Pros and cons.

Google's service seems a bit expensive. But, pricing is still confusing. For example, if I have 5 million reviews, how much am I expected to pay for Sentiment Analysis and NER services? (an estimate)

Does Google charge me again whenever I run sentiment analysis?

Is there any cheaper but still effective cloud computing NLP tool that you can suggest?

I would be happy to hear your insights!",datascience
ng951l,1621438787.0,What is the hardest topic that you encountered in Data Science when you studied it?,"When I studied DS for mastery, I noticed that people came from different backgrounds. Consequently, people were struggling in different classes according to what they studied before. For example, people that did statistics as bachelor mentioned that they had a lot of problems with the programming aspect of DS, but were much more comfortable with modeling. I had a lot of trouble with Bayesian statistics but was much more comfortable with programming (I was a Software engineer before).


So out of curiosity, what was your experience like, what topic did you find difficult, and which ones did you find easy?",datascience
ng6lns,1621432737.0,Selecting a limited number of features,"Due to restrictions from the software development team, I need to restrict the number of features (variables) for my model to within a maximum number, say 10 or less. I am wondering if anyone here has run into such a constraint and how you went about handling it (assuming the restriction above is non-negotiable; and trust me, we have tried negotiating with the software folks :)). I have tried a number of selection methods to go about doing this and selected the ""top"" 10 features, for instance, as sorted by the following:

1. Feature importance (Xgboost)
2. Boruta
3. SHAP

Some drop in performance was obviously expected relative to model with all features available but the drop in performance has been been much sharper than I am comfortable with (using either of the three methods listed above). Therefore, I am hoping folks here have experience with better ways to go about doing this.

I would very much appreciate any feedback.",datascience
ng6gej,1621432383.0,Working environments in the real world.,"I'm beginning to learn data science and in most courses and programs I'm seeing so far, students are often asked to start with learning environments like Jupyter notebooks, Spyder or some sort of text editor like G Edit or something.


I'm just curious as to how things happen in the real world. Do people still work in these environments? I use Jupyter notebooks and sometimes Spyder, but I understand that one can work in Terminal/Command Prompt as well. Although, I'm not sure I understand why - because editing code and stuff seems a lot easier otherwise. Just curious.",datascience
ng287u,1621420425.0,Laws and regulations for working with large anonymised datasets of faces?,"See title.

I'm interested in working with a large dataset of almost 100,000 faces for a research project, but I wish to remain within UK, EU and US  regulations for doing so.

What are, or where can I find, the regulations for such work?",datascience
nfulh9,1621394458.0,Neural Search - I did research on the topic and this is what I learned,">TL;DR: Neural Search is a new approach to retrieving information using neural networks. Traditional techniques to search typically meant writing rules to “understand” the data being searched and return the best results. But with neural search, developers don’t need to wrack their brains for these rules; The system learns the rules by itself and gets better as it goes along. Even developers who don’t know machine learning can quickly build a search engine using open-source frameworks such as [Jina](https://github.com/jina-ai/jina).

Table of contents

* What is Neural Search
* Evolution of search methods
* Rule-based Search vs Neural Search
* Applications of Neural Search
* Get started with Neural Search

## What is Neural Search?

There is a massive amount of data on the web; how can we effectively search through it for relevant information? And it’s not just the web where we need it: Our computers store terabytes of company and personal data that we need to work with; we need effective search to get our day-to-day job done. And what do I mean by effective search

* Can we go beyond just matching keywords?
* Can we search using natural language, just like we would write or speak?
* Can we make the search smart enough to forgive our minor mistakes?
* Can we search for things that aren’t an exact match but are “close enough”?

We can answer all those questions with one word: Yes. To understand how, we need to enter the world of Natural Language Processing. NLP is a field of computer science that deals with analyzing natural language data, like the conversations people have every day. NLP is the foundation of intelligent search, and we have seen three different approaches in this field as follows.

## Evolution of search methods

1. **Rules (1950–1990s)**Complex handwritten rules that emulate Natural Language Understanding.**Drawbacks:** Handwritten rules can only be made more accurate by increasing their complexity, which is a much more difficult task that becomes unmanageable over time.
2. **Statistics (1990s — 2010s)**Probabilistic decisions based on weights, machine learning and feature engineering.Creating and managing rules was solved with machine learning, where the system automatically learns rules by analysing large real-world texts.**Drawbacks:** These statistical methods require elaborate feature engineering.
3. **Neural Networks (Present)**Advanced machine learning methods such as deep neural networks and representation learning.Since 2015, statistical methods have been largely abandoned, and there has been a shift to [neural networks](https://en.wikipedia.org/wiki/Neural_network) in machine learning. Popular techniques using this method make it a more accurate and a scalable alternative. It involves

* Use of \`word embeddings\` to capture semantic properties of words
* Focus on end-to-end learning of higher-level tasks (e.g., question answering)

&#x200B;

>When you use Neural Networks to make your search smarter, we call this a **Neural Search System**. And as you will see, it addresses some of the critical shortcomings of other methods.

Note that the applications of Neural Search are not just limited to text. It goes well beyond what NLP covers. With neural search, we get additional capabilities to search images, audio, video, etc. Let’s look at a comparison of the extreme ends of search methods — “Rules” vs “Neural Networks”:

## Rules (Symbolic Search) vs Neural Networks (Neural Search)

While the Neural Search method has become more widespread since 2015, and should be the primary focus area of any new search system. However, we shouldn’t completely rule out Symbolic (rule-based) Search methods. In fact, using a combination of Neural Search and Symbolic Search may result in optimized results. Let’s look at some of the powerful applications of Neural Search

## Applications Of Neural Search

**Semantic search**

🔍 addidsa trosers (misspelled brand and category, still returns relevant results similar to query “adidas trousers”)

**Search between data types**

With Neural Search, you can use one kind of data to search another kind of data, for example using text to search for images, or audio to search for video.

**Search with multiple data types**

With Neural Search, you can build queries with multiple query data types e.g. search images with text+image

## Get started with Neural Search

For rule-based searches, **Apache Solr, Elasticsearch, and Lucene** are the de-facto solutions. On the other hand, Neural Search is relatively new domain, there aren’t so many off-the-shelf packages. Also training the neural network for such a system requires a lot of data. These challenges can be solved using [Jina](http://github.com/jina-ai/jina/), an open-source neural search framework. To get started with building your own Neural Search system using [Jina](http://github.com/jina-ai/jina/).

&#x200B;

**References/Notes:**

Neural Search term is less academic form of the term **Neural Information Retrieval** which first appeared during a [research workshop in 2016](https://www.microsoft.com/en-us/research/event/neuir2016/). I also found it useful to learn about [how google search  works](https://www.youtube.com/watch?v=0eKVizvYSUQ).",datascience
nfph2x,1621380070.0,Personal project runtime,Hey guys so I’m doing a personal project using Spotify data to recommend songs and also using kmeans to cluster songs for analysis/playlist. I use Pycharm and I have a pretty beefy cpu/gpu but sometimes it’ll take forever to run. I’m not sure if my IDE is just not optimized or is there anything else I can do to get faster runtimes when creating models etc. The dataset has 600k+ rows if that helps!,datascience
nfgxdm,1621359485.0,Alteryx vs Python for collaborating in a team,So I have a silly newbie question.  I am trying to work out pros  as cons for using these tools. We have a team of 20 people and some ( like 3 people) use Alteryx and the rest use python. I am trying to work out what the pros and cons would be for working a team. Does Alteryx make it easier or harder to work together.  What are the other pros and cons for a large team trying to work together vs in their own silos?,datascience
nfezz6,1621354976.0,Confused on different job titles/roles of data science,"After reading through bunch of articles about the different roles I am still confused on specific jobs within the data science community. I really want to focus on the coding, model creation, model deployment and monitoring. Maybe where to ML models are already predefined but my job would be putting it into production and hooking everything up.

What would this role be called? MLops? ML engineering? Dev ops? The sense that I get is no one seems to know what to call these guys or they are sort of interchangeable titles that might mean something totally different to each company you apply for. Also, would this include making data pipelines or is that a data engineer's job?",datascience
nfalsq,1621344152.0,How to make sure my team receives appropriate recognition?,"Hi all,

I work for a fairly small to mid-sized firm, and we're facing some growing challenges as a data team. Our leadership/management team currently respects teams that add value to the company, so our marketing team tends to receive significant recognition.

Other teams tend to take credit for the reports, models, and any other analysis we do. This lends to our team *apparently* not adding business value to the company and makes it more difficult to do salary raises, promotions, hiring, etc. Another issue is that another non-technical team is currently asking me to teach them how to use SQL to do their own data pulls. I want to be a team player, but this adds no value to my team except diminishing the workload they put on us.

How do I, as well as my team navigate through these office politics?",datascience
nfa2e4,1621342714.0,Freelancing?,Can you do freelance works in this field?,datascience
nf8hxs,1621338113.0,Starting out as a Data Analyst to move into Data Science?,"This is a unique situation...

Let me start out by saying I am a “IT Support analyst intern” at my job, part time. What I do however is not all that complex, I use pivot tables and excel as forms to show company spending at several locations(I don’t recommend anything I simply show the bills in the best way I can, currently it’s a pivot table from the previous employee)

My career goal is Data Science and starting out as a Data Analyst to get there. Perhaps getting a masters while being a Data Analyst. Currently, my higher ups told me if I can learn Python and how to somehow implement it in my job I can use it for resume building purposes, so I’m reading “Automate the Boring Stuff” since it has parts about Python with excel and PDFs.

Allow me to also note I am a CS major specializing in Data Science. This does have a class for Python with data science but I’d rather learn it sooner for experience purposes. This has nice a machine learning class too I won’t be able to take for another year. Of course SQL is in the database class next semester .

My question is, what else should I be doing now to help get an actual data science internship sooner? Or data analyst if not, since that’s not my current job title. Would using Python with excel to show bill amounts count as a “Data analytic” experience? I would think not because it really doesn’t cover the broad strokes of the full job position “Data Scientist/Analyst” unless there’s a way I can visualize excel data I’m missing, apart from python. Is there any key skills I have to learn ASAP, even with a class coming up? Like SQL? And during this, what actual Data Science skills should I be looking at right now to aid in actually getting a possible data science internship?

Is there any key skills I’m missing? Are there any good resources to learn these skills like Python(if not my current book), SQL, Spark, etc?",datascience
nf6hhq,1621331302.0,How to deploy a real time model which gets the variables(features) in phases?,"For example I have a linear regression model ready. I dont get all the features at the start. for example, I get 6 out of 10 features. I need to see the target variable range I will get.

&#x200B;

 Also  if I need to deploy it in such a way that it tells me what should be the values of other features provided some features and the desired target variable range.",datascience
nf61wa,1621329683.0,Does the type of company you work for matter for career progression?,"I have been looking for a data science role in the financial sector for quite a while but its been tough with no experience. I have an interview for Mindshare which is a media agency, this is a more analytics position which gives me exposure to projects and clients etc so I thought it would be valuable. Would it being a media agency primarily limit me in any way or is the analytics experience good regardless?

&#x200B;

[https://www.mindshareworld.com/germany/careers/analyst-integrated-analytics-consulting?codes=Indeed.com](https://www.mindshareworld.com/germany/careers/analyst-integrated-analytics-consulting?codes=Indeed.com)",datascience
nf4rnz,1621324928.0,Interested in mentoring networks,"Hi all!

I’m a Data Scientist working in Australia. I’m the sole DS in my company and all the other DS I know outside of there are at a similar level I am. I used to be in academia in a different field so I don’t have a more senior person to talk to.

All this is to ask if you folks know of any mentoring networks that I could join.",datascience
nf47se,1621322786.0,Does Netflix use Jupyter Notebooks in production?,"I love Jupyter Notebooks but never thought of them as a tool to put code into production.

So I was very surprised by this article [Beyond Interactive: Notebook Innovation at Netflix](https://netflixtechblog.com/notebook-innovation-591ee3221233) (found thanks to [u/yoursdata](https://www.reddit.com/user/yoursdata/)'s [recent post](https://www.reddit.com/r/datascience/comments/neylas/data_science_in_practice/) introducing what it seems a very interesting [newsletter](https://datascienceinpractice.substack.com/p/data-science-in-practice-post-1)).

This is a 2018 article, anyone can confirm whether this philosophy continues at Netflix? Any other companies out there doing this?",datascience
nf2q8p,1621317508.0,Techniques for anomaly detection across different time series?,"Most anomaly detection techniques/packages focus on anomaly detection within a single time series; ie, take some sort of steady-state average and alert if the data suddenly goes above or below some threshold. My problem is totally different, however.

I have a hardware device that performs the same operation repeatedly. Most of the time it succeeds, but sometimes it fails. I have sensors that measure position and angle (6DOF), and I have a large data set of each attempt, whether or not it was a success or failure, and the sensor data (and first and second derivatives) from a few seconds before the event to a few seconds after.

What I'm looking for is a technique or python package that can analyze all this time series data and, given label of Success or Failure, identify if there are any anomalies that typically lead to a failure. I've done quite a bit of Googling and Stack Overflowing, but keep coming up with ""typical"" anomaly detection packages. Maybe I'm using the wrong keywords or language here to describe what I'm looking for? Any suggestions or pointers in the right direction would be greatly appreciated!",datascience
nf24f6,1621315410.0,On the job training and education,Hello! I was just curious what everyone's on the job training and employer training program experiences have been like. I've really worked at some smaller startups where a senior data scientist would supervise and give advice. I recently got a job offer at a much bigger company so I'm curious about whether or not is normal for larger companies to have more organized training opportunities. Thank you!,datascience
neylas,1621304210.0,Data Science in Practice,"I am a self-taught data scientist who is working for a mining company. One thing I have always struggled with is to upskill in this field. If you are like me - who is not a beginner but have some years of experience, I am sure even you must have struggled with this.

Most of the youtube videos and blogs are focused on beginners and toy projects, which is not really helpful. I started reading companies engineering blogs and think this is the way to upskill after a certain level. I have also started curating these articles in a newsletter and will be publishing three links each week.

Links for this weeks are:-

1. [**A Five-Step Guide for Conducting Exploratory Data Analysis**](https://shopify.engineering/conducting-exploratory-data-analysis)
2. [**Beyond Interactive: Notebook Innovation at Netflix**](https://netflixtechblog.com/notebook-innovation-591ee3221233)
3. [**How machine learning powers Facebook’s News Feed ranking algorithm**](https://engineering.fb.com/2021/01/26/ml-applications/news-feed-ranking/)

If you are preparing for any system design interview, the third link can be helpful.

Link for my newsletter - [https://datascienceinpractice.substack.com/p/data-science-in-practice-post-1](https://datascienceinpractice.substack.com/p/data-science-in-practice-post-1)

Will love to discuss it and any suggestion is welcome.

P.S:- If it breaks any community guidelines, let me know and I will delete this post.",datascience
nesj5b,1621287179.0,Feeling overlooked and undervalued as a Self-Taught data professional when compared to advanced degree holders.,"I am a self taught data professional, well versed in most data analytics/data engineering program, tools, math/statistics and software. At my current work place, I am constantly coming up with new analysis, tools, automation,  processes, troubleshooting and QA. I have earned the respect of my peers and managers, and I have excellent technical, teamwork, and communication skills. I am at par if not better overall than most of my colleagues whom have masters and PhDs.

I personally feel as if I have a chip on my shoulder because of me being self taught. The grittiness needed to learn the material and find things efficiently on my own is something I value in myself.

It’s just really unfortunate that at face value, no matter what I do, there will be tons of people with advanced degrees in data, who get put ahead of me, and paid more than me, in the job search. I also feel like in the workplace, I also have to go the extra mile with new seniors I meet a lot of the times for them to take me seriously. I understand why it happens, but it really is just saddening and upsetting.

Please tell me there are people in here that have felt and experienced the same thing as I have with this. If so, how have you learned to engage with this?

Yes, I know one of the answers is to get a advanced degree.",datascience
nersx8,1621285366.0,Anyone got a side hustle?,I am a full time data scientist but thinking about pivoting some of my skills on the side to get some extra income. Anyone have experience having a sperate company or offering certain services?,datascience
neqi90,1621282282.0,anyone know of a good 'textbook example' for multi task learning?,"I am in the process of preparing a course on neural networks - it's a broad strokes walk through both basics and various different topics. I have decided that one week will be dedicated to transfer learning and multi task learning (together, since there are some interesting transfer learning approaches which leverage MTL). As part of the course, I want the students to solve a 'small' exercise where they improve some machine learning task by combining it with another one.

However, it is really hard to come up with a good task like that :) regular fine tuning was easy enough - I decided to lean on the pytorch tutorial for that one. So far, I have not been able to find a similar 'toy example' that can both be run in google colab (I can not assume that my students have access to a GPU of their own) and where the benefit is tangible. My best bet so far (which is not working out yet) is to combine age and gender identification on a subset of the cropped version of the wiki face dataset ([https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)). I'm hoping that with a sufficiently small subset, I'll have a task which doesn't quite work on its own, but where real improvement can be seen when each image is analyzed in two different tasks.

 But, perhaps someone knows of a better problem?",datascience
neqdpq,1621281985.0,Thoughts on getting stuck with working on a specific domain?,"My current position is kind of a consultant style role where there isn't a specific product/project to work on and it's kind of whatever projects come through the door. My next position however is working with a specific domain Risk/Fraud. I'm curious if working on a specific area e.g. Fraud/Ads/Recommender Systems/etc ends up locking you into that area for the remainder of your career and future positions. Also, out of curiosity which domain has the greatest potential for future positions.",datascience
necyqc,1621248499.0,Getting a head start when switching to a completely new domain,"I have so far mostly worked in AdTech as a data scientist. Soon in about a month, I will be switching to electric vehicle fleet management which I have never worked with. I think the aspect which I mostly improved upon while working with AdTech was handling huge amount of data but the underlying models weren't so complex. It was almost always logistic regression. I did deal with some deep bayesian models.

Can anyone who has worked in similar field or related fields give me some pointers regarding the problems and the methodologies being used there? What I could gather so far was that the general problem is about vehicle routing and fleet management. What are the underlying methods being used there? What algorithms/models should I brush up on?",datascience
necjee,1621247020.0,Differences between DE and DS actual job along different companies,"Based on my experience, role titles such as Data Engineer and Data Scientist mean very different things depending on the company.

I see three main cases:

1. **Normally Bigger (and Older) Companies**
DEs do all MLOps: They build anything needed to gather and store data. They put DS models into production too.
DSs train models, do exploratory analysis, create variables, validate hypothesis, but don't put any of that into production themselves.
2. **Normally Modern (Tech) Companies**
DEs gather and store data.
DSs don't just train but also deploy their models into production.
3. **Normally Smaller Companies**
One profile does it all.

I work now for a startup whose product is a realtime end to end platform which eases the otherwise complicated MLOps stuff. I'm writing some docs that explain how realtime is done now VS my company proposal and I'm finding that defining how things are done now is not straightforward. So, do you agree with the three cases above? Would you add more? Where would you put Data Architects, ML Engineers, etc.?",datascience
ne72ct,1621227127.0,Anyone working in a music analytics/streaming company like Spotify?,"Hi there! I'm an aspiring data scientist hoping to one day work at a music analytics/streaming company such as Spotify, Pandora, or Tidal. I would like to learn more about what data scientists do at such companies and how they analyse user data to eventually drive company decisions.

If there's anyone here working in a similar field (or even have similar interests), I would love to have a chat with you to learn more about what you do.

If interested, please send me a message or comment on this post so that I can get in touch with you.

Thanks!",datascience
ne4tco,1621219794.0,PDF search - Another project I built using Jina(AI Search framework),"[Source Code on Github](https://github.com/jina-ai/examples/tree/master/multimodal-search-pdf)

In this project I am using [Jina](https://github.com/jina-ai/jina) to search a repository of PDF files. The project allows a user to query the data by providing text, or an image, or both simultaneously.

**How to use it?**

Clone the project and run following commands

    # Install requirements
    pip install -r requirements.txt

    # Start the server
    python app.py -t query_restful

    # Query via REST API
    curl --request POST -d '{""top_k"": 10, ""mode"": ""search"",  ""data"": [""jina hello multimodal""]}' -H 'Content-Type: application/json' 'http://0.0.0.0:45670/api/search'

What's included in this example:

* Search text, image, PDF all in one Flow or in separate Flows
* Speed up indexing time with parallel Peas
* Use customized executors to better fit your needs
* Provide detailed docstrings for YAML files to help you understand the example


Let me know your feedback and what would you use this project for. I'd love to help",datascience
ndt83g,1621186024.0,What is something you're absolutely NOT looking forward to once work from home ends and how do you plan to fix it?,"Hello!

I am personally loving work from home because it saves me a lot of time. But eventually everyone has to go back to the offices so I thought maybe it's a good idea to talk about the problems we face when working from physical office and how can we make the experience better.

Thanks!",datascience
ndrch1,1621180710.0,How do you take notes while reading a statistics book?,"Hi!

It's been a year since I finished grad school and it feels like I need a refresher on the concepts. I started reading ISLR and I felt like I need to take notes so that next time I need to refresh on the concepts I can just go through the notes instead of reading the entire book.
The note taking is primarily because of potential future interviews.

Do you guys just do it old school by taking notes in a notebook or do it differently now?
Also, is there anything else I should do in order to prepare notes for interview prep?

Any other advice is welcome.

Thanks!",datascience
ndpft6,1621175139.0,Statistician vs data scientist?,What are the differences? Is one just in academia and one in industry or is it like a rectangles and squares kinda deal?,datascience
ndobxv,1621171664.0,need advice on the best web scraping tool/approach for this job,"Hey everyone, I first posted this on r/analytics but realized it doesn't fit very well there. I need to scrape some elections data from a website. It has JavaScript and around a 1000 individual pages that all have the same format and variables, stored in a table. I'm new to scraping but have read a bit today and it seems like Python is my best bet. I was wondering if this is the type of thing I should use a full crawler on, like Scrapy. The URLs for the pages i need all have this format:

https://elections.amo.on.ca/web/en/municipal/XXXXX

Where XXXXX seems to be an ID code made up of digits for each page.  I don't know which 5 digit codes actually correspond to the pages I need but its certainly not all 5 digit combinations because the number of possible pages is much smaller than 99,999.

Should I just get started with learning Scrapy in Python, or do you think there is a better tool for this task?",datascience
ndmuat,1621166430.0,Weekly Entering & Transitioning Thread | 16 May 2021 - 23 May 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
ndkwgm,1621158590.0,SQL vs Pandas,"Why bother mastering SQL when you can simply extract all of the data using a few basic SELECT commands and then do all of the data wrangling in pandas?

Is there something important I’m missing by relying on pandas for data handling and manipulation?",datascience
nddpj8,1621129354.0,Market Basket Analysis Help,"Hi, i just started to learn about market basket analysis with FP-growth.


what is the amount of data do i need to create an accurate association rule? is there a minimum? is it pure arbitrary?


thanks for the help.",datascience
ndcl23,1621125450.0,What are some industry standard codex for data pipelining?,"I recently moved from IT Governance Audit, in which we have codex like COBIT 5 to follow. I wonder if there is something like that for data pipelining?",datascience
nd9io8,1621115830.0,Documenting code in data science...,"My team does not do much documentation. They tend to think it's not worth the time to add docstrings or other documentation and figure the code is readable and anyone can just figure out what the code is doing by looking at it.

We all tend to work on different models but often we need to understand how other models work and I think it's worth the time to have better documentation since what seems obvious to the person writing code might not be clear to another team member.

I'm just wondering how other teams think about enforcing documentation. I don't think it's a waste of time and there will most likely be someone taking over someone's codebase eventually and it's painful to try to understand some functions when that person isn't around to ask questions to.",datascience
nd9bi3,1621115228.0,Any good resources for learning statistics applied to datascience from scratch ?,"Hello,

I finally came to realize that I use almost every libraries as pure blackboxes and that it is a problem (I thought before it was not as soon as you can give the management a correct result) if I want to improve myself professionally speaking.

I have zero background in mathematics so learning through a university syllabus is very very hard and I don't think I'll be able to finish that. Would you have any resources that is a bit interactive and noob-friendly ? I enjoyed learning Python and R through small own made project (that's how I ended with my current data clerk position) but I don't see how I could do that for stats.

Thanks,",datascience
nd81cs,1621111433.0,Confidence Intervals for Classification Models,"The idea of creating confidence intervals in regression models is quite straightforward.

For example :
https://www.researchgate.net/profile/Folorunso-Oludayo-Fasina/publication/284729754/figure/fig2/AS:300625800777756@1448686184816/Scatter-plot-with-linear-regression-fit-and-a-95-confidence-interval-for-reported.png

But do confidence intervals carry over to classification models?

1) For example, in this picture here (confidence interval for an ROC curve corresponding to a classification model ) https://i.stack.imgur.com/Y7KSNm.png - can the lower limit of the confidence interval from this ROC curve be used to gauge how well this model might generalize to new data?

2) For a classification model, can we make a confidence interval for the prediction of an individual observation? For instance, I wrote some R code (you can directly copy/paste the code) for a particular example where a random forest (i.e. classification model) is used to predict whether if an observation will be ""approved"" or ""rejected"" (see here for the code: https://shrib.com/#Madelyn_NMjYE8) .

Thus, for each observation, the classification model predicts the probability that this observation will be ""approved"" or ""rejected"". Whichever probability is higher, the model selects that outcome for the given observation.

Also, the higher one of these probabilities are, this means the classification model is more confident with its prediction (e.g. for two observations, the ratio of approved:rejected 0.9:0.1 vs 0.6:0.4 . The model is more confident about the first prediction)

Thus, is there anyway to apply the notion of confidence intervals to the probabilities for individual predictions?

Thanks",datascience
nd3na2,1621098782.0,What are some examples of data science application in Israel Iron Dome technology?,,datascience
ncqjfj,1621052116.0,Tell us you’re a data scientist without telling us you’re a data scientist.,Best answer becomes a meme :-),datascience
nckuwn,1621031693.0,Data Science Projects in Manufacturing,"Hi All,

Are there any data scientists here working in manufacturing (food and beverage ideally)?

I'm part of a new startup data science teams and we're looking for good use cases

Thanks all from Dublin, Ireland",datascience
ncgqh7,1621020257.0,Best Way to Deploy a Model into Production,"Let's say I've built a model using past bank data that predicts which customers will apply for an auto loan with us.  I now have a potential email list with our current customer data that I want to check which specific members who are most likely to apply for a loan and a predicted agg count of how many will apply for a loan, what would be the best way to do so? Can I have it read a CSV file or connect to a SQL table to do this?  I've read a little bit about FLASK, but I haven't seen anything like I'm wanting done in flask. Not looking for a step-by-step or for someone to do the work for me, more of a ""yes/no this can be done"" and maybe a link that might assist me. Thank you",datascience
ncfzss,1621018310.0,Silly Question,"Let me first say that I am not a data scientist, or even a college degree holder. I'm just someone who thought of something but has no idea how to do it - which I am going to ask how to do here.

Pretty much I run a Minecraft server, and want to show player activity over the course of the last 6 months that I have had it. Every 50 or so seconds the console log outputs the following line:

\[ {Day of Week}, {Numerical Day}. {Month} {Year} {Hour}:{Minute}:{Second} UTC INFO\] There are {# of players} of a max of {Max # of players} players online: {Player names seperated by ,}

&#x200B;

For example:

\[Fri, 14. May 2021 05:15:34 UTC INFO\] There are 0 of a max of 15 players online:

\[Fri, 14. May 2021 14:51:30 UTC INFO\] There are 1 of a max of 15 players online: Player1

\[Fri, 14. May 2021 03:40:22 UTC INFO\] There are 3 of a max of 15 players online: Player1, Player2, Player3

&#x200B;

Is there a program out there that I can use to look at those lines of text, and convert them into a graph that can show for how many minutes or something of the sort in a single day a player was on for each day over the last 6 months all the while ignore every other line? And, if possible, how I can make the program do that?

Any and all help is appreciated!",datascience
ncfk0c,1621017146.0,In your experience what were the questions the interviewer asked that made you realise you shouldn't work at this company (or under the interviewer)? (Or do you have any questions to ask that help you decide whether the company/interviewer is good),,datascience
ncbvv2,1621007617.0,"Can dashboard software (Tableau, PowerBI) help with this business case?","A client produces 6-12 spreadsheets each quarter.

They have an excel guru put together a big document that visualizes the data. The document contains things like bar charts and descriptive statistics.

I would like to prepare a dashboard application  that is hosted online or could be shared as a standalone application.

The application should be able to accept the data sets as input (ideally, with a drag-and-drop graphical interface), COMBINE the data sets behind the scenes, and produce the necessary data viz.

Goal is to automate the data viz process, and the mechanics should be straightforward since the data sets have the same structure from year to year.

CHALLENGES:

• The data sets are company sensitive. I cannot host a web application on any old web server. I need some contractual guarantee the data isn’t being spied on. My understanding is that most companies have freedom to intercept online info. Maybe then I don’t host the application online at all? An .html file could work.

• Client has restrictions on what kind of software they can install. I may be able to install PowerBI or Tableau on my system, but client may not be able.

I am aware that Tableau can easily visualize data from multiple sources. I.e. it would be simple for ME to organize the spreadsheets, visualize key metrics, and host it online. What I would like is a freestanding application where the CLIENT drags and drops the spreadsheets and an application spits out some visuals.

Thoughts?

Is this too advanced for PowerBI/Tableau? Do I need Shiny/Dash?",datascience
nc36cc,1620978888.0,On-the field jobs with DataScience - wildlife / nature conservation ?,"\-Also referring to - [https://www.reddit.com/r/datascience/comments/h8bz3b/anyone\_working\_in\_conservation\_wildlife/](https://www.reddit.com/r/datascience/comments/h8bz3b/anyone_working_in_conservation_wildlife/)

Anyone working in nature conservation (wildlife, deforestation, ..) AND also working on the field would like to elaborate how much is beneficial to have a background in data-science ?


Do you use DS frequently, or manage team making use of DS ?
How much is valuable for engaging in outdoor activities and negotiate opportunities to go on the field for part of the job ?
What kind of activities do you do ?

\-

Possibly, I'd like to hear about opportunities of fieldwork in the EU - and possibly, if only volunteering pops up, at least volunteering activities offering full cover of costs and relocation.


My situation is that I'd like to gain a relevant background for PhD making use of tech (e.g. ML) and in perspective aim for jobs where I can live outdoor part of the time. In order to apply for a PhD, I need to get a MSc first (at least in the EU), and due to my background it may be easier to get a MSc in a tech domain rather than a knowledge-related domain (e.g. biology / natural science / ethology, .., that would require prior related academic background in these disciplines).


I'd like to hear from other experiences to think about appropriate expectations and tips to consider - in perspective, I don't want to stay 130% of my time in front of a computer, while I find very motivating the possibility to match direct observations and outdoor activities with the part for processing.


In perspectives, I think tech will open up for new opportunities also in this field, and again I wonder how a tech background would be considered and leveraged VS knowledge domain backgrounds or direct on-field experience.",datascience
nbspk6,1620943509.0,I got blocked from an online data conference for loving data too much,"I don’t want to say much more than that but I was at an online conference a few days ago, and in the chat I said I was totally stoked to be thinking about data analytics all day, and they blocked me from the chat because they thought I was sarcastic.

I just love me some data is all.  So I reposted saying that I meant it, and then the organiser thanked me.

I am just too hard core. Data data data.  Nom nom nom.",datascience
nbo4ik,1620931785.0,Anyone has experience on working with ‘Fully Remote Team’ ?,"I know that we are all working remotely to an extent now. But, does anyone here have experience with working on a team which is fully remote?

I am in talk with a recruiter for an exciting position in a fully remote company (well funded startup and recruiter promises a good work-life balance). I have had colleagues in the same location in all the places I worked before- I very much enjoyed the social aspect of office. So being in a fully remote team is something new for me and I am being a bit cautious.",datascience
nbneik,1620930001.0,Data Scientist responsibilities in a Data Analyst job description?,"I have an interview for a Data Analyst position coming up soon and have several questions.


In the job responsibilities, it mentioned typical responsibilities for a Data Analyst except for 'Predictive Analytics'. Isn't this a Data Scientist's responsibility? Since it would require knowledge a typical Data Analyst would not know. Would it be fair to mention in the interview? The salary range was 60-70k. Assuming I can convince them it's a data scientist position and switch the title, would I be able to negotiate a salary above the range?

&#x200B;

Thanks in advance!",datascience
nbk99e,1620922246.0,How can i create a dataset featuring clusters with inhomogeneous densities with python?,"Do you guys have any idea? Sklearn doenst have a built in library to do that

edit: i mean inhomogeneous INTERNAL densities",datascience
nbjbv6,1620919844.0,Are there any Python packages that can work with big data?," I've got a relatively big dataset (8 GB) and pandas crashes when trying to load it into a dataframe. I've tried modin and pyspark, all with no luck. Are there any Python packages that can work with big data? Currently the data is stored in SQL.

I'm running this on a company VM which has 16GB RAM I believe.",datascience
nbj29s,1620919160.0,Sentiment Analysis Recommendations on Review data,"I'm looking for recommendations on my project, currently, we have a couple of hundred rows of health care review data. My project manager wants me to find a sentiment analysis tool that gives a compound score that correlates accurately to the stars given for the review. My first attempt I used vaderSentiment and it was around 55% accurate at the score to start rating, my second attempt I used texBlob and that was less accurate (35%). I want to know if there is any off the shelf models or other libraries I can use with python, especially if it understand Healthcare lingo. We hope that we can find something that is about 60-70% accurate from compound score to star rating. Eventually, we will build our own model once we have more data and time. For now, we just want to demo the data we have. Also if you think I'm going about this all wrong please let me know. I am relatively new to data science and this is a part-time project for my job.",datascience
nbirwr,1620918414.0,Is it OK to have a coefficient greater than 1?,"Hello,

I'm new and working on a logistic regression model. I have two variables that are (what I would consider) abnormally large at 10.2 and 30.7. I read online that it's usually a bad sign if this is the case and that this may signal multicollinearity. However, the VIF Factor on these is 1.2 (for both) under the 5.0 that I've read signals multicollinearity. Is it OK to leave these in? Should I remove them? Thanks.",datascience
nb8m31,1620880983.0,R/Datascience Discord,Is there a data science discord? Would be nice to have one :),datascience
nb6f0j,1620873373.0,Gourdian Free Dataset Download: Project Sunroof - Solar Electricity Generation Potential by Census Tract/Postal Code,"Hi there! We've just added a new dataset to Gourdian, this one courtesy of Google's Project Sunroof. This dataset essentially describes the rooftop solar potential for different regions, based on Google's analysis of Google Maps data to find rooftops where solar would work, and aggregate those into region-wide statistics.

It comes in a couple of aggregation flavors - by census tract ( https://gourdian.net/g/eric/sunroof_solar.solar_potential_by_censustract#summary ), where the region name is the census tract id, and by postal code ( https://gourdian.net/g/eric/sunroof_solar.solar_potential_by_postal_code#summary ), where the name is the postal code. Each also contains latitude/longitude bounding boxes and averages, so that you can download based on that, and you should be able to do custom larger aggregations using those, if you'd like.

This dataset seems like it'd be interesting to cross reference with things like weather, and perhaps electricity prices, to find the best places for people to invest in rooftop solar. If you have any other ideas of what it'd be good to combine with, let us know, and we can try to prioritize ingesting those!",datascience
nb3mbb,1620865040.0,How to use training data in Python Keras Sequential metric?,"Edit: The title says, ""Training"" because I'm an idiot. Reddit doesn't let you edit titles, but I meant to say, ""Testing"".


I've got a Python Keras Sequential model that I would like to use Early Stopping on as soon as the test mse gets out of hand (to prevent overfitting), but I'm not seeing any way to feed Keras the test data and tell it to calculate a metric off that.",datascience
nb2fdc,1620861640.0,Some beginner-friendly tips on landing data science internships from a recent college grad,"Hello all,

**From 2019 till today (May 2021), I've submitted roughly 550+ applications for various tech roles in California:**

* Software engineering internships
* Data Science / Data analytics internships
* Machine learning / Deep Learning / Computer visions internships
* Entry-level DS / SWE positions (non-internships)

My background: 3.0/4.0 GPA recent graduate with a bachelor's in physics (a top 10 public school) and a background in data science.

***Disclaimer***: I have never interviewed with a FAANG company so this certainly is not a guide to landing your dream FAANG job.

As a non-CS major with a mediocre academic standing, **I hope some of you guys will be able to relate to or learn from my intern searching experience!**

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Starting off: The resume (for beginners)**

In my 2nd year of university, I started taking interest in data science and signed up for some online courses. After 3 months, I quickly realized that my resume was lacking in work experience, skills, and just an overall description of my career objectives. Moreover, my degree in physics was worrying: how can I compete with undergraduate students studying CS or Data science?

The solution: **Open source data projects**.

This is key to kicking off your data science resume-building journey and in my opinion, the most efficient way to learn data science. Learn a programming language for data science: *R or Python*, and stick with it for at least a year. You should start with:

1) Basic programming syntax, coding logic, data structures

2) Data cleaning and wrangling

3) Data Visualization

4) Basics of statistical analysis

5) Linear Algebra

6) Regression modeling (*more advanced, but a great way to start learning Machine Learning*)

I found DataQuest to be very digestible and enjoyable in the early stages of learning data science. There are also tons of other free resources that you can use to practice and learn your basic data wrangling skills (Kaggle, UC Irvine's Repository, [https://www.analyticsvidhya.com/](https://www.analyticsvidhya.com/)).

In a few months, try to formulate a project idea that can be solved with data science. I wanted to analyze/visualize time-series data for a company's drone flights and luckily, they were kind enough to send me some data files to work with. Using python to do some cleaning and visualizations, I discovered that drones were able to fly further in a specific air temperature range. An engineering team could potentially use this information to implement a cooling system in their drones to maintain internal temperature and improve flight efficiency!

Even if your project doesn't feel ""insightful"" or ""creative"", try to stick with it for the sake of learning! Even if you don't make an astonishing finding, you will develop very strong DS fundamentals through these data exploration processes.

**TLDR: If you feel that your resume is lacking experience, work on data science projects. The more unique and personal, the better. These will become great talking points in your interviews.**

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Building your experience: Networking & Research (for those lacking experience)**

By 2019 (3rd-year undergrad), my resume contained 2 simple EDA projects (Exploratory Data Analysis) and I felt ready to start applying to internships. For the next 365 days, I applied to 207 positions. During this time, I received 6 interviews, and 1 offer for an unpaid data science position (remote).

With a **3.0% hear back rate**, I felt very discouraged. The one offer I got was hardly an internship. This percentage told me that my resume and skills were probably not competitive enough, which drives me to my next point: **take advantage of your academic resources while you are in school.**

I did not attend any career fairs while I was in university (shame on me) but to compensate for this, I reached out to several professors in my department, offering to do research work for them for FREE...up to 20 hours a week. Thanks to a colleague, I landed a data analyst researcher role for my university in the summer of 2020. During this time, I picked up some shell scripting, real-time programming, and data modeling skills.

I know unpaid research is not as flashy or alluring as a Google internship, but trust me, anything that adds 2-6 months of data science experience to your resume is HUGE.

Regardless, I wished I had focused on networking more when I was still in university. Would you rather spent 6 months applying to 200 positions or immediately land several interviews in a matter of weeks due to connections? Yep, I would have preferred the latter.

**TDLR: Reach out to professors, colleagues, or even cold email recruiters. Be resourceful.**

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**General Interview/Job-searching Tips**

* If you did poorly on an interview or got turned down, **learn from it.** You should quickly discover what you are lacking after several rounds:
   * Is my coding logic poor or rusty? Practice more Leetcode while talking out loud.
   * Is my skill set not desirable enough? Research valuable DS skills for the current year.
   * What sort of skills are desired in this specific industry? Tailor your resume accordingly.
   * Stuttering or awkwardness? Record yourself or practice behavioral questions with a friend.
* Know your script: your resume, projects, experience, strong points, weak points.
   * While I do have a google doc containing scripts for what I should say, I never actually read from it. An interview script should be more of a rough blueprint for rehearsing and practicing.
* Try to talk about something personal or outside of the job. Don't force it, but if can laugh with your interviewer + connect on a more personal level, you will leave a strong impression.
* Tailor your resume to what you are applying to:
   * If you are targeting computer vision roles, orient your projects around that
   * If you are focused on machine learning roles, your resume should reflect expertise in modeling and training/prediction techniques
* An interview is mutual. After 20 rejections, I know it is easy to place immense pressure on yourself to land that dream internship. Remind yourself that you are interviewing the company as well. Embracing this mindset will turn your interviews into meaningful conversations, which is what you want.
* Ask good questions. If you feel that the bulk of your interview was not excellent, try finishing strong by asking great questions. Some examples:
   * What are some of the biggest challenges you've faced in your role?
   * A favorite project that you've worked on?
   * Where do you hope to see your data science department in X-Y years?
   * How is your company utilizing machine learning techniques to improve sales/customer retention?
* Do some brief research on LinkedIn before you meet with your interviewers:
   * Might find something in common or help you come up with good questions
   * It's also a good idea to read into the company, their products, how they generate their $$$
* You will likely hear back from companies in LA/Irvine/OC more often than ones in the bay area.
   * 63% of my hear backs (interviews) were from companies located in southern California.

**\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_**

**My job hunt statistics**

\[***Rough breakdown\]***

* **50% of applied jobs were related to data internships (DS, DA, ML, Deep learning, Data Eng)**
* **25% of applied jobs were related to software internships (front-end, back-end, etc)**
* **15% of applied jobs were related to full-time entry-level positions in Data Analytics / DS**
* **10% of applied jobs were related to marketing analyst, business analyst, or other non-tech analyst positions**

&#8203;

    Year	    2019    2020    2021    Total
    Apps	     207      57     257      516
    Interviews    6	       0       5       11
    Offers	      1	       0       2	3

My three offers consisted of 1 remote, unpaid, part-time data science internship, 1 digital marketing analyst position, and 1 paid full-time data science internship (currently pursuing).

**TDLR: DON'T GIVE UP. This field is competitive but through sheer numbers, extraordinary connections, interview skills, or luck, you will find a suitable internship. I believe in you!**

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Resources**

* My favorite job searching platforms:
   * LinkedIn
   * Indeed
   * Glassdoor
* My favorite data science resources:
   * Kaggle
   * UCI repo
   * Tech with Tim (Youtube channel)
   * 3Blue1Brown (Youtube channel)
   * Amazon's datasets
   * [https://www.analyticsvidhya.com/](https://www.analyticsvidhya.com/)
   * Cracking the coding interview (a painful book to grind through, but it is very helpful)
   * O'Reilly's Hands-on Machine Learning with Sk-Learn, Keras, and TensorFlow (2nd Ed.)
      * My favorite book!!!

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Reach out to me**

In 12 months, I hope to be enrolled in a graduate program for data science. I am no expert in data science, and I still have a lot to learn. Nonetheless, the past 2 years have taught me a lot about the data science job market. If you any questions or a strong desire to talk about data science, please feel free to reach out to me. I am happy to share my project source code, resume, and additional tips upon request.",datascience
naxegy,1620848362.0,"What's a good ""first step"" data management software for a team that currently has no data infrastructure?","Hi all. I'm a data analyst on a non-technical team that collects and utilizes a lot of data. Because it's a non-technical team, there is essentially no data infrastructure set up. Specifically, there is no data storage or management software being used. We simply access our data directly in the file system. The scope of our work has grown a lot recently and this way of doing things is quickly becoming unmanageable, especially with respect to logging, versioning, and being able to find and reproduce old analyses.

So I'm wondering if it's time we use some actual software to help us with this. I've been reading about data lakes (our data is whole files, can't be put into a relational database/data warehouse). I'm wondering if a data lake might help us. However, I've read that data lakes don't have any inherent structure to them, and this is what allows them to store any type of data.

So what's the benefit of using data lake software/services over just organizing our file system storage? If I use a data lake, will I still end up with the same question of ""how do I organize all this?"" Is there another type of software that I should be looking at that's more attuned to my needs?

Keep in mind this is a non technical team, so I will need to train any newcomer on whatever I use and can't assume they will have DS/CS knowledge (but they will likely be comfortable with simple scripting in Python/R/bash/etc).

Thank you for any help!",datascience
naujhs,1620841094.0,D-Optimal design in the workplace,"I don't know how squarly the argument fall into data science or experimental design, I have worked in 2  R&D departments of industrial machinery dedicated to PVD and CVD (physical vapor deposition, chemical vapor deposition).

How do you convince people at work that d optimal design is not a scam when the end game is formulating a model through multilinear regression?

Edit: i explained both the high level goal and the advantages but the supervisors don't seem convinced I wanted to ask whether or not someone applied the technique in the workplace",datascience
nauc4w,1620840573.0,In the spirit of Mental Health Month - Imposter Syndrome,"Many of my Data Science Candidates and Coaching Client's face Imposter syndrome, I compiled some resources on what is Imposter Syndrome, How to recognize and combat it. [Here is a link to the full article with YouTube videos.](https://www.rexrecruiting.com/staffing-recruitment-blogs/imposter-syndrome-what-is-imposter-syndrome-what-can-you-do-about-imposter-syndrome/)

# IMPOSTER SYNDROME

>“It seems like whenever I have a problem and I go to StackExchange, I almost always get a response like
>
>“Well obviously you have to pass your indexed features into a Regix 3D optimizer before regressing every i-th observation over a random jungle and then store your results in a data lake to check if your normalization criteria is met.”
>
>It’s like **where are these guys learning this stuff?” -** [Link](https://www.reddit.com/r/datascience/comments/cnvc3e/does_anyone_else_get_intimidated_by_how_much_you/)

## CHARACTERISTICS OF IMPOSTER SYNDROME

Some of the common signs of imposter syndrome include ([reference](https://so06.tci-thaijo.org/index.php/IJBS/article/view/521/pdf)):

* Self-doubt
* An inability to realistically assess your competence and skills
* Attributing your success to external factors
* Berating your performance
* Fear that you won’t live up to expectations
* Overachieving
* Sabotaging your own success
* Setting incredibly challenging goals and feeling disappointed when you fall short

## WHAT IS IMPOSTER SYNDROME?

[YouTube Video - The Imposter Syndrome](https://youtu.be/eqhUHyVpAwE)

Imposter syndrome is loosely defined as doubting your abilities and feeling like a fraud. It disproportionately affects high-achieving people, who find it difficult to accept their accomplishments. Many Data Scientists question whether they are deserving of accolades, their job, recognition, or the like.

* You do not have enough time to learn something you want to learn.
* You look around and see that there are other people that know that thing you don’t have time to learn.
* You feel incompetent.

Why do so many Data Scientists have it?

Data Science is an extremely broad field of study. There are core competencies required to have a successful career in data science, but there is also a lot of industry specific and technical knowledge that is ever changing.
Data Science is a career which has many job options, all of which require a high level of expertise and knowledge. If the broad, seemingly confused data science job postings show us anything, it is that many companies do not really understand what a data scientist is, how they compare to a data engineer or software engineer, and how to train or support them within an organization. To add to this, the labor market for data scientists in predominantly new graduated or early career professionals.

When challenge is high, and expectations are unknown it encourages people to fall into high arousal, anxiety, and worry. You can see this from psychologist’s [Mihaly Csikszentmihalyi](https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi) flow model.

These feelings are compounded by a lack of support, feedback, and mentorship provided within a company. This is not generally intentional but a product of small data science departments, business executives licking their wounds from years of poor data quality and technical deficit and increasing demand for better data driven outcomes.

## HOW CAN DATA SCIENTISTS DEAL WITH IMPOSTER SYNDROME?

[According to the American Psychology Association](https://www.apa.org/gradpsych/2013/11/fraud), If you recognize yourself in the description of the impostor phenomenon, take heart. There are ways to overcome the belief that you don’t measure up.

In a nutshell, there are three ideas that you need to get in your head in order to get over imposter syndrome:

* You are a generally competent person.
* There are always going to be people that know more about a certain area of data science than you and that’s ok and expected. Even more importantly: you’re not the smartest person in the planet, so if you look hard enough, you’re going to find people that are better than you at everything you do and that’s ok.
* You have a finite amount of time to learn things, and your goal shouldn’t be to learn the most, but to learn the things that maximize your specific goals – generally, this is going to be career advancement, but for some it may be something else.

When the Imposter Syndrome feeling comes up:

1. Remind yourself that you are a competent person – if you weren’t, you wouldn’t have gotten to the position you are in right now, whether that’s graduating from college or leading a data science team (yes, even DS team leaders catch the ‘drome from time to time).
2. Remind yourself that when you look for people who know more than you about a specific area, you are guaranteed to find them – that’s just how it works. People choose to specialize in certain areas, and if you only focus on that area of expertise, you are going to feel inadequate. But even more importantly, recognize that if you run into someone who is better than you at literally everything you do, that doesn’t diminish your value – it just means you have run into someone that is pretty special\*
3. Get back to prioritizing what to learn. Do you *need* to learn that or do you just *want* to learn it to feel better about yourself? If the latter, learn to let it go, and focus on the things you need to learn – and save the things you want to learn for when you have the time, which will come.

[u/dfphd – PhD | Head of Data Science & Ecommerce](https://www.reddit.com/r/datascience/comments/m71ijk/imposter_syndrome_and_prioritizing_what_to_learn/)


[Youtube - What is Imposter Syndrome and How can you  combat it?](https://youtu.be/ZQUxL4Jm1Lo)

### TALK TO YOUR MENTORS.

“The thing that made so much of a difference was supportive, encouraging supervision”.

Many have benefited from sharing their feelings with a mentor who helped them recognize that their impostor feelings are both normal and irrational. Though many will often struggle with these feelings, you must be able to recognize personal or professional progress and growth instead of comparing myself to other students and professionals.

### RECOGNIZE YOUR EXPERTISE.

Don’t just look to those who are more experienced, more popular, or more successful for help. Tutoring or working with younger students, for instance, can help you realize how far you’ve come and how much knowledge you have to impart. This can be a great way for a Data Scientist to give back to the industry as well as set a more realistic benchmark of your perceived value.

### REMEMBER WHAT YOU DO WELL.

Psychologists Suzanne Imes, PhD, and Pauline Rose Clance, PhD, in the 1970s, impostor phenomenon occurs among high achievers who are unable to internalize and accept their success.

Imes encourages her clients to make a realistic assessment of their abilities. “Most high achievers are pretty smart people, and many really smart people wish they were geniuses. But most of us aren’t,” she says. “We have areas where we’re quite smart and areas where we’re not so smart.” She suggests writing down the things you’re truly good at, and the areas that might need work. That can help you recognize where you’re doing well, and where there’s legitimate room for improvement.

## REALIZE NO ONE IS PERFECT.

Clance urges people with impostor feelings to stop focusing on perfection. “Do a task ‘well enough,'” she says. It’s also important to take time to appreciate the fruits of your hard work. “Develop and implement rewards for success — learn to celebrate,” she adds.

### CHANGE YOUR THINKING.

>“let the challenge excite you rather than overwhelm you.”

People with impostor feelings must reframe the way they think about their achievements, says Imes. She helps her clients gradually chip away at the superstitious thinking that fuels the impostor cycle. That has best done incrementally, she says. For instance, rather than spending 10 hours on an assignment, you might cut yourself off at eight. Or you may let a friend read a draft that you haven’t yet perfectly polished. “Superstitions need to be changed very gradually because they are so strong,” she says.

Avoid all or nothing thinking. Just like a standard distribution, most Data Scientists fall within the center. If you find yourself comparing to outliers, then you are going to continue to feel like a fraud, which will in return stifle your career in data science.


[YouTube - How you can use imposter syndrome to your benefit - Mike Cannon-Brookes](https://www.youtube.com/watch?v=ZkwqZfvbdFw&ab_channel=TED)

### TALK TO SOMEONE WHO CAN HELP.

For many people with impostor feelings, individual therapy can be extremely helpful. A psychologist or other therapist can give you tools to help you break the cycle of impostor thinking.

The impostor phenomenon is still an experience that tends to fly under the radar. Often the people affected by impostor feelings don’t realize they could be living some other way. They don’t have any idea it’s possible not to feel so anxious and fearful all the time.",datascience
naqhuu,1620830959.0,Plotly app to Sharepoint ?,"Hi,

I'm a self-taught data analyst currently working as an office clerk. It's not *that* bad since I'm still a huge beginner and the job leaves me enough freedom to keep learning.

The main problem is that I must end with the Office package that my company uses. I'd love making some dash app (be it only to train my python skills) but since I can't find a way to export them in our Holy Sharepoint, I just end up making boring Excel dashboards.

Do you have any idea that could work ? I can't make my own online website since our data must stay protected.

Thanks,",datascience
naqcd2,1620830561.0,Data Science Training Company - Worth it?,"I've been in the data analytics industry for over 15 years now.  And I have been thinking about starting a company that teaches data science.  Did research and found a lot of competition between Coursera, Udemy, Universities and Boot Camps.  I'd be targeting people who are considering a career change or professionals that need to retrain/upskill.

I really have a passion for training/teaching others and I have credibility from my experience working in the field. I was thinking about how to differentiate myself: personalized training, teaching adjacent skills such as project management for data professionals, and coaching in the job search process.

Do you think it's worth pursuing or is the field just too saturated?",datascience
nao1d8,1620824263.0,EDA query,"Hey all

I have a question about EDA . So I've been working on this project, ""The Movie recommendation system"".  My dataset is a pretty standard one ([https://www.kaggle.com/rounakbanik/the-movies-dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset)). Now I want to understand how much depth should I go into to while performing EDA. Because after a certain point, the conclusions from EDA no longer make the ML model better. However, I can go on making conclusions from the dataset, finding relations between all combinations of features. When do I stop?",datascience
najtbp,1620808270.0,Data logging.,There is not much available on internet about data logging. Any resources or explanations from anyone which can sum it up ?,datascience
naibge,1620801608.0,Are data science skills transferrable to regular SWE roles?,"I might be getting an automation/data science python job soon, and it's full time and I'm still in school full time. To me this job would mostly be worth it if the experience here would be sought after by future SWE roles that i apply at when i graduate, is this the case? I love automation with python but am not personally a huge pandas/numpy guy myself.",datascience
nah26c,1620796386.0,What are the best data visualization tools?,"Sorry I’m new and can hardly explain what I’m looking for - basically what I want to know is, what are the best network visualizaton tools/software? I’m trying to build a data visualization that represents networks kind of like bicycle tires and spokes. Id be interested in any software that lets me make an interactive diagram of different networks represented in an interesting way, and showing how networks connect to one another.",datascience
nagk6a,1620794411.0,Excel Hate,"What is it with data scientists and being snobs about Excel? It's a great tool if one wants to get the texture of a data, build simple one-off things, or even prototype logic for a workflow. Maybe I'm weird, but I like having stats and using that to flip around data in simple pivots, then digging into the crosstabs.

I understand we like our cutting edge and bespoke tooling, but Excel is as if not more effective to walk a client through parts of their data in a familiar environment. Since I've been in the field I had the idea in the back of my mind that it is a difference between people that tend to think in terms of functions vs tables.

I come from microbiology/mycology research where every record was painstakingly recorded in a table, so I probably put more value on dissecting the data much more. As I moved from that career track in 2013 to where I am now, that focus was on increasingly larger ('big') data and greater distance from the data. This may have just been the different between capturing hundreds of observations in the lab by hand to inferring risk from millions of user permissions.

Or, is it customary to dunk on Excel now?",datascience
naf8ra,1620789606.0,Model for Ranking people,"Hi,

I am looking for pointers on how/where to start the use case of ranking associates. For example, there is a class of 10 students who gave exams for last 3 years and we have the marks in those tests. Now can I use the historical marks for each subject and predict the future marks and rank the associates accordingly. Also can I give suggestions to students on where to improve to get a better rank/marks ?",datascience
nacqar,1620781521.0,Coffee chats - what's your preferred way of requesting networking connects? LinkedIn / Email / lunchclub?,"Tried lunchclub, horrible experience - didn't have a single conversation of 10+ scheduled chats. Considering reaching out to folks on LinkedIn, but would love to know if there's a smarter way to do this, like some active discord channels.

P.S. with all the reform talks going on, would be worth opening a discord server or slack channel for the sub as well.",datascience
na8gjw,1620769059.0,How likely is it to work a fully remote job in Data Science?,,datascience
na88bo,1620768466.0,Seeking recommendations for a model evaluation tool if one exists?,"Our team works on various models and prediction problems. Sometimes we get bogged down in discussion about better approaches and want to test new ideas. In each team members specific individual scripts they have test and evaluation data which makes true side by side comparisons trickier than otherwise.

My question is, is there a service, open source server or even a paid tool where we could send our predictions to be tested against a single universal out of sample test set for model evaluation?

The only example I can think of is Kaggle. Years ago I attempted to join a competition and you would submit a csv of predictions on some test data and your score would show on a leader board.

Are there any tools, servers, libraries or platforms out there that work in a similar fashion that would allow our team to compare and compete with each other on some prediction tasks?",datascience
na7z1g,1620767790.0,Glassdoor reviews & work-life-balance,"I always see amazing glassdoor ratings for small (<500 employee) companies and wonder if this is genuine. The general story seems to be that work-life balance is a lot better at large companies like fortune 500s, but glassdoor seems to disagree. Is this a coincidence with the companies I'm looking at, or this there something I'm missing? Is it just that start-ups expect no work-life balance so they give it 5\*?

Also, any tips on finding a job with work-life balance? (currently an overworked data analyst)",datascience
na5kg7,1620761761.0,"How many hours of actual ""work"" do you do everyday?","Hi!

I was just wondering if I was on the low side of number of hours people work a day. I talked to a friend who works at Amazon and they said that they do 8 hours of work. By work I mean when you're sitting on your desk and doing stuff. Not including the meetings, although I understand meetings are also part of work.
I realized I do maybe 4 hours of actual work, rest is just thinking about some stuff for work, lunch, break etc.
It's hard to imagine how can someone just sit and do 8 hours. Won't they be burnt out?

How many hours do you put in?

Thanks!",datascience
na4ytl,1620760300.0,Is the market for data engineering significantly better than data science (specifically for entry level)?,"Apologies if this isn't the correct sub. I believe I've seen similar posts on here before so I figured it'd probably be fine.

Title says it all. Thus far, I've been focusing my search on data science, and to be honest, data analytics positions. For those of you within data engineering, do you feel that the entry level market is significantly less saturated? Or about the same?

Would really like to hear from people who have experience in that field (rather than guesses from those who've exclusively had experience with DS).",datascience
na081v,1620748479.0,"Has anyone ever applied an unsupervised learning method or reinforcement learning method to define ‘roles’ at the company? (Think permissions, AD Groups, and on-boarding)",,datascience
n9wqtb,1620738888.0,Is there a sub-discipline of Data Science that focuses on the physical sciences?,"I’m looking to see if there is a data science ""category"" that focuses on physical phenomena (i.e. physics, math, chemistry etc) instead of data science methods used when analyzing human behavior (like voting tendencies or purchasing habits). I know that both areas can use the same machine learning models, but I'm curious to know if the physical sciences tend to benefit from a certain ""category"" of data science methods.

Am I right in assuming that our approach to data science in the physical sciences can be different than our approach to data science in the ""softer"" sciences like psychology and sociology? If so, I would greatly appreciate your thoughts and any potential references to already existing literature that relates to the topic.

Thanks in advance!",datascience
n9izej,1620688590.0,How do I ask for more resources in a secure environment,"I work at a relatively small, publicly listed bank (corporate hq) as a data analyst intern and both physical and cyber security standards are high.

My job, and most people’s job in my department (finance) entails importing data into excel or modifying data from excel.

As you may know, excel doesn’t really play nice with all kinds of data. For example, we have excel functions calling a cell from a different sheet. If the new data to be imported is minutely different, it may invalidate the function. Many times, this results in hours or troubleshooting (manually parsing through cells and rematching them). Furthermore, excel isn’t really robust enough to efficiently do linear algebra so any automation involves manually going through cells and writing functions.

Additionally, everyday that I’ve come in so far, the first half of the workday involves my colleagues complaining about how the software used to manipulate data results in errors. On my first day, they left me a text book about said software and I read it in full. It’s essentially visual, simplified R.

I come from a stem background and I think it would be evident to anyone from my background that the current data storage system is highly inefficient and attempts at improving efficiency (data manipulation software) is negligible at best.

The problem is, to access anything, we go through a portal. The portal has applications we can use. You can’t access the shell. There are no language interpreters or text editors. Even if I could access the shell, it would either be cmd or powershell. USBs aren’t allowed. And data cannot be stored locally.

IT has shutdown any propositions I’ve made about adding tools. The cybersecurity administration is extremely hesitant along with my boss.

From an accessibility stand point, I do understand. I’m probably the only person in that entire building who knows how to code outside of a query if statement. If we were to make a project, I’d be the only one who could understand it. And if I left, they’d have to hire someone with those skills and completely change this hypothetical project. So that’s not really what I’m asking for. What I want is more tools to do the job they hired me (personally) for. Without those tools, I’m just every other employee. I don’t really have a purpose.

I feel like because I’m young, they don’t really take me seriously. But it just seems so clearly evident that there is no way they can continue to grow like this. It’s just too much data to parse through with the existing process. Unless they just hire more and more but at some point, the overhead will become too high (which is what is currently happening; paying sums for software that doesn’t work, hiring more to parse negate data issues)

Ironically, one of the company commandments (for a lack of a better word) relates to cutting costs anywhere possible.

So my question is, has anyone under similar circumstances successfully passed a proposition for more resources in a similar context? How did you do it?

tl,dr: How do I ask for more resources in the context of a highly secure network.",datascience
n9aj13,1620667019.0,"Rant: If your company's interview process can be ""practiced"" for, it's probably not a very good one","The data science interview process is something that we have seen evolve over the last 5-10 years, taking on several shapes and hitting specific fads along the way. Back when DS got popular, the process was a lot like every other interview process - questions about your resume, some questions about technical topics to make sure that you knew what a person in that role should know, etc.

Then came the ""well, Google asks people these weird, seemingly nonsensical questions and it helps them *understand how you think!"".* So that became the big trend - how many ping pong balls can you fit into this room, how many pizzas are sold in Manhattan every day, etc.

Then came the behavioralists. Everything can be figured out by asking questions of the format ""tell me about a time when..."".

Then came leetcode (which is still alive).

Then came the FAANG ""product interview"", which has now bred literal online courses in how to pass the product interview.

I hit the breaking point of frustration a week ago when I engaged with a recruiter at one of these companies and I was sent a link to several medium articles to prepare for the interview, including one with a line so tone-deaf (not to be coming from the author of the article, but to be coming from the recruiter) that it left me speechless:

>As I describe my own experience, I can’t help thinking of a **common misconception** I often hear: it’s not possible to gain the knowledge on product/experimentation without real experience. I firmly disagree. I did not have any prior experience in product or A/B testing, but I believed that those skills could be gained by reading, listening, thinking, and summarizing.

I'll stop here for a second, beacause I know I'm going to get flooded hate. I agree  - you can 100% acquire enough knowledge about a topic to pass ""know"" enough to pass a screening. However, there is always a gap between knowing something on paper and in practice - and in fact, that is *exactly* the gap that you're trying to quantify during an interview process.

And this is the core of my issue with interview processes of this kind: if the interview process is one that a person can prepare for, then what you are evaluating people on isn't their ability to the job - you're just evaluating them on their ability to prepare for your interview process. And no matter how strong you think the interview process is as a proxy for that person's ability to do the actual job, the more efficiently someone can prepare for the interview, the weaker that proxy becomes.

To give an analogy - I could probably get an average 12 year old to pass a calculus test without them ever actually understanding calculus if someone told me in advance what were the 20 most likely questions to be asked. If I know the test is going to require taking the derivative of 10 functions, and I knew what were the 20 most common functions, I can probably get someone to get 6 out of 10 questions right and pass with a C-.

It's actually one of the things that instructors in math courses always try (and it's not easy) to accomplish - giving questions that are not foreign enough to completely trip up a student, while simultaneously different enough to not be solvable through sheer memorization.

As others have mentioned in the past, part of what is challenging about designing interview processes is controlling for the fact that most people are bad at interviewing. The more scripted, structured, rigid the interview process is, the easier it is to ensure that interviewers can execute the process correctly (and unbiasedly).

The problem - the trade-off - is that in doing so you are potentially developing a really bad process. That is, you may be sacrificing accuracy for precision.

Is there a magical answer? Probably not. The answer is probably to invest more time and resources in ensuring that interviewers can be equal parts unpredictable in the nature of their questions and predictable in how they execute and evaluate said questions.

But I think it is very much needed to start talking about how this process is likely broken - and that the quality of hires that these companies are making is much more driven by their brand, compensation, and ability to attract high quality hires than it is by filtering out the best ones out of their candidate pool.",datascience
n97h4x,1620660208.0,Any DS freelancers out there?,"Hi,

I'm thinking about exploring DS in the freelance world.  I have started working full time in January, but the position is not very challenging or time consuming and I need more projects.  I'm wondering if anyone out there has any experience as a freelancer, consultant, or part-time and what your tips are to be successful?

Thanks!",datascience
n959rr,1620655652.0,Is data science too broad to ever feel prepared for an interview?,"I'm a ""data scientist"" that does data engineering.  I get data science interviews from my job title alone.  Does anyone else think data science is too broad of a field to ever feel prepared for the interview.  For example, I feel data science jobs can be broken down into the following types of roles:





1) The typical data scientist: This is what we typically how we imagine a data scientist.  The role involves a bit of data exploration, ML model building, presentations to management, etc.




2) The deep learning data scientist: This is kind of like the previous example, but with a greater emphasis on deep learning over traditional ML.  The role is more likely to ask for a PhD.  This role looks at more interesting problems in my opinion, such as computer vision and NLP.





3) The data engineering data scientist: This is like my current role.  I work on ETL pipelines and bring new data to data scientists in the previous categories for ML model building.  Because of my job title, I might be asked to do some data analysis work.  I work a lot with python, SQL, and AWS.





4) Software Engineer (Data Science): This data scientist is in reality a software engineer attached to a data science team.  This is not as common, but definitely exists.



5) The data analyst with a data scientist job title: With this type of data scientist, there is less python and ML, and more SQL, Excel, and presentations.  Hiring managers typically look at non-technical skills over technical skills.






Those are all the roles I can think of, and I am sure I am missing some.  But assuming you fit one of the categories, it's pretty hard to prepare for all other data science interviews.  Some roles only leetcode you, others might ask SQL questions, others might ask math/stats trivia, others might give you a take home presentation to prepare.",datascience
n942nw,1620652222.0,Non career focused data science subreddit.,"Is there a reddit for data science that isnt focused on career questions? I'm on r/statistics but I didnt know if there was a similar home for DS specifically.

EDIT: and would anyone else be interested in seeing this sub be more than a flood of career entering and movement threads? If that's what is wanted great, but I've always thought that most of the content in this sub could be contained in a single pinned thread.",datascience
n8tqfe,1620614054.0,How to become a data scientist? There’s a million ways.,"If you read posts/comments from this sub, people are quite assertive that their path is the main path. They say get a masters/PhD in “ “ and that’s the only way in. They say don’t get a masters in analytics/data science but encourage the analytics @ Georgia Tech. Worry about your own goals and domains that you want to get into and focus YOUR path for that. There’s data scientist from a million different backgrounds and educational levels.",datascience
n8f0v3,1620569593.0,Most Important Reporting & Monitoring Tools for your business.,"Reporting and Monitoring.

There are  two important types of tools in BI one is for reporting & one is for real time monitoring.

For reporting - Power BI, Tableau, Qlik Sense, Looker Etc.

For real time monitoring i believe there a few categories based in what i have read in various articles.

[Cliff.ai](https://Cliff.ai) \- for real-time monitoring of business metrics.

[montecarlodata.com](https://montecarlodata.com) \- for real time monitoring of data.

What others tools for reporting & real time monitoring tools you use or know about????",datascience
n8ezvx,1620569504.0,So you trained a model. Now what?,"The courses at university teach me how to understand and build a model. However, we do not learn what to do with the model once it's done. Like how to put it into production for a company. I would like to understand this aspect a bit more.

As I understand it, simple models can be saved and stored on a cloud server and accessed (through API) by the end application to make predictions based on new data. Is this realistic?

How do you deploy models in your work environment?",datascience
n8ddv3,1620563780.0,Populating E-commerce Tables with Products and Variants,"Hey folks,

I'm in the process of building a fashion aggregation website as a portfolio piece. To obtain the data for this site, I have multiple scrapers for many of the largest fashion retailers in North America.

To describe the data - one product can have many variants. e.g, 'Summer Dress' that comes in 3 colours and 8 sizes.  As such this product would have 24 variant products, the generic being the 'parent' product. Each variant may have different pricing, availability, sizing, colour etc.

My question concerns table construction - my scrapers output every variant of every product with their associated data, which can be in CSV or pandas DataFrame format. Can any of you tell me how I would go about populating two database tables from this data:

1. Table with the parent product, with foreign keys to each of its variants

2. All variant products of a parent product, linked to that product such that on my eventual website, they can all be found through searching the foreign keys of the parent product.

I hope that makes sense, in a bit of a jam here. I'm not sure what to Google - even if you can't provide an answer, any points on even what to research would be of great help.

TLDR: How do I populate 2 database tables with one CSV file, one table for the generic product, and one for all of its variant's fields?",datascience
n8ct8y,1620561630.0,Weekly Entering & Transitioning Thread | 09 May 2021 - 16 May 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
n86zp8,1620536390.0,Not sure where in the spectrum I fall...,"Background:

I was hired as a Data Analyst a couple of months ago. It's a startup with a small data science team. The team is really endearing and I absolutely adore them.

That sounds all good. I love the work I do as it's writing code and I love writing code.

But I'm not doing any data analyst work. I write ETL processes, come up with formulas to do certain calculations, fix historical data because they were calculated wrong, i.e. fix formulas that are close enough but there are better ways to calculate them and reprocess the entire data, and writing SQL queries to see things I wanna see. The closest to what we can call 'Analysis' I do is to verify if the ETL Process I wrote shows/updates the graphs and numbers in the platform and if they're correct.

So what exactly am I?

Edit: grammar",datascience
n84g3e,1620527452.0,Mlr vs caret,"For training statistical/machine learning models in R, are there any advantages of using the ""caret"" package compared to the ""mlr"" package? Do you guys have any preferences? For instance - I noticed that caret does not easily allow you to perform grid search on the ""max node size"" hyperparameter in the random forest model.

Does anyone have any advice?

Thanks",datascience
n81n29,1620517810.0,Missing values in XGBoost,"Hello everyone. Does anybody knows how XGBoost treats missing values in the Y dataset when a model is trained? I know it handles well missing values in the independent variables but I have not found what happens if there are some in the Y dataset. I am doing several regression models and it seems to work fine but dont quite understand yet if the NaN rows are excluded automatically or if the training of the model is affected in some way. There are just a few NaNs by the way (less than 5%)

Thanks a lot",datascience
n7x3fe,1620503683.0,Where are my Bayesians?,"At my current job I've been using Bayesian Structural Time Series models to (hopefully) deal with COVID related outliers more gracefully in forecasting. Curious if anyone here has found a way to incorporate Bayesian approaches into their work. If so, what applications are you using them for?",datascience
n7vzf6,1620500385.0,Career path options as a current Data Analyst,"Hi all,

Apologies in advance if I'm breaking any rules or if this is more suited to the weekly thread.

I've been working as a Data Analyst for a healthcare company for the past year. A lot of my work surrounds creating queries to track certain metrics then building dashboards to create insights using visualization tools.

I do like the field, but unsure of where to move next. I do enjoy the coding aspect of my position (Lots of SQL, don't like excel as much), as well as hacking away at a problem and figuring out how to fix certain issues with the code we have.

However, I hate coming up with insights and solutions. I don't mind creating the dashboards, but I don't like the proactive and analytical work that comes with it. ""Oh that's a good find, maybe we should look into this next"". I enjoy more when there's a problem to fix, then I fix that problem.

Does data engineering fit more into the interests I've mentioned above? I imagine a role as a Data scientist would be more similar to what I'm currently doing.

Thanks in advance.",datascience
n7nuuf,1620475610.0,Need advice about building out a model in terms of algorithm picking,"So the situation is basically I want to break down parsed data from a game called Counter Strike and try to figure out what locations on a map are important to winning a round. The features I was thinking of collecting would be

the tick: 128 = 1 second so would probably normalize this as the maximum amount a round can last is 1 minute 55 seconds + 40 seconds (usually lower amount than this).
10 vectors of [91x1] which would be one hot encoded to break down roughly 90 in game locations that I have labelled. A player can only be in one of those locations at a time. A player can also be labelled dead or off the map so was thinking of indicator for that.
10 [1x1] vectors to indicate whether a player is CT or T
Training label would be 0 or 1 to indicate either T or CT side win (two teams of 5v5 face off each round to a best of 30 conclusion for anyone unfamiliar with the rules).
So all in all the ending goal of mine would be to try and figure out how important those locations. Is my idea for the feature set adequate? Or do you see certain aspects of it that would be an issue.

Also if the feature set is fine what sort of algorithms or approaches would be best to go by, I just have not flexed these ML muscles in a decent amount so would like the advice.",datascience
n7akrr,1620425902.0,Are linear models still useful at all?,"If so please comment on their uses, I occasionally use R and it feels weird that lm() is the only builtin ML function and yet I have so far found no real uses for (aside from perhaps simple forecasting and constrained optimization of a hidden function).

I've heard that Andrew Ng seems to find them useful enough that it is almost always the first thing he tries to solve a problem (probably for exploratory purposes). Can anyone comment on that?",datascience
n78g0y,1620420128.0,"has anyone ever worked on a machine learning model for ""queues""?","Has anyone ever worked on a machine learning model for ""queues""? Suppose there is a bakery: the bakery has has ""n"" people working, ""m"" people in line""  and ""q"" orders that they are currently working on. The bakery is interested in making a machine learning model that predicts how long a customer will have to wait before the customer's order is ready and how long will the next customer have to wait before they can place an order.

Has anyone ever come across a machine learning model which can predict waiting and processing times? I have seen examples online where people try fitting exponential distributions to historical waiting times and see how well they fit, as well as trying different m/m/k combinations... but has anyone ever come across an instance where machine learning algorithms (e.g. random forest, neural networks) are used to predict waiting times?

I saw something like this: https://arxiv.org/abs/2002.10788

But there was no python or R code for this paper. Can anyone recommend some source (blog, github, website, book, YouTube lectures etc) which show and provide computer code for analyzing queues using machine learning models?

Thanks",datascience
n74ex9,1620409703.0,How do you guys remember syntaxes?,"I've been working as a new data scientist for 3 months and noticed some people could just jump straight in and type away on jupyter notebook without referring to anything, while I have to maintain a ""cheatsheet"" of syntax

Need to bin categories? Refer to my cheatsheet
Need to plot a few bar charts with annotations? Refer to cheatsheet
Need to do a random forest? Err, refer to cheatsheet

Usually, there's nothing wrong with referring to notes or getting some help from Google, of course. But as a professional data scientist, it gets really embarrassing when I'm having a discussion with my colleagues on a project I'm working on, and they're like ""can you create these new features and let me see how their plots look like real quick"", and I'm like...let me refer to my notes on how to do that",datascience
n74138,1620408692.0,Data engineering: what is the future and what to focus on?,"Today we have loads of companies who either have their data foundation run in the cloud or hybrid solutions where some business processes are in the cloud and some on-premise.

I have been a data engineer building and maintaining an on premise datawarehouse for quite a long time now but I am very intrigued by learning more about cloud datawarehousing and cloud solutions in general as I think its a very practical and promising technology for the future. I have been getting my certificates and want to start working with cloud technologies now as well.

My questions to you guys, do you think that cloud solutions will be the future, or will on premise data systems be there for a while?
And how alike is working as a data engineer in on premise vs cloud solutions?

Please share your thoughts!",datascience
n73pgf,1620407849.0,"On your first DS project, is it normal to ask a lot of questions or have a hard time understanding some of the business process aspects?","Hello!

I'm working on my first DS project where our goal is prediction.
Sometimes I find myself having a hard time understanding a concept related to business therefore ending up asking questions from the person who gave me this project. Different time zone doesn't help and all the conversation is through email, making it harder to communicate.
I don't set up meeting since I think I shouldn't waste someone's time and understand what I can through email only. Usually, here's how it goes, I send my EDA results, then the guy will reply with some more eda stuff I need to do. So sometimes I don't understand that requirement and end up asking a few confused questions related to the requirements.

For people who supervise, is there anything I should change or do you encourage someone like me a fresher, beginner in this field, asking questions?
Is it possible that I'll end up irritating the other person?

For what it's worth, I'm not officially a ""Data Scientist"", just been working on a project because of my interest and having to study Statistics in my Masters.

Thanks!",datascience
n73pb4,1620407839.0,Do data scientists type as much on their keyboard as software engineers?,Just wondering if I can ditch my ergonomic keyboard and use my gaming RGB keyboard for work if the typing is not as intensive.,datascience
n6wfog,1620387359.0,Scalable infrastructure for lonely data analysts with no access to raw data,"Hello DS,

I work as the only data analyst of a small subscription-based streaming company.  Our app is developed by an external company and we have no access to the raw data.

We receive monthly csv files showing usage per customer. We also receive daily updated csv file for subscription data (start and end date per user). This is also the only data I have access to.

Using these through Web API, I've built Power BI dashboards and run some analyses on python.

For usage data: at the start of every month I run 2 .py scripts that aggregate the new month with the existing data and save as csv file in the Data Analytics sharepoint drive. Then I use this data in Power BI or in further analyses in python.

For subscription: Power BI connects directly to the web to retrieve this data. For analyses, I have a small function in python that retrieves the most recent data from the web.

For my scripts and data, I have a folder on our Data Analytics Teams group, where I save all my .py and .pbix files.

I thought this would work okay for the little data we have, and it did for the last year. But now..

* I'm still using a lot of time to run simple analysis on python because I changed some definitions (e.g. which users count as converted),
* I'm 100% dependent on Power BI because I have no other way of sharing analysis. Even analysis that would be much easier to run on python has to be on Power BI because that's where I have all my definitions (aka. feature engineering, categorizing users etc.), and it's the easiest way to share analysis with collegues.
* I want to push to get access to the raw data, but I don't know how I would implement that in my current way of working

I feel like there must be a better way: more automatized, more structured, cleaner way of working, but I have no idea how.

I've been asking my boss to hire a data engineer consultant temporarily to advise us on this, but he hasn't prioritised it yet.

Do you have any advice? What would you do in this situation?",datascience
n6w7oq,1620386541.0,Best way to evaluate two competing recommendation systems,"I have a music recommendation survey, and I have developed a music recommendation algorithm (A), and a simplified *control* algorithm (B).

The users are given a list of songs to rate (1-6) based on how much they like them. My question is, should each user either listen to songs from the same system exclusively (so AAAAA or BBBBB), or should the recommendations from both systems be interlaced (ABABABA randomly) in order for me to be able to compare the average ratings for each system?

The first approach means that some users will never hear my recommendations, and given that I do not expect a huge amount of respondents that is a bit of a concern for me. Also, I expect a large chunk of the respondents to be from family and friends, thus I worry that some of the responses will be biased by that fact (so if the user gets the fake system, they would still rate it relatively highly since they are being nice).

What should I do ?",datascience
n6fgjw,1620329454.0,Anyone ever get fired?,"I got canned from my first job in the industry. Joined a tech startup where devs ran the entire show and did wtf they wanted, not the management. I wasn't the extrovert personality the ex-consultant management seemed to want, client work didn't come in. They nit picked on small stuff in my 3mo review like not responding to slack messages immediately on a Sunday and canned me a week before Christmas. Seemingly nothing really to do with the work I did. Didn't even get to go past my desk to get my stuff.

I now work for one of their clients but 1.5 years on I struggle to let it go of the shame that I got fired from a job.",datascience
n6dx6f,1620325424.0,"Is data science turning into a ""catch all"" title for recent Ph.D grads?","It seems theres a massive influx of recent PhD grads in various fields but especially stem that couldn't cut it in academia or research and claim to be experts in data science but dont necessarily have any qualifications or background in analytics

PhD in stem? Congrats you're a data scientist. Dont worry you dont have to know anything as long as you read blogs on data science central and took an intro stats course you can bullshit your way through the job and nobody will question you because you have a PhD right?

Wonder what implications of this fad will be long term for job market",datascience
n6c4vh,1620320764.0,"Respected data science bootcamps focusing on cloud, databases, big data frameworks, and statistics?","I'm currently employed as a full-time Data Scientist but functionally I'm more of a machine learning engineer. ML is fun, ""hot"" and all that, but I'm more interested in taking a higher level approach to inferring insights from data (via ML or otherwise). Also, despite my title, I haven't ever built a data base or used cloud computing. It's been mostly local computations, csv files, pandas, etc. So I'd love to patch up those holes so I can do more properly data science work.

Given that, are there any somewhat well known/respected boot camps or MOOCs out there that would help me patch those holes? I have a BS in Physics so something more mathy wouldn't be a huge issue. So far I've been looking at DataCamp and Springboard but I'd love some of your thoughts!

&#x200B;

Update: I read all your comments and I really appreciated the feedback! It seems like the best move is to hit some books and maybe take some one-off courses in specific libraries or technologies that would be useful.

Next steps include: identify a solid statistics course/textbook (preferably something with rigor as I like thinking from the ground up), a one-off course in SQL, a one-off course in AWS/Azure, and a one-off course on Hadoop or Spark. I think that'll cover all my bases.",datascience
n691ci,1620312658.0,Whats the difference between marketing data analytics and martech?,Checked google but its only showing adtech vs martech. Would be great to know what the difference is between marketing data analytics and martech!,datascience
n68og6,1620311722.0,Alternatives to Jupyter (Pyhton)?,"I find that Jupyter is a little buggy occasionally and also along with all my other stuff open in chrome i'd rather have a specific window.

Main tasks day to day - condition based based analysis,
Data collection and cleaning
Graphing
Time/frequency/ angle domain analysis
Data sets vary from  1gb to 50gb, rarely more.

What do you guys use?


Edit: Update.

VS Code is the one. I like it a lot, though I did have multiple issues with numpy, due to conda environment. Already moved over my current project did some housekeeping and all looks great.

Also switched to miniconda which is much better again.",datascience
n64nxf,1620298854.0,At what experience level do coding tests (take-home and onsite) go away?,"I'm considering taking an Algorithms course next semester. I doubt the content will add much to my knowledge considering the other courses I've taken, but it would surely be useful for interviews. I'm curious when the entry-level coding tests (stuff like dynamic programming, longest increasing subsequence, etc.) I'm used to will start to disappear in interviews.

This is assuming someone with significant experience won't be bugged with these type of interview questions, could be wrong.",datascience
n5uj0z,1620259814.0,What is your official title currently?,,datascience
n5sci0,1620253465.0,DAE get frustrated after finally finishing something cool and everyone takes for granted how hard it was?,"I built a sweet tool and showcased it and everyone loved it. Then I got the “that looks easier than you made it seem” comments, like yeah because I had to break everything else to figure all of this out. Maybe it’s just me.",datascience
n5kuyz,1620234151.0,How important was/is work life balance in your mid 20's and what did you do to maintain or destroy it?,"Hi!

I'm 26 and work as a BI developer/ Data Analyst at a fortune 500 company. My job pays well and I live comfortably. But sometimes I crave a change, a change of company, a change of tools I use at the current job. Using outdated technology right now is kinda the only reason I want to switch.
Then I think if I switch job, it might be a better paying job but could be bad for my work life balance. Right now my work life balance is super, my manager is absolutely fantastic, knows his boundaries, doesn't check my performance in terms of how many hours I'm sitting on my desk. I can stop working at 4, 4.30 or 5, I won't be asked any questions. I can work till 6 and I don't have to put effort in showing that. My hobbies are in check.

To the seniors of this sub or people of my age, what do you value the most in a job?

Thanks!",datascience
n5gcwe,1620222552.0,Anyone know of this type of ordinal encoding in Python?,"I use my own home-brewed feature engineering package in R, but haven't had time to translate it to Python. I learned from a mentor a while ago about this strategy for encoding ordinal variables which is useful for certain coefficient based regression models. The idea is similar to one-hot encoding, but each level 'adds' on to the effect of the prior lower level. So, let's say you have the following data:

|Customer|Salary Score|
|:-|:-|
|A|1|
|B|2|
|C|3|
|D|4|

You only have the 'score' of the salary, which is essentially a rank. Needs to be encoded somehow to use in a NN. What I personally call 'ordinal encoding' in my personal R package would transform this to:

|Customer|SS\_1|SS\_2|SS\_3|SS\_4|
|:-|:-|:-|:-|:-|
|A|1|0|0|0|
|B|1|1|0|0|
|C|1|1|1|0|
|D|1|1|1|1|

Does anyone know of an implementation of this in Python?",datascience
n5fme5,1620220413.0,Lowball offer or am I being greedy?,"Hi all! I apologize for the forthcoming long post, but I’d appreciate any insights regarding negotiating/walking away from my recent offer.

I recently got my first data scientist offer after spending the last few months actively interviewing for various analyst and data scientist positions.

For some background, I’m in the midwest area of the US. I have 2+ YOE in data analytics, and I’m currently a lead data analyst managing a team focused on building internal NLP, forecasting, and other machine learning models, along with various reporting/dashboarding responsibilities using R, Python, Tableau, etc. I also have a B.S. in Stats and I’m working on my M.S.

I’ve been excited about this position as it is very involved with building and deploying customer-facing machine learning models. I was even more excited to get an offer, but I’m now feeling fairly disappointed after receiving an offer of 65k.

In my interviews with other companies and from my own research, I’ve never even discussed/seen a salary this low for a data scientist position. It seems to match what I’ve seen and been offered for other analyst roles, and I know this isn’t a case where the position is just named data “scientist” while actually being more of an analyst role.

Am I being lowballed, or does this offer make sense for someone starting their first “real” data scientist position?

I’m typically interviewing 3+ times a week, so I don’t want to undersell myself, but since this is my first offer I’m worried I might be missing out on a good opportunity. Am I being greedy expecting more than 65k regarding my experience, or what range should I be expecting?

TL;DR First DS offer of 65k. 2+ YOE and current lead analyst. Was I lowballed, or am I over-evaluating myself regarding typical data scientist compensation?

EDIT: Thank you all for the great comments and advice! You’ve helped ease my mind, and I’ve followed your suggestions to try and negotiate, but they don’t seem interested in budging. I’ll take what I’ve learned from you all on to my next offer! Thanks!",datascience
n5fltp,1620220366.0,"How to compare metrics? (QWK, MSE, r)","I have two machine learning models trained on the same task using the same data; call them A and B. I have calculated the QWK, MSE, and r for both models using their predictions on the test set. I want to use these metrics to determine how much better (or worse) A is than B.

How should I go about this? My supervisor has led me to believe I can just subtract `QWK_B` from `QWK_A`, and that the resulting QWK delta will represent the gain (or loss) of A over B, but is that correct? And what about MSE or r? I’m pretty sure literally subtracting the metrics in those cases is not valid, in which case I don’t know how to compare them.

Any advice appreciated, TIA!",datascience
n53afv,1620176214.0,How to be more structured in formulating queries for SQL interviews?,"When I work on sql queries I usually start with a base query and edit as I go depending on the requirements, sometimes running the query and debugging. However, after being in a sql interview it seems like this approach doesn’t work the best for interviews as I frequently go down the wrong path before correcting myself, and especially not in situations where I can’t actually run intermediate queries.

What’s a good approach for working out a sql query in a structured way?",datascience
n52xsf,1620175177.0,What do you use to run jobs on a schedule?,"I have to run some computationally intensive jobs and I'm not sure what the best practices are.

Right now we manually run ec2 instances in the morning, but I'm looking to automate this.

We've looked into apache airflow, simple scripts, aws lambdas, kubernetes cron, and rundeck. Can you run jobs with spark?

Rundeck seems the most promising, what do you guys think?",datascience
n4xodw,1620160924.0,How do I gracefully exit an interview I am not qualified for?,"I applied for a Data Science job recently thinking I was ready. I've been a Data Analyst for a few years now.  I had an phone interview over the phone and the job is way, WAY over my head. I don't know Python much, just basic syntax and slight use of Pandas, yet they want me to be able to code there. I meet the SQL requirements for sure, however.

The recruiter over the phone did not sound confident when I told her I did not expect Python to be used so heavily per the job description. I also told her I am aware of a models that would be used in the role like linear regression, k mean clustering, etc, but I have never actually coded them. Still, she wanted me to progress to an in-person interview next week.

I really don't think I can do this job. Some of the things she mentioned I have never even heard of. I'd love to work for this company in the future, but I'd like to bow out of the interview gracefully for now. Tips?",datascience
n4to0o,1620148230.0,"To the senior people of this sub, how much reality is there on the app, ""Blind""?","Hi!

I recently joined Blind app to get some insights on an interview I had at one of the FAANGs.
I came across a lot of comments like ""Amazon is giving you $110k, are working as a janitor there?"". I understand many of those people are just doing a playful banter but there were serious posts like ""I'm depressed because I earn only 320k/year and my friends earn way more than me"".
My question is, are those people totally oblivious of the average salary or the fact that not everyone earns 6 figure salary?
I have just started working in the tech industry so I don't have that much experience, so I wanted to ask some of the senior people here that is a salary such 300-400K really possible in the tech industry and if it is what percentage of people do actually reach that level in life?

Thanks!",datascience
n4rmfw,1620143355.0,Product Sales + Marketing Data Reporting,"

Hi all,

I am the CMO of an ecommerce company and have a Shopify store. I have been working towards improving the way I go about presenting in our weekly advertising meetings. In the past I've listed out campaigns, the performance of key metrics, sales attributed from each platforms and then discussed budget based on the performance.

Recently, I have been trying to correlate our advertising campaigns with the percentage of sales related to specific advertising objectives. For instance, if we're spending 50% of our ad dollars promoting wedding products, what percentage of our products sold are wedding related?

This has been helpful but I want to take it a few steps further. I'd like to chart product sales week over week but I am struggling to figure out the best way to go about it. We have a handful of products which each have different designs / customization options. More specifically if one of our wedding products sold 30 times last week and only 12 times this week. I would like it to say the Product Name, the units sold, and then the percentage change from the previous week. The goal will be to use this data to monitor how certain products are selling and then make changes or not based on the data. For instance if a product is not selling and we think it could be due to visibility, we could test highlighting it on the homepage or other landing pages and see week over week if it preforms better. Does that make sense?

Does anyone have a better way that they track and analyze sales and marketing dollars?

*\* I also posted this in* [r/analytics](https://www.reddit.com/r/analytics/) *and someone suggested using ecommerce tracking in google analytics. I am just confused how to go about setting this up*",datascience
n4qh8b,1620140492.0,Would it be a better career choice for me to learn Python (with frameworks) for a Data Science job or the field is already overcrowded with so many Python programmers?,"Python is really an easy programming language and  a lot of people claim to know. So I am thinking about if it's a good investment of time and efforts to learn Python, or I should try Software Engineering with JVM. C, or some other CS field.",datascience
n4i0e9,1620111263.0,Inevitable Manual Work Required in Data Science Projects,"I have feeling that not many people are willing to admit - but ultimately, is a significant part of many data mining projects (e.g. checking data quality, parsing through data, etc.) still done manually?

For example here is an example I just made up relating to Supervised NLP (Natural Language Processing) Classification : Suppose I have 1000 medical reports of patients, containing unstructured text made by a doctor during a hospital visit. For a given patient, each report contains all the text notes that the doctor made for that patient, for visits between 2010 and 2020. These reports make mention of the patients bio data (e.g. age, gender, medical history, etc.) and the details of the symptoms that the patient is experiencing over a long period of time (e.g. let's say that these reports are 2000 words on average). The problem is, different doctors have different styles of writing - each of these 1000 reports is different from another. If a human were to read the report, the human could figure out what happened to the patient - did the patient have a serious condition (let's call this ""class 1"") or a non-serious condition (let's call this ""class 0""). This is what we are interested in predicting for future patients based on the limited medical notes made by doctors for these future patients.

The problem is - there is no clear and fast way (not that I know of) to take the 1000 medical reports that are available, and label each report as ""class 1"" or ""class 0"". For example, for ""class 0"" : one of the doctors could clearly write at the end of a report ""all medical tests were conducted and the results and were all negative"", and another doctor could end the report by saying ""the patient should seriously consider changing their lifestyle and eat healthier food. benign."" .

In this example, how would someone assign labels to all these 1000 cases, without manually reading them and deciding if the information in the report corresponds to a ""serious condition"" or a ""non-serious condition""? I was thinking of using something like ""sentiment analysis"" to capture the ""mood"" of these reports, and use sentiment analysis a method to informally gauge if the tone of the report is ""dark"" (serious condition) or ""light"" (non serious condition). But I am not sure if this is the best way to approach this problem. Is there a way to do this without reading all the reports and manually deciding labels?

In the end - this is what I am interested in doing : suppose a new patient comes in and on the first visit, the doctor makes some quick notes (e.g. patient is male, 30 years old, 180 cm, 100 kg, non-smoker, frequently complains of chest pains, no high blood pressure, works a construction worker and takes daily medicine for acid reflex). Just based on these quick notes and the 1000 reports available (NOTE: I am trying to illustrate a point here, that the medical notes for the new patient and the 1000 reports DO NOT have the same format), can a researcher predict (supervised classification, e.g. decision tree) if this patient will have a ""serious"" or a ""non-serious"" condition?

PS: suppose the doctors have a very detailed medical encyclopedia on their computers - can this medical encyclopedia be used alongside the 1000 medical reports to improve the prediction results?",datascience
n44nzl,1620069297.0,"Working in a bubble, how do I know how I'm *actually* doing?","I think some of us are either solo'ing a lot of DS efforts in our current roles/orgs. , or work with teams that may be inexperienced and rely on you as a ""subject matter expert"" for data science (analyzing / modelling structured data).

That's my situation at least....so how do I know how I'm doing?

* Comparing to kaggle is fine, but honestly most notebooks on kaggle are quite poor quality (and even the better ones are more CS focused than deep thorough analysis)
* My team is happy with my work, but that isn't saying much (they don't know better)

Appreciate some insight here, suggestions, etc.

Thanks!",datascience
n3wdn8,1620049370.0,The modern way to run notebooks on the cloud,"I have been working for a startup where we are a team of 5-6 data scientists. We regularly have to make decisions regarding our infrastructure requirements and the tools that we would use for our analysis/model building.

We have a powerful EC2 server where we run our computation and data-heavy analysis using Jupyter notebooks and python scripts.

However, this probably would not scale and we already have situations where the RAM runs out and we run code overnight to get some results.

Is there an obvious solution on the modern cloud ecosystem that would preclude the need to have a server and allow us to use compute power and RAM as and when we need it? Preferably within the AWS ecosystem.",datascience
n3v93k,1620046401.0,I'm a Senior Data Scientist at Disney and I'm hosting another Data Science Q&A session this Thursday @ 5:30 PM PST. I'll be joined by an Applied Scientist at Amazon!,"**DISCLAIMER**: This is completely free and not sponsored in any way. I really just enjoy helping students get started and potentially transition into Data Science

As the title mentions, I'm a Senior Data Scientist at Disney and I'm going to host **another** Data Science Q&A this Thursday at 5:30 PM PST. This time I'll have **Krishna Rao** join me. Susan is an Applied Scientist at **Amazon** and is responsible for building state-of-the-art advertising recommendation systems! Krishna has had a slightly unconventional path to get to this point. His background is in Civil Engineering and he was first a Data Science consultant before joining Amazon. I'm looking forward to having him share his journey and the tips he picked up along the way.

The last session was an absolute blast with over 250 people who attended from all over the world. I hope you see you all there!

Register Here:

[https://disney.zoom.us/webinar/register/WN\_RF0xeFZZTWqi8l7ZAN4KOg](https://disney.zoom.us/webinar/register/WN_RF0xeFZZTWqi8l7ZAN4KOg)

Verification:

My photo: [https://imgur.com/a/Wg3DMLV](https://imgur.com/a/Wg3DMLV)

My LinkedIn: [https://www.linkedin.com/in/madhavthaker/](https://www.linkedin.com/in/madhavthaker/) (feel free to connect)

Krishna’s LinkedIn: [https://www.linkedin.com/in/achyutuni-sri-krishna-rao-0721a015/](https://www.linkedin.com/in/achyutuni-sri-krishna-rao-0721a015/)",datascience
n3up4g,1620044792.0,I Quit! Stories,"I am ***happy*** to announce that today, I am quitting my current position of 3 years - I built my current team of DEs and DSs from the ground up, but I'm always the last priority in terms of pay and advancement, and on top of it, non-technical colleagues get all the credit for my work, so while they advance, I've been stuck for quite a while. Our leadership team is non-technical and yet, they dictate our development cycles (causing 36 hour work *days*), and to top it off, we have a terrible IT department that has built a horribly configured stack.

Every day can be a nightmare for some of us due to various factors. What's your story? Why did you take the job in the first place and when did it become too much?  Did the experience lead you to land your dream job or was the whole transition a total disaster?",datascience
n3n4hb,1620013397.0,Anyone here working for a non-profit?,"Or any organization that isn't obviously evil, I guess. Jokes aside, I would really appreciate if you could share what role you play in your org and if it's fulfilling work. This is the setting I'm determined to work in, and I need an idea of what roles are given to people with data science skills. TIA",datascience
n3mhga,1620011100.0,How do you organize your text datasets for NLP projects?,"Question in title.

Context: I’m looking to organize the text datasets that we have at where I work. Right now it’s a bit all over the place depending on the data source: BigQuery, PostgreSQL (there are reasons why we have two separate dbs but I won’t get into that), Google Sheets, csvs, etc. Besides of labeled datasets, we also have many dictionaries that we use to build simple rules.

The motivation is, each project usually has their own datasets but there have been a lot of cases where we can leverage other project’s datasets. Currently the only way is to ask the PIC of the project. It doesn’t seem to be very scalable now especially that we’re now having more NLP projects and more people working on them.

Right now, as a first step, I’m thinking to just maintain a list of queries for the ones in db and keep all the docs/csvs in one folder. Although ideally I’d love to have these datasets easily accessible much like TensorFlow/HuggingFace datasets (not sure if we have the bandwidth to build a GUI to explore the datasets though).

Have you faced a similar problem? I would like to hear any suggestions or your experience if any, as well as the challenges you encountered. Thanks a lot!",datascience
n3ew7z,1619986468.0,"In DS field is it possible to get a remote job, working from another country?","I'd like to know how often do companies look for players from another country, if any of you were able to achieve this, considering that earning in dollar would be incredibly benefitial for me, even on a JR analyst position.",datascience
n3ca4c,1619979239.0,I’m a PM a and need data science advice.,"Lead Product Manager here who recently joined a new company. I have about ten years of experience but this is the first time I’m working on a heavy data science product with a junior data science team 😔

I am new to the org. and on my second day the lead of the data science team put in his two weeks but didn’t stick around to provide institutional knowledge or any time for me to understand what’s been going on. The data science is a small team of 4 and they are very very junior.

With that said, I’m really trying to get them involved in our daily meetings so they can understand the vision and product we are building so ultimately be a individual contributor and ultimately

- point out where data science work is needed. The problem is they don’t say a word...

It’s been 8 weeks and the data science really does not give any input at all - not even on our designs which is super important and When asked to give feedback they stall and take it off line but I really think they just don’t have proper leadership.

I just can’t get them to give any Input so I am not able to understand Backend implications and such. I imagine at a certain point the data science team will have to build “something” to power BE efforts for example, but if they don’t tell me that up front when discussing designs or requirements ...I can’t plan or gather solid data science requirements which is nuts.

What can I do to get more data science input to fuel our mission. 80 percent of requirements have a data science implication from what I see and I need the data science team to step up more. What can I do to make sure we have proper data science requirements?

How can I set up a successful data science strategy?",datascience
n3btyo,1619977949.0,Normalizing & Merging two different data signals,"Hi All,

I am analyzing our companies transaction data & visits data , we have lot of user actions before making a transaction . I am trying to segment the user base on the activity signals they are generating ,but was confused on how to merge multiple data signals distribution.

For example :

I have user performing actions such as

 View an Item

List an item

Buy an Item

Since all of these activities have their own distributions , I was thinking to normalize each of them for a user last 12 months activity ,  but was not sure if it would make sense to sum up these individual normalized signals in some way so that I have just one score against which I can benchmark users current activity.

Like if I see that the user has X value (combined score across all actions) in last 12 months , and this month he has X- 12% , I can estimate that he is decreasing so on so forth",datascience
n3ba0g,1619976322.0,Covid-19 India related ask,"Hello everyone,A number of volunteers (product, software, management backgrounds) are trying to build a model to predict how Oxygen demand will shape. When supplies improve, they wish to be able to help agencies distribute to the correct places, logistics issue as you might imagine. There is a model they are trying to build but too many unknown variables/uncertainties.

Do we have folks in **data science** who can help? Even if you can add a little it helps a lot. If you know folks with relevant **forecasting/demand prediction** experience it could be immensely valuable. We can share whatever data points we have. But most people in this sub probably already know what this entails.

Thank you so much,


**Update**:

I am so sorry that I am adding this  late. Here is what I can say the intro document: https://docs.google.com/document/d/1HQDeIlTzl3UrtntNncQVunZNQRU6DXLV4T2UA76Np_w/edit#

Here are the issues on GH for what is becoming the large volunteer alliance, one DB: https://github.com/gantir/covid19alliance-masterdata/issues

All volunteer discussions take place in Slack: https://slack.raksha.life, main channel for this is #coronasafe-demand-prediction

I will respond to each of you through DM.",datascience
n363uv,1619961055.0,Anyone play around with subreddit data?,"I usually just use the site to talk about stuff I do on my free-time, but subs like unpopularopinion have me thinking that it would fun to tinker around and compile some dataframes. Noticed some examples on dataisbeautiful and datart.

If you have used Reddit itself for making models, what models did you make and how did you go about data cleansing?",datascience
n34zv0,1619956830.0,Weekly Entering & Transitioning Thread | 02 May 2021 - 09 May 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
n3339v,1619948768.0,How can someone measure/quantify friction faced by visitors on a website while performing a transaction/action,"This transaction could be anything depending on a website like in my case(financial website) it could range from opening a bank account/ linking an account,etc etc.
Also the problem with using common metrics bounce rate,exit rate is that it completely disregard the intention of the visitors, maybe the person is just there for explorative purpose and if he doesn't perform an action that not necessarily means it's a friction point given the intention",datascience
n2je24,1619879224.0,Is it a waste to not go into data science after getting my MS?,"I'm on track to graduate with a MS in Statistics in a few months time. I have no prior working experience (only software and data engineering internships) and my bachelors was in engineering (Industrial Engineering with Computer Science minor).

I tried applying to data science jobs but not much luck so far. Most of my interview callbacks are from engineering positions. I honestly do not mind being an engineer. However, does it mean that I would be wasting my MS?

Ps I currently have an offer as an engineer in Cyber Security. Just would like to know the general feedback for a graduate with no work experience. Thanks for reading.",datascience
n2gqwb,1619869482.0,What GitHub template do you guys follow?,"Hi All,

I have to set up a GitHub repo for an upcoming project and was researching some data science templates to follow. I came across cookie cutter and this template by drivendata: [https://github.com/drivendata/cookiecutter-data-science](https://github.com/drivendata/cookiecutter-data-science)

&#x200B;

It looks pretty comprehensive, but I feel I might not need a lot of it, like my data would be pulled straight from a db and not from a dump and neither it would be stored somewhere so the need for data folder is not there.

I would be developing a modelling pipeline and would not be saving the serialised model files, so no need of model folder as well. I think you guys know where I am going here.

So, I just felt like I will get to know what the community is following?

Thanks.",datascience
n2ftwx,1619865514.0,Is there software that can build a 'model' of disease research findings with what's normal/abnormal?,"This might be the wrong sub, so please direct me to the correct one if it is, but:

Is there software that can create a model for research findings for a disease? Preferably free/cheap.

Wishlist:

- Organized per subtopic (immune system / metabolome / genetic etc).
- You can mark if something was found normal/abnormal with color, with more than 1 option per thing because some research is contradicting (researcher A found thing X was higher than normal but researcher B found it was lower), with a link to the pubmed article, and maybe a field for a pop-up with notes when you click on it
- Click a button and only show the abnormal results (fade out the rest)
- searchable?

Something like this maybe

https://imgur.com/mytOuJW

where you can create a giant visual mindmap web of research results and zoom in on the different areas.

What do medical researchers use for this anyway? Is there some kind of central model/database per disease or is everyone starting from scratch with their own research area?",datascience
n240bf,1619818474.0,What's your approach to developing/iterating on models when you have enormous amount of data?,"If you have billions of rows of data sitting on a cluster, and you need to develop a model that will then be used to make billions of predictions. And it's intractable to develop your model (i.e., run experiments, tune hyperparameters, compare models) on all data, because it's too expensive. How would you approach developing a model?

I'm curious if people have principled ways of approaching these kinds of settings. Mine would be:

* Take a stratified random sample of the data. The stratification should respect the distribution of target labels, and any features you consider important. The sample should be small enough so that you can feasibly tune the hyperparameters of models you consider and use cross-validation rather than simple train-test splits.
* Once you've gone through iterations of feature engineering/model comparison/analysis, and identified your best/candidate model. Re-train on a larger dataset to plot the learning curve and see how important additional data is.
* Depending on how much your model benefits from additional data, re-train on as large a dataset as possible and use that model in production.

In terms of tools/libraries, I'd imagine the stratified sampling would be done using Spark. The model development with libraries like scikit-learn and PyTorch.

I realize there are ML frameworks, such as SparkML, that allow you train models on Spark, but I feel like they aren't nearly fleshed out enough to support the iterative workflow described above. However, since these libraries are a lot more efficient, you could train on a lot more data. Thoughts on the tradeoff between more iterations on smaller data vs. fewer iterations on more data?

And for inferencing (making predictions), I assume there are ways to deploy scikit-learn/PyTorch models in a Spark environment.",datascience
n22njp,1619814480.0,I’m struggling with data structures and algorithms,"Hello all I’m currently a rising junior, majoring in statistics. My goal is to become a “data scientist”. Prior to being a statistics Major I was a data analytics major, and took two courses of software development, one of which focused on data structures and algorithms.

I switched majors because I wanted to learn more of the math, and I just genuinely liked statistics and wasn’t all into the systems design courses later on in the major.

Long story short, my naive young self a few months ago kept thinking that as a stats major I could get away with working with machine learning algorithms and big data with a masters degree in statistics, and that I would never face data structures and algorithms again. After reading this sub I came across several people who mentioned it’s important and I should learn it because I need a software side and they ask in interviews.

I am now spending my summer trying to get good at them for interviews, but man... am I struggling. I’m sitting here learning linkedlists, being asked to implement a function for like getting the position of an element or deleting an element and my mind goes blank. I don’t know where to start. Not to mention I can’t even do leetcode easy. I’m just really frustrated because I can wrangle data, make dashboards, know when to use specific models and have an understanding of statistical learning, but it is this leetcode data structures and algorithms that is holding me back.

I don’t know how to learn this stuff other than mindlessly memorize leetcode problems. Any suggestions?",datascience
n21tiw,1619812058.0,"[D] how many layers/neurons are required for a neural network to be considered as ""deep""?","I know this might sound like a silly question: but when people use the term ""deep"" neural networks - is there a minimum number of layers/neurons required for a neural network to be called ""deep""?",datascience
n20bu5,1619807767.0,How hard is powerBI to learn coming from plotly / dash?,"So I’m looking at this job and they mention wanting tableau or powerBI (Prefer powerBI) so I feel like that’s the big one. How long would it take to pick up enough power BI to feel comfortable listing it in on a resume? Tableau took all of a few hours to pick up the basics and I’ve heard powerBI is even easier
Edit - Should probably mention I’m a DS with 6 years xp",datascience
n1xvpz,1619801004.0,"Am I an idiot, or is there some lingo I wasn't taught in school?","I had an interview for a DS position last week and the interviewer asked me a couple of questions that threw me for a loop. First, he asked me to compare a *rectilinear decision tree* to a random forest, and second, he asked me about *scale-free distributions*. My guess is that he wanted me to speak of the advantages of using an ensemble of trees (along with randomly selected features and bagging) over a single tree. As for the distribution question, no clue and I can't find anything on Google.

&#x200B;

Any thoughts?",datascience
n1wwyo,1619798349.0,"JIRA roadmap, backlog?","Anyone else has to pedantically update jira tickets for every task (subtask) with story point estimates?

I'm having trouble communicating the fact that even i don't know how much time an analysis for a client might take. It's not a developer journey where i know where the insight/function i have to write pre hand. i don't know where the insight might lie. I can't give you an estimate that's accurate to the hour. Or am i being naive here? ",datascience
n1wnp6,1619797601.0,Disillusioned with the field of data science,"I’ve been in my first data science opportunity for almost a year now and I’m starting to question if I made a mistake entering this field.

My job is all politics. I’m pulled every which way. I’m constantly interrupted whenever I try to share any ideas. My work is often tossed out. And if I have a good idea, it’s ignored until someone else presents the same idea, then everyone loves it. I’m constantly asked by non-technical people to do things that are incorrect, and when I try to speak up, I’m ignored and my manager doesn’t defend me either. I was promised technical work but I’m stuck working out of excel and PowerPoint while I desperately try to maintain my coding and modeling skills outside of work.

I’m a woman of color working in a conservative field. I’m exhausted. Is this normal? Do I need to find another field? Are there companies/ types of companies that you recommend I look into that aren’t like this? This isn’t what I thought data science would be.

EDIT: Thank you for the responses everyone! I’ve reached out to some of you privately and will try to respond to everyone else. Based on the comments and some of the suggestions (which were helpful, but already tried), I think it’s time to plan an exit strategy. Being in this environment has led to burnout and mental/physical health is more important than a job.

To those of you suggesting this as an opportunity to develop soft skills or work on my excel/ppt skills, that’s actually exactly how I pitched it to myself when I first started this role and realized it wouldn’t be as technical as I’d like. But being in an environment like this has actually been detrimental to my soft skills. I’ve lost all confidence in my ability to speak in front of others. And my deck designs are constantly tossed out even after spending hours trying to make them as nice as possible. To anyone else reading this that is experiencing this, you deserve better. You do not have to put up with this in the name of resilience. At a certain point, you are just ramming yourself into a wall over and over again. Others in my organization were getting to work on data science work, so it wasn’t a bait and switch for everyone. Just some of us (coincidentally, all women).

I’m not going to leave DS yet. I worked too hard to develop these skills to just let them go to waste. But I think an industry change is due.",datascience
n1c3gr,1619724451.0,Platform to create a data science blog,"As part of a few courses I've been creating tutorials on the class forums, which are hosted using using a platfrom called [Ed](https://edstem.org/us/). Ed has the ability to write in LaTeX natively using a built in WYSIWYG editor, or just writing out the LaTeX code between $dollar signs$. It doesn't seem to support markdown, but I would be fine with markdown support.

I'd like to begin transferring my content to my own site, and was wondering if anyone has any recommendations.

So far I've seen some excellent blogs hosted on Ghost and using Jekyll and am considering those two. I'm not interested in Medium due to it's pay model and requirement that people either subscribe or use incognito mode to view it. Wordpress is another option, but I've used it before and it's just a little too bloated.

Any thoughts? Anyone run their own site and can recommend any platform? Many thanks in advance!",datascience
n1ampx,1619720476.0,In which cases Random Forest Algorithm requires Cross-Validation?,"I'm modeling with Random Forest algorithm medium size data set, but I didn't get any difference using CV roc\_auc\_score. I don't know if I'm just spending time doing CV, then could someone explain which cases it's good to do it for rfc.",datascience
n182tu,1619713446.0,is it common to use the ZIP code as a predictor variable in statistical models?,"Suppose you want to make a model that predicts if a student will drop out of university- you have historical information about many students and whether they dropped out or not. You also have access to the ZIP code (postal code) where they lived.

1) Is it common to actually the zip code as an input variable (probably not, since there are too many categories)? Or, maybe use the first 3 numbers of the zip code as an input variable?

2) I was always told to avoid using a predictor variable that has too many categories. Is there a mathematical reason behind this? From a mathematical standpoint: if your data has 1000 rows and one of your predictor has 450 categories - mathematically speaking, why might this harm your statistical model? I can understand it intuitively - having too many categories means too much information and your model might get ""confused"" - but is there a mathematical explanation?

Note: I know you can just take students from different cities and make a sepperate model for students in the same city - but I am not interested in doing this.

CLARIFICATION: I am using zip as a CATEGORICAL variable!",datascience
n17etb,1619711664.0,How to encoding NaN values with meaning.,"The two most common cases I've seen NaN values appear in datasets are either because the data was simply not collected and/or is just missing for no meaningful reason, OR that a ""response"" is not applicable to a feature due to the nature of that specific data point.

As an example:

|ID|HAS ARTHRITIS|ARTHRITIS LIMITS ABILITY TO WORK|
|:-|:-|:-|
|1|yes|yes|
|2|yes|no|
|3|yes|NaN|
|4|no|NaN|

In the table above the values are missing in rows 3 and 4 for different reasons.  Seemingly the value in row 3 Is missing because most likely the data was not collected. However, in row 4, the missing value is due to the feature not being relevant (I.e. we do not need to ask if a patient's arthritis limits their ability to work if they do not have arthritis).

It would thus seem that in order to make the most accurate model we should not treat these two cases the same.

What are some methods for dealing with these types of situations?",datascience
n15d9y,1619705972.0,Which topics from Calculus do you use regularly in your work?,"I’m curious which big concepts from Calculus do Data Scientists  need to know and use regularly?

Do you use any of these concepts often? Things like integrals? Polar Coordinates? Single variable calculus or multi variable calculus? Fundamental theorem of line integrals?

What concepts from calculus is used heavily in data science work?

Thanks for your time!",datascience
n10o03,1619688353.0,Thank you r/datascience & r/dataisbeautiful - you guys helped me get my dream job! ❤️,"Context: I used to love working with technology. When I was younger I did computer science at school, worked at Apple at 17 & had work experience at Toshiba Research Europe. Everything was going great until I got my GCSE grades back and realised my coursework was terrible. It wasn’t my fault but rather the teacher had taught us the complete wrong thing to do and only 1 person managed to pass. He was fired but when it came to A Levels I didn’t end up picking computer science. As much as I wanted to, I was anxiety riddled as a teenager and I didn’t believe in myself to do it. I ended up going to university, dropping out because of severe depression & going into bookkeeping. Then lockdown happened. I had so much free time that I ended up doing programming for fun & I got Reddit to try and find fixes to syntax errors when I’m programming but Reddit recommended me this subreddit & data is beautiful and I would check it everyday just because I found it interesting & it was the perfect blend between number crunching and technology - leading me to learn Python & get better with excel.

Fast forward to a few days ago and I manage to get an interview with an amazing employer to work as a Junior Data Analyst. I was really worried because I didn’t know who or what the competition was but I did my best & I mentioned that I followed these pages on Reddit. Turns out they only interviewed one other person and I had the edge as I used Reddit & taught myself in my spare time showing huge enthusiasm! Thank you to everyone on this page you are all legends!!!!!!!! ❤️❤️❤️




TLDR; I fucked up computer science when I was a teen even though I loved it so much. Taught myself over lockdown and got a job partly because I read these subreddits in my spare time",datascience
n0xn9o,1619674254.0,"Odd question, but will a tattoo hurt my chances of being hired in this field?","Currently studying for a BS in data science, and I'd like to get some tattoos but I don't want to hurt my chances of success. I assume something easily visible like a hand tattoo would be a bad idea, but what about something like a forearm or ankle?

Sorry I know this is a ridiculous question, I just don't have any experience in an office environment haha",datascience
n0wlj5,1619669785.0,Any advice on how best to parse ~1TB of Excel files with horrific formatting?,"I got lucky enough to stumble in to an analyst role at my job and have recently been handed a huge archive of documents that have been collecting 'dust' for the last couple of years. I have been tasked with ""Seeing if there is anything worth finding"" in this beast because apparently someone up the food chain recently read a McKinsey article on strategic analysis.  ¯\_༼ ಥ ‿ ಥ ༽_/¯

Up until now I have been lucky enough to only mess with curated data and, on my worst days, a folder of Excel docs full of simple transactional data.
This dataset is altogether terrifying. Each files contains a single sheet but is structured almost like a comic book; by which I mean whoever put the intial 'template' together was clearly never intending it to be parsed by anything other than a human. (Varying field names, merged cells, no ACTUAL tables, imported pictures,  clip art, check boxes, and other odd bits and bobs that I don't understand existing in Excel).

I prostrate myself before you actual data scientists with a simple query; where the hell do I start? Do I try to programatically convert them to CSV? JSON? Is this legit ML territory that I have no business touching? I am at such a loss that even suggested search terms for me to start researching what to do next would be a huge help.",datascience
n0vmnm,1619666127.0,What is data philosophically speaking?,Is it interesting to study onto itself like particles in article physics or computation?,datascience
n0oz21,1619644419.0,Little Analyst in a Big Data Pond,"Hey folks. I’ve been working as a sales data analyst for the past two years. Just kind of worked my way into this role, despite the fact that my education is in the soft sciences (as in some light STATA use).

The problem is that now I’m the CRM admin. And we’re about to go from a company of 500 people to 5000 people, thanks to a dozen or more acquisitions coming up. I look at our infrastructure and all I see is a looming train wreck. Most of these companies keep their sales data on excel files in a shared drive. Some have Salesforce (my current company does not).

My goal is to best prepare myself and my company for these small, but numerous data integrations. I want to keep things organized and have a clear input/output system for all data sources. And then of course I need a way to easily access all of these to compile company-wide KPI reports. Reading the wiki, I think this counts as “data science” and I think I should start with learning R. Anything else to add?",datascience
n0o5is,1619642102.0,"Standard approaches for ""binning"" data","Suppose you have a dataset where some of the predictor variables are categorical and have hundreds of possible (discrete) values. Are there any common ways to ""bin"" all these values into general groups?

E.g. suppose one of the variables is : 50% ""A"", 25% ""B"" , 20% ""C"", 0.5% D, 0.5% E, 0.5% F ....etc.

Could you reformat this variable as A, B, C, OTHER ?

Is this a common technique? Is this acceptable? Some statistical computing software can not always handle so many categories, other times perhaps it is advantageous to ""bin"" many low frequency entries together to facilitate statistical modelling?

thanks",datascience
n0gzf8,1619622691.0,Best ETL processes/tools?,"Hi data people! Hopefully this sub is the appropriate place to post this, I posted to r/dataanalysis and r/dataengineering, but since this sub has about 10x the members of either of those, it would get a lot more attention and feedback I thought.

Our company has been acquiring new companies at an increased rate lately, and - where possible and realistic - we're looking to streamline and combine our data streams and ETL process so that our team can be the central data go-to team for reporting.

As a part of this process, we're looking at potential new ETL processes we could adopt, and I'd love some suggestions from other people in the field.

Currently, we use Visual Studio to manage .dtsx packages where we do the majority of the ETL work. These packages kick off various stored procedures in our SQL servers to load/combine/aggregate data wherever needed.

What systems or tools do you all use in your work environments, and do you have any suggestions on good processes I could look into? Thanks in advance!",datascience
n0gqgz,1619622033.0,"How do you plan, estimate, and communicate Data Science projects?","I'm currently working on all Deep Learning based projects, and tasks involve reading a fair bit of research papers then implementing them, experimenting, etc. However, I'm struggling to estimate the timelines, especially for research-oriented tasks, and communicate them effectively to the management.

Any advice on planning projects better? Do sprint cycles work for DS projects, if not, what works?

Are there any Data Science related design documents, etc that are publicly available which goes into more details into the planning of tasks?",datascience
n0bpyg,1619605320.0,Labeling whether or not a vest has been shot with an airsoft BB using ML,"Hello mates. I've been thinking for a while on how to approach this. Let me give you some context before anything else:
I have an array of piezoelectric sensors inside a vest that will signal analog values to a embd system every interval, lets call it 't'. This sensors will throw data when they are hitted by a BB, when a player crouches, whenever he pick ups something(basically whenever they receive a force).... The value of the analog signal will be as big as the force applied.

My toughts so far are on recording as much data as I can of different scenarios, label it whether the vest was hitted by a BB or not and fit it in an algorithm.

 All I could think about is to use a basic NN and feed it with lets say t, t-1..., t-5 iterations and see how well it does.

Any thoughts, ideas, criticism... Everything is welcome. Thanks in regards.

Edit: just to make sure everyone is on the same page. Remember that the controller will be receiving dats from multiple sensors.",datascience
n04ga6,1619575649.0,Physics PhD transitioning to data science: any advices?,"Hello,

I will soon get my PhD in Physics. Being a little underwhelmed by academia and physics I am thinking about making the transition to data-related fields (which seem really awesome and is also the only hiring market for scientists where I live).

My main issue is that my CV is hard to sell to the data world. I've got a paper on ML, been doing data analysis for almost all my PhD, and got decent analytics in Python etc. But I can't say my skills are at production level. The market also seems to have evolved rapidly: jobs qualifications are extremely tight, requiring advanced database management, data piping etc.

During my entire education I've been sold the idea that everybody hires physicists because they can learn anything pretty fast. Companies were supposed to hire and train us apparently. From what I understand now, this might not be the case as companies now have plethora of proper computer scientists at their disposal.

I still have \~1 year of funding left after my graduation, which I intend to ""use"" to search for a job and acquire the skills needed to enter the field. I was wondering if anyone had done this transition in the recent years ? What are the main things I should consider learning first ? From what I understand, git version control, SQL/noSQL are a must, is there anything else that comes to your mind ? How about ""soft"" skills ? How did you fit in with actual data engineers and analysts ?

I'm really looking for any information that comes to your mind and things you wished you knew beforehand.

Thanks!",datascience
mzvicb,1619549110.0,TIL random forest randomness,"TIL that changing the order of features when calling the fit method of sklearn random forest regressor  can lead to a different model, even if the seed and random\_state is the same.

For ex:

1. Function call 1: RandomForestRegressor(random\_state=42).fit(dataframe1\[\[feat1,feat2,feat3\]\])
2. Function call 2: RandomForestRegressor(random\_state=42).fit(dataframe1\[\[feat3,feat2,feat1\]\])

The models you will get from the above two functions will be different! This could be down to the random nature of the algorithm and how it indexes features and considers them for making splits.

I spent an entire day trying to figure out as to why were my experiments not repeatable even when I set the random\_state and numpy seed at the top of the notebook, and at the end of the day it was this small thing.",datascience
mztf8j,1619543671.0,Does anyone mind sharing their professional githubs? Or passing along some ideas on how to build one's out?,Hello! I'm still learning about this field and trying to figure out how best to build out my skills as well as create a professional presence. My personal git has a handful of repos but nothing too exciting so I was looking to see how other people build theirs,datascience
mzqqee,1619536584.0,Why is php nowhere to be found when talking about data science?,"I started intensively learning php a couple months back but still can't figure out why no one wants to use it for complex systems, everything seems to line up, it's decently fast, scalable with a good framework, very easy to mantain and develop in, yet its popularity is steadily decreasing, especially in complex areas like data science",datascience
mzqobo,1619536418.0,How much data should you use in a model?,"This is a concept i always struggled with: in statistics, is ""more data always better""?

Suppose you 50 years of data about hospital visits. You are interested in supervised classification. You have predictors such as age, height, weight, blood type, salary, etc. You are interested in predicting if the hospital stay will be less than 1 day or more than 1 day. This can be easily solved using random forest.

My dilemma is: using all 50 years of data might be able to capture a wide variety of patterns  ... but since we are interested in predicting future information, maybe some of the older data is less relevant and might surpress more current trends?

How do you deal with this problem?",datascience
mzk16l,1619513324.0,Question Answering AI," Hey people,

I'm working on my personal project which will be quite a challenge. One of its features is that the user can interact with an ""Open-domain question answering"" chatbot which will be trained on the data I provide it.

I want the model to resemble a specific person/group and it will be fed everything that that person/group wrote, said and etc. Have in mind that the model can answer questions in 1-4 sentences and it doesn't need to be based on pure facts. This means that the user won't ask the model questions like ""What is the capital of France?"" but more something along the lines of existential questions (""What is the meaning of <thing>?"").

Here are the questions I have as I didn't dabble into the NLP world of AI at all:

1. Are there any pre-trained or prebuilt models out there that I could use for this? I've found that the open-source Pavlov AI library has some interesting ones.
2. Which models would suit this task the best?
3. Are there any features I should watch out for or provide more information on?

The biggest part of the job will be to collect relevant data on the group I want the model to resemble. What would be some of the best practices when making the data as informative as it can be? Also, if I want there to be 4 groups that the model can resemble - Do I need to train 4 models or can I filter what a model learned into 4 categories?

Thanks for all replies and questions in advance. If some of you are interested more in the project feel free to send a dm and we could even collaborate on this part of the project to make the model great.",datascience
mz3s2z,1619460103.0,Why was my career question on the data science industry removed?,"Hi, I posted over the weekend in r/datascience about how someone might navigate the data science field without masters or a PhD. Within 15 minutes my question was removed, and I’m hoping someone can help me understand why this happened? Thanks,",datascience
myurtx,1619433632.0,The Journey Of Problem Solving Using Analytics,"In my \~6 years of working in the analytics domain, for most of the Fortune 10 clients, across geographies, one thing I've realized is while people may solve business problems using analytics, the journey is lost somewhere. At the risk of sounding cliche, ***'Enjoy the journey, not the destination"".*** So here's my attempt at creating the problem-solving journey from what I've experienced/learned/failed at.

The framework for problem-solving using analytics is a 3 step process. On we go:

1. **Break the business problem into an analytical problem**
Let's start this with another cliche - *"" If I had an hour to solve a problem I'd spend 55 minutes thinking about the problem and 5 minutes thinking about solutions"".* This is where a lot of analysts/consultants fail. As soon as a business problem falls into their ears, they straightaway get down to solution-ing, without even a bare attempt at understanding the problem at hand. To tackle this, I (and my team) follow what we call the **CS-FS framework** (extra marks to those who can come up with a better naming).
The CS-FS framework stands for the Current State - Future State framework.In the CS-FS framework, the first step is to identify the **Current State** of the client, where they're at currently with the problem, followed by the next step, which is to identify the **Desired Future State**, where they want to be after the solution is provided - the insights, the behaviors driven by the insight and finally the outcome driven by the behavior.
The final, and the most important step of the CS-FS framework is **to identify the gap**, that prevents the client from moving from the Current State to the Desired Future State. This becomes your Analytical Problem, and thus the input for the next step
2. **Find the Analytical Solution to the Analytical Problem**
Now that you have the business problem converted to an analytical problem, let's look at the data, shall we? \*\*A BIG NO!\*\*
We will start forming hypotheses around the problem, **WITHOUT BEING BIASED BY THE DATA.** I can't stress this point enough. The process of forming hypotheses should be independent of what data you have available. The correct method to this is after forming all possible hypotheses, you should be looking at the available data, and eliminating those hypotheses for which you don't have data.
After the hypotheses are formed, you start looking at the data, and then the usual analytical solution follows - understand the data, do some EDA, test for hypotheses, do some ML (if the problem requires it), and yada yada yada. This is the part which most analysts are good at. For example - if the problem revolves around customer churn, this is the step where you'll go ahead with your classification modeling.Let me remind you, the output for this step is just an analytical solution - a classification model for your customer churn problem.
Most of the time, the people for whom you're solving the problem would not be technically gifted, so they won't understand the Confusion Matrix output of a classification model or the output of an AUC ROC curve. They want you to talk in a language they understand. This is where we take the final road in our journey of problem-solving - the final step
3. **Convert the Analytical Solution to a Business Solution**
An analytical solution is for computers, a business solution is for humans. And more or less, you'll be dealing with humans who want to understand what your many weeks' worth of effort has produced. You may have just created the most efficient and accurate ML model the world has ever seen, but if the final stakeholder is unable to interpret its meaning, then the whole exercise was useless.
This is where you will use all your story-boarding experience to actually tell them a story that would start from the current state of their problem to the steps you have taken for them to reach the desired future state. This is where visualization skills, dashboard creation, insight generation, creation of decks come into the picture. Again, when you create dashboards or reports, keep in mind that you're telling a story, and not just laying down a beautiful colored chart on a Power BI or a Tableau dashboard. Each chart, each number on a report should be action-oriented, and part of a larger story.
Only when someone understands your story, are they most likely going to purchase another book from you. Only when you make the journey beautiful and meaningful for your fellow passengers and stakeholders, will they travel with you again.

With that said, I've reached my destination. I hope you all do too. I'm totally open to criticism/suggestions/improvements that I can make to this journey. Looking forward to inputs from the community!",datascience
myn5sa,1619402662.0,How to pronounce SQL?,"I transitioned into data science from the life sciences in the past 3 yrs and I’m wondering how I can pronounce SQL so I don’t sound like a total novice.

I have heard the developers in my company say it like ‘ES QUE EL’ but the data science/stat folk mostly say ‘SEQUEL’

Which is the correct one??",datascience
mylony,1619397481.0,Data Science Tattoos,Rediculous topic but my friend who is also a data scientist got a neural network tattooed on him and it got me wondering if anybody else had data science/ machine learning tattoos or ideas!,datascience
mylh4e,1619396772.0,Is there diversity in Machine Learning Engineer backgrounds like there is with DS?,"I’m a statistics student in school, and my goal is to become a “data scientist”, in quotations because that can mean many different things. Anyways, I’ve heard that data scientists tend to have very diverse backgrounds depending on the industry, ie. Statistics/computer science/Math/civil engineering (or some other engineering) / physics ie. List goes on and on.
Even saw someone who was a geospatial data scientist with a background in something GIS related.
Point is it seems like the “data scientist” has very diverse backgrounds for the role.

However, for something like “machine learning engineer”, is this as diverse? I mean yea there is some machine learning involved, so some statistics, but 90% I’ve heard is SWE related, so most of the backgrounds are generally computer science? Am I right in saying that? For people who are non computer science, is there a higher barrier to entry to become a MLE than it is to be a data scientist? Can non-Cs backgrounds still be considered for MLE positions?",datascience
my6w3q,1619352030.0,Weekly Entering & Transitioning Thread | 25 Apr 2021 - 02 May 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
mxy6bp,1619315290.0,[D] how accurate were the statistical models you developed on real-world data?,"When it comes to real-world data, how accurate were the statistical models you developed? Were these models able to consistently and accurately make predictions?

E.g. for supervised binary classification, has anyone been able to develop a model that had high accuracy, high sensitivity and high specificity?",datascience
mxvzwl,1619307779.0,Do you think there is a stigma against (US) government employees trying to get data science jobs in the private sector?,"I work for the government as a data scientist, as my first (and so far only) post-masters job. I like my job, but I don't like where I have to live to do my job at my specific branch of the government (and there is no chance of this kind of work being done remotely from my preferred living location). I may change my mind over time, but I think maybe in two or three years when I have more on my resume, I may go back to the private sector (preferably a big and more stable company, not a startup) so I will be able to go back to where I'm from (which is NYC and there is a lot of tech and DS there so that shouldn't be a problem). However I do hear a fair amount of chatter amongst DS people both inside and outside the government that there is somewhat of a stigma against government employees amongst big tech corps when looking to hire programmers & DS, primarily for two reasons: 1, that gov employees get too used to working exactly 40 hours/week less willing to put up with being pressured/forced to do unpaid overtime frequently, and 2, that gov handles DS and SWE very differently than FAANG/etc and that the skill set is too different. I don't know about #2, but I think #1 maybe be true, because I know a couple of people (SWE and DS mostly) who left, went private, and came back because they discovered that they cared more about reasonable workloads and good PTO than making 30-50% more money & getting bonuses. And honestly, I may too,  but for me it's primarily the location.

I realize the answer is probably ""it really depends on the company and it really depends what part of the government"", but any general takes on this?",datascience
mxuojo,1619303552.0,Applied Mathematical Methods: Are they useful?,"I am in a graduate level program Social Sciences program and leaning towards data analyst / data science fields when I am finished. I am currently evaluating a course I would like to take on Applied Mathematical Methods. This particular course is taught in the economics college, but the methods should be applicable in a broader socioeconomic context. Here are the mathematical methods listed:

Matrix algebra, differentiation, unconstrained and constrained optimization, integration and linear programming.

My question: how much math do you use in your daily? Would knowing any of these concepts bolster your skills? If not, what mathematical methods would take your game to the next level in a data science role?",datascience
mx245j,1619203370.0,How to do Daily Check Up?,"I want to start sending a list of tasks for the day to my manager in the morning, and at the end of the day give a status update on all the tasks.

Is there a good way to do this other than sending out emails?

Mainly want to keep myself accountable in the WFH situation. We don't do daily standup meetings so I've found myself slacking more and more.",datascience
mx20vs,1619203121.0,[D] How to extend a text classification ML model to work with more than one language?,"We are using (in production) an ML for text classification. We trained our model using some custom English text corpus. Currently, the model is working acceptable level of accuracy for our purpose. Now we want to extend it to handle French language as well. We are planning to investigate the following two approaches.

1. We have a French-language corpus. Therefore, we would like to train a new model for handling French text.
2. Use the same model trained with English corpus. But use a third-party language translation service (such as Google Translator) to translate French text to English before inputting it into the ML model.

So I would like to know your thoughts regarding these two approaches.",datascience
mwxyac,1619192072.0,Surprise 45 minute technical assessment in late-stage interview with several of company's team members,"I'm in the process of interviewing for a Data Scientist role. I had taken a two hour Python/SQL technical evaluation and passed it. One week later, I'm in a late-stage 90 minute interview with several team members. With 45 minutes left, they suddenly had me do a screen share with everyone and bombarded me with SQL/Python questions. This effectively left no time for me to ask questions I had for the team. It was stressful, and in no way reflects a typical coding environment (that I've been in).

I didn't botch the surprise technical assessment, but didn't ace it either. Certainly wasn't an environment to do my best work. I'll be honest, it was a huge turn-off.

I know data science is technical oriented, but I felt that I had little opportunity to absorb/ask about team and company culture.

Bit of a rant, but also curious if anyone else has experienced this, and what your experience was like?",datascience
mwwulj,1619189077.0,DS to Find Kids Who Read Good,"I work at a network of charter schools. We have 50 schools, thousands of kids, and to keep it simple, let's call it 4 main reading tests per year, plus the typical, everyday grades kids get on reading assignments. How do we aggregate all this info to get to one measure of a child's reading ability?

In my mind, we could standardize the scores, then weigh them based on what we feel are the most valuable assessments and output one measure, a ""Reading KPI"". But is there a way to mathematically calculate these weights? Or just rely on SMEs to guide us?

Would a regression model help us isolate the features (in this case assessments) that are most important to predicting their Reading KPI?

Can we use ML to predict their score on an upcoming test, and take action if they are +1 SD below it?

Should this metric consider the child's progress over time, or only compare their performance against their peers?",datascience
mwvk2p,1619185404.0,Simple ways you use data science to improve your day-to-day job?,"I’m curious what various ways this group has found to use data science, or data science-like skills to make their day to day job better?

I’ll start - I wrote a script using primarily regular expressions to turn code log files back into code. I don’t use it a lot, but every now and then I’ll get my hands on a log file without access to the code, and this lets me easily back door my way into the code.",datascience
mwur7p,1619182938.0,Machine learning is not always the best answer,"Hi, I've seen enough of this trend that every big company (especially in north Africa) is forcing the inclusion of machine learning in every aspect of its activity.

People are literally misunderstanding how things work, the state of art of how to tackle every subject in hand hence creating problems that don't exist. It's solutionism at its worst.

They  dumbing down machines that are inherently superior. ( Gilfoyle's quote from SV)",datascience
mwtor5,1619179366.0,Starting a job as a data scientist in a month and freaking out!,"I've been a data analyst with some data science-ish work for years and now have finally secured a job as a data scientist and I don't want to F it up. I'm freaking out. Everyone on the team seems nice but it's also small so I assume I'll need to be pretty independent. I'm going to have a few weeks off before starting and wondering if anyone has any advice on things I can do to refresh my skills in this area so I don't seem like a complete idiot when I start? It's been a while since I did any academic DS work.
Tia!",datascience
mwqwfv,1619167591.0,"Getting sent 4 years of Data, what is the best way to make this searchable for the whole team independently?","Hi, sorry for the newbie question. We are getting 4 years of donation data sent to us as we can no longer use the service portal to pull specific reports and search through it. I need to set up a substitute that will allow members of our team (who have no experience outside of basic excel) to search through the data and if possible save spreadsheets based on reporting parameters.

&#x200B;

What is the best solution for something like this? Could I use Power BI? Am I right in thinking SQL would probably be best but the person submitting the queries would need to know SQL (which would rule it out for this use case). The size of the data would crash most of the team's excel programs.

&#x200B;

Thanks for your help!",datascience
mwl2zj,1619144585.0,Do you often find hyperparam tuning does very little?,"In python/sklearn, most of the time the defaults produce the best (or very close to it) performing model (F1 score), and doing a gridsearch over 6,000 combinations or whatever rarely improves anything. The only thing I've found to be helpful is building new features. Is this typical?",datascience
mwfrbq,1619128105.0,Anyone interested in being a mod?,"Obviously you’ll need post/comment history here.

Post in this thread and we’ll check you out.",datascience
mwf3h1,1619126303.0,"What ""futuristic"" industries do you see data science playing an integral role in the next 50 years?","Data Science is continually changing and is unlikely to ""settle down"" and stay in one spot for a long time. What industries, sectors, etc. that only exist in concept or even ones that are just starting to emerge now do you see data science dominating?",datascience
mw8bzl,1619108105.0,Salaried DS: No Work & Kept on the Bench,"I’ve been working as a data science/data engineer hybrid for about 5+ years. I would consider myself a practitioner – I’m not looking for cutting-edge methods to address common problems, rather I’m just trying to deliver as much business value as possible to a client. Currently I’m in a consulting role but previously I worked for a big enterprise.

I’m in a situation where my consulting group does not have work for me at the moment. Obviously what you do in the consulting world is heavily dependent on what sales can pull in and they don’t seem to be doing a great job. I’m salaried, so even if they don’t have work for me, I’m still getting paid (lack of work does affect my bonus, but overall not such a big deal & I am content with my level of pay even without my bonus). It’s been like this for a month or so, but there are no clear signs of a big project in the future so this could continue for many more months.

While I’m on the bench they literally have nothing for me to do and my boss has told me so himself. He said you can do trainings if you want to make good use of your time, but otherwise there’s not much else to do. I’ve been taking him up on that.

I’ve come to the realization that selling data science is a difficult chore for salespeople for a variety of reasons (lack of technical knowledge, can’t guarantee ROI in many cases, difficulties in pricing, etc…). For this reason I sympathize for them, but it makes me worry.

My questions to the community:

1) Have you experienced anything like this at your work? Is this common and what should I do?

2) Should I be thankful to have this sort of “problem” or is this a worrisome position? My company has made it clear that they have no intentions of laying me off any time soon (and seem to have a history of keeping people on salary even without work)

3) Do you agree with the assertion that selling DS is hard? Or could this just be an issue I’ve seen with the companies I’ve worked for?

Edit: I do currently help with sales in a pre-sales role. Sales generates leads and I'm brought in to talk about the technical details and help sell the service.",datascience
mw79sm,1619105281.0,What is the best data analytics product that you have ever used?,"What is the product or tool that analysed or summarised your data in a way that provided you with a memorable user experience (eg very useful, pleasant, easy to use)?

Why was that?

I am interested in *products that analysed your data for you*, such as Google Analytics for data of your website, Apple Health for data about your sleep, Apple Screen Time for data about your device usage, etc.

I am not interested in products or tools that allowed you to analyse your data, like MS Excel.",datascience
mw60gc,1619101773.0,"Time series forecasting of sales data - NO TREND, ONLY SEASONALITY *URGENT*","Greetings DS community,

&#x200B;

**Please help me out here.**

I have a dataset provided by a company which is a daily tabulation of sales data over 6 months. I want to create a program which would predict and showcase the next 'n' values(n as an input).

The data has no trend, although it shows seasonality on a weekly basis. The data rejects the ADCF test and is stationary without any differencing. Even if I difference it over a shift of 1, the p-value just drops heavily below 0.05.

Furthermore, I have applied autoarima for understanding the best parameters for the SARIMA model but I still can't get good predictions.

I even used fb-prophet but I don't know how to actually maximise the accuracy of these models.

Can someone please help me understand what exactly should I do to get tangible results?

If someone can spend some time, I'll reach out to them via PM and share the PACF, ACF and the decomposition plots.

**PLEASE HELP ME, THE DEADLINE IS TONIGHT.**",datascience
mw3hi6,1619093957.0,What's your best use of AutoML?,,datascience
mvhyxz,1619018454.0,What separates the jobs and fields in and related to data science?,"Depending on boss or colleague, they introduce me various ways - data scientist, researcher, statistician. Those are the main titles I'm introduced as, but there are more.

On paper I'm titled as a statistician according to HR. But I think the title of researcher is probably the best fit. The majority of my duties, design research studies (experimental and survey), collect data (from a research study and/or public data), clean, structure, analyze and visualize data, create papers, decks, and reports, present findings.

What separates the jobs and fields in and related to data science? Statistician, researcher, data analyst, data scientist, et cetera...",datascience
mvcuae,1619001355.0,Data driven Web Frontends....looking at React and beyond for CRUD,"Hello fellow community,

So...While we might love jupyter and all our fancy tools when getting results into the hands of customers Webapps seem to be the deal.

Currently I am developing a few frontends, calling them “data driven” for now. Whatever that means, but it’s trendy.

Basically they are CRUD Interfaces with a lot of sugar.

Collapsible lists with tooltips, maybe a summary row, icons, colors, basically presenting data in a way that people will like to pay for.

Currently I decided to go with a Django backend and a react frontend.

Overall I have to admit I hate frontend dev almost as much as I hate Webapps. Still I thought react was a reasonable choice for a great user experience with a modern toolset.

Right now the frontends authenticate against the backends and fetches data using GraphQL instead of traditional REST. Which sounded like a great idea at the time.

But actually I feel like this was a terrible approach. When fetching data there needs to be a ton of transformation and looping over arrays done in the frontend to bringt the pieces of fetched data together in a format suitable to render tables.
Which in my opinion is a mess; fiddling with arrays in JS while there is a Python backend at my fingertips that could use pandas to do it in the fraction of the time. But that seems just how this works.

I also got fed up with react. It provides a lot of great advantages, but honestly I am not happy having tons of packages for simple stuff that might get compromised with incompatible versions and stuff down the road. Also I feel bad about the packages available to create those tables in general.
It just feels extremely inefficient, and that’s coming from someone usually writhing Python ;)

Overall what I like:
- beautiful frontend
- great structure
- single page applications just feel so good
- easy to use (mainly)

What I just can’t stand anymore:
- way too much logic inside the frontend
- way too much data transformation inside the frontend (well, all of it)
- too much packages that don’t feel reliable in the long run
- sometimes clunky to debug depending on what packages are used
- I somehow never get the exact visual results rendered that I want
- I somehow create a memory leak daily that I have to fix then (call me incompetent but I can’t figure out why this always happens to me)


So I have been talking to a few other DS and Devs and...GraphQL and React seem to be really popular and others don’t seem to mind it too much.

What are your experiences? Similar problems? Do you use something else?
I would love to ditch react in favor of something more suitable.

Overall I feel like providing a crud interface with “advanced” stuff like icons in cells, tool tips, and collapsible rows (tree structure tables) should be a common challenge, I just can’t find the proper tool for the job.

Best regards and would love to hear your thoughts",datascience
mv35ze,1618960846.0,Are there any 3rd party tech/data sci recruiting firms worth their salt?,"I swear, every time I decide to work with a 3rd party, I'm reminded of why I never want to work with 3rd parties - even if they say they specifically place data science folks. Anyone here had luck working with a 3rd party recruitment firm and, if so, which one(s)?",datascience
mv2l0a,1618959073.0,Are there any data science applications in the nonprofit space?,"Or any companies/products aimed in the nonprofit direction?

I’m just curious if due to the cost of data science any nonprofits employ it in any way.",datascience
mutr8a,1618934826.0,Recruiters reaching out,"I’m a data scientists at a very large corporation and after hitting three years at the company, I’ve noticed I get at least 5 emails/LinkedIn messages from recruiters about different DS positions available. Normally I ignore them, but lately recruiters from the companies themselves have been reaching out (rather than contracts or recruiting companies) and I am tempted to respond. Has anyone else worked with recruiters for data science positions and if so, what was your experience? I’m happy at my job but I’m getting so curious about these. Thanks for any insight!",datascience
muqo6t,1618926369.0,Are there any companies out there that don't insist on owning everything you do in your free time anymore? Or is it standard practice to assume you're a slave 100% of the time as a data scientist these days?,"Curious if anyone has managed to land a job where they actually can frolic in their free time. Currently all of my code, any models I make for research or a hobby, and all stocks I want to buy are monitored by my company.

I was very careful to negotiate in my initial contract such that all work done for school would be owned by school/ me (because otherwise my company forces us to send any academic papers we want to publish through a review process where they edit the document and review it in corporate first...).

I've had to deal with gnarly contracts like this for the last ten years and they're always a bit off-putting. Curious to hear if anyone has had any luck not ending up in this situation.

(I should mention I also had to take down my Github when I started at this company and cannot have a blog or social media presence...)",datascience
mual4y,1618866445.0,Effective ways of choosing number of neurons/layers in a neural network?,"I have been reading more about the theoretical backgrounds of neural networks (e.g. ""universal approximation theorem"") and have seen several authors demonstrate that even a simple (few layers, many neurons) neural network can (theoretically) approximate the variable of interest (i.e. the response variable) to a ""decent"" level of precision.  However, the implication being that to use simple neural networks in order to achieve good results, this would require a very large number of neurons. Therefore, deeper neural networks have been developed over the years, which attempt to provide good results with more layers but a fewer number of neurons.

This brings me to my situation: I have never been able to successfully fit a neural network to any real-world data that I have used. I have always gotten really bad results with neural networks (after trying all sorts of combinations of number of neurons, number of layers, learning rate, activation function, ""drop out"" regularization, etc.). This seems to be a hyperparameter-grid search problem.

(Ironically, models like CART decision trees have good results on the same data (supervised binary classification) and random forest has produced even better - this data is not ""small by any means"", contains around 30 columns and over 300,000 rows of data).

 Does anyone know if routines have been written (e.g. in tensorflow keras) that can assist in this problem of deciding the number of layers and the number of neurons? Is there a ""ground rule"" for deciding how many layers and how many neurons to begin with? Is there something around that can ""intelligently"" point you in the right direction for how many neurons/layers to choose?",datascience
mua4ky,1618865179.0,Deploy Machine Learning model on website,"Hello everyone,

My field is not Web Development but data science. With that in mind I have the following questions.

I have developed a machine learning model in Python's SKlearn. I would like to build a website where users provide inputs for predictions (e.g. their age) and output some prediction (e.g. expected income) .

**My objective is not just to make a ""dashboard"". I could easily use Python's Streamlit or R's Shiny to deploy my model and make it accessible by anyone.** I want to use this as an opportunity to learn about Web Development and build a website from the ground up to solve this problem and have full control over it. For instance , I would like to be able to have ads on the website and control how many predictions are requested by each user per minute.

So what would be **a step-by step clear approach/'syllabus'** to do this ? What specific libraries and tools would I need to use in each step ? Where should the model be ""stored"" ? Where should I host my website and make it call the model for predictions ? How can I make it safe so that my model building code is private ? What are the most cost-effective solutions ?

Further details : I know some CSS, HTML and JS. Never created any API. Not much experience in deploying website or web app.

Thanks in advance.",datascience
mu9lj7,1618863703.0,Leaving corporate data science,"I somehow landed a job right out of undergrad as a data scientist. Over the last few years I’ve spent a ton of effort to get up to speed with the masters/PhD level DS that I work with and about a year ago I feel like I got to their level and started teaching them new things. The issue is, I’m really starting to hate working in the corporate environment. They’re so much pressure to perform perfectly and little room for experimentation. I love the data science but I end up spending most of my time finding data, fighting with IT to get access, finding SMEs to work with who have business knowledge of the data, and so on. I really like building models and working with data but the time I spend coding is so little it doesn’t feel worth it. It also doesn’t help that I’m not the career driven type, I care about how much money I make, but couldn’t care less about what title I have. So I guess my question is, does any one have any suggestions of alternatives to working in corporate as a data scientist? I’ve looked into consulting work but that takes some years of building a network. Considering I’ve only been in the industry a few years, I have some room to grow. Thanks everyone!",datascience
mu43ek,1618848825.0,What is the best tech stack/ data pipeline for apache superset?,,datascience
mts5h2,1618802996.0,How would you explain linear regression to a non-technical business partner?,"My approach would be to explain how it's a modeling technique that identifies the line of best fit between the inputs and the desired output that's being predicted. I'd probably also mention that the framework can explain relationships between features and the individual contribution each feature has towards final output.

Anything else you'd add or mention? These people are truly non-technical, so anything to simplify this would help. Thanks in advance.",datascience
mtpp09,1618793931.0,Any of you learn Web Dev or App Dev for a change?,"I know many of you have jobs and don’t really have the time to learn new things, but do any of you get bored or tired of just doing “data” related coding, whether it be training models/data cleaning/data visualization and just try and learn how to build a website or an app? I’m a student and ive just gotten bored of doing sklearn/tidyverse/pandas/tidymodels all day or doing data stuff with Python or R and just feel like learning react or something random like that for a change of pace. I don’t actually intend on getting into web development, I want to be a DS but sometimes too much data stuff bores me. Anyone feel the same way? And if so what did you learn?",datascience
mtj6dq,1618772823.0,How can I make this workflow better?,"Hello, I am trying to automate some manual tasks prone to human error. I have some ideas, but they are all so janky, and I hope some one smarter than me can offer an elegant solution.

The workflow is like this:

I have a series of binary files in a proprietary format on a redhat server. On this server is a c++ binary application that can decode this file into .csv format. I log into the linux machines, run this application on the binary files,  then copy these files over locally to a windows laptop and run a python-based data analysis. Putting python+analysis software on these linux servers is not an option. I have mounted the linux server's home directory as a mapped drive on my windows machine for easy copying of files. but I still have to log in to the linux host to run the binary decoder application. I want to automate the whole process where I can run a python script on my windows laptop and point it to a file (or folder) on the mapped linux drive, have it execute the decoder script remotely, then read in the csv files and perform the data analysis.

The problem is that the decoder script is compiled in the native linux env, so it needs to be ran via its native environment. Is there an elegant way to execute a binary remotely on linux from windows?

&#x200B;

P.S. My current proposed solution is to have python launch a Cygwin application, and then have Cygwin try to 'ssh user@host <command>' to remotely execute the decoder binary.",datascience
mtj0ch,1618772335.0,Data Scientist == Ancillary Analyst,"I'm curious to hear how many Data Science/AI/ML or other adjacent analysts find themselves working in tasks outside of what would generally be considered analytics. I'm at my second job now where the majority of my work comes from ticketing systems. How common is this?

I can't tell if this is an issue that I keep walking into, maybe it's how I'm marketing myself, or maybe it's normal. In my previous role, I was hired and worked on big data projects for around 5 years in an IT department before slowly being shifted over into fielding support calls for confused users. My current role (Senior in DS team) is almost 100% ticket-based work (ex: ""Check that junior resource copied cells correctly between sheets""). It feels like I'm being intentionally deskilled wherever I go and I'm not sure if it's normal. For reference, I'm an American with 7 years of experience and a BSc in CS and MS in AI.",datascience
mtbrwb,1618748351.0,What is your definition of Data Science?,"I’m sorry if this post is breaking any rules on this subreddit.

I just wanted to know how each one of you Data Scientists would define this field.",datascience
mtbi4s,1618747230.0,Weekly Entering & Transitioning Thread | 18 Apr 2021 - 25 Apr 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
mtanu3,1618743358.0,How might you display overlapping binary data other than a Venn diagram?,"I’m plotting data in R that consists of which countries have A, which countries have B, and which countries have A and B.

I feel like a Venn diagram is the most obvious choice but was wondering if anyone might recommend any alternatives?",datascience
mspnso,1618661850.0,Moving to a company where you are the only DS: growth opportunity or suicidal move?,"In my current DS job I am free to experiment with models and my boss lets me do some R&D. However, the production side is deficient: they use old tools, and very outdated pipelines and technologies. Most of the time we do ad hoc analyses for clients that require no production at all. I feel the need to grow my skills on production, and that's something I can't do where I am now.

That's why I'm looking for another job, even though I like my current company, boss and colleagues.

I was contacted for a new opportunity by a cool non-profit organization: they want to start a DS project that sounds very interesting to me (and useful for society IMHO), but there's one caveat: I'd be the first DS ever there. I would basically need to build everything from scratch, all by myself.

One one side, I could build a good career, I'd be plenty of room to do things my way. On the other side I'd be all alone, without anyone to learn with and from.

In career terms, would that be a suicidal move? Is there a risk to ""cut myself out"" the DS job market?

Have you every been the first DS in a company? Did you ever move from ""multi DS"" to ""single DS"" companies? And what have your learned from that?

I hope this might help also other readers too. Any advice is very welcome.",datascience
msc85z,1618606296.0,"I'm burnt out with learning, can't find work. How do you guys keep pushing forward?",,datascience
ms365m,1618579781.0,What interview questions do you think are really good indicators of DS skill / ability? And what makes a good DS?,"I know this has been asked before, but I figured I'd bring it up again to compile some more responses. I've been asked tons of terrible interview questions that are more reflective of if I'm capable of memorizing things about DS than if I'm actually capable at all. So I'm curious: What questions do you think are really good at illuminating whether or not someone is / would be a good data scientist?

&#x200B;

And, along the same lines: What traits, skills, etc. are you trying to select for when hiring new data scientists?",datascience
mrwzkq,1618552549.0,What is the best structured ds project you have seen?,I am doing my post-grad in data science and do a lot of projects that I think I could structure better from start to finish. I look at top submissions on kaggle for reference. What is the project you use for reference when doing your projects? What is your general structure?,datascience
mrqoix,1618528858.0,"For data scientists and BI Analysts at companies large and small, how do you deal with customer privacy when building models and/or dashboards?","I'm a data scientist at a medium sized financial company. Lately we've gotten quite concerned about customer privacy in data science and analytics, and while I have a high level of personal ethics on the topic, I'm not familiar with what is typical at other companies in how the privacy of customers is handled while doing data science tasks.

For internal data science projects, how do you reconcile the need to restrict access to some personally identifiable information with the need for as much data as possible in a model? Do you have names/addresses hidden to most by default with an exception process for when this information is needed?

How is consent handled normally? Does a data scientist assume that there are processes in place to ensure that whatever data is available in the warehouse/pipeline/whatever has adequate consent for the purpose you're using it for? Do you need to do a ""check"" on consent before any development can begin?

Thanks for any discussion on the topic.",datascience
mrg4ag,1618497800.0,Is it impolite to ask a hiring manager to change the job title?,"I currently work as a data scientist, currently interviewing for a data analyst role at a company I am interested in.  Despite the job title, the job description sounds like more of a data science job than a data analyst job.  Would it be impolite to request a title change for the job as part of the hiring process?



I have heard that job titles in data science don't mean much, and people often do go between data science, data engineering, and data analyst jobs as part of their career.  How true is that?",datascience
mrdttx,1618490473.0,Product cannibalization - Would affinity analysis help?,"We send an email to our customers to advertise 3/4 products every day.

Supposing that today's email is advertising three products (product A, product B, product C), the customer is given four options:

1) purchase A
2) purchase B
3) purchase C
4) make no purchase. 

Each choice is mutually exclusive i.e. each customer can make at most one purchase per day. (EDIT: This is because of the nature of the business, which is subscription-based).

Every day we advertise different products and some products are advertised with more frequency than others.

We want to test if certain products cannibalize others, for example if customers that like A also like B, it would be wise not to advertise both products on the same day.

I am exploring affinity analysis to measure support, confidence and lift for each product pair - the issue is however that some products are more likely to be purchased simply because they are advertised more frequently than others.

Any suggestions on how to go about it?",datascience
mr1989,1618438098.0,Is Geospatial Data Science a good field to get into?,"I am a civil engineering graduate considering starting a master's degree in geomatics engineering at a Canadian university. I know one of the applications of geomatics has to do with geospatial data science, things like spatial databases, data mining, and spatial statistics. For those who work in this field, how good is it? What are some typical tasks you perform? Does it have good future prospects? Does it require as much math and stats as ""regular"" data science?",datascience
mqz70b,1618431838.0,What do you use to plot your multiple regressions?,"See title.

I've created a nice and simple multiple regression which works as intended:

    X = multi_df[['Drug Offences', 'Public Order Offences']]
    y = multi_df['Homicides']

    regr = linear_model.LinearRegression()
    regr.fit(X, y)

    Y_pred = regr.predict(X)

I had a look online to see what was recommended for plotting multiple regressions, but nothing stood out to me.

What do you use to plot your multiple regressions?",datascience
mqypuu,1618430478.0,How long do non competes last?,"I am a partner in a data science company as well, going to work in another company, both in data science. Non compete says it's lifetime. Is this viable?",datascience
mquq1z,1618419144.0,any PMs here? How do you run weekly meetings?,"This isn't specific to data science, but I was asked to project manage a data/coding effort. I've been totally winging it but I realize it's time to get organized.

What should be the weekly agenda? There are four of us meeting for 30 minutes twice a week. They suggested doing two week sprints and user stories.

 I figure a basic agenda looks like:

1. Discuss the sprints for the next two weeks based on user stories, then (next meeting):
2. how far did we get since last time
3. Challenges in the approach
4. Other project-related business (there are various angles to this project, long term goals, etc.)
5. retrospective at the end of two weeks

Does that make sense? Also one member setup a kanban board in Github. Very useful.

I searched ""Agile meeting"" etc. but keeping getting results for scrum. We're not doing a daily standup. But maybe it's a similar format.",datascience
mqqpw4,1618407381.0,Agent based modeling vs Statistical Learning Approaches,"Hello, I’m currently a sophomore at my university whose in a undergraduate data science club. We had a speaker come talk about the use of “agent based” models, network models, feedback models, spatial models etc. which the way he described it as was simulation based approaches.

As a statistics Major and only being familiar with the statistical learning approach to modeling, this was very different from the usual tree based models/clustering models that I’m used to hearing about.


Can anyone go into a bit more depth of what those types of models are? Where are they used? Are agent based models part of reinforcement learning?",datascience
mqnn9s,1618395629.0,Should I feel bad for stepping on other people projects?,"Hi! I'm kinda new at the company (7\~ months).

 Since I've started working I noticed that there are a lot of tools and programs that simply are poorly done and don't work pretty well.

The thing is, I have tons of ideas on how to improve these tools or re-made them and I also have the ability to do so, but I'm afraid of what the people that made them would feel like if I step on the programs that they've worked so hard on, how should I approach this? should I just get used to how things work here?",datascience
mqls7s,1618386406.0,"If you want to run SQL queries on CSV files from the command line without installing/opening any DBMS software, use CSVKIT","It happens at times that we don't need to create a database/table, just run some SQL queries on CSV files to test data.
Use a python package CSVKIT.

-Install the package with PIP.

-Run the command on command line-

csvsql --query ""ENTER YOUR SQL QUERY HERE""
FILE_NAME.csv

You can also save the output to a separate CSV file.",datascience
mqjgwm,1618375888.0,Coming up on 1 year of being a data scientist. What’s next?,"A year ago I was graduating with a masters and signing the papers for my first job in data science. All has gone well so far. At first I thought I wasn’t nearly tech savvy or math minded to belong but I’ve improved in those areas and I’m learning I bring other things to the table.

My question for the senior scientists out there is: what should I be working towards at this point?

In my first year I’ve learned:
- basic Linux
- basic version control
- object oriented programming
- debugging
- Python anti-patterns to avoid
- how to write clean, reusable code
- plenty of NLP techniques
- enough AWS to pass the practitioner and ML specialty (although I haven’t used them)
- what MLOps is and kinda/sorta where to start with it

So my question is: what should I be working on?

- ML Ops sounds like it will be in big demand before too long
- Cloud stuff seems like something I should capitalize on while it’s rare
- Math isn’t going away, but I don’t know how much more value spending a lot of time on this will bring to my situation
- Software engineering concepts/practices are great but I feel like I’m running out of ones that directly apply to me

Should I drill down on one of these skills or try to get a general understanding of each? Something else?",datascience
mqhujp,1618369209.0,Entry level position needs a PhD with 3-5 years experience!?,"Is it an entry ""entry level"", or I've got a PhD and 5 years experience ""entry level""?

[Job ad](https://i.imgur.com/Xb6jNmx.png)",datascience
mq9cuv,1618341329.0,App for Project Management,"I am a statistician and I work as consultant in lots of projects. I would like an app to keep track of my jobs, track progress, schedule deadlines and the like. Most of the time I work alone, so no need of collaboration features. Would be nice that the app can have some kind of connection to github since all my work is stored there (not really a must do but desirable).

Support for linux (Ubuntu), Windows and Android is a must

I would appreciate any suggestions for this",datascience
mq25g4,1618320163.0,Farming Automation,"What are people's thoughts on farming automation, listened to the Stuff You Should Know podcast where they talked about Farming 4.0, and sounds really interesting.",datascience
mq12kk,1618316328.0,"Make sure to test code that you pluck from Github, becase it can be really terrible","Sometimes I'm trying to make my life easier by snooping around on Github to see if I can steal code for my own work.

I've found that a lot of DS open source projects are done by people who don't test their functions/classes properly and it almost always gives me a headache sorting through the mess, making me regret cloning the code in the first place. How come so many data scientists don't know how to write a basic unit test? Hell, even a bunch of assert statements would fix so many preventable problems with whatever you're trying to do. I'm no software engineering rockstar by any standards, but it is really appalling what I find sometimes. People will genuinely write a function where they describe a relationship as **e\^ln(x)**, fucking really??

I'm resisting the urge to link a few repos that I've found because I don't want to call individual people out as it's a broader problem. Is this something that I'm alone in or do you guys see the same thing?",datascience
mpq9rc,1618270611.0,Is it okay to have an updated title on my resume to get a foot in the door?,"I work at an outdated company that calls my role something vague with words like “quantitative analytics”.

Recently a recruiter told me to just call it “Data Scientist” as that’s what I’m doing functionally as demonstrated by the details and what I convey in interviews. Is the risk of being called a liar too great or should I go with it to improve my traction when applying?",datascience
mpmy55,1618260312.0,How do you decide how much of historical data is needed to build a predictive model ?,"It's going to be a vague question and but I just need some insights especially who works with real estate data. We recently started moving all our data to a data lake(GCP) to store all the historical data. Now, we also have access to years of listings data and some sort of other information from different vendors.  And we are struggling to decide how many years of Listings historical data we want to pull from their servers. Our plan is to build some predictive models in future but not sure at the moment. We just want to make sure we have the data available when the management want us to build a product. I know the more data it is it's good but we need a cutoff. I looked into different places for example, In [realtors.com](https://realtors.com) you can see the listing price for last 5 years while Zillow shows you for last 10 years. I am not sure for building predictive models how much data we needed. How do you guys decide that? So far we have decided to go with 5 years + current year but If anyone here has any ideas it would be helpful. Thanks.",datascience
mpk8fz,1618252637.0,Tools for creating Interface models?,Which tools do you use for creating interface models? I am currently working on something which would need doing model driven system engineering.,datascience
mp6ink,1618200565.0,I found a research paper that is almost entirely my copied-and-pasted Kaggle work?,"I did some work a couple of years ago on W.H.O. suicide statistics. Here's my [Kaggle project](https://www.kaggle.com/lmorgan95/r-suicide-rates-in-depth-stats-insights) from April 2019, and here's the [research paper](https://www.researchgate.net/publication/338479643_Analysis_of_Mental_Health_Program_based_on_Suicide_Rate_Trends_1985_to_2015) from January 2020.

It was immediately clear from me seeing the graphs that the work was the same, but most of the findings are entire paragraphs lifted from my work. This isn't the first time this has happened but it's probably the most egregious. My work is obviously not mentioned in the references.

Is there anything I can actually do here? I don't care about people using or adapting my public work as long as credit is given, but copying most of it and giving no credit really isn't cool.

**Edit:** Thanks for all the help and advice. I contacted the universities of the authors this morning (no response yet... and I can't help but feel like I'm not going to get one)",datascience
moptek,1618142430.0,Weekly Entering & Transitioning Thread | 11 Apr 2021 - 18 Apr 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
moe1wl,1618092080.0,How do you remember how statistical theories work? To me it's like learning a language that you instantly forget if you don't move to the host country and use it daily.,"I've learned the basic stat theories 100 times apiece in my career, because they are completely absent my brain every time I need them. Binomial distributions, Gaussian distributions, central limit theorem, on and on.

(Somehow I *can* remember Bayes, but figuring out why will require more introspection on my part.)

I learn them as a means to some end. Like a Machine Learning course instructor asks us to make sure we know them before we move into our first modeling exercise. I say ""Oh, shit I completely forgot everything about those."" So I deviate for a day, brushing up on those theories.

I make it through the course, go back to work with my new skill, and then...somehow never even think about those basic theories again. Until the next time I take a course, that is. ""Make sure you know how binomials and Gaussians work before you continue."" Oh, shit.

Part of it might be that discussions of stat theories *never* occur in my professional life. In fact, nobody I know ever wants to hear about them. So, maybe I don't get practice in the same way that we don't get practice with foreign languages without moving to a country where they're native.

It also might have something to do with theory being taught with games. In a recent binomial distribution lesson, the instructor focused entirely on a game with coins and truth tables. I've been able to memorize the pattern in a way that helps me understand the density function, but it's all so abstract, that I don't think I'll be able to derive the density function myself in a year when I need it, again.

**How do you remember this stuff? Is there a good way to get past the memorization encouraged by instructors and into robust understandings of these theories?**",datascience
modtqa,1618091326.0,Opinion on choice of model - Recommender System,"Hey guys, how are y'all doing? Hope you are well and safe!


I've been doing a small project on recommendation systems for board games. I just started the project this week, so I am pretty lost.


Of course I want it to be personalized (item-user interaction, instead of making a recommendation based on stock of the store) and initially I'm trying to go with collaborative filtering, maybe in the future I will try doing a Hybrid system.

&#x200B;

I've tried some really simple memory-based methods, using pearson and cos similarity, then I tried SVD, but I got an RMSE of \~1.5 (the rating is ranging from 1-10) that doesn't look awesome and I don't even fully believe that the model is running ""right"" ? Explanation for that is, I've engineered the data to be like the model asks for it (user-item-rating / int-int-float), and then when I try to predict the rating for a random game (with svd.predict( user\_id, game\_id)), I could use any number at all, even if the user/game is not in the dataset - which I think is weird.

&#x200B;

Then I tried to find some more advanced models and I found this really good [list](https://github.com/grahamjenson/list_of_recommender_systems) and in there I found the [Microsoft one](https://github.com/microsoft/recommenders). So it's' where we are now, which a bunch of different models and not a documentation/tutorials out there.

&#x200B;

Does anyone know where should I start? What are the possible things I am missing? Thanks a lot!",datascience
mod2i5,1618088781.0,"Is everyone using the same software tools/libraries, just with more sophistication?","While I may not be a CS/CE I have studied programming for years, and in the DS game today......

The amount of startups/solutions/platforms being created is insane....and as I wrap up my MS of DS and read more on this sub/other subs about DS and solutions, I think to myself....is everyone essentially using the same open source tools, just in slightly nuanced ways?

For example: With all these companies coming out with deep learning solutions/tools.....is it fair to assume that at a certain point they are all basically using PyTorch, TensorFlow, nnet(R)? Then it's up to their development team to leverage these libraries for their applications? It then becomes a game of who can use the library best, vs developing something ""new""....does this make sense? I am wondering if these startups/majority of these companies do have some secret sauce....or if it's all the same at the end of the day?

Another example: Google releases Kubernetes as open-source, very sophisticated tool for orchestration, launches containerization to a whole new level.....so anyone that offers containerized solutions/orchestration, is it fair to assume that's what they all use (Kubernetes?). Is there something unique in what they do, or is it more integration of these open source tools? What about Google....they must be using something more sophisticated internally beyond Kubernetes? Or is it just

Lastly, I understand the purpose of open source....release it to the community, so people pick it up, learn your desired skills, then you hire them....it works.....I'm just asking more on the tech stack side, and what makes it unique. I am always daunted by ""solutions"" in data science, but I am starting to think they're all amalgamations of all the libraries I typically use, just packaged in a professional way (respecting development time too)",datascience
mobadw,1618082880.0,What content would be useful to intermediate Data Scientist,"I’ve been working as a data scientist for 2 years now, and I’ve noticed that the  content on medium targeted towards intermediate data science professionals is limited, and I wanted to fill the gap.

What kind of content would you guys like for me to write about.",datascience
moaujx,1618081456.0,"All the wrong things with predicting purchase, churn and similar targets in digital marketing","Recently, I have been reading a lot about common prediction tasks in digital marketing like churn prediction and predicting the probability of purchase on a user level.
From the articles and books I have read so far and my own understanding as well, there are several things that make such tasks more complicated in different ways.


* It's pretty hard to commit the so-called Type III error when the model you build in the end doesn't answer the real business question. This can be illustrated by the now classical case of churn prediction. Even though it's not too difficult to build a binary classifier, it's not clear at all what the end users can do with those predictions. In general, it's more useful to do uplift modeling, but this creates another level of complexity because you need to conduct an experiment first to even collect the necessary data for uplift modeling.

* Trying to interpret the results to stakeholders is another challenging part of the process. One of the issues is the falsely obvious belief that correlation implies causation, and the graphs you get from \`plot\_importance\`  and SHAP values do not really answer the questions like which feature defines users' behavior.  In addition, the traditional metrics used in classification are not really useful. It's often stated that there is this well-known trade-off between precision and recall in most real situations especially when the distribution of classes is heavily skewed. What I personally encounter now is that even the business guys do not have a very clear definition of success. They just want to get ""some insights"" and ""have a model"". I usually try to put it this way: we have a value of AUC score that equals X, which is overall a measure of the classifier's ranking ability. On top of that, here is the cumulative gain/lift curve which you can use to understand how useful the model can be as opposed to a random classifier. Honestly speaking, I realize that as a data scientist I have to answer all the questions myself and suggest something meaningful, but sometimes it feels like the end-users of the models have no idea about what they really want to have in the end, which makes everything super complicated.

* To be more specific about the target misconception, I just recently found this post by Frank Harrell that emphasizes the idea that in most real-world cases what you really need to output is probabilities. This is more informative in general than just binary 0/1 answers that only appear when you make the threshold-related decision. The same applies to using improper scoring rules that are functions of the selected thresholds. It's not often taught in machine learning courses, but using accuracy as an evaluation metric might make sense for the Iris dataset, but much less frequently in real tasks.

* Currently, I am working on a task where I am expected to predict the probability of a subscription purchase. The problem can be easily boiled down to the standard binary classification problem with all the issues mentioned above. There is some level of uncertainty when it comes to how the model will be used by the marketing team. My simplistic and naive idea is that the pragmatic way around this problem is to get a decently calibrated classifier that outputs probabilities (technically speaking, not yet probabilities but after some calibration, this is hopefully something similar). The scores are sorted and top X% users (based on the ""best"" value according to the cumulative gains plot) are selected for some form of communication. I realize that taking any percentage of users implicitly means that we are selecting a threshold, but the focus is different and we do not even need to report the shamefully low values of precision. Algorithm-wise, this is just plain old gradient boosting in XGBoost/LightGBM/Catboost.


I have a feeling that a lot of us have encountered similar tasks in this field and I would highly appreciate any advice and discussion. If you have any great resources that discuss such tasks and approaches in detail, please mention them as well.
Here's one freely available book I like very much:
[https://algorithmic-marketing.online/](https://algorithmic-marketing.online/)",datascience
mo8dzl,1618073654.0,How to compare accuracy of 2 time series datasets?,"I am the CTO of a startup, with no ML/DS background. Customers in the maritime industry use our software to get real time price estimates for fuel in ports around the world. These prices are continually updated by an ETL process which takes actual fuel prices + a few other data points as input.

We want to improve the accuracy of our ETL, and potentially experiment with ML/MS models.

We have our first dataset of actual prices+timestamps, that needs to be compared with another (forecast, generated by a model) dataset of prices+timestamps. The timestamps and their frequency are totally different.

How do we compare accuracy between our actual and forecasts datasets?",datascience
mo7bxs,1618070255.0,Shipping data science projects together with other teams,"In the last two companies I worked for, we had a separate data science team, and we had to work together with ""feature teams"" to deliver models into the product. In my experience, in many cases, there is a misalignment between what the data science team is doing and the roadmap of the feature teams that makes it super hard to ship stuff. I think one of the main reasons is that data science teams have to work with more uncertain timelines, which makes it hard for PMs to allocate resources to ship the DS projects once they are ready.
Do you depend on other teams when it comes to shipping features? If so - how do you collaborate with them in these terms? Have you experienced issues when having to ship models? Before starting to work on a particular project, how do you choose which project to work on and how do you make sure that the feature teams will have the resources to integrate the models in production?",datascience
mnyai9,1618030170.0,Can anyone recommend some comprehensive blogs/tutorials/projects for text mining/nlp in R?,"Can anyone recommend some comprehensive blogs/tutorials/projects for text mining/nlp in R? I have come across a lot of basic stuff - but is there anything more detailed and comprehensive?

Thanks",datascience
mnsqrl,1618008965.0,Dank or not? Analyzing and predicting the popularity of memes on Reddit,"A new study in one of my favorite academic journals.

[https://appliednetsci.springeropen.com/articles/10.1007/s41109-021-00358-7](https://appliednetsci.springeropen.com/articles/10.1007/s41109-021-00358-7)

""Internet memes have become an increasingly pervasive form of  contemporary social communication that attracted a lot of research  interest recently. In this paper, we analyze the data of 129,326 memes  collected from Reddit in the middle of March, 2020, when the most  serious coronavirus restrictions were being introduced around the world.  This article not only provides a looking glass into the thoughts of  Internet users during the COVID-19 pandemic but we also perform a  content-based predictive analysis of what makes a meme go viral. Using  machine learning methods, we also study what incremental predictive  power image related attributes have over textual attributes on meme  popularity. We find that the success of a meme can be predicted based on  its content alone moderately well, our best performing machine learning  model predicts viral memes with AUC=0.68. We also find that both image  related and textual attributes have significant incremental predictive  power over each other.""",datascience
mnkciv,1617983953.0,How can I use data to help people?,"I've always been interested in helping people/animals since as long as I could remember. I'm a Data Analyst in my current role (Tableau, SQL, Excel, learning Pandas) and don't deal with any complex Data Science projects/models, but I am self-teaching myself and having a blast.

Does anyone know of any ways we/I could use Data Science/Analytics to help people, non-profits, etc?

Thanks!

Edit: Any projects you have done for the community would be awesome to hear too!",datascience
mnk6oz,1617983500.0,Media pluralism and media development ranking for countries?,"Partially because of my profession (photojournalist), and partially because of sheer curiosity, I started thinking about some sort of media index.

What would be some good indicators of media development to compare countries? Newspaper circulation? Number of newspaper titles? Number of television stations? Internet news analytics? Per capita?

There definitely are countries where there are more newspapers to choose from. There are also countries where people give less shit about news and media. How to find the most news-obsessed and media-curious country?",datascience
mnjjh8,1617981722.0,"With the growing number of undergraduate majors and MS degrees in data science, will employers expect data science degrees in the future?","I will admit, my question does not make sense now.  But CS was a relatively new field decades ago, and most older software engineers I have met do not have CS degrees, but degrees in math, engineering, physics, or are even self-taught.





Now, it seems like we see less self-taught programmers and more programmers with CS degrees.  Couldn't the same happen with data science?",datascience
mnahis,1617946457.0,Data science projects and reporting results,"I am part of a data analysis R&D team in my company that deals with developing ML solutions for our products ( large scall manufacturing equipments). My background is not data analysis but electronics circuit design. The problem at hand is that everytime I do a progress report about the project I am working, my team lead expects me to elucidate every little background information of the project before entering into the topic being researched and the results. His reasoning is that since he is management I can't expect him to know all these first hand knowledge about the project. For example the things he never seems to remember:  the kind of data we are currently dealing with, why we chose the method A to test, the kind of parameter we are using to test the model efficiency and why, etc.
It's not like I never tell him these. I always explain things when they're brought up for the first time. But he wants me to recap these things every single report. We do progress reports every week and he wants me to spend the better part of report bringing him upto speed.. is this normal ? He handles 3 different project teams. Am I the one being unreasonable here ? I want to hear experiences of other data scientists/analysis.",datascience
mn9ril,1617943420.0,An End-To-End Analytics Process - What tools to consider?,"In my efforts to move towards a career in data science, I am being fortunately afforded an opportunity to propose a set of deliverables for a 3 month Data Science PoC for a customer.

Requirements are:

\- Define metrics / what data points we want to grab

\- Develop Data Pipelines to collect data (real time sourced from the internet + static data pre-loaded)...

\- Store data in a cloud data store (AWS/Google/Azure/Snowflake)

\- Analyze data and present to customer on front end tableau dashboards

I am thinking of the following tools:

**Data Sources:** Depending size, either API calls to social media/news data, or pySpark Streaming. Automated, running 3-4 times a day

**Data Cloud Store:** Aggregates data sourced from real time sources, with static sources (S3 buckets or something similar)

**SciKit Learn + Pipelines:** Automated modelling and analysis

**Tableau:** Receives output of SciKit Learn models + grabs data directly from Cloud Data Stores for interactive visualizations

There are probably many things I am overlooking, but this is my rough solution at this time. It will be delegated between 3 guys, but I just completed my MS of DS so I hope this will be a good hands on oppty for me to do as much as I need to....I don't think I need a serious Data Engineering stack (Kafka/Hadoop/Airflow etc.), because I don't believe that aspect is important at this phase....it's more to demonstrate feasibility of modern data stack to solving analytical problems.

Please critique (Gently :) ) ,

Thank you",datascience
mn7thd,1617936155.0,How do you deal with Data Pipeline/Engineering sales people on LinkedIn?,"Title says it all. I accidentally accepted too many friend requests without thinking.

Now I'm getting bombarded with ""do you have a moment to chat (about our aWeSoMe eTL PrOdUcT)?"" messages.

Do I just ignore them? Unfriend them? Or politely decline?",datascience
mn44bt,1617923667.0,Does anyone do event tracking at their job?,"Does anyone work in event tracking and designing them?

I was wondering if any other data scientists work on eventing (designing schemas) and qa(ing) the events (GTM, Google Analytics, Snowplow etc...) and how much of the job is doing said task?",datascience
mn30jz,1617920253.0,Who here uses Windows as their primary work OS?,"I come from CS, but I have a friend who is in a data science masters program at a no-name school and the program seems to be allergic to unix systems. All their classes are taught assuming Windows is the only OS anyone is using and thus my friend never bothered to learn any unix.

I've told he should be learning at least how to work around a bash terminal for when he needs to ssh into a server, but I am wondering if that is all he'd need to worry about. Coming from CS, I told him he should just drop Windows all together and install linux but I began wondering how many data scientists actually use or need linux proficiency since I know many need to use Microsoft tools like Excel.

So it is actually important for data scientists to be proficient on a unix system?",datascience
mn2avb,1617918210.0,Style Guides for Jupyter Notebooks,I started working my first job as a data scientist at a small startup and was wondering if other companies developed their own style guides or conventions for producing plots within jupyter notebooks. Something for stylistic consistency as exploration is being done and could be shown off to other team members. Is that something that's done more on an individual basis?,datascience
mmzbgq,1617909736.0,I just got offered a data science internship with Amazon. I've been lurking on the sub for 3 years and just wanted to thank the folks who put together stats/ml cheat sheets.,"This sub really motivated me to take my undergraduate degree in biomathematics/statistics and turn it into a masters in data science. I use to think I wouldn't have the programing background or that I wouldn't have the technical skills people wanted. It took a lot of my moving past my imposter syndrome as a woman in stem and working on my skill set but I've gotten this far. Thank you all so much.

Edit: Just came back to this post and saw all the support. For any one interested i have been applying since September to internships and have since then applied to 83 positions, reworked my resume twice, ended up making my own website for my projects just to look better on paper, and got 5 interviews at the end of March. I have gotten offers so far from every place I interviewed at and used the smaller offers to ask Amazon to give me a decision earlier, which ended up working. I only did 2 interviews with Amazon before I got my team and offer, which from reading online isn't common as they usually have a 3rd or 4th interview for interns. Its been a long process and a battle at every stage. Just 2 weeks ago I was resigned to the idea of a summer with no internship, but here we are now.",datascience
mmyed0,1617907184.0,What industry do you work in?,"
From my last post I learned that data analysts do work in education. Thinking about it now—duh of course they do because how can we improve education without analyzing data? I do have some experience in education as a substitute teacher and academic tutor, but now work in clinical research. I love reading people’s stories about how they entered the field, so can y’all tell me what industry you work in? Why do you like working in that industry? How do you feel you’ve made an impact? Also, how’d you get into the industry you work in?",datascience
mmvd91,1617898846.0,Eastern University - MS in Data Science | My review,"So I'm currently enrolled in [Eastern University's online MS in Data Science](https://www.eastern.edu/academics/graduate-programs/ms-data-science). I haven't finished the degree yet, but I'm far enough into it that I can give an honest assessment for those interested in enrolling.

# First, the good stuff:

* Eastern University puts their students first. The professors, administrators, and admissions staff at EU have it together when it comes to solving problems and interacting with students. They usually respond to my emails within an hour and give helpful feedback.
* EU is *super* military-friendly. I'm using the Post-9/11 GI Bill to fund my studies. If you have 100% GI Bill, then you get a degree for free and pocket *at least* $15k in stipends. Even if you only have 60% GI Bill like I do, you'll still net around $6k. At Eastern, you only need to take *one class* at a time to qualify as a full-time student, so you can collect that $894/month stipend while only enrolled in a single class. They also offer a $30 per credit discount for veterans and active duty personnel. If you're using tuition assistance while serving, the *whole program* will only cost you $500 out of pocket, which is an *insanely* good deal for a graduate degree.
* Everything is self-directed. No weekly modules. If you burn the midnight oil, you can finish an entire seven-week course in just a week or two! That's quite convenient if you're a full-time working professional with an unpredictable schedule.
* The professor's videos give a clear description on how to use programming languages. I enrolled with *zero* programming experience, but they hold your hand through the whole thing and explain in detail how it all works at a theoretical level. I usually have the instructional videos open in one window and my Python editor open in another so I can pause and play around with it. It's an effective way to learn.

# And, there are a few drawbacks:

* Academically, it's not super challenging. For example, all the assignments can be retaken until you get the grade you want. Also, as an online program, it's possible for an unscrupulous student to cheat their way through, although I have no idea why someone would spend all this money on a degree to learn data science and then just ""coast"" through the program. If you want to gain proficiency with Python, R, statistics, etc., you'll have to practice writing code and crunching numbers on your own in addition to the class assignments. They do, however, provide you with all the learning materials you need to gain proficiency.
* The student account website isn't the most user-friendly. Simply signing up for a new class is a drawn-out, cumbersome process that took me a while to figure out. The learning management system they use, Brightspace, isn't the most efficient either.

# The bottom line:

I know this sounds cliche, but **you'll get out of this program what you put into it**. If you only do the bare minimum to pass each course, you can pay all this money just to get a fancy diploma, but lack the data science knowledge to succeed in the real world. If you go the extra mile and take time to master the material on your own, you'll have a strong enough foundation in data science to get into the industry, gain experience, and build a successful career in a lucrative field. EU's program is a convenient and affordable option for working professionals who want to branch out into data science and have the motivation to work for it.

# And now, I'll answer a few Frequently Asked Questions:

**How much time per week would I need to put in as a student?**
It varies depending on how much time you need to practice and how many classes you take. Each course is seven weeks long. I've been taking one course per term while working full-time as a civil engineer, part-time as a national guard officer, and taking care of my 9-month old daughter and I still have had plenty of time to finish each class with a few weeks to spare. If you plan ahead each week, it's possible to balance this program with a full-time job.


**Eastern University isn't as prestigious/high-ranking as (for example) UT-Austin or Georgia Tech. How will employers judge a degree from EU?**
I wouldn't worry too much about university rankings. Once you're in the industry and have experience, no one cares where you got your degree. You'll also find that many data scientists are completely self-taught and have degrees in unrelated subjects. Some of them don't have degrees at all! For example, my brother attended a bottom-tier, open-enrollment university and studied computer science for a few semesters before dropping out. Even though he never finished his degree, he became proficient at writing code and now makes six figures as a software engineer. All you have to do is get good enough at writing the code to pass a technical interview to make yourself marketable.


**Do I even need a degree for this career field? Isn't it possible to learn data science simply by watching YouTube videos?**
Yes, it is possible to learn data science on your own, but the structure of a degree program makes it easier to keep a consistent study schedule. It also gives you something palpable to list on a resume when you start applying for jobs. As I've stated earlier, many private sector tech companies are loose on degree requirements, *however* government and military jobs stipulate certain degrees for their applicants. I currently work for DOD as an engineer, and every time I apply for a new position within our department, I have to submit my transcript along with it. An MS in Data Science can help you land a federal job as a data engineer, operations research analyst, statistician, etc.

If you have further questions, don't hesitate to ask!",datascience
mmqfsn,1617883982.0,What are some applications of Data Science in Digital Marketing?,"Hi there, I am a student pursuing a Master's degree in Applied Statistics & Analytics. I don't have any domain knowledge of digital marketing. I wanted to get some hands on experience, so I got in touch with a Digital Marketing Agency through one of my contacts. I had a short meeting with one employee of this agency and he was interested in knowing how I can help him fine-tune campaigns for the clients.

&#x200B;

If you can share some use cases of Analytics in this field or guide me to any resources for learning the same, it would be a lot helpful.

Thank you!

 Edit: This agency only runs Google PPC ads ",datascience
mmjq29,1617855091.0,Data Scientists who have Podcasts?,"Hi, among many data scientists, who among them has the most number of audience/followers in their Podcast?",datascience
mmfyc4,1617841889.0,Worst mistake anyone’s made while handling data?,"Hello, currently a sophomore doing some classical stat analysis at a lab on campus. It’s a driving simulation laboratory so it’s mainly doing analysis on the data  they get between two different scenarios and doing some hypothesis testing.

Anyways the lab manager told me how my analysis was completely wrong and how I mishandled the data because apparently I joined two datasets which weren’t supposed to and ended up with duplicates.

I’m kinda bummed that I made this mistake cause I felt pretty confident about and proud of my results.

This had me thinking, what mistakes have you made at your work when handling data?",datascience
mm7w8r,1617818278.0,LinkedIn / Blind / This sub is not real life,"Not sure if this is relevant, but seeing so many posts about people feeling like they aren't good enough / smart enough / successful enough / \_\_\_\_\_ enough because they see others on LinkedIn / Blind / Twitter or even reddit posting about their sky high compensation and amazing accomplishments.

Keep in mind that the folks who post on these forums are not a representative sample. It naturally skews towards people who are drawn to high compensation / level / ""prestige""

Even sources like [levels.fyi](https://levels.fyi) only show the compensations of people who choose to share it, which again isn't a representative sample. If compensation / level / prestige is what you're after, by all means, go for it and work for it. But comparing yourself to people who  *humble brag* on social media does nothing good for your mental health. [Studies](https://time.com/4793331/instagram-social-media-mental-health/) have shown that Instagram is bad for teens' mental health, comparing yourself to the humble braggers on LinkedIn/ Blind / other CS / DS focused social media would likely have a similar impact on your mental health too.

Also keep in mind that on average \~65,000 CS graduates graduate every year in the US. If you include China, India, and Russia the number is more like 460,000 graduates per year, of which \~45,000 are considered elite. My source is this [research article](https://www.pnas.org/content/116/14/6732). Assuming a 15% annual growth rate , that means \~3.5 million CS graduates just in the last 10 years,  (5.5 million in the last 20 years).

Of these, only about 10% (just napkin math based on number of employees in Amazon, Apple, Alphabet, Facebook, Microsoft and assuming only \~50% of them are ""tech"" roles) can ever work in Big N, and of the 10% there, only about another 10% make it to Staff levels, which is where you see compensations of 500k+ (some seniors can make it too, but it's more reliably available at staff+ levels). And these salaries too are only common in SF Bay Area, Seattle, NYC, and maybe Austin.

So you're comparing against 1% of an industry that is already on average better paid than most other industries. So take a deep breath, stop comparing yourself against humble braggers, and know that for the most part you will be ok.",datascience
mm6tnh,1617815305.0,Biquery - Query editor alternative to console/web interface,"Using the Query editor in the web (BigQuery console) is a big pain. It's too small, doesn't really have a lot of functionality.


Anyone have any ideas on a user-friendly ""IDE"" one could connect to BigQuery directly to manage views, tables, scheduled queries? Bonus if you can create views and such directly from this IDE instead of doing it from the console.

I'm doing all analytics in Datastudio, so just need a simple way to browse and write out SQL.",datascience
mm5hg8,1617811617.0,Feature Selection for Large Datasets,"To begin my question, I would like to quote a paper (by Ishawaran et al) on ""random forests for survival analysis data"", in which the authors (very concisely) outline the difficulties of feature selection (i.e. which variables to include in a statistical model) in classical regression models and how this problem is somewhat alleviated with more advanced models :

""Further, because these methods (i.e. classical regression models, e.g. cox ph regression - even though it's semi-parametric) are often parametric, nonlinear effects of variables must be modeled by transformations or expanding the design matrix to include specialized basis functions. Often ad hoc approaches, such as stepwise regression, are used to determine if nonlinear effects exist. Identifying interactions, especially those involving multiple variables, is also problematic. This must be done by brute force (examining all two-way and threeway interactions, e.g.), or must rely on subjective knowledge to narrow the search.

In contrast, these difficulties are handled automatically using forests. We illustrate the ease with which RSF can uncover complex data structures through an in-depth case study of the prognostic implications of being underweight, overweight, or obese and having severe, but stable coronary artery disease.

Investigators have noted complex patterns surrounding possible reverse causation in underweight individuals, interactions with smoking, and an unclear inflection point at which point increasing body mass confers increased risk Some have identified a possible obesity paradox among patients with established heart disease in which increased body mass predicts better survival. To clarify these issues, we analyzed a large cohort of patients with coronary artery disease undergoing isolated coronary artery bypass surgery. Using RSF, (random survival forest) we identified a complex relationship between long-term survival, body mass, renal (kidney) function, smoking, and number of internal coronary artery bypass grafts. We believe our novel findings help explain some of the apparent contradictions previously reported.""

Source: https://arxiv.org/pdf/0811.1645.pdf

Essentially, the authors claim that traditional regression models struggle with feature selection and the newer models (e.g. bagging, random forest) are able to better deal with feature selection. I do remember from an intro stats class, the somewhat tedious process of determining which variables to include in a multiple linear regression model. As the authors described, I remember there was something called ""CP Mallow's Criteria"" in which potential variables were repeatedly included and excluded in the regression model and the value of CP Mallow's Criteria was monitored - a final selection of variables for the model was decided on the basis of this criteria. However, this selection process becomes inefficient for large datasets (if I understand correctly, this means you would have to refit the model for many different combinations of variables, resulting in a ""combinatorics explosion"" for a large number of variables). Like the authors mention, you can also ""manually hard code"" interaction terms in the model (e.g. log(var1), var1var2, var1/(var2var3), var1/(var2+var3), etc.) - and there an infinite such number of potential interactions. Improper feature selection can also result in unwanted effects such as multicollinearity. The last point I would like to bring up - although my knowledge of mathematics is not strong enough to fully substantiate it - is that classical regression models are said to have a tendency to overfit (I don't know why - I have seen visual demonstrations of this, but I don't know if there is a mathematical explanation behind this, or if it's just an empirical observation) and poorly generalize to new data (again, I don't know why); and that classical regression models are only able to ""recognize linearly separable patterns in the data"" (intuitively I can understand this, e.g. draw a circle of red points and a smaller circle of blue points that fits in the red circle, a single line can not separate the two colors - but I don't know if there is a mathematical explanation behind this).

This brings me to my question about feature selection for large datasets. With the advent of technology, data is becoming bigger and bigger everyday - convolution neural networks are the ""go to method"" for analyzing pictures (a standard black and white picture is said to have 786 variables), whereas DNA is said to have even more. In such instances, it surely must be impossible to address feature selection as done in conventional statistical modelling. Please excuse my poor understanding of math - but my understanding is that newer statistical models have ""built in"" methods of handling the feature selection problem. For instance, random forest ""randomly"" chooses different combinations of variables and sees which combinations result in better model performance, the exact randomizing mechanism (uncorrelated trees) is said to also prevent against multicollinearity (I ahve heard that the creator of the random forest algorithm Leo Breiman claims through theoretical statistics that random forest by definition can not ""over fit"" and has some desirable error bounds and convergence properties - is this true?). Meanwhile, I have read on data science blogs (I'm not going to lie) that deep neural networks are able to ""automatically"" learn and consider ""useful"" combinations of features for approximating the target function (am I correct?).

All in all, what I want to ask here : for large datasets, where sometimes the features don't have any immediate meanings (e.g. a patient's blood pressure vs the information contained in the 231st pixel of a photograph) - is there any ""real"" way to handle feature selection? Or is this usually taken care of by the statistical model itself (e.g. random forest and neural networks)? I have seen examples online where people attempted to write a massive FOR LOOP in which they train the same model with thousands of variable combinations ... but I am not sure how feasible this is.

Can someone please provide a comment on this?

Thanks",datascience
mm25oy,1617802356.0,"When you've created a finalised dataframe, do any of you convert it into an excel document to help you visualise your data, or am I being inefficient in doing this?",,datascience
mlfy02,1617727391.0,What is your DS stack? (and roast mine :) ),"Hi datascience!

I'm curious what everyone's DS stack looks like. What are the tools you use to:

* Ingest data
* Process/transform/clean data
* Query data
* Visualize data
* Share data
* Some other tool/process you love

What's the good and bad of each of these tools?

My stack:

* Ingest: Python, typically. It's not the best answer but I can automate it, and there's libraries for whatever source my data is in (CSV, json, a SQL-compatible database, etc)
* Process: Python for prototyping, then I usually end up doing a bunch of this with Airflow executing each step
* Query: R Studio, PopSQL, Python+pandas - basically I'm trying to get into a dataframe as fast as possible
* Visualize: ggplot2
* Share: I don't have a great answer here; exports + dropbox or s3
* Love: Jupyter/iPython notebooks (but they're super hard to move into production)

I come from a software engineering background so I'm biased towards programming languages and automation. Feel free to roast my stack in the comments :)

I'll collate the responses into a data set and post it here.",datascience
mlb6p8,1617714289.0,Anyone here use Confluence (or something like it) to document their projects? How is your space setup/configured?,,datascience
mla7gh,1617711127.0,Inferring values for one column based on other columns. What is the best statistical approach?,"Hey,

I have a table which is 10000 rows and contains financials fields. I want to infer values for *Field1*. It looks like this:

| ID | Field1 | Year | FinancialField1 | FinancialField2 | FinancialField3 | FinancialField4 | FinancialField5 | FinancialField6 | FinancialField7 | FinancialField8 | FinancialField9 |
|----|--------|------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| 1  | 2.000  | 2018 |                 |                 |                 | 0.000           | 37779           | 37779.000       | 23719.000       | 14060           | 14060           |
| 2  | 12.000 | 2018 |                 |                 |                 | 1922468.000     | 3909002         | 4352188.000     | 769411.000      | 3582777         | 3266110         |
| 3  |        | 2018 |                 |                 |                 | 0.000           | 12590           | 12590.000       | 551321.000      | -538731         | -538731         |
| 4  | 10.000 | 2018 |                 |                 |                 | 0.000           | 0               | 1.000           | 0.000           | 1               | 1               |
| 5  | 2.000  | 2018 |                 |                 |                 | 13887.000       | 26866           | 61139.000       | 59261.000       | 1878            | 1878            |
| 6  | 5.000  | 2018 |                 |                 |                 | 8943.000        | 469020          | 614197.000      | 716975.000      | -102778         | -128778         |
| 7  | 84.000 | 2018 | 117720573.000   | 502937.000      | 565222.000      | 4772234.000     | 36220798        | 37446611.000    | 31198748.000    | 6247863         | 6247863         |
| 8  | 7.000  | 2018 |                 |                 |                 | 0.000           | 248181          | 257646.000      | 284207.000      | -26561          | -33793          |
| 9  | 4.000  | 2018 |                 |                 |                 | 468357.000      | 808098          | 809070.000      | 457911.000      | 351159          | 351159          |
| 10 | 25.000 | 2018 | 2899000.000     | 4695000.000     | 4683000.000     | 0.000           | 8590000         | 8590000.000     | 0.000           | 8590000         | 8590000         |
| 11 |        | 2018 |                 |                 |                 | 0.000           | 46660           | 50955.000       | 18855.000       | 32100           | 32100           |
| 12 |        | 2018 |                 |                 |                 | 0.000           | 0               | 0.000           | 0.000           | 0               | 0               |
| 13 | 1.000  | 2018 |                 |                 |                 | 0.000           | 130736          | 132205.000      | 99254.000       | 32951           | 32951           |
| 14 | 12.000 | 2018 |                 |                 |                 | 2106164.000     | 3325246         | 3437339.000     | 1257829.000     | 2179510         | 2179510         |
| 15 | 2.000  | 2018 |                 |                 |                 | 0.000           | 20189           | 23254.000       | 52510.000       | -29256          | -29256          |
| 16 |        | 2018 |                 |                 |                 | 0.000           | 615955          | 616522.000      | 104137.000      | 512385          | 512385          |
| 17 | 2.000  | 2018 |                 |                 |                 | 2717.000        | 16251           | 45660.000       | 44965.000       | 695             | 695             |
| 18 | 4.000  | 2018 |                 |                 |                 | 0.000           | 923824          | 1759978.000     | 1090139.000     | 669839          | 669839          |
| 19 |        | 2018 |                 |                 |                 | 0.000           | 27341           | 27341.000       | 28324.000       | -983            | -983            |
| 20 | 3.000  | 2018 |                 |                 |                 | 0.000           | 135932          | 270622.000      | 249758.000      | 20864           | 20864           |
| 21 |        | 2018 |                 |                 |                 | 0.000           | 1588            | 1588.000        | 0.000           | 1588            | 1588            |


As you can see there is missing data in the first 3 financial fields but the availability of data in the rest of the fields is great. Field1 will often contain values but is often blank. I am looking for some advice on how to infer values for Field1 for rows 3, 11, 12, 16, 19 and 21. What is the best approach here?

I'm not sure how to do it but I believe there must be a way to use the availability of data from the financial fields to apply a sound logic for field1?

I'm mainly looking for advice on what to read up on.",datascience
ml70sj,1617697929.0,"Advice on working on personal projects, while maintaining a regular 9-5 day job.","I ask this as I'm currently in a career switch, and finally coming to realisation that I'm only left with few hours after work.

How do you create time for your personal work outside of your day work? Optimizing sleep to gain more hours? Waking early to have uninterrupted focus?",datascience
ml5krl,1617691605.0,College feels like such a racket but every job requires a degree. Are there any other options?,"Pretty much what the title says. I just started college last week, but for the past half year of so before that I had been self-studying math and programming every weekday by myself, for a minimum of 6 hours per day. I used to look forward to waking up and being busy the next day - I feel like I taught myself a pretty solid foundation in Python and made up for my almost nonexistent high school education.

Now that I’ve started college(I’m studying lower-level CS and stats at the minute) all the fun has been sucked out of learning for me. I feel like I’ve got no choice but to power through if I want to do data science, though, given how many data scientists hold graduate degrees - am I not seeing other options? Does it get better in grad school or is this going to be six years of slogging through needlessly repetitive busywork and inefficient learning? I barely have time for personal projects anymore because of how long my homework takes to complete.",datascience
mku08q,1617654311.0,"As a beginner in this field, Is it normal to feel insecure after seeing people showing crazy ML projects on linkedin?","Hi!

I'm working on my first ML project at work, needless to say I struggle very often in performing various data wrangling or any other tasks that I do for that project.
I don't open linkedin that often but whenever I do I come across people posting crazy Machine learning projects that they build ""for fun"", ""passion"".
This makes me feel, I am struggling so much in performing tasks that I'm paid to do whereas people are just building end to end so difficult ML models ""just for fun"".

Do you guys also feel like that sometimes or am I missing something here?

Thanks!",datascience
mk8wn9,1617583615.0,"Data scientists who have moved to a LCOL area and work remotely, what have been your biggest learnings?","I just got a dream job with a Bay Area company who is allowing me to work remotely. I’ve been living in the Bay Area for 5+ years, and now want to move to a more peaceful, less-stress area that is closer to family.

Fortunately my salary won’t be adjusted, so that’s not an issue.

What I’m wanting to ask this network is:

Those of you who decided to move away from HCOL areas to LCOL areas and work with a distributed team, what have been your biggest learnings? What advice would you give? Do you have regrets? How would you have modified your decisions with hindsight?

I’m particularly curious about Zoom fatigue, culture shock, communication effort, stability/security, etc.",datascience
mk6ix2,1617575512.0,Relaxed work environments or alternatives for DS?,"Could be quarantine or zoom fatigue setting in, but lately it's felt like I just don't want to put in so much effort any more. Granted, I'm in a senior position (and maybe I just don't want the responsibility) at a startup, and the majority of my career has been in startups. I find myself waking up everyday just waiting for the weekend


I'm thinking that in the next year or two I would really like to take a slower pace, where I wouldn't have to juggle so much or have so much riding on my projects. I've done a whole lot of studying and improving on the side for years, in stats/ML but also development, and I kind of just want to relax a bit. Originally I was going to shoot for management roles down the line but I don't think it's for me.


Anyway, I know the first step would probably be to get out of startups, generally. I've read government and banking are a couple of more relaxed choices. How are the big tech companies in this regard? I know some of the open DS positions are more analytics, which is slightly concerning given that I like the development side a more, but I might be okay with it. Just want to collect a paycheck and feel more at ease


Alternatively, there could be paths that aren't entirely data science but data-related. I did do some SEM work years ago that I find interesting, so that could be something.


Anyways, generally feeling unmotivated to continue advancing in the field and want to pull back a bit and take a breather. Anyone have experience with transitioning to a more relaxed industry/role?",datascience
mjzti8,1617554646.0,Setting up a feedback loop for performance evaluation and retraining of a model.,"I am working on a project which shows a warning to the end-user whenever a particular event takes place. For the feedback loop, I have decided to give the end-user an option to annotate the warning as correct or incorrect. I can calculate the precision of the performance using this feedback info since precision is the proportion of positive identifications that were actually correct.

But I don't see how I will be able to calculate recall since recall is the proportion of actual positives identified correctly and I am not really getting False Negatives (When warnings aren't generated when they should be in this project) from the feedback.

Should I set up my feedback loop in some other way?

Sorry for the vague language. Can't disclose specifics of the project because of NDA.",datascience
mjvg8i,1617539804.0,Why do so many people think Python is easier to productionize than R?,"I hear this all the time (this sub, others, out in the wild in real life). People talking about how python is better for production than R, more performant, etc. Why? Everything I deploy at work is Dockerized, and IMO it's no easier to spin up a container to run python than R. Python is also not a ""fast"" language by any stretch, and I'd argue that while pandas is faster than dplyr for data wrangling in most cases, you probably aren't doing tons of wrangling in production situations where you need things to run fast.

I don't want to call it a myth necessarily, but where does this idea come from?",datascience
mjuxa5,1617537630.0,Weekly Entering & Transitioning Thread | 04 Apr 2021 - 11 Apr 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
mjsey4,1617525637.0,Whats with all the sudden hate for DS and shift towards DE?,"A few months ago Data Scientists were saints sent from heaven. Now suddenly data science is not as important anymore?

I understand that analytics and data science departments won’t function properly without an sound data foundation, but why is everyone glorifying data engineers on the expense of data scientists? Why is everyone following the hype whatever direction it goes?

Is there a real reason for all of this or are people really just following bloggers and “data influencers”?

Any opinions? Ideas?",datascience
mjmr23,1617502155.0,ML Libs robust to missing data?,"So I was searching on how to handle missing data and came accross this post from Machine Learning Mastery: [https://machinelearningmastery.com/handle-missing-data-python/](https://machinelearningmastery.com/handle-missing-data-python/)

This article states that some algorithms that can be made robust to missing data, such as naive bayes and knn.

>Not all algorithms fail when there is missing data.
>
>There are algorithms that can be made robust to missing data, such as k-Nearest Neighbors that can ignore a column from a distance measure when a value is missing. Naive Bayes can also support missing values when making a prediction.

But then it says that sklearn implementations are not robust to missing data.

>Sadly, the scikit-learn implementations of naive bayes, decision trees and k-Nearest Neighbors are not robust to missing values.

Are there ML libs (preferably in Python, but could also be in other languages) that these algorithms are robust to missing data?

Thanks!",datascience
mjlz5m,1617499381.0,"Peer group benchmarking, a cool concept","Recently I learned about ""peer group benchmarking"" from someone at another company in the context of converting a continuous score (model output \~ probability) into a binary decision (e.g. accept or decline). The idea as she explained is to make a decision off of a continuous score not solely based on a fixed threshold but rather based on the score of its peers within a sliding time window.

I might be completely wrong but one example I can think of is this. Let's imagine we are building a fraud detection classifier and assume that from cross validation we decided if the outputted probability is greater than 0.8 we reject the transaction. That is of course assuming the real world data will have similar distribution to our training set. Now, let's say due to pandemic the behavior has changed rapidly and unexpectedly in a way that our model generally produces 0.1 higher probabilities; this change in distribution might be different in different groups. if we still decline based on 0.8 threshold we may end up declining a lot of transactions. The peer group benchmarking comes into play here. if we can see that a certain transaction now has a 0.85  score but at the same time it is still well below its peers in a group, we may not decline it even though it is breaching our hard threshold of 0.8.

I would like to learn more about this but I couldn't find any resources just by googling it. I appreciate it if anyone is familiar with the concept and can refer me to a good reference.",datascience
mjkv5y,1617495486.0,Plotting in R's ggplot2 vs Python's Matplotlib: Is it just me or is ggplot2 WAY smoother of an experience than Matplotlib?,"I came up in the space using R for ad hoc plotting and EDA, and I'd like to check to see if it's my home base bias warping my perception or if Matplotlib really is a more cumbersome experience for plotting.

In my experience, ggplot2's chains make plots easy to manage in the code. Functions corresponding to plot elements are simple and take care of all of the customization I could want. Matplotlib, on the other hand, makes me feel like I need to write whole separate programs to build and style my plots.

Am I missing something in Matplotlib that makes it especially powerful for plotting?",datascience
mjkab5,1617493535.0,DS Consulting,"I’ve accrued a few years of experience as a data scientist and have become quite specialized. My current company has been fantastic in providing me external opportunities to present my work through various conferences and speaking to industry experts. I definitely consider myself more of an applied data scientist (not at all interested in developing novel algorithms, much prefer the business application of existing tools) and I am trying to find a way to continue working in data science but stop working in the corporate structure. I’ve just found it so stifling, because of politics, regulations, and misalignment on what data science is. I would like to move into a more consultant type position and work with smaller companies which may not be able to commit to an FTE DS but still have questions that DS can solve. So my question is, do y’all have any tips for getting into consulting or something along those lines? I am working on building an online presence and building my network, but any advice would be great! Thanks!",datascience
mjisiw,1617488692.0,Does your company make use of the skills they expected from you when you applied?,"I have noticed more and more data analytics/engineer and science roles require extensive knowledge of Tableau, PowerBI, and of course SQL. But I want to know how many companies actually make use of these skills, and how many just list them as requirements because they know they are ""supposed to"".",datascience
mjdopj,1617472854.0,"Is anyone trying to switch out of data science, and if so, what jobs are you applying for?","I'm pretty interested in software engineering, and I'm actually looking into more client-facing/sales roles.



I was wondering if anyone has had a similar experience?",datascience
mixh5t,1617409546.0,Data science in a regulated industry,"I’m a DS in a highly regulated industry (pharma) and I was wondering what y’all thought about validating AI or ML models. I have my own opinions on what is best but I tend to see attempts at validation fall into two buckets. First some teams try to go at it all and validate the whole pipeline, ML model and all. These teams usually spend loads of money and time to validate only to do it all over again when they retrain the model in six months. The other path I see is where teams try to treat the model as a black box and validate the surrounding infrastructure. These are much quicker to validate/verify but run high under high risk in the eyes of regulatory bodies. So what approach do y’all think is best? Or if there’s another one I’d love to hear some suggestions :)",datascience
miwy9l,1617407784.0,Asset Retirement Year - Optimization Problem,"

Hello all

I have been assigned to consult a traditional mom and pops logistic company in deciding at what year they should retire their trucks. Currently they are running them down until they cost more to repair than to sell.

I have data on their current demand for asset types and total maintenance cost of assets and obviously the number of assets on hand. I was wondering if there's hope looking to build a model using optimization with this limited set of parameters. I know in terms of cost we could potentially look at their revenue per asset and do a minimization on cost but they don't have that kind of information available and I'm only dealing with demand and maintenance cost.

Any advice would be highly appreciated!",datascience
misei3,1617393940.0,Is nonprofit salary negotiation a thing?,"Currently working at a nonprofit. Is it worth asking for a review? If so, typically how long before you should ask?",datascience
mir0r3,1617389997.0,"Making the transition from ""small data"" to ""big data""","In the past, all the work I have done has involved ""small data"". What I mean by that, the data I have used to perform statistical modelling and machine learning models - this data was ""carved out"" from a larger data source using SQL, and is able to fit into a very large excel  document (multiple spreadsheets). From here, I use R studio to import all these spreadsheets into R and ""concatenate"" the spreadsheets together (i.e. stack them on top of each other). So in the end, the final dataset I am using for my analysis is about 30 columns and 500,000 rows. From here, the analysis can take some time - but I usually put some coffee on and step away from the computer (a ""family laptop"" from Costco, no GPU) while the numbers crunch.

However, I am starting to realize that this approach will become less efficient and eventually stop working for larger data sources. I am aware that there is a whole world out there that is dedicated to dealing with and solving these problems - a world that I am not very familiar with. This world uses words like : hadoop, spark, aws, the cloud, parallelizing, apache, containerize, chunkize, etc.

As I see it, I feel that the problem can be viewed from different prespectives:

1) Performing machine learning and statistical analysis on large data might not be possible because of limitations in the individual computer you are using : this means, these procedures on this large data might not work on my computer - but it might work on my friend's (more powerful) computer who lives down the street

2)  Performing machine learning and statistical analysis on large data might not be possible because of limitations in the software (e.g. python, R) you are using : I am not very knowledgeable about what happens behind the curtains of the software, but my understanding is that software you are using (regardless of how powerful your computer is) might have certain limitations related to ""memory and ram"".

3) Both 1) and 2)

With this being said, I want to start exploring different ways to address these limitations. Based on my limited understanding of these topics, I think there are two main ways to address these limitations:

A) With money : Apparently you (or your company) can buy ""cloud services"" such as AWS, which will allow you to perform machine learning/statistical analysis on large data using ""remote servers"". I was told that this does not require a lot of knowledge or extra work - after purchasing these services, only a slight amount of extra code is required, and then you can effectively perform machine learning algorithms on big data.

B) with less money: this is where my understanding stops - apparently tools like ""hadoop"" can divide the computing costs between several computers and reduce the required time, or there is something called ""chunkize"" which allows you to sequentially feed your data into the algorithm without maxing out your computer.

How can I learn more about this? Suppose I have the same dataset with 30 columns, but this time there are 100 million rows. I want to use the random forest algorithm for a binary classification task.

How have people on r/datascience approached this kind of problem in the past?

Thanks",datascience
miql3b,1617388728.0,Data Scientists / DS Management | what makes you different?,"Interesting predicament I'm in....

I'm highly skilled in a unique domain (manufacturing, robotics, sensors, machines), and have done data work for 2-3 years....finishing up a MS of DS.

I (naively) thought that I'd be a hot commodity on the job market....but from my experiences, people are looking for a certain **type** of DS (cross ref to this [post](https://www.reddit.com/r/datascience/comments/me2w0n/what_data_science_specializations_do_you_think/) on popular specializations) like:

* Ad/Marketing (how do I solicit data from people to sell them stuff)
* Finance (how do I use market data to make more informed financial decision and transactions)
* Computer Vision (converting pixels into data, and inferring things (person, cat, stop sign etc.))

I thought being different would be welcomed....but it seems like there is also a certain **type** of person that gets into these roles...Data Analysts from day 1, people from the domains listed above...and for the rest of us who are on the outside looking in, as a personal anecdote it makes me feel like what makes me unique, is actually a *bad* thing.

So in the spirit of curiousity, what makes you different?

As a practicing DS, DS management, whatever....what do you do/know that makes you different than your peers?",datascience
mimpre,1617377518.0,"Against the negativity here, I just received my $200k salary offer in just 2 years (even in this economy)","Few months ago, I wrote in this thread (with an older account) about how I think some Data Scientists are getting underpaid and negotiation is an important skill during interviews as much as ML frameworks. It was meant to be a message to uplift all of us into better career development.

But when I wrote that my first job as a Data Scientist was making $150k a year and that we can easily make $200k with upgraded skills, experience and right negotiation, people here laughed at me -- said that I was trolling and that kind of salary was insane. I told them this is the average in the Bay Area, but they said that even seniors don't make this kind of salary.

Well 2 years later, I have just secured a $200k salary, $170k in base and $30 in yearly bonus (not including RSU). This is for a Data Scientist in ML role at a company in SF (not well known, but a stable company). I eventually settled for another company with far less salary but far better stock potential. But still.

Given that I proved my initial point, I want to say few additional points of affirmation.

1. Don't undersell yourself. Know your value and worth and stick to it with confidence even in this terrible economy.
2. If you can impress the hiring manager and the senior management during interviews, they're more than happy to work with your professed worth (if not in salary, then in bonus, stocks, etc.). Otherwise, they will lowball you. This requires a refined skill in both communication and technical chops
3. Know how to play the political game during interview cycle. Master the negotiation tactics. Know how to bluff. Too many tech folks don't like to do this and think that they can keep their heads down and work hard, and their accomplishments will be naturally rewarded by some supernatural force. That's rarely the case. Data and Software folks are not immune to necessities of nuanced and skillful communication.

BTW, I don't have FANG-level experience. My first company 2 years ago was a mid-sized startup most people haven't heard of.",datascience
migd9s,1617353800.0,Discovering column mappings,"I have a challenge to work on at work and am trying to figure out the approach. We have an internal system that stores transactional data in a tabular form.

We receive daily files with data from the same domain (transactions + metadata) but the column names are not standardised, and the data fields are not always the exact same (e.g. The amount field may have 3 digits behind the comma, where our system expects 1 digit  or what our system calls ""amount"" might be called ""quantity1"" in the incoming files etc.. )

We have a manual mapping and transformation defined for each incoming file, but the volume of different formats and sources is ever increasing. Im looking for a way to take any input file and to train a model that predicts for each column what the most likely corresponding column in the target file is.

I've been looking into a few things : using NLP\spacy to train a model that recognises patterns in the column data. E.g. Numeric + period + comma is likely to correspond to amount. I've also looked at modeling the data and extracting an RDF representation using a open source tool called Karma to see if I can train a model on a network graph. But really struggling to see how to implement this.

Is anyone aware of the formal name of this type of problem and if there are tried and tested approaches\implementations out there that I could build upon?",datascience
mieuhi,1617346317.0,How is data science being applied in our lives? (ELI5 please),"Just a brief description of my background. I'm an education counselor in an Asian country where Data Science program is starting to trend. My job includes to explain to students what kind of degree would achieve their desired job or help them to choose the right career path.

Very often, I am able to explain what Data Scientist do (thanks to this subreddit and eli5) but I struggle to provide examples to high school student how is data science applied and shape our daily lives .

I've tried searching this subreddit but I am getting very technical answers which I struggle to understand. So to put it simple, how do you apply what you do in your job into our lives.",datascience
miar50,1617329782.0,My first data science client - experienced data scientists: am I on the right track?,"I have no one more senior to ask and this is the only job I was able to get to break into the field.

Basically,  client is a procurement company that wants to use AI to make ""data driven decisions"". They don't really have much experience or idea of what they want.

I have asked them to send me some invoices and other types of data that they are currently capturing. if they don't have enough data, I will simulate something. They do understand that they will have to get their data management in place before they do any machine learning or AI.

My idea is to take couple of weeks and use open source tools to show them what's possible (like a prototype) and hopefully they will sign a longer term contract with my company.

I was thinking of doing some anomaly detection/predictions (which is fairly easy to implement) and some classification ML to classify their invoices into different categories.

This doesn't sound too impressive though :/ Any ideas what more I can do in the short time-frame, like some kind of an easy win?",datascience
mi8z00,1617323450.0,"How do I deal with ML models taking soooo long to train, when I have to optimize results?","Noob data scientist here.

This is a bit of a general question, but I'll ask it nonetheless. I've lately been involved in two projects at a company that wasn't very interested in the quality of my development approach and code, just the results. And I think that I have not really learned best practices regarding model training.

For example, at the last project, I regularly changed the architecture of a neural network and ran the usual tests and went to do something else. Using Jupyter Notebooks also probably didn't help, since I always had to come back to run another test manually.

However, there was no real method to how I did it, and it sometimes just felt like a stroke of luck when I found better results, apart from feeling like a huge waste of time when the model underperformed.

So I was thinking if you could point out some things that may help me to structure my code and model development.",datascience
mi4dia,1617309234.0,Data science specialties,"I’m a data scientist at a large firm and I specialize in deep learning approaches to NLP. Over the last few years I’ve gotten particularly deep into this field and it got me wondering, do other people specialize or do they stay generalists? I’ve found with all the different areas of data science growing so fast, you’ll never be able to keep up the pace with CV, NLP, etc if you try to do them all. Also, for those that do specialize, what’s the distribution of the different specialities across the industry? Like what proportion are computer vision experts vs. NLP vs. other.

Apologies for the formatting and grammar, on mobile today.

Thanks internet!",datascience
mi30qg,1617305423.0,Any library that can help me with identifying the correct data type for a given column?,"I'm looking for anything that can help me with this type of problem, I basically need some help identifying the type that a given array is intended to be, given its values, titles, etc.

For example, I would need some code that realizes that this ""$ 45321"" is intended to be numeric, or that a given column is intended to be date, even if some values are misformatted.

Any help in the right direction is appreciated",datascience
mi28l8,1617303256.0,What types of questions and coding samples are normal to expect when one is interviewing or thinking about prepping for a data science job interview at a manager or director level?,"I'm probably looking to change my job within the next few years after I finish my doctorate. My current supervisor has informed me I'll get a bigger salary bump if I leave and come back with the Ph.D. rather than stick it out and try to negotiate with my current company, so I assume I'll be at a disadvantage when I go through this process as I'll be applying as a student! (I'm a manager right now and would like to interview for a similar or higher level role.)

I have casually interviewed with a few places in the past and have been frequently surprised at the types of things asked for data science manager or director level roles. One company, we'll call them Swamazon for anonymities sake, asked me to code a regex function at the level of ""write a function that splits the string."" Another company while trying to assess technical skillset went into depth about having me code a group by function in SQL. Neither was very interested in seeing examples of anything more advanced from me either.

I can't tell if they asked this because they assume someone who manages a team must be an idiot, or if I just look like an idiot. But curious to hear if this is standard these days? What do you guys typically ask when interviewing experienced data science folks?",datascience
mhxv2i,1617291275.0,Tips on leaving a job that you like for a better opportunity,"I just landed a job at a big tech company and need to put in my 2 weeks to my current boss and team virtually.

I like my boss and I like the team. I learned a ton on the job in the year and a half I've been here.

The new job I'm guessing will be a better career move in the longterm. More learning opportunities and room for professional advancement.

How did you resign from previous jobs and what are some things you wished you did differently? Any advice on what to say?",datascience
mhvr1h,1617285110.0,Just failed an interview but I have a feeling that the interviewer is wrong,"So I had a technical take-home challenge. Due to having to do machine learning on a laptop and having 100 million records, I took a random sample of the data (or more accurately only 1% because that's all my laptop can handle). I proceeded to do EDA, train data and fit a few models that looked well fitting.

This is retail data and my interviewer immediately told me that my random sample approach is wrong. He said that I should have taken a few stores at random and then used ALL their data (as in full data for all the stores picked) to train the models. According to him, you can't train the model unless you have every single data point for a store. I think that he doesn't seem to understand the concept of random sampling.

I actually think both approaches are reasonable, but that his claim of needing every single data point for a store or you are not getting the ""full picture"" is incorrect.

I failed the challenge due to this issue and that was literally the only thing that was wrong with my solution (according to feedback I asked for) :(

To add: data set contained 100000 stores in the same chain. The goal was to fit a model that will predict total sales for those 100000 stores.",datascience
mhmhpr,1617247241.0,Struggling to find a data job after being laid off in August,"Hi all,
This is really stupid but I've been struggling to find work. I have 3 years experience as a data analyst in a research institute and a data analytics and modeling degree from an accredited university. In the beginning i wasn't applying as religiously because of how overwhelmed and burnt out i was but I have consistently been applying to jobs since January. I have experience in MATLAB, SQL, R, Python. I also have a publication under my name.

Starting to feel a little bit helpless. I have gotten to the technical interviews at 2 different companies which obviously i didn't pass. For these i prepared doing coding problems and basic machine learning (I'd love some study recourses if available). More than anything i have had a hard time even getting the initial interview. I always get the second interview after a behavioral one.

Really any advice would be great. I can black out parts of my resume and post it. I've always felt really insecure job hunting after being in abusive relationships where my partners have put me down and told me I wasn't smart enough.",datascience
mhh5zu,1617228989.0,"Why you're ""bored"" at your job (and how to fix it)","This is a post especially relevant for those of you transitioning into data science from a non-traditional background - so I hope you find it especially helpful :)

In the 1950s, Frederick Herzberg developed a theory that states there are two dimensions to job satisfaction: motivation and hygiene.

Hygiene factors can minimize dissatisfaction at work, but they can’t make you love your job. These are factors like salary, supervision, and working conditions.

When you look back at the best moments of your career, they won’t really include the perks or the free lunches you got.

Instead, you’ll look back and remember the *motivators*. These are factors like recognition and achievement. They mean that your work is challenging and that you’re learning about topics that you’re intrinsically interested in.

These are the factors that’ll be the predominant source of your work satisfaction and what contribute to your personal growth.

Here’s the thing though. If the hygiene areas aren’t properly addressed, you won’t feel satisfied regardless of how fulfilling your work is.

No matter how challenging and exciting your work is, if you’re not getting paid what you deserve, you’ll constantly have a nagging thought at the back of your head telling you to leave.

On the other hand, *only* having hygiene areas resolved is the reason why you constantly think something’s missing. You’re puzzled over *why* you’d be unhappy - you have a high status job, plenty of cash, and great coworkers.

But we need challenge and growth to drive us forward. And that’s why the motivators are integral. Without the motivators, we go to bed at night dreaming about what we’d be doing in an alternative world. Just look at these Hacker News posts ([link](https://preview.redd.it/ed99k3mjsfq61.png?width=2360&format=png&auto=webp&s=c3d640a23b0b37726ffdb4a3a5cc872601eae7f9)).

The reason this can be hard to identify in our day to day is because we wrongly assume that just because we’re not fully unsatisfied, we must be satisfied. And when we inevitably don’t get that resounding feeling of congruence with our work, we get puzzled.

One of my favorite examples of someone who prioritized her intrinsic motivators over factors like money or status is [Kristina Lustig](https://www.linkedin.com/in/kristinalustig/). She quit her high paying Director of Design job to retrain as a Software Developer.

It might not have made sense to others around her, but only Kristina knew what motivated her intrinsically.

**Loss Aversion**

Let’s assume you realize you want to make a career change into something more rewarding. Your brain is going to freak out.

It’s going to start screaming:

* What if I don’t like my new job as much as my current one?
* What if I don’t end up happier?
* I can’t change if i don’t make as much money.

The key to overcome this thinking is to *separate short term losses from long term losses.*

So here are a few examples:

* **Short Term**: In the short term, my salary will drop. **Long Term**: But 5 years from now, why can't it exceed what I'm making right now?
* **Short Term:** I might have to take an entry level role which feels like a big drop from my current position. **Long Term**: But 5 years from now, won't I not only be in a more senior position but also a few steps closer to doing work I enjoy?
* **Short Term**: I might have to give up the stability of my current role. **Long Term**: But 5 years from now, won't I have stability and a new skillset I can leverage?

**The Next Thing**

It’s really easy to fall into the trap of thinking that the nicer office, the next pay raise, or the more prestigious title is what will make us happy. After all, it’s what your friends and family see. It’s the labels that stick.

Instead, we should aim to ask a different set of questions:

* Is this work meaningful to me?
* Is this job going to give me a chance to develop?
* Am I going to learn new things?
* Will I have an opportunity for recognition and achievement?
* Am I going to be given responsibility?

These are the things that will truly motivate you. The rest is just noise.

\-------

I hope that was helpful!

*If you liked this post, you might like* [*my newsletter*](https://www.careerfair.io/subscribe)*. It's my best content delivered to your inbox once every two weeks. And if Twitter is more your thing, feel free to follow connect with me* [here](https://twitter.com/OGCareerFair)*.*",datascience
mhg356,1617225734.0,Looking for open-source model serving framework with dashboard for test data quality,"Do you know any open-source framework for model deployment but with the following features:

- it should have a dashboard for test data quality monitoring - ideally with alarms from the great_expectations framework https://github.com/great-expectations/great_expectations

- should support A/B testing of models

- it should be cheap to deploy and run

The live data quality dashboard is important to me. Maybe there are other ways to monitor new data quality?",datascience
mhbynm,1617214032.0,"Looking for general advice - How do you guys handle conflicts in Data Science Projects? With respect to peers, managers and stakeholders?",,datascience
mhb403,1617211614.0,Creating a data warehouse and dashboards for my business,"Hi, I'm looking to set up a new centralised system for aggregating all the data my business has, and then perform further BI queries with it, including building dashboards that inform of things I need to know.

Here are some of my concerns:

- I have had troubles with many big name cloud players in the past, such as Facebook, PayPal, AWS where they disabled my business accounts/rejected without reason (common issue all around even if you're paying them, and Google is no exception). Not even doing anything controversial nor are we in any high risk industries. Their algorithms just act up. I'm mostly skeptical about anything cloud where I don't control it directly and the ""partner"" can cut you off anytime. So I lean towards on prem unless you can convince me that cloud data warehouse providers are ""different"". There's also the cost of setting it up so a set up and then a disabling later on is far too costly. What guarantees can one get? Any legal contracts or terms?

- What on-prem data warehouse stacks do you suggest for smaller volumes? Not doing big data, but  ETL functionality would be nice to have .

- What analytics and BI softwares are flexible enough? I used to use SAS EG in my earlier days to cut data and that was the best for me so far (like Excel for data warehouse, I would say) , but am wondering if there are better. I tried metabase and grafana and they don't query well without much more tweaking. Haven't tried tableau but am wondering about their costs.

- Prefer open source but licensed software can be considered if costs are suitable. Was looking into apache but only briefly.

- Small business, so nothing too fancy and enterprise grade.

- Prefer web dashboards so I can view it anywhere.

- Prefer GUI where possible, and minimal code unless it's for a special custom query.

- Data ownership and control over the system is important.

Lots of ground to cover here but I appreciate all your opinions and how you unleash your passionate idea of an ideal setup :D",datascience
mh47nt,1617190698.0,What is the difference between a Data Engineer's job and Data Scientist's job?,"I have Googled this, but I'd like to know from experience what the primary differences are.
Do the interview questions for these positions also vary? How detailed is one's knowledge of ML and DL expected to be for Data Engineering positions? Are these names often used interchangeably?",datascience
mgq0eo,1617138329.0,Dashboard for market research reporting,"Hello everyone,

after a long time of research and many fruitless looks, I would like to ask you a question that is burning under my fingernails. I am currently working in a market and social research institute for a little over two years, which would like to gradually (finally) dedicate itself to more modern solutions to deliver results. Before that, you could find me as a market researcher in financial consulting, trying to slay the spreadsheet-headed hydra with Python, but I'd rather tell that story another day...

Anyway, if you know market research, you will also know the typical researcher type of guy who still throws around piles of crosstabs and PowerPoint slides and prefers to create their PostScript tables based on fixed column ASCII data (as our company still does in parts...), but this industry does not sleep either and so interactive reporting formats are gradually gaining acceptance. Now here comes the difficulty:

**What solution can be found to create dashboards for external customers in ad-hoc study projects without much infrastructural effort?** It needs an environment that I can give to less code-savvy people if they want to set up at least rudimentary reporting that nevertheless offers a minimum of interaction.

The big difficulty here is that many solutions I find on the market typically handle metric data very well, but in market research there is also a lot of categorical and ordinal scaled data generated by multiple choice and matrix questions, where I need, for example, stacked column charts of 30-matrix items with their corresponding Likert scales sorted by top-2 values from the respective scale, which I also need to function after drill-down filtering. And as reproducible as possible.

Open source solutions are preferred in our company; Tableau, PowerBI and relatives are less attractive due to licensing costs. Around the corner, I'd also thrown tools like Metabase on a server, hooked it up to a few sample databases and tried it, but the internal query capabilities were too limited for the multi-variable graphs I just mentioned. It worked, but ate up too much time for one graph.

Prorietary tools like Dapresy and DisplayR can inherently work very well with such data as they can even handle wide-format input, which of course makes importing data easier, but again there are licensing costs that quickly scale along with the projects. At the moment I'm thinking about covering this use case with R Flexdashboards and giving my colleagues a library that provides typical functions for us, so that we can at least generate a viable product, but I refuse to believe that there isn't a more scalable solution around.

I would be very happy to hear of any good solutions, experiences or tips!

Have a great day everyone and kisses on your eyeballs.


TLDR; Need good dashboard solution for research projects. A lot of categorical data need better solution than multiple union all queries in SQL. Colleagues can't code but demand egg-laying woolly milk sow. Excel smells. Death to pie charts. Help me. I love you.",datascience
mgjaid,1617120033.0,Data science in VC/PE firms,"Hi Everyone

Those who work as data scientist in Venture Capital / Private Equity firms, can you share what kind of work do you do? What do you solve for, etc.",datascience
mgixgr,1617119102.0,"Has anyone else noticed a huge uptick in unsolicited data science recruiter emails lately over linkedin? I can't tell if this is a sign that the field is growing, or if everyone's hiring data scientists for departments that will inevitably collapse in 5 years.","Historically when I've been on the hunt for a new data science role, I've found it's generally taken me anywhere from 6 months to a year to find and start a position. Prior to this year I'd get maybe a few linkedin recruiter emails every few months or so, but something about the past few months seems to have thrown everyone into overdrive. Literally 3 - 5 emails a day have been rolling in for everything from ""12+ month contract role! 3 years experience!"" to ""want to be a director of data science starting a department at this particularly well known company""?

I can't tell if this is a good sign that the field is growing, or if this is a sign everyone's hiring data scientists for projects that are going to ultimately end up disappointing them and will collapse the department in a few years.",datascience
mgf5lz,1617108207.0,Is it a primary objective to establish cause and effect in data science?,"Like the title says, is data science like other sciences in that it’s important to determine cause and effect or is it enough (at least in the business world) that you have a model that seems to work?",datascience
mgeryk,1617106959.0,"How do you handle ""marketing speak"" by execs and misrepresentation of yours/your team's work?","So, I'm the lone data scientist in my company (startup in the healthcare tech space) like I imagine many here are.

Last week I saw a LinkedIn post from the company's CEO flaunting how data we provided was used in an article published by a major news outlet (I'm omitting details here to preserve anonymity). He said it was all thanks to our new product: <insert-flashy-name-here> and our cutting-edge work with BIG DATA (all caps), AI, and Business Intelligence. The thing is, neither this particular data nor this product are thing which I've even heard of.

Now, like I said, I'm the only data person in the company and we're not a large company at all, so there's no way there is someone working on stuff like that without me knowing. We're nowhere near close ""big data"" and there's very little ""AI"" stuff being done. Like in most startups, the majority of my time is spent juggling data engineering/data analysis demands and if I had to bet, I'd say this particular case was probably something done in some random excel spreadsheet by the product/marketing people at the last minute.

I know part of the CEO's and other execs jobs is making the company look good, but sometimes the way they misrepresent the technical work the company is actually doing by using random data-related buzzwords is really hard for me to overcome. Is this me being ""immature""? Should I just learn to embrace this kind of thing as an inevitable part of corporate work?",datascience
mgdnrk,1617103209.0,Zindi's official response to claims of unfair treatment by u/maroxtn,"*An official response to* [*this post*](https://www.reddit.com/r/datascience/comments/mdlnvy/everything_wrong_with_zindi_data_science/)*.*

My name is Paul Kennedy, I am Zindi’s Community and Communication Manager ([LinkedIn profile for reference](https://www.linkedin.com/in/-paul-kennedy-/)). I and my colleagues at Zindi were disappointed to read this comment, and I would like to take the time to address the principal claims made in the above post. We take cheating on the platform very seriously, as it erodes trust for all our users.

***Claim 1:*** *I opened my email thinking it was some sort of a mistake, I found an email sent by them stating that they banned me under the pretext of ""Collaboration outside of team"". I responded explaining to them that I single handedly worked on the solution of my problem, telling them I'm ready to provide proof if they want. They didn't respond.*

The user in question (and the author of this post) was banned from the [AI4D iCompass Social Media Sentiment Analysis for Tunisian Arabizi Challenge](https://zindi.africa/competitions/ai4d-icompass-social-media-sentiment-analysis-for-tunisian-arabizi) for contravening rule 2.2 of the platform (Please see our [Rules page](https://zindi.africa/rules); these rules are also replicated in every competition page):

*2.2. Multiple accounts per user are not permitted, and neither is collaboration or membership across multiple teams. Individuals and their submissions originating from multiple accounts will be immediately disqualified from the platform.*

The user was given a first offence warning and removed from the challenge on 19 March 2021, as per Rule 7.1:

*7.1.* ***First offence: No prizes or points for 6 months (probation period)****. If you are caught cheating, all individuals involved in cheating will be disqualified from the challenge(s) you were caught in and you will be disqualified from winning any competitions or Zindi points for the next six months.*

***Claim 2:*** *Then today, out of sheer luck, I discovered that the team that took my place on the leaderboard when I got banned work as a data scientist for Zindi, which is quite preposterous to say the least.*

This is an utterly false and baseless claim. As per Rule 1 of the Zindi platform, employees of Zindi are not allowed to participate in any competition on Zindi. Further, any contracted individual may not participate in any competition that they worked on and helped to prepare:

1. *Participation*
   1. *All members of the public are permitted to participate in any Zindi competition, unless:*
      1. *They are a full-time or contracted employee of Zindi, or an immediate family member of a full-time or contracted employee of Zindi*
      2. *They are a full-time, contracted employee, or intern at the host company of the specific competition*
      3. *Individuals may not participate in a specific challenge if they have helped design the challenge, source and prepare the data, or if they are/will be involved in code review.*

Lastly, I’d like to express my sadness and regret at the awful sentiments expressed in the post above regarding ‘everything wrong with African countries’. As a company, we distance ourselves from such bigoted remarks. Zindi is dedicated to growing, supporting and uplifting Africa through the transformative potential of data science and machine intelligence. We are, at our heart, a company dedicated to making AI accessible to African and other developing countries. We strive every day to promote fair and ethical data science as a career choice, a technology for disruptive positive change, and a movement that will reshape the African landscape for decades and centuries to come. We have hope and optimism for Africa and for African data science. We are constantly inspired and motivated by the amazing work of our African and non-African users. Anyone who shares these sentiments is welcome on our platform, and is invited to join us in building AI together, for everyone, and for good.",datascience
mgczg1,1617100586.0,Hostile members of an interview panel - how to handle it?,"I had this happen twice during my 2 months of a job search. I am not sure if I am the problem and how to deal with it.

This is usually into multi-stage interview process when I have to present a technical solution or a case study. It's a week long take home task that I spend easily 20-30 hours on of my free time because I don't like submitting low quality work (I could finish it in 10 hours if I really did the bare minimum).

So after all this, I have to present it to a panel. Usually on my first or second slide, basically that just describes my background, someone cuts in. First time it happened, a most senior guy cut in and said that he doesn't think some of my research interests are exactly relevant to this role. I tried nicely to give him few examples of situations that they would be relevant in and he said ""Yeah sure but they are not relevant in other situations"". I mean, it's on my CV, why even let me invest all the time in a presentation if it's a problem? So from that point on, the same person interrupts every slide and derails the whole talk with irrelevant points. Instead of presenting what I worked so hard on, I end up feeling like I was under attack the entire time and don't even get to 1/3 of the presentation. Other panel members are usually silent and some ask couple of normal questions.

Second time it happened (today), I was presenting Kaggle type model fitting exercise. On my third slide, a panel member interrupts and asks me ""so how many of item x does out store sell per day on average?"" I said I don't know off the top of my head. He presses further: but how many? guess? I said ""Umm 15?"", He does ""that's not even close, see someone with retail data science experience would know that"". Again, it's on my CV that I don't have retail experience so why bother? The whole tone is snippy and hostile and it also takes over the presentation without me even getting to present technical work I did.

I was in tears after the interviews ended (I held it together during an interview). I come from a related field that never had this type of interview process. I am now hesitant to actually even apply to any more data science jobs. I don't know if I can spend 20-30 hours on a take home task again. It's absolutely draining.

Why do interviewers do that? Also, how to best respond? In another situation I would say ""hold your questions until the end of the presentation"". Here I also said that my preference is to answer questions after but the panel ignored it. I am not sure what to do. I feel like disconnecting from Zoom when it starts going that way as I already know I am not getting the offer.",datascience
mg2lih,1617060756.0,Environment management skills,"After a slightly frustrating evening after work with VS Code and virtual environments and all that good stuff, I’m switching over to Spyder (which came with Anaconda, and therefore will find the packages I installed for my pet project).

A question off the back of this: how important & difficult is it to get a good handle on juggling these virtual environments? It looks doable but I have a list of things I want to do.

Background: 6 months into my first job out of college doing non-CS, so there’s a lot of random tech skills I need to develop.",datascience
mg0the,1617055478.0,"Is deep learning more ""computer science"" than it is ""Data Science""","Please bare with me if this has been asked before, but over the past 3 months, as I have continued my job search, I have picked up deep learning (Keras mainly). As a MS of DS student I found it interesting that deep learning has its own vernacular around popular statistical concepts (cost function (DNN) vs. loss/error (stats) is an example)

Then I started to better understand CNN, backpropagation, and CNN in particular really have nothing to do with stats, and everything to do with computer science / representing pixels as matrices, and analyzing these matrices accordingly.

I almost feel like deep learning is much more of a computer science, while data science is focused on more traditional statistical methods.

Is this fair to say? Thoughts on this?",datascience
mfxwjn,1617047463.0,How much of your work is descriptive rather than predictive or explanatory?,And how limited are your analyses by your data sources?,datascience
mfu3bo,1617037305.0,What are some of the most complex/difficult Data Science concepts that you've struggled to grasp?,"In my role (Data Scientist at an e-commerce company) I focus primarily on building recommender systems. We recently implemented a Variational Autoencoder based system, and while the architecture/implementation is fairly straight forward, unpacking the nuance and derivation of the KL Loss function (and understanding Variational Inference in general) I found to be quite challenging.


I'm wondering what projects/concepts you have worked with that you found challenging to understand/implement?",datascience
mfs2yw,1617031817.0,Does having few girl students in DS is common? Even in developed countries? Is it harder for girls to be in this field?,,datascience
mfqwpe,1617028562.0,"Has anyone ever made a ""html"" presentation instead of a ""PowerPoint"" presentation?","https://m.youtube.com/watch?v=qKU97mVs6nM&feature=youtu.be

I saw this video here that shows some of the advantages of a html presentation vs a PowerPoint presentation (e.g. smaller size, interactive graphs).

Has anyone ever done this before? Is there a straightforward way to make a html presentation? What software do you use for this?",datascience
mfhjwv,1616991654.0,Audiogram Data,I'm considering taking on an internship project that involves using audiogram data to predict/translate into parameters that can be used for hearing aids - does anyone know which libraries/models can be utilized to treat this type of data?,datascience
mf5q51,1616953267.0,"After a year of remote work, what does your WFH setup look like?","For those that are still working remote, how has your WFH setup evolved over the last year?

I'm currently using a work-provided 16"" MBP with a single 27"" monitor. The monitor has a built-in KVM which makes it easy to swap between my work laptop and personal desktop, but the screen real estate is a bit lacking. I'm curious to see what setups /r/datascience use to maximize productivity. Anything you guys really like? Hate? Upgrades you wish you made earlier?",datascience
mf5grs,1616952528.0,Disappointing Interview Experiences,"I want to (commiserate) hear about your terrible interview experiences. Here’s mine that happened a few weeks ago:

I saw a job posting for one of my most watched companies and it was for a job that was an exact mirror of my resume. I had work experience, academic research, and personal projects done in the exact area (and oddly specific tech stack I had worked in). I applied on Day X, they emailed me on Day X+1 to set up an interview for Day X+2.

I was scheduled for a 45 minute phone call to go over the usuals + some technical stuff. The interviewer called and started off the conversation by saying how they contacted me as soon as they read my resume. On the first “tell me about yourself” kind of question I stuttered really bad (I have a usually mild speech impediment but it is worse over the phone) and the interviewer’s tone immediately changed. I didn’t think this was going to be a problem because I briefly mentioned this in one of my emails giving them advanced notice. The interviewer basically was like “if you don’t have anything else for me I think that’s fine.” and ended the call after 4 MINUTES. It was a 4 minute phone call that was supposed to be 45.

I received the rejection email a little later.

Just very disappointed as this was a company I had built up in my mind and a place where I really could have added value. I will be okay as there are lots of other opportunities for me, but I was just very upset following this.

Has anyone else had a similar experience or any advice to offer up? Really not looking for sympathy as this is not a new thing and I will absolutely be more than okay in my career, but just wanted to hear from others about their bad interview experiences.",datascience
mf04oz,1616932830.0,Weekly Entering & Transitioning Thread | 28 Mar 2021 - 04 Apr 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
meykq1,1616925642.0,What are some methods to build Google Trend-like indexes?,"I have my own corpus of text indexed by date time.

I wish to generate Google Trend-like index based on this corpus.

Maybe for simplicity, I just want to avoid dealing with more complex issues like synonyms, etc.

Are there some good references on building these indexes?

Thanks",datascience
mevi0q,1616910311.0,At what point does data visualization require photoshop?,"I am looking at trying to make much more ""attractive"" data visualizations (using R software). I came across articles like this that tend to show you the capabilities of data visualization : [https://www.royfrancis.com/elegant-scientific-graphs-learning-from-examples/](https://www.royfrancis.com/elegant-scientific-graphs-learning-from-examples/)

These graphs look amazing - I tried to search online for tutorials that show you how to replicate these kinds of graphs ... but all you end up seeing is how to make the basic graphs (nothing wrong with that), but nothing which allows you to make it ""pretty"" (e.g. all the fancy labels, blocks of text, cool colors, etc.). At this point, I am starting to think that some of these graphs might have been created with advanced software such as photoshop, and not so much using python and R.

Does anyone have any ideas about this?

Thanks",datascience
men2hf,1616880310.0,"If you made a huge discovery to improve AI (e.g. Self-Driving cars), what would you do next?","I've sometimes wondered what I would actually do if I came across a discovery like this, it's not like I can just send Elon Musk an email.

What would you do?",datascience
megths,1616861488.0,Data science in a non tech company vs data science in a tech company,"Hey all,

I am currently working as a data scientist in Europe at a non tech company (a global brand) in fast moving consumer goods (FMCG) for a year, and currently got an open offer with a tech company (which would bring an increase of 17% in total compensation) that is quite popular in my country.

In the future, I would like to work for one of the big tech companies or start my own company. With this information, I am wondering staying at my current employer is the best thing to do or moving towards the tech company is the best thing to do.

The FMCG company overall has less technically skilled people, less challenging problems from a DS perspective, but a lot of emphasis on delivering business value (which is a plus) and is only at the beginning of transforming into a 'data driven business'. While I prefer to maximize the value we deliver with our solutions, I am afraid that I'll progress less on my technical skills. On the other hand, at the tech company, I'd be less business-facing and have more advanced use-cases that also involve more engineering.

Have you guys faced similar thoughts or a similar situation? What are your thoughts?",datascience
me2w0n,1616806234.0,What data science specializations do you think are worth looking into in the future?,"

I wanted to go down a route that may not be traditional, a field where people can stand out. What fields/niches do you think those might be and how could one enter? And also, how can one gain these skills?",datascience
mdwcsh,1616786843.0,Data Scraping Risks,I am working on a fun personal project where I am scraping some info on places and reviews. I want to analyze a large dataset based on the scraped data and put the analysis on Github. Also I would like to talk about this project during my job interviews? Can I get into trouble doing so? I know Google specifically does not like its data being scraped/stored.,datascience
mdlnvy,1616754558.0,Everything wrong with Zindi data science competition platform.,"**WARNING:** rant coming

I want to to share my unfortunate experience with Zindi platform. It is a data science competition platform, same as kaggle, but the bounty doesn't usually exceed 2000$, and it is geared more toward African countries.

I participated in a competition there hoping that the company hosting it would hire me if I win. After few weeks I snatched the second place on the leaderboard. I kept slightly improving it for the span of of what's left on the competition. Then, one week before the deadline, I got my account banned.

I opened my email thinking it was some sort of a mistake, I found an email sent by them stating that they banned me under the pretext of ""Collaboration outside of team"". I responded explaining to them that I single handedly worked on the solution of my problem, telling them I'm ready to provide proof if they want. They didn't respond.

Then today, out of sheer luck, I discovered that the team that took my place on the leaderboard when I got banned work as a data scientist for Zindi, which is quite preposterous to say the least.

How can they work in the company and be allowed to participate? Meaning it's in his advantage to ban people who are topping the leaderboard: they eliminate any competition, and they get the money. This explains the very empty, devoid of any logic explanation provided by Zindi as the reason on why they banned me, the such of ""Collaboration outside of team"", without the willingness to elaborate any further, or give sufficient proof, even if my solution out-performs theirs.

It's just insane. I would say stay out of Zindi, it is an unfair community, chances are not equal, and they are not professional. Zindi epitomizes everything wrong with African countries, conflict of interest, lack of respect to people, rentier state, and corruption (ps: I come from an African country).",datascience
mdf70q,1616727535.0,What is going on with SAS and how do you use it?,"My company is insane and, despite investing in cloud technologies and building out a team of python data scientists, they are silo-ing us to deploy all our products in SAS to facilitate collaboration with non-coding engineers (for context, we're in the energy industry so lots of MechE and EEs who are competent at data analysis but don't really program).


I have about a thousand questions I am praying the community can help me with. As you know, SAS puts all their products behind enterprise licensing so Stack overflow is failing me and I don't have any influencers on youtube to walk me through the mechanics like there is with python/R (if you are one of these people, know that I love you forever and always).

- What are good resources to learn SAS fundamentals? I have access to hours of videos from SAS that are all a series of sales pitches for how great the product is but don't actually tell you how it works.

- How does the data architecture of SAS work? All our data is stored in the Google Cloud Platform and I'm expected to pipeline this into SAS. Is this even possible?

- How can I explain to my boss that this isn't like the myriad other products we are expected to adopt? We're a growing branch of our organization so it is common for us to trial various SaS (software as a service) products but they give me a git repo I can dig into along with a support engineer I can ticket for elaboration. Not the case with SAS.

- Should I be updating my resume now because my company is run by morons who make python/R data scientists use SAS?",datascience
md9gtp,1616709299.0,Looking for a data visualization tool,"I am looking for an open source data visualization tool, ideally for Python, that can generate graphs similar to what is shown in the following link. I don’t know what this graph type is called. Any help is much appreciated.

https://media.istockphoto.com/vectors/stock-symbol-winners-and-losers-gain-loss-display-vector-id1143790377",datascience
md7z44,1616705121.0,"Is it better to pivot data before working on it, or to work with it unpivoted?","I'm getting into a lot of data projects lately and the data I'm being given is unpivoted. There is a primary key column that has repeating values, in my case company ID which is a ID number assigned to each company the sales team sells to, a process step column which shows where sales is in the sales process (five different steps), and finally the process step change date. If I leave the data unpivoted, if I want to do any sort of analysis on how long it takes to go from stage to stage then I have to figure out a way to subtract dates at different stages from one another for a specific company ID. If I pivot the data, then I will have repeating company ID values, and have the process step in their own columns with the process step change date as the values in those columns. There will obviously be blanks because there are multiple company IDs that I then have to delete. Which creates another problem, we can sell to a company more than once so if I'm removing duplicate companies, I could be deleting data unnecessarily



Any recommendations here?",datascience
md3r4b,1616693706.0,"Do you have a separate DevOps projects for data science, data engineering, data management and separate scrums, or is eveything kept in one DevOps Backlog?","Just curious how things are tracked - curently in a small team that will be steadily growing into more formalised functions over the next few years (thing DS, DE, governance, architecture, BI, etc) and some people want to integrate all backlogs into one and have one sprint for everything, whilst I have reservations about how this would work in practice when some workflows are just different (even if they need to communicate from time to time).

I guess I think separate DevOps processes ans backlogs that integrate into JIRA would work best and data scientists need only join DS stand ups on the regular and other stand ups on ad-hoc basis.

What's your experience and view of this?

Thank you!",datascience
md0sr1,1616685947.0,How annoying is it to see undergrads embellish their titles?,"Hello all, I’m a currently a sophomore whose been actively involved with various data science projects. Obviously once I gain some good experience at an opportunity I like to put it on my LinkedIn or resume. I never have been the person to “flex” internship or research positions, and I don’t feel that those who do it are bad either, if your excited about an opportunity you worked hard for good on you, I love to see such posts! But for me I don’t like the attention. I even turnoff the notifications on LinkedIn regarding my change in positions or when I get a new position so other people don’t see it.

Anyways, the point of this post is to guage how much it bothers data science hiring managers about the embellishment of titles by undergrads who are applying for internships. For example, this summer I’m doing undergraduate research doing data cleaning and classical statistical analysis, but I don’t call the position a “statistician”, or my other two positions I had previously as web scraping data sources/creating db for a professor and creating scouting reports for the university baseball team, I didnt call them “undergraduate data engineer” and  “data analyst” respectively. Am I right in not placing these titles on my resume? I have friends who put their titles as “data scientist” but I feel as though if I don’t have a degree yet or am an undergrad it would feel like I’m embellishing a title and it may annoying hiring managers especially when I apply for internships. Thus far I just have “research assistant” or “project manager” and talk about what I did underneath.

What do you think? Am I right in not putting such titles? Quite frankly I feel like the title is not as important as the actual work that is done right?",datascience
mcvi63,1616669701.0,What are your thoughts on analytic app frameworks in Python e.g. Dash etc? Do you miss R’s Shiny?,"Hi,

I am wondering what’s your opinion on frameworks for building dashboard / analytics apps in Python e.g. Dash, streamlit, Panel, voila etc?

In Python there seems to be some fragmentation. For example, people say that Dash is more customizable but has a verbose syntax while streamlit is easy to start with but not so customizable.

This is interesting because in R there seems to be a clear winner which is Shiny. I heard multiple people say that they either miss Shiny in Python or that they even go back to R when having to develop an analytics/dashboard app. (Kudos, that they are so fluent both in R and Python.)

What’s your opinion on this? Which framework do you prefer?",datascience
mcr4wc,1616651167.0,What is with the assumption that if you are using the jupyter you are a noob?,"I have usually read/heard this on platforms and all that if you are using a jupyter notebook you are a noob. Why the assumption?

Is it because the code is not production ready?",datascience
mcfull,1616617887.0,Any thoughts on M1 chips?,"It's new laptop time and my IT guy is of the opinion I should wait on M1 chips to come out on more powerful machines. He's a huge fan. Thing is, I do everything locally and we deal with some decent sized datasets. My main machine is an iMac with 128GB of RAM and on some of our datasets I still have to do some fancy footwork to read them in. My app memory usage is regularly over 100GB. So I'm concerned about these things only having 16GB. He's convinced the SSD is fast enough that it won't be an issue.

Can anyone weigh in on this? I'm primarily in R and do a good bit in parallel if that makes a difference.",datascience
mccvw7,1616610497.0,Propensity score matching and then testing to compare group outcomes,"I need to bounce some ideas around and am looking for any input .

I have two groups , one that benefits from a long ago implemented policy and one that does not .

I have data for the current year of these groups. I don’t have data pre-intervention.

I want to understand if the treated group offers any financial savings compared to the non treated group. Outcome variable is total cost per person in each group (but other outcome variables are of interest too)

Would it be unreasonable to propensity match and then use t test to compare different outcomes (or another test depending on my metric)

I want to Psm so it’s apples to apples .some members are more costly than others and this could account for that .


To add extra layers of complexity- from one year to another - people could actually switch between groups . I am
Not sure how to account for this .


Please let me know if this isn’t a good sub for the question and point me somewhere else . This sub is more active than stats.",datascience
mc77r3,1616596374.0,How do you motivate yourself to pursue your own projects in your free time when working full-time?,"Like the title says, I'm struggling to spend my free time doing extra projects. There are tools and project ideas that I want to explore but when I work M-F, full time, it's just so hard to spend my evenings/weekends doing this. I'm pretty early on in my career so I don't have family commitments but I really need my own time to recharge. The weekend just flies by and it's been more than two months since I decided to do my own projects but nothing's really materialized. Anybody struggled with this and any advice on how to overcome this?",datascience
mbr701,1616540156.0,How do you organise your reading materials?,"Recently I've been working in a research and development capacity and have found myself taking time out of my day to read more papers. I'm just wondering if anyone has any suggestions of software/apps you use to keep your reading materials organised? Right now I'm using Notion and it's pretty good, does the job, I can create pages to take notes of each paper I go through but does anyone use anything perhaps more specialised to do this?",datascience
mbq8dt,1616537450.0,Designing a Team,"Sort of curious what people would do if they had the opportunity to work for a team that was something “like the brochures” and not just a team that people came to with analytics questions.

Suppose you are given the opportunity to design a small (5-8) data science/machine learning team in an engineering department. Your team’s skills are legitimately data science/machine learning, not analysts, and there is skill in building production ready software among some members.

the question is sort of an open-ended “what if?” but am curious how people might answer some of these questions as examples:

How do you help people in the org who might come to you with analytics/KPI questions without brushing the off, but helping them get to the right data they need. In other words what is your interface to non-engineering business types if they don’t have direct access to your priorities?

How are tasks handled? Are you still in an agile process where people pick up tickets as they free up resources? Do you allow multiple people to work on the same ticket? What is considered a “unit of work”? In other words, is your focus solely on direct applications or do you devote significant time to experimentation, and if so, what does experimentation look like?

What do you differently that other engineering teams wouldn’t even think to do but you think are important to your team? How do you get buy in for all of the “Data Science has to do it this way because...”?",datascience
mblsxz,1616525514.0,How important is AWS?,"I recently used Amazon EMR for the first time for my Big Data class and from there I’ve been browsing the whole AWS ecosystem to see what it’s capable of. Honestly I can’t believe the amount of services they offer and how cheap it is to implement.

It seems like just learning the core services (EC2, S3, lambda, dynamodb) is extremely powerful, but of course there’s an opportunity cost to becoming proficient in all of these things.

Just curious how many of you actually use AWS either for your job or just for personal projects. If you do use it do you use it from time to time or on a daily basis? Also what services do you use and what for?",datascience
mbg20h,1616510056.0,Selling Data,"Hey!

As a side effect of one of my projects, I now have a dataset full of random images that have been described and labeled by a person. This made me curious about the market for selling data that has had human intervention, in this case maybe for a test set in a machine learning algorithm so that the model's accuracy can be calculated. I am not necessarily interested in what I can do with my current dataset, but just curious about how this type of data is generated and how it is distributed. If anyone knows any information about this field I would be very grateful.

Thank you!",datascience
mbekp1,1616505646.0,Visualising anatomically-linked data interactively,"I am a PhD candidate in pharmaceutical science, with a dataset from a very wide lit review/meta-analysis. The dataset describes the concentration of a protein in all different tissues and cells of the body.

I would really like to make some kind of interactive visualisation (like a Shiny dashboard using R) of this data, where hovering over different regions of a human silhouette would show summary statistics for that region (mean/max/min concentration). Ideally, clicking the region would zoom into it, and display all the values + references for the papers they were obtained from.

I've done a good amount of data wrangling, processing, visualisation etc as part of my PhD, in both R and MATLAB (and a little Python). Is my goal a) achievable at all, and b) achievable with these tools? If so, what packages/modules would you recommend? If not, I guess post F in chat.

<3",datascience
mb4yqf,1616468301.0,Geo-Spatial analysis and visualization techniques?," I'm just curious what tools and processes and analysis practices you've used.

I'm relatively new to granular geo-spatial analysis.

I'm looking into uber's h3 hexagonal map (basically translating longitude and latitude coordinates into hexagons of different sizes 1-12 that cover the globe --- the grouping allows for categorization and logical analysis).

Is there a tool that can quickly visualize a table of long/ latitude coordinates into these hexagons? (I can of course map to the hexagons).

I'm researching myself rapidly here but --- wondering if anyone has any insight. Say I have a bunch of hotel lat/ long in the city of Nashville. What would be a rapid way to translate these into say Uber h3 hex size #10 -- or frankly any size -- (they did a lot of the legwork already) and then map said results?",datascience
mazvd0,1616452475.0,realize I don't want to be hardcore stats guy,"I like statistics and the theory behind a lot of the models implemented in data science but I don't think I can be learning this stuff for the rest of my career. I feel like the more I learn the more I realize how much more there is. I'm not sure if all subjects just keep getting deeper and deeper or if data science is just really hard to master due to the combination of CS and Stats. Right now it's the linear algebra foundation of PCA,  I can obviously do the matrix multiplication but I don't understand how it reaches the result and feels like magic to me. But I have so many subjects to go through, not looking forward to data structures and how computers work. I feel like I can keep doing this for 4 more years or so but I'm worried it's never going to end due to the field evolving. I really like presenting to upper management and applying business domain to problems and just plain old thinking about problems. I'm not sure what this realization means for me, I guess I'll keep up with data science for now but where do data scientist go after they say enough math? Or am I just being a wuss",datascience
mazc6k,1616450963.0,What does it mean when changing the seed changes the predictability of a model?,"I have a glm model that outputs a percentage of likelihood in predicting a binary outcome variable. Whenever I change the seed, the prediction value for all elements is different every time. I ran some loops with hundreds of different seeds and saved the results, and the majority are in the same ball park, but some are way off.

You could say, if you get many different results, it’s a bad model, but if that’s the case I don’t get how some seeds are super predictive. The sample size is too large to be considered random chance.

Any guidance here would be appreciated",datascience
mavhpl,1616440465.0,"That feeling when C suite would rather keep you grinding support and busy work, while asking you to teach the middle management your entire graduate degree instead of just making your title data scientist and tasking you with that stuff...","Yeah, so, innocent question about some analyses by an executive to me because I have a MSCS with focus in data science is turning into me giving a lecture series to middle management about how to do said analyses, instead of just promoting me/changing my title and taking me off the shit dino-tech generalist BS role I’m in already.

They’d rather just keep me marginalized doing menial support and basic BS programming in some godawful proprietary stack, knowing full well I’m underemployed there, ask me to show them how to do stuff I spent years learning instead of just making my role the one to do that and take me off the BS work.

I wish I had enough cash to just ghost this place, but I can’t even get an interview while I’m employed (because of said garbage work I do and why I pursued my masters independent of this job).",datascience
mav35m,1616439416.0,Dwindling Team,"Hello! My data team at work is slowly losing more analysts as they look for jobs at other companies. I’m wondering if there are any guidelines when it comes to continuing good work while we actively look for analysts to hire onto the team.
My main concerns are the slowing down of typical turnaround times, senior analysts being forced to do less-exciting work yet again etc.
Any tips would be greatly appreciated! Thanks in advance",datascience
mauadb,1616437293.0,How to move away from creating dashboards?,"I currently work as a data scientist for a govt owned corporation. This corporation has different business units under it and I have been working as a DS in one of those business units for an year now.

I am the only ""technical"" person in my business unit so no one in my company understands my role. They just call me ""the data person"". Anyway, I have done around 8-9 data science use cases (mostly regression problems and some clustering and classification problems) for my business unit and the insights are actually being used by the business.

Few months back, my boss asked me to ""assist person X"" in creating dashboards. Person X has no idea how to use any visualization tools and is at a much senior position than me so I basically created a few dashboards for person X. Everyone at my company lost their minds and started praising me ""for leading them to a data savvy stage with these dashboards"".

I was then asked to share my key achievements with all the business units of the corporation.  I had to explain 2 of the key data science uses cases and one dashboard as well. After the meeting ended, I was bombarded with so many requests to create dashboards for all the business units of the corporation. I was a little disheartened  regarding this tbh - I spent so much time creating and explaining those data science use cases but what impressed them was that one dashboard. Ugh.

Now the problem is that I don't really enjoy making dashboards. Tbh, that was the first time I made a proper dashboard for a business and I didn't bother to research much into the whole dashboard process cause I am not that interested in it. I prefer coding things out rather than using drag/drop tools.

Most of the work that is ""formally assigned"" to me is EDA like work which I do using python scripts. During my free time, I would think of ways to implement data science use cases and start working on it. Since I will be busy with all these annoying dashboard requests, I won't have time to work on data science use cases which is really annoying me.

How do you think I should approach this? The boss of my boss has already dragged me into these dashboard requests without consulting with my boss. Even if I express my unwillingness to my boss, I don't think he can do anything cause of the designation hierarchy, right? :(",datascience
matdze,1616434964.0,Any data scientists and data engineers who work in hospitals care to discuss their experience?,"I have a similar post on r/cscareerquestions to get information from the software engineering side.



My company wants us back in the office ASAP, and my wife got a new job offer in NYC. The job market in NYC is still kind of rough at my level of experience, but was thinking of looking at non-profits and hospitals too.

NYC seems to have a huge amount of big hospital systems, including Columbia, NYU, Cornell, and Mount Sinai, so it seems like a big area to work in.

Can anyone describe the interview process, salary, average workday, and potential to switch back into the tech industry afterwords.",datascience
mam99b,1616415786.0,Is the subscription for Towards Data Science (Medium blog) worth it?,"I must say from the start that I’m a novice, so advanced articles definitely won’t help me. As far as I know, there are many articles written in a tutorial-style, some of them suitable for beginners and I would be interested in them.

However, I’ve heard that Medium is not a reliable source of information and the quality of articles might be poor over there. I can’t judge by myself whether this is true or not because of my lack of experience.

What do you think? Is it worth it?",datascience
mai469,1616400012.0,Working at consultancies?,"Does anyone have experience working at a consultancy?

Mainly doing government work and/or making small products in a ‘startup’ sort of environment.

What was the work/life a balance like?
Did you have suitable people to mentor you?
Was the tech stack modern?

Share your experience!",datascience
m9yvwq,1616340142.0,How To Give Effective Feedback (Without Sounding Like An Asshole),"You’ve probably heard of Toastmasters, the organization helping people improve their public speaking.

I noticed the level of detail with which they approach giving feedback.

Think about it. If you fail to properly articulate the *why* behind someone’s subpar performance, they’ll likely just ignore your comments because they’re not actionable.

On the other hand, if you’re a bit too blunt, you risk offending someone. And ironically this leads to most people not doing anything because instead of focusing on what you told them to improve, they’ll go into defense mode.

I’m convinced that the Toastmasters Feedback Guide can be applied to our day to day as Data Scientists.

Let’s get into it. Here are **6 actionable tips** that you can use to give feedback that doesn’t suck.

**1) Setting clear and concise objectives**

Before you give effective, actionable feedback, you actually need something to measure it against. These performance expectations and goals then need to be clearly *communicated* to others around you.

The new intern at work is not going to have the same level of expectation as your veteran data scientist. That doesn’t mean the intern can do crap work - it just means that what you expect from both individuals is going to naturally vary.

**2) Provide immediate feedback**

Right from the Toastmasters guide:

*The passage of time diminishes the effectiveness of your praise or criticism.*

If the feedback you give is too late, then your co-workers won’t be able to act on it, because they’ll have forgotten what they did. There’s a reason why back in High School your teacher would give you feedback on an essay before you wrote the next one. It sounds simple, but in a fast moving workplace it can often be forgotten.

**3) Be Specific**

If the feedback you give is too general or broad, your message is going to be hard to interpret. And when what you’re saying can’t be distilled down into something specific, it’s going to be ignored.

Here’s an example. Instead of saying:

*“The product presentation you gave to the sales team was too technical at times.”*

Say:

*“On Slide 7, I noticed how you went in-depth into how our bidding algorithm works. But it was a bit hard to follow because the sales team didn’t have context on the algorithm. A slide earlier explaining why it’s needed in the first place would have helped make it more digestible.”*

**4) Use the “I” Technique (my personal favorite)**

Avoid using “You” too much when giving feedback. It’s one of the main reasons why someone might get a bit defensive.

Remember: this is feedback coming from your perspective. It’s not some kind of label you’re trying to stick on someone.

Say, *""I felt like you didn’t spend enough time crafting next steps to follow up the presentation we gave yesterday""* rather than *""You were unprepared yesterday""*

**5) Start and End in a positive manner**

A good rule is to start off with something positive. This disarms the person and allows them to ease into the conversation.

Once they’ve settled down, you can share more constructive criticism. Studies have shown that the ideal praise-to-criticism ratio is 5:1. Meaning, for every negative comment you make, you need to share five positive comments as well. Five might seem like a big number, but I’ll get to this in a bit.

Finally, try to end on a positive note too. Give them a roadmap to aim for and express your confidence in them.

**6) Feedback is a continuous process**

Some of you might have gotten scared when I stated that the ideal praise-to-criticism ratio is 5:1. Five seems like a big number.

But if you’ve put yourself in a situation in which you’re just stacking negative comments on top of negative comments, there’s likely a huge communication gap that has led to the low level of performance. Perhaps a project or presentation aim wasn’t clearly communicated.

Or more likely, you’ve just waited too long to give feedback. If the only time you give someone feedback is during their quarterly performance review, then they’re going to be surprised. They won’t know where they stand and will blame you for not being more transparent with them sooner.

And that’s the last tip - make it regular. Giving someone feedback shouldn’t be some type of formal, ceremonious event. It should be frequent and simple.

\*\*\*\*\*

That’s it folks. I hope that was useful.

*If you liked this post, you might like* [*my newsletter*](https://www.careerfair.io/subscribe)*. It's my best content delivered to your inbox twice per month. Cheers :)*",datascience
m9w70f,1616331633.0,Anyone started a PhD after a few years as a data scientist?,"Hi All! Wondering how many people have worked as a data scientist for a few years then gone back for a PhD whether just for fun or to advance the career. Mostly wondering how you were able to sell it, like we use a ton of ML models to solve business problems, but they're rarely cutting edge and probably difficult to sell as academic research.

Did anyone get any impressions of how data scientists were viewed in academia? Whether the industry data science experience helped or hurt you in being admitted to top schools? And what it was like to go back to a PhD after working as a data scientist?",datascience
m9v7ok,1616328030.0,Weekly Entering & Transitioning Thread | 21 Mar 2021 - 28 Mar 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
m997qc,1616253944.0,Modern infrastructure and Data Science,"I've spend the last years mostly in DL and there I'm am quite happy with our current tooling and infrastructure. However, lately I've noticed that there is another area of data science where I now find myself lacking knowledge now. It seems I've missed too many trends while I only looked into DL:

In our company there is an undisputed trend away from larger standalone machines towards lots of small instances. In particular we have set up some on-premise k8s clusters with the possibility to launch plenty of pods on many worker nodes. However, individual worker nodes support very limitted amounts of RAM. Since this transition was managed by people with much deeper knowledge about infrastructure and modern software engineering than me, I'll trust they know what they are doing.

Now what I observe in our data science team: There are still lots of applications that require huge amounts of RAM. Sometimes unncessarily and simply because they're written by novices, but mostly for good reasons. Often large amounts of data has to accessed with fast random access. Hashmap-like access still is a great way to do this and I've been seeing everything from very basic solutions à la ""just put it in a large dict"" over intricate special-pupose indices into compress data to well-known data structures (tries, btrees, bloom filters) used just like your algoirhtms and data structures prof would have wanted them to be :)

This means we're still using a lot of legacy hardware, running programs that use 30, 40 or even 60GB RAM at times. SUch instances are not supported by the new kubernetes could.

An obvious pattern to resolve this would be to just move data into third party software and frameworks that allow horizontal scaling, deploy them into kubernetes and use them as data backend for everything. Large pandas df -> spark. Large dictionaries -> redis / mongo / whatever, and so on.

That said, I see a few downsides:

1. I really dread the management overhead for all these thrid-party things. New versions, incompatibilities, etc.
2. It would take a lot of convincing to make all data scientists embrace the new paradigm and get comfortable with kubernetes at all (I hope juypter enterprise gateway could help us here).
3. I would imagine the new solutions would sometimes be slower than the status-quo. After all, RAM is pretty fast and some projects even condiered cache-efficiency in the design of thier data structures. Outsourcing this to horizontally scaled off-the-shelf solutions is porbably only worth it once we scale it further than the sattus quo (for which there is no imminent need)

What is your view on this? Is there a different way to approach this transition? Or do you have experience with similar transitions and would you say it was worth it in the long run?",datascience
m96sfw,1616245987.0,What is the percentage breakdown of your workday?,What is your job title and how many years of experience do you have?,datascience
m8wcnl,1616203514.0,Julia vs R/Python,"Recently, I found a programming language called ""Julia"" that is used for data science, statistical analysis and machine learning. Does anyone actively use this software for their work? How have your experiences been with Julia - does it offer anything that R and Python can not? Is it worth learning Julia (e.g. some companies still have a loyal SAS user group, does the same happen with Julia?)?",datascience
m8ksxl,1616170632.0,People who've built data science architecture from scratch - how did you go about it and what were your experiences like.,"This is the accompanying question to the ""how did you build a DS team from scratch"" that doesn't quite seem to be discussed as much.

Let's say you have a very simple product that offers a portal for users to log in, runs on EC2 servers in the cloud, does read and write into a DB, etc.

How do you build on the above gradually with things like a Data Warehouse (and how do you decide when this is needed), and introducing Machine Learning into the mix in a product where the only thing it references is just the database itself.",datascience
m8kjzv,1616169954.0,What no-code tools are you using?,"Everybody talks about no-code. But actually, what no-code tools are you using at your job? Do you have any specific tasks that you would love to replace with a no-code tool?",datascience
m8ixqe,1616165516.0,"What is your approach to building a time series model, before coding to after deployment","I want to know your process of building a time series or other predictive model from scratch.

Sources - How do you keep track of the data used, stakeholders interviewed, assumptions made, sql codes, python/R codes, markdown, wiki, etc.  Code reviews? How do you convince other teams to use your model? What output do you give them the data (csv? web app? power point deck? api? ).

Quantifying Success - How do you measure success outside of RMSE? Do you revisit your projections and measure your errors and revise your model? Is it built to do that automatically?

Team - How big is your team? Just you? Who else is involved in the stages of work (research, data sourcing, review, deployment, follow up)

Do you follow CRISP-DM or other framework? Loosely or rigidly?

My main fear with my own project is building a model no one uses. I am sure the project's success will depend a lot more on ""soft skills"" like relationship building and cross-department communication, and less on my code or if I use ARIMA over ETS or whatever.",datascience
m8g75q,1616157088.0,How to use Product Matching to create Product Bundles,"

I am working on a product matching model.

**GOAL**

* A store has many products like creams, perfumes, other beauty products.
* Based on product properties I have to cerate bundles of it so we can sell more product at once while giving a small discount to the customer.
* I can not make a project based on Collaborative filtering because the goal is to have similar styles matched together ex.: 1.) Hugo Boss perfumes and creams, 2.) Summer lipstick collection (any brand). That is what is our customer base is all about that we have big sales and nice discounts. Currently these products are matched manually.

**Project Plan**

\#1. Product Matching \[Clustering Algorithm, Unsupervised Learning\]

* **QUESTION 1.1.** It has about 70 metrics. For product\_type(lipstick, cream, perfume) -> at unsupervised learning (Clustering) should I A.) label Encode this or B.)one hot encode it?
* **QUESTION 1.2.** What Unsupervised Learning algorithm you recommend if I don't know how many products groups ther should be. We have currently 4000 products. (I am currently using: Agglomerative Hierarchical Clustering)
* **QUESTION 1.3.** How can I get an ALL PRODUCT x ALL PRODUCT matrix with 1 number in each matrix cell that defines the closeness of the 2 compared product
* **QUESTION 1.4.** What should be X and Y axis of a plot when I want to see product groups like in simple k-means clustering. I have more than 70 product properties.

\#2.Salles Representative want to define some parameters of the products (price, product types)

* My goal if they pick 1 product (they copy the product\_id to the cell) -> that an excel sheet looks up for them that
* They want to define things like: product type(), Quantity, Price, Margin %, Review Score(at least 4/5 star on our site), Wishes(it is on people's Wishlist) -> ex.: the sales person can filter it that he only wants lipsticks in an excel sheet -> so he get the closest matching lipsticks

\#3.Supervised Machine Learning Regression

* Predicts sales based on previouse product bundles that the salles representative created even before this algorithm.",datascience
m8firo,1616154669.0,"If DS is evolving into sub-specialties, what are they exactly?",I know about ML but what else is there?,datascience
m8dky4,1616146546.0,Can somebody give an example of their model being audited?,"I keep hearing concerns about reproducing old models. While I might see the reasons behind rolling back due to technical needs, some bring forward auditing reasons.

So I'm interested in who gets to audit your models? What does that process look like? What do you need to present? What are they specifically looking for?

Thanks!",datascience
m881tj,1616123914.0,"How do you go about negotiating a contract (hourly rate) position? Any tips, pointers, lessons learned?","I got a job offer from a FAANG as a remote data engineering contractor for a 6 to 24 month contract.

Now that I have the offer, I would like to get an idea if the compensation makes sense enough to leave my current job and take on some of those risks as a contractor.

What were some lessons learned from your negotiations as a contractor?

What were you able to negotiate on and what do you wish you did differently?

\----------------------------------------------------------------------------------------

For further background:

I have only worked FTE positions, and my current total compensation (salary, bonus, benefits, retirement) is $127k.

To get this position, I worked with a staffing agency called Insight Global to get the contract. During the initial conversations when salary was mentioned, they said max hourly pay is $75/hour -- which translates to an annual $156k by multiplying by 2080 hours -- (52 weeks, 40 hours/week).

I am not sure if this max rate is determined by the FAANG, or by the recruiting agency, since my understanding is that I will be a direct contractor to the FAANG. One perk is that the FAANG allows 15 days PTO, but that's about it.

I have heard the best way to determine hourly pay is to increase your base salary by 30% to cover benefits and retirement, so in my case salary + bonus = $105k \* 1.3 = $136k -- so the hourly rate seems more than enough.

I plan on taking the offer since it looks like a challenging and interesting opportunity for growing my skills and learning. My wife and I will probably get a cheap health plan off the Exchange since we will be without benefits.

I would like to negotiate since it seems like I'm in a good spot -- already have a full time job, so I have that leverage.

Any advice is much appreciated!",datascience
m86joz,1616118831.0,I'm scared for my future,"I'm a college student with a Data Science major and Accounting minor, and I'm frightened for my future. Recently, I've been reading about how competitive the market is and I'm afraid that when I'm finished with my degree then I won't be able to get a job. Furthermore, I struggle with coding. I know coding is such a large part of this job, so it just hurts me to know that I suck. My professor says I'm doing the right things going to office hours almost every single day, but I feel like I get the concepts but don't know how to create the code. I hate the feeling of writing code but it fails but when I get it right, it’s like the best feeling ever. Generally, learning comes easy to me. I hate to say it but time flew by in high school. School came to me easy, I graduated with a really high GPA and perfect attendance (what a nerd). I'm not saying I never worked hard at all in school because when it came to dual classes I worked my ass off. I feel like I have imposter syndrome and that I'm not learning anything. I love data and stats, but I love the business side of the career even more. I like the concept of being able to explain the models and have an impact on the company. Would the best course of action be to take online python courses in the summer and stick it through? Also, in my course, we have three cognates which are Inferential Thinking, Business Intelligence and Analytics, and Machine Learning. Which would be the best? Inferential Thinking contains mostly statistic classes, Business Intelligence and Analytics contains BIA and INFS classes, and Machine Learning contains a bunch of CS classes. Thanks, DS guys, this year has been rough on me mentally. This is my 2nd semester and it's been hard. After this semester I will have 51 credit hours and I feel like life is moving so quick for me. I barely get to hang out with friends anymore and I am pledging for a fraternity (mainly for networking), so this semester has been my hardest. Any tips or advice would be awesome!

Edit: I haven’t started on my Accointing minor at all and I have decided on switching to Business Administration for my minor to be more educated on the business side of things",datascience
m816ei,1616102841.0,"Lost 700 gb worth of projects, codes, data sets, tutorials, reading materials as my external hdd got damaged. It was 4 years worth of work and personal projects.😫 Whats your data loss story?","Tried recovery software, but didnt get any valuable data.😴

Please suggest some best practice to store data other than 3rd party cloud storage like google, dropbox, etc.",datascience
m7yea7,1616094748.0,Data Science salaries in India,"For those from India, can you share the base salary you are earning with your years of experience? I've been offered a raise at my company and want to understand if I'm being offered according to market standards.

As for my background, I'm an IIT graduate and have 3 years of experience.
I'm currently working out of Bangalore, India. My current base salary is 19 LPA which is being revised to 25 LPA (~34K USD) (24 fixed + 1 variable) from April'21.

Any data would be helpful. Thanks!",datascience
m7tt1h,1616082714.0,How is testing conducted in data science?,"I've seen people stress the importance of testing, but how is testing used in data science?

I'm aware of unit and integration testing in software engineering, but am having trouble seeing how it applies to data science when an output given some inputs is usually not deterministic. It would be great if any one has recommendations for resources to learn about testing in data science.",datascience
m7slnv,1616079404.0,Should I accept the FANG offer?,"Hi guys,

I have 4 YOEs and am in a data role right now. Current co has lots of challenging projects and I enjoy the technical work that I’m doing. Recently got a FANG offer, TC lift is more than 60%. Scope of this role is 50-50 tech and stakeholder management. I am pulled towards this offer solely because of the brand and the TC lift. Not too hyped about the role due to the reduction in technical scope, but I also do recognise the need to have more experience in stakeholder management in order for me to grow. What do you guys think? To go or not to go? Super torn",datascience
m7rxp5,1616077498.0,What are some limitations/long-standing goals of probabilistic programming languages?,"I'm very interested in probabilistic programming language design, but I have very little user experience in actually writing probabilistic models and performing inference, hence I lack awareness of what technical limitations one might find when trying to program with realistic models in everyday life.

As an example, I'm aware that a desire is to be able to perform inference in a *modular* way so that distributions, probabilistic queries, and inference algorithms, can be reused, composed, and modified - but I have no in-depth knowledge as to what this elaborates to.

It would be extremely useful/interesting if people could provide their personal user-experiences (either as programmers or statisticians) with any languages they've used, such as Church, Anglican, Pyro, TensorFlow Probability and PyProb, etc. Or if someone could point me to some nice resources around this.

Thanks a lot! (Please let me know if I've posted this in the wrong place).",datascience
m7pbp5,1616069102.0,Senior Data Scientist vs Senior Data Science Consultant,"Senior Data Science Consultant is my new title. I would like to use Senior Data Scientist on my CV. My actual duties are hands on work for long term projects rather than just presentations and consulting.

Do you think it is acceptable to have Senior Data Scientist as a title on CV/LinkedIn?",datascience
m7n4ur,1616059831.0,How much of your time do you spend with boring data tasks because your colleagues cannot code?,"Hey,

when talking to other professional Python/R users, I sometimes hear them complaining that they have to spend a lot of time answering basic data questions for their colleagues just because they cannot code.

I am wondering: what's your perception about this? Do you have the feeling that you are hired for your Data Science skills where you are actually working on interesting and challenging tasks or do you spend a lot of your time just bridging the gap for colleagues who cannot code?",datascience
m7jvg6,1616044952.0,Data Science Blogs?,"Title pretty mcuh sums it all.

The last post on this sub regarding this topic was 2 years ago, so I'm posting hopeful that the list is more updated.

Currently reading towardsdatascience.

Any other suggestions?

Edit: Thank you for all the responses, very helpful.",datascience
m7blw4,1616017703.0,Mainframe Limitations,"Has anyone dealt with the limitations of data science against a mainframe, and if so, what was the key to success?  As background, I recently took over a team with the mandate to start developing analytics and predictive models. However, a large portion of the data we might be interested in is stored in mainframe files.

We can access subsets of the data in downstream data lakes, but those tables are highly curated or transformed, without clear source to target mapping.  We also have the capability to use EasyTrieve to extract mainframe files, but that tends to be a manual and tightly controlled process.

I’m currently researching an API or other connection that would allow for use of Python, Power BI, etc against the mainframe files.  I’ve also toyed with the idea of creating regular batch jobs to push entire mainframe files into an SQL server for our purposes.

Any thoughts would be greatly appreciated.",datascience
m76iz0,1616004272.0,How to handle a potential career misstep?,"TL;DR: I was working building cool stuff at a big company but didn't have opportunities to build my skillset, so I took a job with a smaller company that indicated I could do the same thing, but have more resources at my disposal. I took the job and now I'm building Tableau dashboards based on requirements lists.


Hi everyone,

I am curious to know if anyone else has found themselves in a similar position. I work in healthcare analytics and recently left my previous role after 3 years at the company. Overall, I liked my previous job, but I was the only person with a ""data science"" skillset in my area. This came with big trade-offs. On one hand, I was seen as an expert and had good discretion on project selection. What started to concern me was growth. I didn't have others around me to hold me to a higher standard and there were very high barriers to truly productionalizing work. As in, deploying containers to a production environment / working on real-time issues was basically impossible. Most projects had to be run monthly on personal computers and IT support or access to IT tools was non-existent, so I started looking passively. This was a publicly traded, top 50 US company, but my area was only responsible for about $400 million in revenue.

I was contacted by a smaller, private company (~$300 million in revenue) in my area, and had a few rounds of interviews with them. The director of analytics and the manager I would be working for were both very knowledgeable people. I expressed the areas I wanted to be able to push forward with and what I had done in the past. I discussed that I was an end-to-end consultant. I worked directly with stakeholders, got an idea of their needs, prototyped ideas on how I could develop solutions, and did all the AI/ML work. Sometimes I would work with an analyst to package the results into Tableau. They seemed really interested in my work (I built predictive engines for deal modeling, fraud detection, competitor price estimation, churn, etc) and I asked them what problems/projects they had on the horizon. They shared some ideas that seemed interesting. I asked about whether they get IT resources and if they can deliver solutions and they explained that they have recently started working in AWS.

So, I started there just over a month ago and to some extent I feel like I was sold a bag of goods. They have me working a Jira queue for projects that get submitted with requirements lists for dashboards that business users want created. They don't seem to give much thought to what projects could make money for the company or save operational costs. At the time of the interview, they did ask me a few questions about Tableau, which I answered fine, but explained that I didn't use it much in my role. They also asked some fairly straightforward questions about models like what parameters would you tune in certain libraries, differences in regularization techniques, etc. The types of questions I would ask a candidate just to make sure they weren't lying on their resume.

I got about a 20% increase to leave, so I'm paid well, but honestly I have no idea why they would hire me for this type of work. I had several viz-focused colleagues that I'm sure would be happy to take double the money for a role like this.  I thought I did a decent job interviewing them, but it really feels like I've made a huge mistake. I've met with my manager to ask about strategic priorities and how we manage the project queue. His examples of strategic priorities were just bullet points from a project that had been submitted by the sales team. I'm sure things could improve, but it has been a serious shock to the system thus far. The most charitable view I can take so far is that they want to take on new styles of project work, but haven't gotten there yet and are just staffing up for the future.

Sorry for the long post, I tried to keep it brief and left out a lot of other strange tidbits. What would you do in my position?",datascience
m74yvs,1616000315.0,Do you ever stick with legacy estimates or always use the most recent?,"I couldn't think of an elegant way to explain the question in the title so hold judgement on it until I explain further with an example.

Many of the data sources I use are estimates. For intercensal population from the Census Bureau as one example, when a new version comes out the source will update the prior year's estimates using the new data. In v2020 population for Springfield in year 2015 could be 1,000. But then in v2021 population for Springfield 2015 might be 1,005. In some cases the changes are so extreme using older data is just not possible. However, most of the time it's minor enough not to change takeaways but rather just to make the results a little different. This is the case with a good number of the sources I use.

I feel bound to use the freshest data possible. The non-technical folks hate this. It means prior materials no longer jibe with new ones and they have to explain it to clients. So I always get pushback on it. There have been a few situations where I simply couldn't convince my boss and had to use prior estimates.

So my question to you, my data brethren: does anyone ever utilize the old estimates in situations like this? Do you think it's defensible? Or are there no circumstances in which you would ever do so?",datascience
m74n1a,1615999426.0,Text Analytics & LDA Topic Creation -- Any success stories?,"I've been doing some text analytics work, and am trying out LDA (Latent Direchlet Analysis) as a way of categorizing text into different topics.  I've used it for two sets of survey data, one from local post offices, and one from medical education, and some police report data.

I'm unwhelmed by the results.   For the data sets I'd done topic modeling on by hand, and have a fair amount of domain knowledge.   I've played with varying parameters, but had a fairly clear idea going in what a 'reasonable' number of categories would be.

The category clusters use common words, but I can't think what the clusters are supposed to represent, even when I go back and look at the quotes that best match those categories.   For example, with the post office one, you'd think ""Damaged stuff"", ""Late Mail"",  ""Missing Items"", or ""Like my Mail Guy"" would come out, but I can't go from the word clusters suggested by LDA to any of these obvious categories.  In the medical stuff, one concept that gets mentioned a lot is ""Broken Arm Syndrome"", and I find that ""Broken"" and ""Arm"" appear in different clusters.  (There's nothing else in this data set related to ""Broken"" or ""Arm"" separately).

I'm wondering if text size is the problem.  While the corpus size is at least 10k's of words, and \~1M in some sets, the individual quotes are almost all <100 words, with some only a few.  Could that be the problem?   Those of you who have some experiences with real data sets and LDA, could you confirm or deny whether you've been successful.  I'm best in R, but I've done some work in Python and SAS Viya also, and done LDA in all of them. Before getting into real data, I ran through some online exercises in R and Python, for sorting chapters of classic books.  (You know, where you get ""20,000 Leagues Under the Sea"", and ""Nemo"", ""Submarine"", and so forth pop out, and ""Pride and Prejudice"", where ""Elizabeth"", and ""Proposal"" pop out, and so on.)",datascience
m74h1q,1615998988.0,Using data skills for activism,"So I work as a full stack data professional (handle both engineering and science) and have recently become very interested in doing some side projects around using data for activism. My first thought was to look at some examples of people doing this or maybe some blogs or online communities to get ideas around what I could do to help my local area.

However, my google searches are really only turning up articles around ""Data Activism in the workplace"" or are ads for cloud data platforms. Does anyone have any good resources on the topic, know some better terms to search, or just have their own ideas in general?",datascience
m72vvw,1615994738.0,Best libraries for distribution based modeling,"Hey folks,

Looking for some good repos to read over documentation for purposes of distribution based modeling. For example, which repo allows me to use poisson for queue building, etc.

I haven’t used distributions for modeling so new to this. Any repos that also profile data-frame and provide distribution recommendations? Thanks!",datascience
m71ijk,1615990949.0,Imposter syndrome and prioritizing what to learn,"Imposter syndrome comes up in this sub a lot, and as someone who feels like he has (mostly) learned to manage it, I wanted to share my experience with it - and what was ultimately my major breakthrough.

In a nutshell, there are three ideas that you need to get in your head in order to get over imposter syndrome:

1. You are a generally competent person
2. There are always going to be people that know more about a certain area of data science than you *and that's ok and expected.* Even more importantly: you're not the smartest person in the planet, so if you look hard enough you're going to find people that are better than you at everything you do *and that's ok.*
3. You have a finite amount of time to learn things, and your goal shouldn't be to learn the most, but to learn the things that maximize your specific goals - generally, this is going to be career advancement, but for some it may be something else.

In that order.

I think that, generally, imposter syndrome shows up in a thought cycle that goes the opposite direction. That is:

1. You don't have enough time to learn something you want to learn.
2. You look around and see that there are other people that know that thing you don't have time to learn
3. You feel incompetent

So when you feel that, flip it:

1. Remind yourself that you are a competent person - if you weren't, you wouldn't have gotten to the position you are in right now, whether that's graduating from college or leading a data science team (yes, even DS team leaders catch the 'drome from time to time).
2. Remind yourself that when you look for people who know more than you about a specific area, you are guaranteed to find them - that's just how it works. People choose to specialize in certain areas, and if you only focus on that area of expertise, you are going to feel inadequate. But even more importantly, recognize that if you run into someone who is better than you at literally everything you do, that doesn't diminish your value - it just means you have run into someone that is pretty special\*
3. Get back to prioritizing what to learn. Do you *need* to learn that or do you just *want* to learn it to feel better about yourself? If the latter, learn to let it go, and focus on the things you need to learn - and save the things you want to learn for when you have the time, which will come.

\* As an anecdote - my first encounter with this scenario was a professor that literally did everything I liked doing - but better. He was a tenured professor at a top school, he had come \*this\* close to being a professional soccer player, and he was a classically trained musician, was in incredibly shape for his age and was a generally charming dude. I was a fumbling grad student who played recreational soccer poorly and played in a shitty metal band that no one ever went to see play, out of shape and generally a not-so-charming dude.

It made me *incredibly* self-conscious for about a minute until I realized ""wait up... this guy is just an abject abnormality of humanity. I shouldn't feel bad about myself, I should just be impressed by how smart and accomplished this guy is *because 99.99999% of the population would be looking up at him too"".*

That helped me later in life when I would encounter people who I felt were just fundamentally smarter people than me. In particular, I remember hiring someone for my team that was so smart and thinking ""there is a better chance that I am going to be working for her in 10 years than the other way around"" *and being ok with that.*",datascience
m711hc,1615989604.0,Exploratory data analytics,"Does anyone know of any research papers that have an extensive ""exploratory data analytics"" phase? I am  looking to see how professional researchers document the exploratory data analytics phase, and I am trying to learn from them. So far all I find are research papers with minor exploratory data analytics, nothing too extensive. Can someone please recomend something a bit more detailed (e.g. researchers extensively doing exploratory data analytics on their data before making a predictive model for Corona virus)?

Thanks",datascience
m702f3,1615986687.0,RMSProp algorithm in machine learning: Why square the gradients?,"I’m learning about RMSProp, and have read about it quite widely around the web, but am finding the explanations lacking on one key detail (TL;DR in the title, lol).

It’s clear that the whole point of RMSProp is to replace a static learning rate with a dynamic learning rate that is a function of the size of the derivative. Because in RMSProp you divide the learning rate by the (square root of the moving average of the square of the) gradient, the effect of this on the learning rate is to grow it when the derivative is small and shrink it when the derivative is large. This helps to slow down learning (i.e., weight update steps) as the model approaches local minima, because the function is flatter and thus gradients smaller in these regions.

That’s all fine and good, but why square the gradient? Looking over the equation, wouldn’t the same effect happen if we just used the gradient *without* squaring it? Is it just that we want to make small gradients even smaller? Or is it that positive and negative gradients would cancel each other out, and squaring fixes this? If the latter (i.e., squaring to avoid cancellation), why not just take the absolute value? AFAIK were not differentiating the RMSProp equation, so the discontinuity at y=0 characteristic of absolute values shouldn’t be a problem.

Relatedly, why take the square root when dividing the learning rate? Interpretability of the units isn’t important here like it is for variance vs, stdev in statistics, and the dynamic growing/shrinking of the gradient would occur just the same whether the took the square root or not. So what benefit does taking the square root bring?",datascience
m6ysa7,1615982321.0,Future of Data Science,"Hi guys,
I am sure all of you must have seen the popularity of the field these days, from being stated as the ""Sexiest Job of the 21st Century"" to having a variety of its courses & programs online on platforms like DataCamp, Edx, Coursera, Dataquest, Codecademy..etc

Most of all, recently Google just launched their Data Analytics Professional Certificate so that ""anyone"" could get a job in the field having to have followed the program, as there is a ""vast"" number of job openings worldwide.

My question is, what do you guys think about the future of Data Science in the upcoming years? Is it going to become oversaturated in the upcoming years or is the job market, in contrary, going to increase?

How is it going to affect students enrolled or thinking of enrolling themselves in the Bsc of Data Science as more & more people are taking these courses online from these huge enterprises & companies?

Would love to hear your insights!",datascience
m6vcws,1615968318.0,Possible to export Jupyter notebook to PowerPoint slide deck?,"I imagine that this has been asked before. I'm aware that you can create html slide decks using reveal.js, but I was wondering if it was possible to get what is in my notebook into PowerPoint. Whilst I think I can get away with using notebooks and reveal slides within my team, senior management will probably just be confused with a html file, even though the concept is the same.",datascience
m6nwaa,1615941710.0,Why are data scientists in the sports industry underpaid?,"I’m currently a undergrad sophomore whose very much into data science. I myself have no idea as to what industry I want to go into, but i have thought of sports analytics as being one of them. Moneyball was ultimately the first movie that go me into data science, and after getting deeper into the languages & statistics/ML I have noticed I do enjoy centering my data science projects around sports analytics. I have considered sports analytics as a possible route and dream of being a data scientist for a professional team (NBA/NFL), but I have read that data science in these industries are heavily underpaid compared to others. From what I’ve read on this sub and others that sports analytics is fascinating, but the work u do is underpaid and you are better off doing it as a side hobby than as an actual job. Industries like tech and finance pay more for data scientists compared to sports.

My question is why? Why do data scientists in sports get underpaid? If there are currently any people out there who are data scientists on sports teams or have worked in the past, what are your experiences? And do you agree with these claims? What advice do you have for a student whose interested in the field? Should I pursue it or am I better off going to a tech/finance related industry?",datascience
m6lbgu,1615933997.0,Is it possible to self teach myself data science??,I am a sophomore student who is in college but I am interested in learning data science. I am about to graduate college in two years but I am interested in learning math as a degree. The  applied math degrees are computational mathematics and financial mathematics. I am interested in learning at least enough to build projects and show a good portfolio. I just wanted to know how I can teach myself data science and build a good portfolio. How exactly hard will it be to get a job without a degree in computer science??,datascience
m5w3ot,1615853794.0,For those of you working under/with executives that are completely ignorant to their own company’s limitations with data. How do you all deal with their demands for results?,"Came down the pipe at work today, “CEO was at a conference and another CEO was talking about how they ‘stole’ customers from bigger industry players by looking into customer transactions and tailoring products and services to them to attract them over.” (Financial industry so these are transactions in and out of one company that are being munged). The thing is, we don’t have decades of preserved customer data, we don’t even have a data warehouse of any sort. Just some old clunker of a legacy hierarchical database that’s meant for acting as the data layer of a transactional system. Now our CEO wants to basically know who of our customers has certain account types at other companies based on our “data” because of something he heard at a conference that another company was doing. There is no way we’re mining our trivially available data and coming to any conclusions or assumptions about our customers financial business with other companies.

This isn’t the first time our CEO has done this. A year or so ago he wanted a full travel prediction system built like Chase or Cap1 has for his credit cards there that automatically know when he’s traveling (so he claims). Everyone else in the company licks his boots except me, and I’m always the one coming off as the ass shooting these ridiculous demands down (yes I’m looking for a new job, no I haven’t had an interview in 2 years now while looking, I’m tired of people telling me this as the answer to my problems). The other day it was, “we’ll use prebuilt AI and just give it data and see what it finds.”

How do you all deal with absolute pie in the sky demands from executives?",datascience
m5tk3t,1615838760.0,Do any of you do modeling with pymc3 or other Bayesian-oriented packages?,Trying to get a sense of example industry problems where a Bayesian perspective would be relied upon,datascience
m5rhfl,1615833263.0,Why/when should I use object oriented programming?,"I understand the basic concept of OOP but I just don't see how implementing it would make things better.  Defining a class to store information in an object that I would usually just store in a series of lists or a dataframe, just doesn't seem like it would be an improvement.  So can anyone describe a situation where it would be a good idea to implement it?",datascience
m5mub0,1615821209.0,Why do so many of us suck at basic programming?,"It's honestly unbelievable and frustrating how many Data Scientists suck at writing good code.

It's like many of us never learned basic modularity concepts, proper documentation writing skills, nor sometimes basic data structure and algorithms.

Especially when you're going into production how the hell do you expect to meet deadlines? Especially when some poor engineer has to refactor your entire spaghetti of a codebase written in some Jupyter Notebook?

If I'm ever at a position to hire Data Scientists, I'm definitely asking basic modularity questions.

Rant end.

Edit: I should say basic OOP and modular way of thinking. I've read too many codes with way too many interdependencies. Each function should do 1 particular thing colpletely not partly do 20 different things.

Edit 2: Okay so great many of you don't have production needs. But guess what, great many of us have production needs. When you're resource constrained and engineers can't figure out what to do with your code because it's a gigantic spaghetti mess, you're time to market gets delayed by months.


Who knows. Spending an hour a day cleaning up your code while doing your R&D could save months in the long-term. That's literally it. Great many of you are clearly super prejudiced and have very entrenched beliefs.

Have fun meeting deadlines when pushing things to production!",datascience
m5gv7p,1615800378.0,Is it reasonable to ask for a full Kaggle task as part of an interview process for a contract DS role?,"I have been recently asked to do a Kaggle task and 40 minute presentation and given a week to do it.

I think it is  an overkill for a 3-6 months role.

How to politely decline it?",datascience
m5c7fk,1615780770.0,NLP for contract review,"Hi everyone,

I'm in unfamliar territory honestly, but I've been given an opportunity to work on an NLP project for contract reviews, and I'd rather give it my best shot than anything else.

So here's what I can share:

* I need to redline contracts where a prospective customer has violated one of our pre-defined rules (prepared in a separate file)
* I have a corpus of contracts that are 50% standardized....meaning paragraphs are numbered in order, in a specific format.
* the other 50% of contracts are in an unfamliar format, unique to that particular customer engagement, however the content of interest is in there

What I need to do is sift through these contracts and redline specific parts of the contract that violate the pre-defined rules.

&#x200B;

Here are a couple thoughts I have:

* Validate that the specific rules I've been given are actually representative of the examples in the corpus....so that I will be looking for specific group of words/text matches (easy option?)
* Try to segment the document into sections...easy with the ordered ones, little trickier with the non- standard ones, and then based on section ""identified"" looking for words/features of interest

&#x200B;

Appreciate any insight, or even books/articles for further reading.

&#x200B;

Thanks!",datascience
m52jkb,1615751204.0,What opportunities exist for data scientists in engineering and product development?,"I’ve come to realize that I’m less interested in providing insights to decision makers than I am in contributing to the development of the actual product. I realize that there are plenty of applications for machine learning/data science in software products, but what about in hardware products? I really would like to work alongside mechanical/electrical engineers and scientists to develop new technology. Currently working on a statistics MS with a concentration in data science/machine learning. Any thoughts?",datascience
m52jjk,1615751202.0,Graph module reccomendations?,"Any easy graph model packages/libraries that i can use for a quick modeling project?

Use both python and R (with some prefrence for Python).

Trying to model and optimize for min time in an automated elevator from one floor to another (i.e, set ""path"" no pressing buttons), so i could theoretically pack it all into a matrix, but i feel like graph theory is applicable here.

Thanks",datascience
m4you5,1615740409.0,Happy Pi Day!! 🥧,,datascience
m4u0uu,1615723230.0,Weekly Entering & Transitioning Thread | 14 Mar 2021 - 21 Mar 2021,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience
m4fhfg,1615669705.0,How would you feel about a handbook to cloud engineering geared towards Data Scientists?,"Think something like the 100 page ML book but focused on a vendor agnostic cloud engineering book for data science professionals?

Edit: There seems to be at least *some* interest. I'll set up a website later this week with a signup/mailing list. I will try and deliver chapters for free as we go and guage responses.",datascience
m4d8k8,1615663313.0,Floating an idea - workshops for data scientists interested in contributing to conservation and the environment,"Hey all. I'm an academic scientist with a background in data science (ecological models for invasive species). I'm working with a non-profit conservation group interest in hosting educational workshops in the New York City metro area.

We've talked about organizing a workshop for career data scientists interested in finding paid or volunteer work in environmental science and conservation biology. We're talking about 3-4 day course with speakers from government and non-profit environmental groups, plus some skills lessons on how we extract environmental data from government or private databases. The goal would be to provide data scientists without a biology background some domain-specific knowledge to break into this field. There isn't much money, but it is exciting and rewarding to be a part of environmental advocacy and protection.

Hypothetically speaking -- If this was near your city, would you want to drop by (or even be willing to pay to attend)? We're not looking to make a profit on these workshops, just cover the costs for speakers, lodging, etc.",datascience
m49u2i,1615653409.0,"How to choose between a well-structured code base for all analysis, a collection of one-off scripts, and the spectrum in between?","This question is primarily to understand how you all think of structuring your code and/or file system structure for projects. There are times when what I need to do is very well defined, and it's easy to think of a package structure for a version-controlled package of code within a Docker container that I can develop on and deploy. Other times I'm doing what seems like a simple ""one-off"" type of analysis that's meant to support or check the results of a more major line of work, do some computation and hand off something to someone else in a different format, etc. Often I'll do this type of work in a different directory that's not version controlled, because I don't want to complicate it by adding it to my clean code base or create options for my existing code base that are unlikely to be used in the future and will complicate its interface. However, sometimes these ""one-offs"" build momentum, and become more persistent and important, and I often struggle with finding the right time to put them into the official package (or their own) versus letting them exist on the side as one-offs (and modifications thereof).

A related issue is that when my code is not structured into a well-thought out package, my directory structure tends to look like this:

    .
    └── new_project
        ├── data_prep
        │   ├── prepare_data.py
        │   └── raw_data
        │       └── raw_data_file
        └── run_model
            ├── model_code.py
            └── try_with_mod
                ├── model_code1.py
                ├── output_explore.ipynb
                ├── with_more_iterations
                │   └── model_code1.py
                └── write_out_intermediate_for_jim
                    └── model_code1_for_jim.py

The problem with this structure is a couple things:

(1) Sometimes the number of \`try\_with\_mod\` trees can get pretty nested in ways which are difficult to manage from a git branch perspective. On the other hand, when they do get nested they do convey useful information on the time-ordered progression of my projects, something that branching in git doesn't necessarily preserve. That time-ordered progression is one of the main reasons I keep this directory structure and have to actively fight against it.

(2) The code I put into \`write\_out\_intermediate\_for\_jim\` is usually something quick and hacky to give someone an intermediate result and is not version controlled. Not having it version controlled or documented is just not a great practice.

Do any of you struggle with these types of situations? How do you view the trade-offs of clean, well organized code bases versus one-offs? Do you have a better way or organizing your one-offs than to create subdirectories like I've outlined here?",datascience
m47cat,1615645735.0,Periodic Snapshots for Jupyter Notebook.,"I come from a business intelligence background, and I'm looking for a way to create data snapshots using a jupyter notebook. Long story short they told me during the interview process they had a data warehouse, and that turns out to be not quite true. I probably won't be there long, but I've been asked to create something that sounds a lot like something that would be supported by that kind of data structure/etl process. What I'm looking to do is to be able to run a SQL query, and then dump it into a 'month' file with the snapshot date in the file name, and the snapshot date in the file. The same thing would happen the next month, and so on, and I would load the files in and append to perform the analysis. Has anyone had to do anything like this before, or can provide any useful resources/references? Thanks.",datascience
m46buw,1615642257.0,"Do you tend to ""over-think"" data science projects? And in your experience, is this characteristic valued in data science roles?","When faced with a data science task, I often find that I naturally start critiquing the data. I sometimes list a couple hundred questions: Why are the multi-time series not equal in length? Was the data unavailable? Why are some values missing? Are they missing at random? Across a particular class? How can we fix this in the future? Why are there zero values? What does zero mean in this context? Is zero real or a default database value for ""not available""? Why are there so many duplicate rows in the data? Are they duplicates, or are they real values? If no ID field is available, then two independent rows may have the same values etc. I list assumption after assumption. If we assume this -> we can do this etc., etc.

I've found mix responses when working with people. So people love my pragmatic and thought-provoking approach to solving problems. I often end up uncovering something that nobody even thought to ask. Others would rather I just glossed over it all and not bothered to ask such questions. What is your experience with this? I feel like a lot of the time; people don't want you to overthink data science.

I'm curious to know what others have experienced?",datascience
m458au,1615638004.0,Has Data Science failed to answer criticisms over bias and discrimination?,"We've all seen multiple articles along the lines of lack of diversity in data science leads to algorithm being biased against...

It's an interesting and important topic but am I alone in thinking that most of the articles written about this show a complete lack of understanding about what machine learning is, how it works and even what bias and discrimination are and that data science and data scientists are generally pretty silent about this or even seem to go along with the accusations so as not to be seen somehow as pro-discrimination?

I watched something (I think from Google) about this recently where one of their senior DS/MLEs was talking about how an algorithm was biased because it was more likely to predict men earned $50k+ than women. But isn't it a fairly established fact that men on average earn more than women and so you'd expect a higher % of men to earn above 50k and so any good algorithm should be picking that up? To fix this ""problem"", you'd essentially have to doctor your data until you get the result you want. Which is just nuts.

I'm not saying there's not any ethical issues around these kinds of topics at all. DS should be aware and responsible for not reinforcing discrimination that already exists but if the world and the data it produces have biases, discrimination and even just plain old differences between groups built into it, DS should be reflecting that.

I mean, if you were building a salary predictor and you found that it predicted higher salaries for 50 year olds than 19 year olds, who in their right mind would think that was a result of ageism?",datascience
m44g1s,1615634562.0,JIRA for data science,"I am a data scientist, and in every company I've worked for in the past years, my team had to use JIRA for project management. I am not a big fan of it, and I think it doesn't really fit data science teams' needs. I am curious what tools others are using to manage their data science work. If you use JIRA, do you enjoy it? If not, what tools do you use? How do you organize your workflow? Also, I had a hard time convincing engineering managers to start using other tools because the whole company is using JIRA. Have you managed to transition away from JIRA, and how did you convince your managers?",datascience
m3in2j,1615559248.0,Can't land a data internship? Try volunteering for a political campaign's data team,"I've seen a few posts about how to find volunteer opportunities, or get experience before you are able to land a full-time job.  One avenue I've used to get experience was volunteering for a political campaign's data team.  Campaigns are ALWAYS looking for extra help, and will usually be happy to assign you some easy data cleaning or analysis tasks that you can use to hone your skills.

To get started, I reached out to the data/tech director for a mid-size PAC (after finding them on LinkedIn) and asked if they had any data volunteering opportunities.  If you can't find this person, reach out to anyone in the campaign and ask if they know who to talk to.  Within a few days they had me sign an NDA and I was working on getting insights out of their textbanking data - figuring out which messaging was working best, weeding out phone numbers that volunteers should have added to the opt-out list but didn't, etc.

This can be a great way to build a few industry connections, learn some skills about working within real data infrastructure, and have a killer resume bullet point.",datascience
m3ifk6,1615558585.0,Uses and limitations of Data Science in Finance?,"What are the best applications of Data Science in Finance? Particularly in Investment Banks, Trading, and Investing in the markets in general.

Then what are some limitations? I've read a comment by a Data Scientist that, predicting stock prices through Data Science / Machine learning is a ""pie in a sky problem"" and hence is not realistic.",datascience
m3di8w,1615538534.0,When can you call yourself a 'Data Scientist'?,What are the things that a data scientist must know so that they can call themselves as such?,datascience
m3atml,1615527238.0,Best way to politely refuse a job offer?,"Casually applied for a position, interviewed and really liked the company, eventually landed an offer. However I'm currently a year or so away from when I have a significant equity vesting with the current little company I'm working for, and would hope to not burn any bridges with this new company, maybe eventually hope to work there after I finish my current stint. Tried asking for some time on the offer and the answer was no, any other good way to politely refuse the job offer while possibly keeping the connection open?",datascience
m2yusp,1615491637.0,Does a 'classical' job as a statistiacian still exist?,"I've graduated a few years ago and I always like my courses in stats and econometrics. I found a job in another field which I very much enjoy.

Working in a big company, I sometimes take a look at the internal vacancies. Often there is a a vacancy for a 'data scientist', 'data analyst' or similar, but I've never seen a vacancy that's looking for a statistician.

For these kind of jobs they're generally looking for someone with a background in IT or engineering, and the job requires more than excellent knowledge of stats (programming and the like). I've only seen vacancies for a statistician/econometrician for government and central bank jobs, which are rare and attract many candidates.

Do these kind of jobs, where the main tasks are statistical analysis, still exist?",datascience
m2rc0y,1615472989.0,How much statistics/ML knowledge does your manager/supervisor have?,"I’m about 1.5 years into my first roll out of grad school as a data scientist and I find myself frequently frustrated with my manager’s total lack of even pretty simple stats knowledge. For example, he has on multiple occasions tried to emphasize effect size by pointing to p-value. Saying things like “this effect size is big and significant, and the p-value is super small so the effect size is super big.” Is this standard?

For a little more clarity, in my team my manager typically plays more of a herding and prioritizing role than actually recommending any sort of method or answers. Very much a “this needs done more than this” guy and the most hep he can typically offer is industry domain experience.",datascience
m2ollj,1615464163.0,Causal data science,"My background is economics and currently I’m a data scientist intern.
I really like causal relationships but haven’t seen anything too advanced.
Only stuff like granger and impact evaluations.

I want to know which are the hot topics in causal inference. Any tips?

Edit: so many comments! I’m very grateful and I’m reading them all!",datascience
m2ig8q,1615439576.0,DE Salary Expectation,"Hi guys,

I'm currently looking for jobs in the San Francisco/Bay Area, in Data Science/Data Engineering. I finished interviewing with a small company/start-up for a Senior Data Analyst role two week ago, but was not given an offer. This week the recruiter reached back to me for a Data Engineering role and I was given a verbal offer of $125k-$130k + equity(unsure how much). While the recruiter and HR prepare the offer letter I would like to know what range of salary I should come with that would be fair for me to negotiate.

**Location:** San Francisco/Bay Area

**Company:** small start-up

**Job title:** Data Engineer

**Education:** B.S. in Applied Math with Computer Science, M.S. in Data Science

**Experience:** 3 years of experience as Data Scientist per se, not much, but I have a good background in maths/stats, data analysis. For my current role I do a lot of automation in SQL + Excel Power Query.

**Current Salary:** $110k

The recruiter told me that the first 6 months of the Data Engineering role will be focused in building ETL processes and there are high potential of moving into a Data Science Analytical role.

I have done my research in Glassdoor, but because I am in the silicon valley the salary numbers are saturated with big tech companies salary compensation that seems unrealistic for me to use to negotiate.

Thanks in advance for any insight.",datascience
m284n6,1615409438.0,Question: MCMC Chain,"Not sure if this is the correct place to ask. But I am doing a Bayesian Analysis using MCMC. I have 100,000 samples and I am planning to use IAT (Integrated Autocorrelation Time) to determine my thinning factor. Yet I don't know if I should calculate my IAT before or after my burn in.

Does anyone with experience could tell me? Thank you.",datascience
m22qso,1615396748.0,Why does everyone talk of deployment as something which is hard to do?,"I keep running into people who say that you're only valuable as a data scientist if you know how to deploy your models and how anyone can learn model development but not model deployment. And though I agree that model deployment is crucial, I'm not sure that they're right about how tough it is. I've deployed conventional machine learning models (logistic regression) at my job and CNN based deep learning models for my self projects. I made the app using Flask,  containerized using Docker and deployed it to a Linux EC2. The thing is all of that turned out to be pretty trivial to me and something which any data scientist can learn in 2-3 days.

What I'm missing here? Did I find it easy because I was dealing with models of smaller scale? Or so many people say it's tough to deploy models as they've never actually done it?",datascience
m203v5,1615390337.0,Volatile DS role vs usual SDE,"I've received an offer letter from an amazing research company where my work profile would be exactly what a data science student could dream of. I'd not think twice before accepting the offer but there are many 'buts'. It's a termed employment and I don't see anywhere on LinkedIn where a grad student (read huge loans) has worked for more than a year. Also, the salary is way less than what SDEs would be paid as their starting salary. I do not like SDE roles(I'm not good at it) or any role where there's no room for research. But at the same time, I've prepared myself to accept such roles as they're highly paid. This would mean getting rid of the huge education loan and taking responsibilities of my family (parents).
I've asked my parents and sister for advice but I feel their opinions are biased. Dad being in research field says it would be foolish to leave this job since he knows I love this role. Rest of the family, having seen the financial downsides of it are pestering me to go for high paid/stabler jobs as it's a one solution for all problems(loans, visa, finances etc). I'm super confused, that's why reaching out to the community.

Would appreciate an unbiased input about this.
Thanks!",datascience
m1vvmz,1615377337.0,"New Job: No training, too busy to help you, we don't have documentation, we want AI and Machine Learning applied wherever I say so (even if we don't know what that means)","How many of you have started a new job as a data scientist and this is the culture you are thrown into? How long did / have you lasted in this type of company?

I had come to this company out of a bad situation so I'm already pretty jaded and pissed off. After almost 5 months, I've had virtually zero success. I'm ready to jump ship again and pursue consulting full time. Should I wait to try and get some large contracts first or try and operate in a dual capacity until I get fired?

Honestly it horrifies me that I would be ok with getting fired. But, I am so tired of doing extra to be successful and overcoming bad management, disorganized cultures, and lack of support without being met in the middle.

Edit: thanks everyone for setting me straight today. Needed the course correction. Too easy to wallow in the struggles!",datascience
m1v9pg,1615374923.0,Features Showing the Decrease of a Value in Time,"Guys, need help on this one.

I am building a binary classificator to output whether a costumer is going to churn on the next few months or not.

I believe that the number of transactions that said costumers do on our app greatly reduces over time, until he finally churns.

With this in mind, I need your help to:

1. decide if and on what time frame of time the decrease is relevant;
2. how do I represent this as features? Let's say that we decide on item 1 that the # of transactions on the last 3 months greatly reduces. Is it enough to include like # of transactions on months 1, 2 and 3 before the churn?

I was wondering that maybe I can set a hypothesis test to verify and confirm 1, though would still need help to decide on the time frame.

I tried to search something to read about this on the interwebs but couldn't find. Thank you guys for any help.",datascience
m1tlp5,1615367997.0,Is it good practice to manually fill in missing data?,"A date column for all but one row is complete, with the one row containing only the year.

This is an issue for the analysis I want to undertake, and I can quite easily replace it with the correct data after a quick Google search.

My question is, is this good practice? Or does it generally complicate things due to the data now coming from multiple sources and therefore should an alternative approach be used such as estimating the date?

TIA!",datascience
m1safz,1615362116.0,Data Science PoC Project Tracking in an Agile Environment,"Hello folks,

I work as an analyst and we are currently exploring some data project PoC’s and explorative studies. We don’t have a clear requirement from the stakeholders. We run 2 week sprints and most of the engineering team have dedicated back log items and tracking. How do you track data science exploration tasks in the backlog and how do you currently size tickets ? With something like an explorative task that has no specific requirement I’m struggling to set sizes as I uncover something everyday. It may or may not be useful for the business but it’s an insight that has emerged. The business thinks I’m not sizing tickets right. Any pointers is highly appreciated.

TIA fellow data travelers.

Best,",datascience
m1g38f,1615323381.0,Prescriptive analytics subtopics?,"Hello, I’m currently in a undergraduate data science club and we had a chief analytics officer from a company come in and speak to us about linear programming and optimization. It was towards the end where I had asked him how optimization techniques could be used in predictive modeling and machine learning. He told me that the concepts he was telling us about actually didn’t fall under predictive analytics, but prescriptive analytics. The difference being predictive analytics is using previous data to predict new outcomes, and prescriptive analytics being using previous data to find what the most optimal solution is. That peaked my interest because thus far I have had a rather narrow view on data science with only predictive analytics and machine learning as my focus of interest, however I wanted to learn more about the prescriptive analytics side.

For those of you who work with prescriptive analytics, what are some math topics or sub topics that could help me explore this? I’m a statistics student and naturally my tendencies have gone to predictive modeling with machine learning, so I’m wondering what other math concepts would be useful for prescriptive analytics?

Linear programming? Optimization? Graphs?",datascience
m1d3u6,1615315357.0,CDO of the future: background in data science or data governance?,"I am basically at a crossroads where I can continue growing in DS and MLOps and DS management or focus more on data governance. I'm in my late twenties and my career goal is to one day be CDO and I have been thinking a lot recently about which pathway will provide me with the best learning and development opportunities and will best equip me for that role. On one hand, data governance is about people, documentation, process, driving a data-oriented culture and doing it right and that is a great path to be on if your plan is to one day be CDO, on the other hand I do like data science, particularly the maths, stats, and MLOps part of it and I have been successful at it so far at my company - would I be pigeon-hole'ing myself too much if I stayed on the DS track? Shall I seek a more data management / governance oriented track? Would you say that someone with a background in DG would have a competitive advantage?

Thank you.",datascience
