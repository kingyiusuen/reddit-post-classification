{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook assumes the data have been preprocessed by the notebook `notebooks/03-preprocess_data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "X_train, y_train = df_train[\"text\"], df_train[\"label\"]\n",
    "\n",
    "df_test = pd.read_csv(\"../data/processed/test.csv\")\n",
    "X_test, y_test = df_test[\"text\"], df_test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function for doing cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def fit_and_evaluate(model, X, y, n_splits=5):\n",
    "    \"\"\"Fit and evaluate each model.\"\"\"\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df=10)\n",
    "        transformed_X_train = vectorizer.fit_transform(X_train)\n",
    "        transformed_X_val = vectorizer.transform(X_val)\n",
    "\n",
    "        model.fit(transformed_X_train, y_train)\n",
    "        y_pred = model.predict(transformed_X_val)\n",
    "        auc_scores.append(roc_auc_score(y_val, y_pred))\n",
    "\n",
    "    auc_scores = np.array(auc_scores)\n",
    "    metrics = {\n",
    "        \"mean\": np.mean(auc_scores),\n",
    "        \"std\": np.std(auc_scores),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a 5-fold cross-validation on different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"logistic-regression\": {\n",
      "    \"mean\": 0.7562863309593524,\n",
      "    \"std\": 0.019642962156474545\n",
      "  },\n",
      "  \"k-nearest-neighbors\": {\n",
      "    \"mean\": 0.6906516560367517,\n",
      "    \"std\": 0.022377017060785254\n",
      "  },\n",
      "  \"random-forest\": {\n",
      "    \"mean\": 0.7232899886800905,\n",
      "    \"std\": 0.029347233658478362\n",
      "  },\n",
      "  \"gradient-boosting-machine\": {\n",
      "    \"mean\": 0.7017718608251133,\n",
      "    \"std\": 0.025234778387473736\n",
      "  },\n",
      "  \"support-vector-machine\": {\n",
      "    \"mean\": 0.7236191172970615,\n",
      "    \"std\": 0.03117893968722548\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_dict = {\n",
    "    \"logistic-regression\": LogisticRegression(),\n",
    "    \"k-nearest-neighbors\": KNeighborsClassifier(),\n",
    "    \"random-forest\": RandomForestClassifier(),\n",
    "    \"gradient-boosting-machine\": GradientBoostingClassifier(),\n",
    "    \"support-vector-machine\": LinearSVC(),\n",
    "}\n",
    "\n",
    "performance = {}\n",
    "for model_name, model_class in model_dict.items():\n",
    "    performance[model_name] = fit_and_evaluate(model_class, X_train, y_train)\n",
    "print(json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best model on the full training set and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6986111111111112"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(min_df=10), LogisticRegression())\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../artifacts/model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper</td>\n",
       "      <td>-2.474073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>course</td>\n",
       "      <td>2.191506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>learn</td>\n",
       "      <td>1.917166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>research</td>\n",
       "      <td>-1.910634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models</td>\n",
       "      <td>-1.838475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>python</td>\n",
       "      <td>1.819297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>learning</td>\n",
       "      <td>1.697943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>papers</td>\n",
       "      <td>-1.693024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>start</td>\n",
       "      <td>1.662301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>regression</td>\n",
       "      <td>1.500483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>source</td>\n",
       "      <td>-1.491233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>beginner</td>\n",
       "      <td>1.464622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train</td>\n",
       "      <td>1.443143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>-1.370605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>courses</td>\n",
       "      <td>1.356617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resources</td>\n",
       "      <td>1.339075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>explain</td>\n",
       "      <td>1.313193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>-1.195331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>need</td>\n",
       "      <td>1.187498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>machine</td>\n",
       "      <td>1.176072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>discussion</td>\n",
       "      <td>-1.161136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>something</td>\n",
       "      <td>1.148554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>help</td>\n",
       "      <td>1.135741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thread</td>\n",
       "      <td>-1.125560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>language</td>\n",
       "      <td>-1.119175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature      coef\n",
       "0        paper -2.474073\n",
       "1       course  2.191506\n",
       "2        learn  1.917166\n",
       "3     research -1.910634\n",
       "4       models -1.838475\n",
       "5       python  1.819297\n",
       "6     learning  1.697943\n",
       "7       papers -1.693024\n",
       "8        start  1.662301\n",
       "9   regression  1.500483\n",
       "10      source -1.491233\n",
       "11    beginner  1.464622\n",
       "12       train  1.443143\n",
       "13     pytorch -1.370605\n",
       "14     courses  1.356617\n",
       "15   resources  1.339075\n",
       "16     explain  1.313193\n",
       "17        2022 -1.195331\n",
       "18        need  1.187498\n",
       "19     machine  1.176072\n",
       "20  discussion -1.161136\n",
       "21   something  1.148554\n",
       "22        help  1.135741\n",
       "23      thread -1.125560\n",
       "24    language -1.119175"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n = 25\n",
    "features = model.steps[0][1].get_feature_names()\n",
    "coefs = np.squeeze(model.steps[1][1].coef_)\n",
    "\n",
    "ids = np.argsort(-abs(coefs))[:top_n]\n",
    "top_n_features = [features[i] for i in ids]\n",
    "top_n_coefs = coefs[ids]\n",
    "pd.DataFrame({\"feature\": top_n_features, \"coef\": top_n_coefs})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "735b1bbd8e64d5b8ac9eb5cce3af7988e476745b427477cf0ca4dda5d6ade974"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
