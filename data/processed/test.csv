id,label,text
rj7ivc,0,different results for the model every time i train the model with same parameters i have the following model i am facing an issue with the results as every time i run the model i get different results the train and test data remains the same in every run i can give you more details if you have any questions for me let me know note data 1 and data 2 do have a correlation between them and that s the reason for using them both x200b
rbaq7a,1,when should we apply normalisation to our data let s assume i have data set with tweets and binary variables that represents positive and negative tweet do i need to normalise my binary data if i want to apply naive bayes what about if i have 3 category positive 1 negative 1 and natural 0 will i need normalisation
rau451,1,no code machine learning platform from amazon aws sagemaker canvas the recently launched sagemaker canvas is pretty awesome for beginners in machine learning like me i tried my hands on a few ml projects like customer churn spam sms detection etc and it gave the predictions almost accurate there is a short course on udemy on the same that is currently free so do join
r4it3w,1,are there any examples of semantic search being leveraged at scale i ve been doing some research and i haven t been able to find any resources outside of faiss prototypes it has me wondering if this is something that is used at scale any examples or sources would be much appreciated
qorekl,0,simple questions thread please post your questions here instead of creating a new thread encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread
rla8ja,1,what should i use for a beginner project colab seems too slow have any of you had any experience with google colab or similar tools i m trying to train some models but i m a beginnier i m looking for something that s relatively easy to use but will work well enough for what i m trying to do i tried to run it on my macbook but it took 5 hours do any of you have any suggestions thank you
ruf6eq,1,what is an eigenvector a 2 minute visual guide x200b 🔵 eigenvectors 🔵 🚀 an eigenvector is a special vector associated with a linear transform it s special in the sense that after applying the said transform it does not change direction but only gets scaled multiplied by a scalar value by the eigenvalue 🔨 each eigenvector comes with a corresponding scalar called the eigenvalue breaking a matrix m into its eigenvalues and corresponding eigenvectors is called eigendecomposition 🔭 the word eigenvector comes from eigen in german where it means its own it was originally used to study rigid body motion and in the discovery of principal axes however nowadays it has found its way into a wide array of applications from my favorite principal component analysis differential equations and problems in physics and chemistry relating to wave transport and molecular orbitals 🎭 another one of the classical applications is the eigenfaces project for facial recognition eigenfaces decompose a face as a composition of face templates basis called eigenfaces imagine n eigenfaces e 1 e n when given a new face f it can be written as a composition of each of these n eigenfaces for example f 10 of e 1 55 of e 2 35 of e 3 each eigenface would represent a meaningful feature in the high dimensional space of faces if you like such content and would like to steer the topics i cover suggest topics you would like to know more about in the comments
qtik3a,0,lyric studio artificial intelligence song lyrics i created an ai generated song lyrics app thought this subreddit would love it pytorch for text generation and also does live sentiment analysis with background shading link do you have any feedback or improvements
rbbl88,1,image emotion classification when i researched about the subject i found this paper and i am very pleased with the results they got but they dont give any code or model far as i saw so the equations and explanations are pretty much magic to my untrained eyes i also found this classifier but i really cant get it to work for me i am sure they did everything to explain how to set it up but it isnt clear enogh for me so if anyone can explain to me or give me any lead it will be appreciated
rc08a4,0,what is the latest large dataset used to benchmark feature selection models i submitted a paper to aaai22 but was rejected and one of the comments left by the reviewers are that i used traditional small datasets i used all uci datasets i have read many papers in this domain but none seem to be consistent on what datasets to use and many are still using uci data my paper is in the field of dimensionality reduction feature selection for classification algorithms what is a good large dataset to use for this field of research
rbudur,0,why is distilroberta 15x less used than distilbert according to huggingface distilroberta base was downloaded 287k times last month vs 3m9 times for distilbert why from a pure performance perspective roberta seems better than bert in my case with limited hardware capacity i am looking for a distilled model i was wondering why 15x more people chose distilbert last month compared to roberta as i would have chosen otherwise thanks
rb7oa7,1,dissecting lobe ai models in tensorflow where to start i m new to machine learning and trying my hand at cnns at the moment i have a raspberry pi set up at my window to take pictures of birds who visit a feeder what i want to make is a model with tensorflow to detect and save photos of birds sometimes a car or pedestrian passing by is captured and are of no interest to me x200b the models i made thus far are no good for two reasons its accuracy is basically a coin toss and i don t have enough knowledge to improve it yet i came across the lobe ai model builder and decided to reverse engineer its models it has a desirable accuracy with the same dataset and i want to see what makes it tick it can export the model it makes in tensorflow format but i have no clue on how to compare it with mine i m interested in the preprocessing data augmentation used layers number of epochs etc is this possible at all once the model is made what files do i look at x200b i could just use lobe s model but that is my last resort since i won t learn anything
qnznd4,0,help choosing right data file format for storing text data hello i m working on a nlp project which requires me to collect the data as of now i have collected data and stored in to individual text file one article into a single text file so for future analysis i have cleaned the data and converted into dict article id and article text and now i want to store this data into some specific file formate such as json hd5 etc so i want your recommendation on this which is the best format to store this kind of data please provide suggestions by keeping in mind the latency in loading data from drive or faster the better
ra5m26,1,an idea for a project with cnn s hello all i am currently looking for some cool project ideas to work on which have cnn s so that i can familiarize with them the more interesting the project the more i can learn so pls drop some cool project ideas in the comments below thanks in advance
rv7w4p,1,convolutional neural network from scratch hello fellow learners if you are searching for a tutorial about convolutional neural network from scratch then please follow this link this blog gives begginer s guide to create a cnn model like keras but from scratch
rolzia,0,segmentation based on shape identification i need help making a deep learning classifier do what i want so right now i have an algorithm that splits an image into equal squares then classifies each segment and counts how many of each i want to use a mask that finds shapes of the objects first then the classifier will work within the individual shapes it finds so instead of classifying equal segments it will classify pixels located within the strange shapes it found see drawing sometimes the mask can t find shapes and contour lines on certain parts of an image on those areas i d like it to segment into a grid and classify that way see pic 3 of drawing hope that makes sense and someone can point me in the right direction its in python
r5p9nx,0,build automations powered by machine learning from a single python file hi all machine learning has the potential to automate a huge portion of boring processes but often gets stuck at the jupyter notebook stage and never make it to the real world take for example the case in which we want to predict whether customers will unsubscribe using some basic customer data many of you from this sub can build a simple machine learning model to predict whether a customer will churn if they get a nice pandas dataframe with some customer data however it gets really complicated if you want this model deployed and integrated in production say a procedure as such 1 pull data from a new customer from shopify 2 predict for this customer whether they will churn 3 if we predict churn true 4 send a discount code to this customer automatically suddenly we have to code api integrations build etl pipelines deploy our original machine learning solution onto a rest api spin up an http server etc and maintain all of this a huge pain indeed we are building a framework that takes care of exactly all the boring stuff described above we really believe this will bridge the gap between research and real world ml super excited to get some early feedback so please shoot any questions in the comments
r1swhm,0,aamas 2022 paper reviews i am creating a discussion thread for aamas 2022 reviews
r4ra5g,0,patrickstar a pytorch based training framework that can train faster and larger ptms github paper last month our team at tencent open sourced patrickstar a pytorch based ptm pretrained model training framework that could train larger model and have better performance with the same hardward environment compares to sota training frameworks like deepspeed version 0 4 1 performance on 8xv100 node the key idea of the project is to use a chunk based memory manage strategy which means group parameters in chunks of the same size and dynamically move the chunks between cpu and gpu compare to deepspeed which would determine which part of the model need to put in cpu memory before training the dynamic memory scheduling would make better use of the gpu memory namely only the params involve in computing at the moment are loaded in gpu this results in larger model also we designed the efficent prefetch and sharding mechanism based on the chunk based method and those bring us the nice performance as large ptm are becoming a must in nlp we believe patrickstar would be a help to researchers and engineers it would be so nice if you could checkout our github repo and give us some feedback
rjwwfi,0,advice for training on full imagenet for my project i need to train on the full imagenet from scratch it’s taking me ages and i’m struggling to get good accuracy any advice on general approach directions to follow parameter choices would be greatly appreciated setup pytorch vgg16 ilsvrc2012 imagenet batch size 300 optimizer sgd lr 0 001 momentum 0 9 weight decay 0 006 num workers in dataloader 12 pin memory in dataloader true using nn dataparallel for the five blocks of vgg16 hardware a cluster with rtx6000 i m using 4 x200b i have been getting many cuda oom errors hence the choice of small batch and particular num workers these are the highest that seemed to work generally the cluster i’m on seems to affect training when many other jobs are running in terms of parameters i’ve heard that adam should do a much better job as the optimizer compared to sgd so i’m going to try that next also from what i found online pytorch’s distributeddataparallel seemed like a useful but difficult to implement parallelization option i’m not sure it will be manageable in the time frame of my project this is what training looks like at the moment ps i am a newbie in ml if that s not obvious already lol
r332qa,0,iclr rebuttal deadline sorry i can t find this info online the deadline is on 29th of november but is it anywhere on earth or is there a specific time
rhpjg6,0,would anyone be interested in an automated object detection data labeling tool hi all i m a recently graduated jobless computer engineer i m currently working on a tool which allows for automated photo capture bounding box labeling data augmentation and training of object detection models such as yolov5 you can basically create a fully labeled and diverse dataset for 1 object category in less than 10 seconds of manual work as opposed to the tens or even hundreds of hours usually required to collect label and augment the dataset using conventional methods the main advantage of my tool is the fully automated labeling of bounding boxes which otherwise can take a very long time to manually annotate as well as extremely potent data augmentation the training of the model is also automated not really anything new and will take the usual 8 30 hours depending on the gpu hardware the main limitation is that the object must be smaller than approximately 50x50x50cm to fit into the automated photo capture labeling device you cannot for example label a sofa too big or a single red blood cell too small there is also a physical hardware cost around 1000usd for the automated photo capture labeling device i would like to know if the cv ml community would find this tool useful or worth the 1000usd the capture device would likely cost i currently have a working prototype but i want to know if anything similar exists and whether it is worth it to keep developing and maybe developing it into a product in the future thanks for any of your ideas suggestions or criticisms
rb2gi0,0,label efficient semantic segmentation with diffusion models tl dr image representations extracted from s o t a ddpms contain high level semantic information that might be useful for your downstream vision tasks examples of k means clusters formed by the features extracted from different diffusion steps and unet decoder blocks in this work we show that a simple approach based on ddpm representations can provide strong performance in the context of semantic segmentation when the amount of labeled data is scarce arxiv code
r6v5dx,1,logistic regression log odds linearity assumption hello i m trying to understand what this assumption means i drew a picture of what i think it means that is i believe that the assumption is true if the data is separated so that we can split it correctly with a straight line left image and the assumption is violated if the boundary between the classes is highly non linear or just mixed together right image just looking for confirmation on this really thanks then as a follow up question if the above is true is it okay to just fit the model and simply evaluate the validity of the assumption with the model accuracy so if we get a low accuracy it probably means the assumption is violated and if we have a high accuracy the assumption is probably valid
rick1i,1,should i take an ms for computer science or and ms specialized for artificial intelligence so i was deciding to what masters degree i would be taking ai degree consists of 10 cs courses and the rest more on machine learning i am taking a few courses by andrew ng on coursera to prepare for it on the other hand cs degree has a more comprehensive coursework with cs like databases theoretical computing and software engineering it only contains a few machine learnign courses so i was asking because i want to know how employers or practictioner view one over the other but based on my readings cs degree offers more flexibility on employmeny while the ai degree will project you to the ml path right now i’m leaning towards the ai deg as it heavily works with mulitple algorithms that cs degree does not offer
rp3926,1,vehicle detection and counting intelligent vehicle detection and counting are becoming increasingly important in the field of highway management however due to the different sizes of vehicles their detection remains a challenge that directly affects the accuracy of vehicle counts this simple project treats this issue using opencv for image processing and hear cascade which is used for object detection
rcz0bd,1,a beginner here i want to build a natural language model to classify comments how do i start hello redditors i am a beginner for machine learning and i am currently working as an entry level data analyst our team wants to implement a model to classify comment provided by our customers our customers consist of people coming from non english background all of them know english but sometimes they cannot not spell properly i am not sure if spelling mistakes would affect the model i have attached an image of a sample dataset to give you an idea about the data i am working with a bogus data sample i have like 50 000 80 000 comments in my dataset i don t know how to start i have done a bit of traditional machine learning using sci kit learn but have never stepped on nlp i searched on the internet the results were overwhelming i saw some implementations using bert and huggingface can you shed some light on this can you suggest some good reading materials or youtube videos which tackle this is using a model like bert huggingface would be easy or building an own rnn from the scratch will do the job better another question the comment service ws fasr do i need to do the spell correction before passing into a model is there any libraries which do that i will be using python and i am familiar with r as well if the model is good then i would deploy it in the cloud this will be a later question in this forum thanks in advance
rrxikg,0,mel frequency cepstral coefficients transformation hi i need some guidance on my project i work on a simple keyword spotting problem with spiking neural networks snn and for that i use the akida brainchip now the catch is that the snn layers can only work with unsigned integers and the mfcc functions from librosa audio ops etc are returning float since i m not an expert on audio data i wanted to ask if there is simple or common way in which you usually transform mfcc s to integers currently i shift the data such that the minimum is the new zero point and simply cast it to integer afterwards but i m not really happy with that approach
rdff22,1,which model is used for document extraction camscanner microsoft lens etc i want to start a small project where i d create a model s that would extract document from a picture and rescale it something like camscanner or microsoft lens apps do i ve gathered a small dataset just to prototype the concept but i m not sure what might be the best approach to label the data 1 using bounding boxes this might work best to locate the document but it would bring some noise to it since the picture might be under some angle or document could be held in hand etc so it might require further processing to eliminate background noise 2 using mask r cnn will probably do a good job to isolate the document but i guess it would be tricky to reshape center later on since it s possible to get a irregularly shaped mask for example if someone is holding it in hand finger holding the document might get excluded from the mask so some extrapolation will be needed probably 3 my idea was to use keypoints like they do in pose estimation models where the keypoints would be the edges of the document and then they would be connected by a straight line to isolate document and then re center it has anyone worked on this type of problem or has and idea how the apps mentioned above are handling this probably there are some other approaches that can be used that i m unaware of
r9dri0,0,sota stylegan inversion explained hyperstyle stylegan inversion with hypernetworks for real image editing 5 minute digest by casual gan papers it proved to be a surprisingly difficult task to balance the reconstruction quality of images inverted into the latent space of the stylegan2 generator and the ability to edit these images afterward now yuval alaluf omer tov and the team that originally reported the infamous reconstruction editability tradeoff in their “designing encoders for editing” paper are back at it again with a new encoder design inspired by the recent pti paper that sidesteps the tradeoff by finetuning the generator’s weights in a way that places the inverted image into a well behaved region of the latent space and leaves the editing capability unchanged hyperstyle is a hyper network that speeds things up by training a single encoder to predict the weight offsets for any input image replacing the compute intensive per image optimization with a single forward pass of the model that takes a second instead of a minute how are the authors able to predict the weight offsets for the entire stylegan2 generator in such an efficient manner let’s find out full summary h blog post hyperstyle arxiv code demo subscribe to casual gan papers and follow me on twitter for weekly ai paper summaries
rf95gl,0,useful data summary statistics with image classification hello x200b i am doing image classification with tensorflow for learning purposes i am splitting the data into 5 folds i would like to get useful summary statistics on these validation sets what could be useful other than the shape of the validation sets
qxo4ym,0,how to search for machine learning phd internships effectively i am a machine learning phd student in a uk university i am interested in research internships at some of the big tech companies and there are just some questions that i d like to ask the reddit community what is the best strategy to land offers interviews i have submitted cv and filled application forms to many of them but haven t heard back since except a summary reject from deepmind it took them only 3 days to do so are there more effective ways to progress further or am i just worrying a bit too early at this stage positions based in the us i found that many of the positions available are in the us north america i know that for the 2020 21 cycles most of the internships were virtual so the location might not have mattered so much but as the world starts to open up will it be commonplace for us based positions to hire someone from say europe i d actually prefer uk european positions but just couldn t find that many online what are they looking for in propective interns i found all the job descriptions are rather vague but rumours of leetcode worry me a bit since i did not do hardcore cs for my undergraduate from my initial experience leetcode medium seems to be the hardest i can do in a realistic interview setup without more hours put into practice about myself i m just starting my 3rd year in one of the top uk universities uk phds nominally last 3 years but my observation is that people tend to do slightly longer i did an research scientist internship in a big tech company not at the level of faang but decent but someone referred me for that position and they urgently needed someone back then so i guess i didn t get the full interview experience and i also expect the positions at the top tier companies could be more competitive so my interview experience there might not be that representative in terms of publications i have 3 first co first authored papers at top conferences i e icml iclr neurips and a couple under review 2 first authored papers at lower tier conferences journals and a few non first authored papers otherwise any insights and suggestions are welcomed many thanks for your help
rq6uih,0,other ai methods algorithms except deep neural network that are promising i have heard some other ai methods except deep learning like these free energy principle thousand brains theory hierarchical temporal memory tsetlin machines spiking neural networks predictive coding associative memory fractal ai updated hyperdimensional computing hyperbolic machine learning complex valued neural networks x200b do you think which methods algorithms are interesting and will become more popular or are there any other methods algorithms do you think that is promising x200b
rd20n0,1,increasing the accuracy of textual data analysis on a corpus of 2 billion words at soroco we ingest between 200 million and 2 billion words over the course of model training and analysis for a single team of workers using our scout product in this blog post i talk about some tips and tricks that we might use to increase the accuracy of our models including appropriate processing of text for the purpose of leveraging standard techniques from machine learning i then demonstrate this by showing how to represent text in a high dimensional vector space with applications to a toy regression problem
rgudcg,1,best source to learn pytorch i improved my tf from hands on ml with tensorflow keras and scikit learn is there anything which is equivalent to this book but for pytorch or equivalent and no need to be a book
r84bxk,0,shape generation algorithm hello i am not from the field i was looking for an algorithm for shape generation my field is mechanics and i want to see how different shapes in structure would affect the stress i envision instead of intuitive design how an ai can come up with interesting shapes i dont know if that already exist i would appreciate your kind help thanks
rpum3a,0,article suggestions for where graphs meet transformers hey everyone i am trying to gather some articles about graph network and use of transformer like architecture that uses attention mechanisms which are used for biological or medicinal purposes but i am open to read some articles from other fields too also i am trying to come up with a review article in a disease drug therapy triad about the use of ml dl of course so if you feel like some of the studies from this field are undervalued comment below and i will take a look thanks in advance cheers
r6eple,1,november updates the data science interview book the month of november is up and christmas month is here feels like 2021 has almost slipped past us so what did we do in the month of november nlp section updated missing values section added formatting changes in the statistics section took some break was obsessively working on this 😌 new section tree based approaches industry application added launched our linkedin page have some interesting plans for it in near future added support for dark theme 🤯 had to remove it as it was breaking a lot of other stuff will wait for official support added new problems in probability python regression sql added temporary datasets and time page in sql covering ctes regression section extensively updated don t forget to show this project your ❤️ and support
rnegp0,1,data science machine learning interview participation request good evening among current circumstances i hope this message finds everyone well i am current high school senior student in the state of illinois seeking potential data science professionals or prospective data scientists willing to participate in an interview for my ap research course to provide a general overview my institution is currently partnering with college board s ap capstone diploma a diploma program that develops student’s skills in research analysis evidence based arguments collaboration writing and presenting skills based on two long year courses ap seminar and ap research as a student currently enrolled in the ap research course and an expected requirement i am tasked with the year long process of exploring an individual area of interest that may be an academic topic of choice idea or circumstantial issue this year i am centering my research on the effects traditional mathematics subjects retain in minority students academic success primarily latino a students and students of hispanic origin as well as assessing the measure of academic success of collegiate students or professionals in attaining a post secondary education degree and or career it is worth noting the state of illinois does not offer any data science education within its public school districts and is an objective i would like to have implemented in my community i have tried to establish contact with potential participants but have had no success therefore i have decided to post my objective here in hopes to gain participants though i am willing to take 20 participants who are interested i am seeking those who have been previously enrolled in data science course in their secondary high school career or post secondary if you are interested in participating or know of those who may be interested please do not hesitate to contact me for further information i am more than willing to set up a date time through either platform zoom and google meets and address any questions or concerns thank you for reading this lengthy post and happy holidays
qojz5g,0,comparing deep models with different complexity and different accuracies i am working with a deep learning based system where complexity has to be reduced to a minimal however this is having some impact on the accuracy i am having to ask the question in somewhat hypothetical scenario and hope that i am clear in my statement say one system uses 1 billion flops network to achieve 99 accuracy yet another uses 0 5 billion flops network to give 95 on equal accuracy we could say that the system with lower flops is better likewise on equal flops we would have been able to say that the first system is better is there a direct way like a standard kpi to compare these two systems in the given scenario in short can we compare two systems with different accuracies and different flops
ruxg67,1,estimating the orientation and fractional occupancy of two crossing bundles hi goal i currently have a model that estimates the orientation and fractional occupancy of two crossing bundles in a cubic volume based on a noisy signal x200b fig 1 2d representation of the two crossing bundles current approach since the two bundles are basically indistinguishable from each other i decided to always put the bundle with the higher fractional occupancy as the first target and the bundle with the lowest fractional occupancy as the second target the network architecture with the target ordering is depicted in fig 2 fig 2 network architecture issue when the two bundles have a fractional occupancy close to each other for example frac 0 0 51 and frac 1 0 49 the network sometimes swap both bundles frac 1 x y z associated with the bundle 1 is output in bundle 0 during backpropagation the network is thus heavily penalized because of the swapping since the error on x y z is huge if the network wrongly estimates frac 1 and frac 0 it will swap both bundle and will be heavily penalized x200b fig 3 mae of the fractional occupancy in function of the ground truth fractional occupancy the mae increase for volume fraction close to 0 5 due to bundle swapping during learning x200b is there a way to better arrange target to prevent this kind of issue thanks and regards
qw0rxa,0,organizing ml reproducibility – the reproducibility scale hey r ml a lot has been said ranted about reproducibility in ml it always seems like everyone agrees that reproducibility is important but still many projects are difficult or impossible to reproduce part of the reason is that reproducibility is hard to quantify and different people define it very differently i wrote a blog trying to provide a concrete scale for reproducibility with a practical rating system and a checklist that can help project creators maintainers validate the reproducibility of their work the scale consists of 5 criteria a 5 star system 1 code 2 configuration 3 data artifacts 4 environment 5 evaluation with specific requirements for each one i tried to order them in a growing level of complexity so that a 3 star project is lower effort but less reproducible than a 5 star project i also add a format for a reproducibility md file that can be filled out and added to projects to help the community assess the reproducibility of a project they want to use check it out here 👉 i know this might be controversial so i d honestly love to have an open discussion – do you think i m missing something should the order be different would also love to get a pr to the format of reproducibility md you can do that here
robe2y,1,master project ideas hi all for my masters project i am looking for some ideas for final project my aim is to nail down ds concept and also get exposure to deep learning and ai algorithms i want to build an end to end solution i have bi and data engineering background initially i nailed down three broad areas for reserach remote sensing cybersecuity and algorithmic trading although i am open to other areas as well as long as my basic criteria is met learning and easy availability of data any suggestions on topic would be appreciated ps i am not afraid to take some complex assignments as well
ragd4u,1,where can i find good resources for using nlp techniques when it comes to processing commands and requests from a user
r9hir9,1,latent space walk with custom stylegan2 model hi guys i started working with ai a few weeks ago and it s going well so far i dont have any coding experience so it s pretty hard sometimes to understand what s going on in some github posts or colab notebooks but i managed to train a custom model with stylegan2 in colab i trained the ai with around 6k pictures for 3 days now i want to create an interpolation video with this custom model but i m kinda stuck at this point i couldn t find a proper tutorial or an easy to use colab notebook on how to generate a video can anyone explain to me how i can generate a video from my cutsom model or has a functional colab notebook guidance i found this notebook which generates an interpolation video of anime faces from a pretrained model i believe this notebook could work with any other custom model but i couldn t manage to edit the code properly i grant 1000years of thankfullness for every help 3
qm5nfs,0,neural program generation modulo static analysis mukherjee et al 2021 neurips spotlight nice paper using program analysis as a learning signal for program synthesis i am not the author alas paper twitter 1 10
r6xzz7,1,machine learning methods for classification with categorical variables to start i d like to say i have very little experience in machine learning or statistics computer science in general what i am interested in is a list of models i can use to classify a binary dependent response output y variable with non ordered categorical independent explanatory input x variables i know the list at that has been super helpful but i can t tell which models use quantitative or ordered variables or a quantitative output variable i ve used a randomforest and neural network model to some great success but i d like to find some other models that i can play learn with x200b edit just in case anyone is curious what models i ve used so far single decision tree model rpart in r random forest classification neural network classification using one hot encoding of predictors done in nnet package naive bayes classification done in e1071 package the naivebayes package had some issues
rbue4h,0,us gov launches ml competition to predict snow water from remote sensing data 500 000 prize pool x200b seasonal mountain snowpack is a critical water resource throughout the western u s snowpack acts as a natural reservoir by storing precipitation throughout the winter months and releasing it as snowmelt when temperatures rise during the spring and summer this meltwater becomes runoff and serves as a primary freshwater source for major streams rivers and reservoirs as a result snowpack accumulation on high elevation mountains significantly influences streamflow as well as water storage and allocation for millions of people snow water equivalent swe is the most commonly used measurement in water forecasts because it combines information on snow depth and density swe refers to the amount of liquid water contained in a snowpack or the depth of water that would result if a column of snow was completely melted water resource managers use measurements and estimates of swe to support a variety of water management decisions including managing reservoir storage levels setting water allocations and planning for extreme weather events over the past several decades ground based instruments including snow course and snowpack telemetry snotel stations have been used to monitor snowpacks while ground measures can provide accurate swe estimates ground stations tend to be spatially limited and are not easily installed at high elevations recently high resolution satellite imagery has strengthened snow monitoring systems by providing data in otherwise inaccessible areas at frequent time intervals given the diverse landscape in the western u s and shifting climate new and improved methods are needed to accurately measure swe at a high spatiotemporal resolution to inform water management decisions the goal of this challenge is to estimate snow water equivalent swe at a high spatiotemporal resolution over the western u s using near real time data sources prizes will be awarded based on the accuracy of model predictions and write ups explaining the solutions as described below getting better swe estimates for mountain watersheds and headwater catchments will help to improve runoff and water supply forecasts which in turn will help reservoir operators manage limited water supplies improved swe information will also help water managers respond to extreme weather events such as floods and droughts seasonal mountain snowpack is a critical water resource throughout the western u s snowpack acts as a natural reservoir by storing precipitation throughout the winter months and releasing it as snowmelt when temperatures rise during the spring and summer this meltwater becomes runoff and serves as a primary freshwater source for major streams rivers and reservoirs as a result snowpack accumulation on high elevation mountains significantly influences streamflow as well as water storage and allocation for millions of people
qlt4cz,0,aaai 2022 paper reviews now that aaai 2022 reviews are out i am creating a discussion thread for this year s reviews
rsm8st,0,bayesian evidence calculation with normalizing flows is there any way to calculate evidence marginal likelihood or model evidence using normalizing flows i usually calculate it using nested sampling algorithms and was wondering if there was an ml alternative
rrydgm,0,ecco language model analysis and visualization toolkit hi r machinelearning over the last couple of years we ve been building this toolkit to explore and visualize transformer language models it brings together a wide variety of tools and methods to visualize and analyze model inner workings and activation spaces features support for a wide variety of language models gpt2 bert roberta t5 t0 and others ability to add your own local models if they re based on hugging face pytorch models feature attribution integratedgradients saliency inputxgradient deeplift deepliftshap guidedbackprop guidedgradcam deconvolution and lrp via captum capture neuron activations in the ffnn layer in the transformer block identify and visualize neuron activation patterns via non negative matrix factorization examine neuron activations via comparisons of activations spaces using svcca pwcca and cka visualizations for evolution of processing a token through the layers of the model logit lens candidate output tokens and their probabilities at each layer in the model x200b we just released v0 1 0 which brings encoder decoder model support t5 t0 feature attribution via integrated gradients and many other methods provided by captum github paper
ri1qvp,1,having trouble with scipy optimize minimize while building a logistic regression from scratch hi i m am trying to build logistic regression model to predict heart diseases from this kaggle dataset i am unfortunately struggling with an issue for which i cannot find an answer with google here s my code df pd read csv heart classification csv delimiter shuffling it as target are all ordered df df sample frac 1 reset index drop true data df to numpy creating training and validation set m n data shape train nb round 0 8 m x train y train data train nb 1 data train nb 1 x train np concatenate np ones x train shape 0 1 x train axis 1 x val y val data train nb 1 data train nb 1 features df columns initializing theta theta np random randn n def sigmoid z return 1 1 np exp z def cost function theta x y m x shape 0 pred sigmoid np dot x theta j 1 m np sum np dot y np log pred np dot 1 y np log 1 pred grad 1 m np dot x t pred y return j grad options maxiter 500 res optimize minimize cost function theta x train y train jac true method tnc options options j res fun theta res x executing this gives me typeerror nonetype object is not subscriptable i tried removing both method and options arguments i am using optimize minimize as that is how i learnt it while completing andrew ng s coursera course i could code a gradient descent if it s the best way to do it but did not try yet any idea why this is happening and how i could change my code any unrelated comment on its structure is welcomed too thanks
qryaz4,0,p alphafold 2 1 1 without docker want to fold monomers and multimers using alphafold2 without the need for docker look no further than my fork of deepmind s alphafold repository that removes all docker dependencies enjoy alphafold docker
qnchpo,0,google uc berkeley’s data driven offline optimization approach significantly boosts hardware accelerator performance reduces simulation time by more than 90 a research team from google research and uc berkeley proposes prime an offline data driven approach that can architect hardware accelerators without any form of simulations compared to state of the art simulation driven methods prime achieves impressive performance improvements of up to 1 54× while reducing the total required simulation time by up to 99 percent here is a quick read google uc berkeley’s data driven offline optimization approach significantly boosts hardware accelerator performance reduces simulation time by more than 90 the paper data driven offline optimization for architecting hardware accelerators is on arxiv
rfum8k,0,batch normalisation with batch size 1 batch normalisation has shown to have poor performance on small mini batch size for large scale computer vision tasks but for large input data e g medical image segmenation batch size of 1 is sometimes required i have a very simple question is it still adviseable to use batch normalisation with batch size 1 and is this different from instance normalisation see wu 2018 group normalisation i e do the tensorflow pytorch implementation of batch norm and instance norm calculate exactly the same metrics for batch size 1
ri4wl9,1,suggestions on my learning path hello everyone i made myself an ml dl learning path and ask you to make comments suggestions on my learning path please note i ve already finished codecademy data scientist path and want to keep learning ml dl first i have to say that i want to get my hands dirty in the first weeks of this path instead of spending weeks just to learn theory so my intention is to learn ml dl by using ml dl and start building my portfolio courses specializations 1 practical deep learning for coders fast ai 2 part 2 deep learning from the foundations fast ai 3 deep learning specialization deeplearning ai 4 tensorflow developer professional certificate deeplearning ai 5 aws fundamentals specialization aws for the next specialization 6 practical data science specialization deeplearning ai aws 7 tensorflow advanced techniques specialization deeplearning ai 8 code first introduction to natural language processing fast ai 9 natural language processing specialization deeplearning ai books 1 hands on machine learning with scikit learn keras and tensorflow concepts tools and techniques to build intelligent systems aurelien geron 2 ai and machine learning for coders laurence moroney x200b please feel free to advise more courses or books thanks in advance
qmsyf8,0,pruning for self supervised speech recognition mit news paper neurips 2021
r3bi9l,1,a problems with gaussian processes with or without quaternions a problem involving gaussian processes should i use quaternions or not i am researching a solution to a problem that requires the use of gaussian optimization i am looking for the rotation of a 3d object that maximize an arbitrary score the space of the problem is a unit quaternion and the score is a real scalar for each possible rotation do you think it would be better 1 to use a gaussian process h r 2 to use a gaussian process r 3 r with some cyclic kernels such that there is no discontinuities and the space wraps around the unit sphere i saw a lot of papers using dual quaternions but translations are not required in my case i just need to find the way to rotate my object to maximize the score i don’t mind if i were to get euler angles instead of a quaternion i am just uncertain about the best way to go quaternions feel more theoretically beautiful but i am not confident in my abilities to implement and combine gaussian processes with 4d complex numbers i hope i gave enough information in this post to give relevant answers otherwise feel free to ask more questions and i will edit the post
rju3nf,1,how to detect timing anomalies using ml methods hello everyone i am really new to machine learning algorithms right now there is a research project on my desk and being expected addressed with some ml methods we would like to detect the timing anomalies in the power traces of our embedded system let s say i can sample the system voltage at some rate for 1 second exactly after the moment when the system powers on to make the scenario as simple as possible for an easy start the system embedded power on behaviors are fixed so we expect the voltage patterns should be the same for each run as well if the noises are not considered what i have done is to collect 30 traces 20 items for training while 10 for validation as the training set hoping the trained model can give me a prediction at each timestamp during the testing phase so that a threshold can be set to alert if the incoming values deviate too far from the prediction it is an anomaly the collected 30 traces would not be exactly the same considering the random noises and the different micro architectural states the main reference i am using is this tutorial i select the cnn algorithm and perform the training and retrieve the prediction waveform as shown below x200b blue is the reference trace without timing anomalies while red is the prediction trace it looks like the cnn captures some patterns but the amplitude seems to appear a proportional difference the below are the squared errors between the two traces the maximum error is around 25 x200b square errors between the reference trace and the prediction one however if i compare the prediction trace with a corrupted trace with many timing anomalies the square errors report the deviations at more timestamps but the maximum value is smaller than 25 so i cannot set a static threshold for claiming those anomalies x200b blue is the corrupted trace with timing anomalies while red is the prediction trace x200b square errors between the corrupted trace and the prediction one with that i do have a few quick questions which might look naive to you experts 1 is cnn the correct option to go with for this purpose otherwise what kind of algorithm i should use for this project in your opinion 2 does the prediction trace make sense why does the amplitude difference occur between the predictions and reference 3 is it possible to set a dynamic threshold to differentiate the timing anomalies in the latter scenario 4 i am using pytorch any suggestions you can offer to run the training procedure faster the training took me more than 1 day i really appreciate you finishing reading such a long question really looking forward to hearing from you about any suggestions and opinions thank you
qk2bj6,0,current state of the art and novel research in support vector machines title pretty much says it already i m interested in the current state of art of svms svrs and on which topics researchers currently work on in that area i guess optimization still being a big one would also appreciate any paper links posted here on not so much known svm extensions etc go nuts
rfkcdy,0,my deep learning 2021 year review and predictions for 2022 hey everyone wondering what people s thoughts are for deep learning in 2022 here is my little recap and predictions a little background is i work as a data scientist with python have been working with supervised deep learning models for nlp tasks for my own personal endeavors just recently started looking into audio models for fun i haven t played with many computer vision image models like clip and dall e but i have been meaning to because of all the cool art i see luckily i have next year python library s pytorch tensorflow jax pytorch definitely made big moves this year in research with tools like speech brain being released for audio models like eleutherai gpt neox and other large transformer models using pytorch they are also beating tensorflow in google trends tensorflow still reigns supreme on github with 3x the stars and in industry the tensor board and tfx for pipelining are really powerful stuff google used it for most of their papers like bert which was also huge i haven t built anything in jax yet but it looks like it s got great potential i can t wait to try it out in 2022 my understanding is you re able to run the same code on either gpus or tpus this brings me to my next prediction cloud platforms gcp aws azure ibm cloud my background i mainly use gcp so biased i have used aws sage maker but not a lot aws sage maker in the industry has basically been unmatched till this year gcp released their vertex ai service and well it works it s just way too new for many people to adapt to it yet additionally they also released their fully managed kubernetes clusters it s my first time working with kubernetes so i can t speak on this but talking to other people say it s amazing i have no experience with azure or ibm cloud so please fill me in my prediction is that jax will lead to a huge rise in models that can use tpu s google has plans to release its tpuv4 while amazon trainium is still in early access 2022 deep learning might go to gcp they got the tpu s and the kubernetes amazon of course still has the ml industry in a chokehold then again with everything being containerized switching services over well it s still a hassle but if you re working with large deep learning models i think you might consider moving some models over to gcp shout out some other cool organizations in the dl ml space hugging face for growing like crazy with their transformers library weights and biases for always tracking my models nvidia has just been flexing hard with stylegan3 and megatron open ai gpt 3 i bought into the hype for a bit that it solved language eleutherai gpt j and neo speech brain is not an org but a cool toolkit that was released this year what are some other groups that do awesome stuff you love there is way too much stuff to keep track of i would love to do a broad overview year review of 2021 so please comment below your thoughts of the year i think the attention transformer models are the biggest thing this year i want to hear more about these crazy image models and what they can do i really wanna hear from people who do unsupervised learning which libraries have you used in 2021 which is your favorite most used does anyone not use python what cloud provider do you use for ml did you switch do you want to do you use azure ibm cloud hows watson doing what are your predictions will people not care as much for tpu s are the slaughter bots coming one thing is for sure there s only going to be more with no hope of keeping track of it all cup
rsn8mc,0,mse difference magnitude in tabular data deep learning is not all you need i m reading the paper tabular data deep learning is not all you need and looking at the differences in mse between the various dl architectures and xgboost and the ensembles tested table 2 in particular where the yearprediction and rossman data sets comparisons are shown as mse frankly these values all seem fairly close and some of them are very close for example the deep ensemble with xgboost does best on yearprediction with an mse of 76 19 while node is really close at 76 39 several others are within a couple of points of these are the differences really that great given that the error is squared i would guess not unless the error 1 i don t know exactly if the 76 is bad or good itself but 76 vs 78 seems close enough that i m not sure the dl xgboost ensemble is worth the trouble i suppose that the correct answer would be it depends on your need for accuracy vs cost of training etc but i m trying to get an intuition here if i were to look at these some of these dl models seem pretty close to xgboost and even the furthest don t seem to be that bad at 83 vs 78 am i missing something the same question applies to the cross entropy comparisons but i am less familiar with that metric
r6dzjf,0,uniform sampling over the feature space hello i have a question concerning my master s thesis and thougth maybe someone can help me here to put it simply i have a supervised learning problem i need to predict a regression target value based on circa 20 features do not want to go into detail as it is under disclosure with a classical ml model like random forest regression this project uses real world data the model does not need to generalize beyond the test set as the prediction on the test set is all we want i split the dataset into training and test set not randomly but by uniformly sampling over the entire feature space simply spoken this is done by calculating euclidean distances between the points in feature space and iteratively sampling the points farthest away from each other the result is a uniform distribution over the feature space for training and test set this is the kennard stone algorithm but i came up with it without having heard of this algorithm the algorithm ensures that the test set lies within the training set in feature space and even ensures that outliers are included in the training set the thought process is that the ml model will not need to perform extrapolation on the test set which should yield better results performance shows that this data split indeed performs much better on the test set than random splitting my supervisor wants me to prove that this works better than random splitting not only empirically does anyone of you have an idea how to prove that including the outliers in the training set and performing data splits that uniformly sample over the entire feature space improve the performance on the test set i mean i often read that extrapolation is very hard for machine learning models but i cannot come up with an experiment to show this if something is unclear pls ask your questions thank you in advance alex edit note that these so called outliers are the points on the surface of the feature space if we think of it as a ball in a 3 dimensional feature space so the data points on the surface of the sphere are included in the training set
r47lvu,1,looking for beginners to try out machine learning online course hello i am preparing a series of courses to train aspiring data scientists either starting from scratch or wanting a career change for example from software engineering or physics i am looking for some students that would like to enroll early on for free and give me feedback on the courses the first course is on the foundations of machine learning and will cover pretty much everything you need to know to pass an interview in the field i ve worked in data science for ten years and interviewed a lot of candidates so my course is focused on what s important to know and avoiding typical red flags without spending time on irrelevant things outdated methods lengthy math proofs etc please send me a private message if you would like to participate or comment below
rc60ei,1,sagemaker canvas limits pitfalls and short comings was getting my feet wet with using sagemaker canvas and fell into my first hole please ensure that the dataset has at least 250 rows with no missing value can t even train on kaggle titanic because not everyone has an age or cabin what other limitations and short comings am i going to have to make allowances for
rf8vfu,1,useful data summary statistics with image classification hello i am doing image classification with tensorflow for learning purposes i am splitting the data into 5 folds i would like to get useful summary statistics on these validation sets what could be useful other than the shape of the validation sets
r6srub,1,where do i look for data hello i m a newbee trying to make an elearning or ehealth website and i want to some big data sets to implement machine learning ideas into the website where do i find such data sets and which is easier to find data for elearning or ehealth and i d appreciate some machine learning suggestions if you guys have any thanks
r3hb3j,1,is there any overview of what specific layers groups of layers do i m in a strange situation i m working on a program that should help people to learn about neural networks by showing pretty much everything i can that goes on inbetween like the outputs of layers visualized if they look like images the data that goes through the layers and so on while i m not very experienced with creating nns myself i know this is a strange situation writing a program to help people to understand nns without understanding them myself but this is just how it is now i do this with tensorflow js so people can do it in the browser without having to write any code you can think of my program as a gui for tfjs in which you can drag drop layers around and that automatically generates graphs like the corresponding python code and the tf model in the browser and so on for example from the structure of the network in the gui this part works fine by now so people who know about nns can already use my program and train the network in the browser what i want to add is something like this this is a real albeit modified screenshot of my working program prototype my question is is there any overview of what groups of layers like some conv2d s followed by a maxpooling or something do so i can add bracket notations like that one that make it easier for people to understand what s going on since data can be very diverse i m aware that no single way of describing thouse groups will be correct all the time but i d be fine when it s correct in most default use cases i d really appreciate any links and as i ve said please assume i have no idea what nns really are because except for a very high level description of them i don t
rchib3,0,neural flows efficient alternative to neural odes neurips 2021 want to use neural odes but the solver takes too long try modeling the ode solutions directly instead using neural flows our model takes the initial condition and the time s at which we want to obtain the solution it outputs the solution that corresponds to solving some underlying ode this is done in a single call without numerical solvers to enable this the model has to satisfy two simple properties 1 it has to return the initial condition at t 0 2 it has to return unique solutions this is easily implemented in code the speed up is measured in orders of magnitude and we get better results across time series and density estimation tasks check out the paper code for more info
r9yjtq,1,minimum support hi all a basic question from me when working on a data set i ve been told the minimum support value is 0 3 what would this mean any help is greatly appreciated thanks
rug7ce,1,is the super harsh guide to get into machine learning up to date it s been 4 years and i just want to know if people still believe this information is relevant or do there need to be any additional changes the link is below for those that don t know what i m talking about x200b a super harsh guide to machine learning x200b i m a data scientist interested in getting a career as a machine learning engineer so i just wanted to know where i should focus my efforts
qk6h7n,0,how does ai fit into the metaverse future what are popular applications and research topics of ai relevant for vr ar as an ml engineer i am interested in learning more about ml topics that are could be useful for building vr software and hardware this is meant to be an open ended question so all kinds of opinions and perspectives will be appreciated thanks
rf4vyo,1,can i repurpose yolo to classify objects like usual but also do a binary classification of those objects so here s the deal i want to take a pretrained yolo model and replace the last layer to do a slightly different task my classes will be individual people gary vs chris vs stacy etc but i also want to know if they have their hand in an open or closed fist my dataset would consist of bounding boxes with class x y width height 0 annotations with an open fist and class x y width height 1 annotations for a closed fist i know that the standard yolo algorithm returns an s s b 5 c sized tensor where s is the number of grid cells per axis b is the number of bounding boxes per grid cell and c is the number of classes and obviously b 5 means that every bounding box will have 5 outputs namely confidence x y width height so if my intuition is correct i need to change the output layer of yolo to output a s s b 6 c tensor which would represent bbox confidence x y width height hand confidence and then retrain it on my labeled dataset is this correct i could also double the class vector and have gary open gary closed chris open chris closed but my guess is this is a really bad solution gary open would be a complete separate class from gary closed which would be confusing to the model and if i wanted to add more hand poses for example then i m tripling quadrupling or worse to the class size also the output layer has just a linear activation function would that not be optimal for a binary classification problem
rc1dor,0,paper explained nüwa visual synthesis pre training for neural visual world creation video walkthrough nüwa is a unifying architecture that can ingest text images and videos and brings all of them into a quantized latent representation to support a multitude of visual generation tasks such as text to image text guided video manipulation or sketch to video this paper details how the encoders for the different modalities are constructed and how the latent representation is transformed using their novel 3d nearby self attention layers experiments are shown on 8 different visual generation tasks that the model supports x200b outline 0 00 intro outline 1 20 sponsor clearml 3 35 tasks naming 5 10 the problem with recurrent image generation 7 35 creating a shared latent space w vector quantization 23 20 transforming the latent representation 26 25 recap self and cross attention 28 50 3d nearby self attention 41 20 pre training objective 46 05 experimental results 50 40 conclusion comments x200b paper github
qq5c51,0,iclr2022 review stats i crawled the iclr2022 preliminary reviews with some help of another repo and uploaded the crawled raw data crawled today around 2pm utc 1 you can also find some quick stats like distribution of mean scores etc best paper by mean median score most controversial paper by std of scores in the following notebook feel free to play around with it ✌ excerpt of the data best 10 paper by median score paper id title link keywords mean max min std median num ldlwbbp2mlq minibatch vs local sgd with shuffling tight convergence bounds and beyond local sgd minibatch sgd shuffling without replacement convex optimization stochastic optimization federated learning large scale learning distributed learning 8 8 8 0 8 3 imsjopcon0p mt3 multi task multitrack music transcription music transcription transformer multi task learning low resource learning music understanding music information retrieval 8 8 8 0 8 4 brpdx1bdzkq demodice offline imitation learning with supplementary imperfect demonstrations imitation learning offline imitation learning imperfect demonstration non expert demonstration 7 33333 8 6 0 942809 8 3 sok zs6whb responsible disclosure of generative models using scalable fingerprinting generative models fingerprinting responsible disclosure deep fake detection and attribution 6 4 8 3 2 05913 8 5 bvvmotlmiw diva dataset derivative of a learning task leave one out cross validation automl dataset optimization 7 8 5 1 41421 8 3 lrocyb 0st2 approximation and learning with deep convolutional models a kernel perspective kernel methods deep learning theory convolution approximation generalization 7 5 8 6 0 866025 8 4 sict4xzn5ve what happens after sgd reaches zero loss a mathematical framework sgd implicit bias generalization deep learning implicit regularization manifold 8 10 6 1 41421 8 4 0dlwqqlmqv nas bench suite nas evaluation is now surprisingly easy neural architecture search automl 7 5 8 6 0 866025 8 4 k0e f0gfdga the multiberts bert reproductions for robustness analysis pre trained models bert bootstrapping hypothesis testing robustness 7 33333 8 6 0 942809 8 3 fkv aszk47 learning similarity metrics for volumetric simulations with multiscale cnns metric learning pdes numerical simulation physical modeling 6 33333 8 3 2 35702 8 3 10 most controversial papers by std of scores paper id title link keywords mean max min std median num p0rcmden visual hyperacuity with moving sensor and recurrent neural computations visual system convolutional neural networks recurrent neural networks active vision active sensing ocular drift 4 75 10 3 3 03109 3 4 fpgs276lueq palette image to image diffusion models machine learning artificial intelligence computer vision 4 75 10 3 3 03109 3 4 sc6jbeviud0 white paper assistance a step forward beyond the shortcut learning shortcut learning bias classification imbalanced classification robustness 3 75 8 1 2 94746 3 4 7iwgzq6gz1d constructing a good behavior basis for transfer using generalized policy updates reinforcement learning lifelong learning transfer learning successor features 6 10 3 2 94392 5 3 jgo8cvg5s9 universal approximation under constraints is possible with transformers constrained universal approximation probabilistic attention transformer networks geometric deep learning measurable maximum theorem non affine random projections optimal transport 7 10 3 2 94392 8 3 3ilxkq7yelm learning continuous environment fields via implicit functions continuous scene representation implicit neural networks 5 8 1 2 94392 6 3 v1mbgnbx5e mask and understand evaluating the importance of parameters influence function interpretability model pruning feature importance ranking 4 8 1 2 94392 3 3 tq75md fqqp efficient and modular implicit differentiation implicit differentiation bilevel optimization autodiff jax 6 33333 10 3 2 86744 6 3 memmmuwrxsy robust robotic control from pixels using contrastive recurrent state space models contrastive learning model based rl distractions predictive coding 4 66667 8 1 2 86744 5 3 kxarp2zoqak information aware time series meta contrastive learning information aware time series meta contrastive learning 6 33333 10 3 2 86744 6 3
rg43yb,0,international data analysis olympiad idao 2022 x200b we invite ml students and specialists from all over the world to take part in the international data analysis olympiad hse university and yandex are organizing it for the 5th time and the otkritie bank will be our platinum partner this year since it’s our first anniversary we decided to change the format students and ml specialists are divided into two separate divisions only students are able to join the main competition — the student division all others can join the open division to participate hors concours for their own interest traditionally the first stage’s task will be given by the laboratory of methods for big data analysis lambda hse university it will be about predicting the properties of two dimensional crystals of various configurations the task for the finals will be provided by the otkritie bank the olympiad includes two stages online stage 1 28 february 2022 • track 1 traditional machine learning competition on yandex contest platform you will need to make new predictions and upload them to the automatic verification system • track 2 come up with a solution for the same problem keeping within a rigid framework of time and memory used final 16 17 april 2022 moscow • top 30 teams according to the online stage results will be invited to the online final • in the final 36 hours of the competition participants will try not just to train the model but to create a full fledged prototype which will be tested both in terms of accuracy and performance registration is open till february 13
r81v4u,0,supervised training of spiking neural networks for robust deployment on mixed signal neuromorphic processors spiking neural networks running on mixed signal devices promise highly energy efficient edge ml inference but deployment is an issue — mismatch between devices breaks down network performance because mixed signal devices rely on sub threshold analog signals small differences between transistors lead to large changes in neuron and network behaviour between chips you can train or calibrate each and every chip but that’s hugely expensive at scale we used a class of spiking networks called efficient balanced nets from the labs of sophie denève and christian machens which can correct for errors in network encoding we built a supervised training method around this architecture by copying the network dynamics from a trained teacher ann by doing so we can learn arbitrary tasks in robust snns we compared our approach against other methods for training snns — liquid state machines spiking force training and bptt — and showed that our approach was the most robust against parameter mismatch preprint arxiv open access sci rep code github
r4pjqu,1,tensorflow and no cache dir in requirements txt i am trying to install tensorflow for my flask application how do i write no cache dir in requirements txt file where should i write it
re0oxk,1,how much linear algebra is required to be able to follow core ml theory hi so i already know the basics of linear algebra from high school i was wondering if that would be enough for me to able follow one of the ml lecture series like cs229 by andrew ng or cs156 by caltech or i should go through linear algebra lectures by professor strang first because that would be really time consuming if i follow that course completely along with assignments
roulqh,0,apple ai residency 2022 hi all i am starting this thread for everyone who has applied to the apple ai residency in 2022 the applications have closed on the 15th of december has anyone heard about the online coding test thank you for this and wishing everyone the best of luck with their applications
re1hgk,1,forsyth d 2019 applied machine learning hi everyone i am searching for the pdf of this book if someone can help me i would be very greatful
qkfgxj,0,how does tensorflow perform on m1 pro max basically the title apple claims that tensorflow is optimized native for m1 chips but how does it actually perform
rd26uw,0,increasing the accuracy of textual data analysis on a corpus of 2 billion words at soroco we ingest between 200 million and 2 billion words over the course of model training and analysis for a single team of workers using our scout product in this blog post i talk about some tips and tricks that we might use to increase the accuracy of our models including appropriate processing of text for the purpose of leveraging standard techniques from machine learning i then demonstrate this by showing how to represent text in a high dimensional vector space with applications to a toy regression problem
rogiq2,0,weak supervision in practice when to collect strongly labelled data i ve spent some time trying to find good resources for practical weak supervision most tutorials guides research papers this is somehow reasonable etc assume you have a strongly labelled validation set before you start defining rules labeling functions in most cases this validation set is also used to evaluate labeling functions e g in snorkel via the lf summary in this context i d love to know what are people doing in practice first label collect validation set and then do weak supervision or other workflows such as starting with rules lfs and then labelling a subset of weakly labelled data would love to hear your experiences and pointers
rgfo6n,1,how to build a grid map x y from addresses hello guys anyone knows if there a way to build a grid array 2 d from addresses there may be an api googlemaps like to link the respective sql database addresses as positions on the map or convert to latitude and longitude i d like to study these points in the field of geostatistcs kriging x200b thank you all
qshm5b,0,questions regarding self supervised learning for music dino moco hello everyone first of all i am pretty inactive on reddit so i hope that this is the right place for this post i am a computer science graduate student focusing on machine learning working on an interdisciplinary research project regarding the analysis of music tl dr i try to extract general and descriptive music features on various different levels which self supervised methods can you recommend for limited resource capacities which data augmentations to use for music general tips and tricks for ssl with music is it a good idea to use a pretrained backbone in order to get away with a small dataset and compute e g openai s jukebox vq vae why is my dino setup not converging x200b general idea rather than solving some specific mir task e g genre classification my goal is to extract generic interpretable and descriptive music features in other words i want a model that “perceives” and “understands” music in general without giving it a specific goal i would then further analyze extracted features e g to find relations to human music perception or use them for downstream tasks ideally the outcome is a model that can describe music on various different levels e g beat rhythm harmony for example by features extracted from different neural network layers shallow low level deeper higher level i know that this is by far no easy task but it is worth investigating the possibilities and limitations in my opinion which self supervised learning method after some research self supervised learning ssl seems the way to go here ssl is a research area that gained momentum over the last two years or so and there are multiple proposed methods however applied mostly in the computer vision area images additionally ssl methods seem to be rather data hungry and as you might imagine my resources are quite limited i have a gtx 1060 available locally but i am also willing to pay in order to train a model on gpu cloud services e g lambda gpu since my budget is low i’d like to do all testing locally or on other free alternatives such as colab in order to find the right method hyperparameters etc for the actual training on a payed server idea using pretrained jukebox backbone my idea is to use the pretrained vq vae from openai’s jukebox see below as a backbone and hope that it extracts useful intermediate features which i can forward to my comparably small model with this i hope to get away with a small dataset 60 hours of music and relatively low resource usage while still achieving reasonable results does anyone have experience with such setups now to the ssl method itself ignoring generative models on the one hand there are contrastive methods such as cpc simclr or the less resource hungry moco on the other hand there are methods which do not explicitly formulate a contrastive loss such as byol or dino especially the latter one seems interesting unfortunately i have no experience in training such models at all which is why i wanted to ask the community for some tips and feedback suited for my problem preferable methods are those which do not require much hyperparameter tuning time and compute limitations or much compute during training e g large batch sizes with simclr but still achieve good results dino not working properly currently i am testing the dino method on a very limited setup locally my dataset consists of a very small portion of the fma dataset 90 minutes of music with a sample size of 4 seconds and a batch size of 14 using the lars optimizer additionally i have adopted the audio augmentation strategy from a paper that applies simclr to music clmr see below i am very happy about ideas for other better music augmentations for my problem though however the model does not seem to converge properly the loss decreases quite quickly after a few epochs after a while however the model seems to collapse and the loss increases rapidly staying high over the remaining epochs i figure this has something to do with the momentum hyperparameter i e how much of the student’s weights get transferred to the teacher after each iteration when increasing this number the collapse effect is minimized or is non existent at all if large enough but the loss does not really decrease much either i have logged everything and computed stats for several epochs if anyone is interested when splitting the loss up into the teacher entropy and the kl divergence between the student and the teacher one can see that the collapse is caused by the entropy part does anyone have experience with dino or similar methods and might have a clue why this is happening as mentioned i can give more details about the hyperparameters logs statistics etc is it possible that this phenomenon is due to the small dataset and batch size on my local machine and it would diminish on the cloud with a larger dataset and or batch size though they mentioned in the paper that they have successfully tested their method even with a batch size of 8 i know this is a lengthy post but i wanted to share as much detail as possible about my goal and resulting problems hope anyone might give some feedback papers jukebox clmr dino
ruqaoc,1,tensorflow keras implementation of vision transformer tensorflow keras implementation of an image is worth 16x16 words vit excellent results compared to sota cnns while requiring fewer computational resources to train paper code
r1bau8,1,model for credit payment probability i was asked to work on a model to predit a credit payment probability i know there are models to predict credit default which gives you true or false in the outcomes but in this case i need a number as a probability which model could give me that
qvgc13,0,u s fda fellowships in regulatory science for machine learning systems to apply see link anticipated appointment start date as soon as a qualified candidate is identified start date is flexible location silver spring maryland x200b organization u s food and drug administration fda center for devices and radiological health cdrh office of science and engineering laboratories osel division of imaging diagnostics and software reliability didsr artificial intelligence and machine learning program ai ml x200b assignment continual learning in machine learning is poised to bring changes to the speed at which the healthcare industry will adapt to the changes in patient management research in this area is still at a nascent stage with several recent research publications aiming towards solving the plasticity stability dilemma this is a critical time for the agency to develop performance assessment strategies to evaluate the safety and effectiveness of these continual learning algorithms in this project our goal is to develop a evaluation framework for continual learning algorithms specifically for segmentation and classification tasks the research fellow will play a key role in developing and evaluating ai ml algorithms x200b job responsibilities under the guidance of a mentor the participant will be involved in the following activities conduct research to answer emerging evaluation challenges in medical imaging and diagnostics systems contribute to the agency’s regulatory efforts by providing technical expertise collaborate with team members and stakeholders to complete and report widely disseminate findings and regulatory science tools in conferences and peer reviewed journal publications x200b candidate qualifications the qualified candidate should be currently pursuing or have received a master s or doctoral degree in one of the relevant fields degree must have been received within the past five years preferred skills strong background in the fundamentals and an eagerness to solve technical challenges systematically with experimental and or computational approaches developing and analyzing ai ml methods cnn rnn gan etc programming with python including scientific stack numpy scipy scikit learn etc and deep learning frameworks tensorflow pytorch etc experience with image segmentation processing and data management
qngw0u,0,buying a pc for training does it make sense in 2021 i work with text data i d love to put 500 down to have a machine that can fine tune the largest gpt 2 instance the largest two are 774m and 1 5b parameters does it still make sense to buy a computer to do it i ve spent a few hundred dollars on aws credits but knowing that i m being throttled by the cost limits the experiments i can run i would love to hear from those who have bought machines or those who have decided against it i would probably look for a used one on ebay though i know very little about purchasing a pc
qxl93a,0,state of pytorch mobile in comparison with tflite does anyone have experience with both frameworks and have a more in depth knowledge on the current state of affairs regarding embedded dl i wouldn t like this to turn into another framework flame war and instead have a more general comparison between tflite and pytorch mobile the latter being still in beta in terms of ease of use mostly how much you need to break your model what layers are actually conversible to mobile format etc api stability support for mobile ios android in terms of cross compilation tools and hw acceleration support for other socs and fringe devices also are there any other contenders i am missing
ropcvb,0,researchers from the university of chicago and tel aviv university introduce ‘text2mesh’ a novel framework to alter both color and geometry of 3d meshes according to a textual target in recent years neural based generative models have been at the center of attention for their exceptional capability of creating aesthetically attractive graphical content seemingly out of nowhere recent solutions of this kind like vqgan and in general all derivations of generative adversarial networks and their combination with other deep learning techniques like clip from openai a joint image text embedding model led to amazing results using very complex and powerful generative techniques with the advent of nfts and the application of transformer based techniques to computer graphics in videogames the hype built during recent years for generative models might finally lead ai generated art to meet the growing market demand in the field of entertainment the main perk of generative models that is their versatility in learning latent representations of given datasets comes at the cost of higher complexity and lower success rate of training experiments researchers from the university of chicago and tel aviv university introduce the’ text2mesh’ model the text2mesh model tries to avoid the above problem by proposing a non generative method to alter the appearance of 3d meshes by using a “ neural style field ” nsf learned with neural techniques that maps vertices of an input mesh to rgb color and a local displacement along their normal direction based on a text prompt that determines the style and appearance of the result the model is powered by the clip joint text image embedding space and appropriate regularization to avoid degenerate solutions paper summary paper github project page x200b
rib9m5,0,is there any work on embeddings that understand different measurements i would like to know if it is possible to create embeddings that understand different measures for example with such embeddings i would have text a more similar to b than c in terms of cosine similarity text a 13 inch screen text b 30 41 x 21 24 cm text c 3456×2234 pixels create an embedding that understand the order of magnitude and measurements
qrknk3,0,what are your favourite annotation platforms i have tried a few annotations platforms redbrick ai v7 labs supervise ly none of them quite hit the sweet spot for my use case i mainly care about uploading pre annotations of a semantic segmentation network to be double checked by human annotators the aforementioned platforms do offer this service but it involves fiddling with their respective sdks and doesn t always work that well can anyone share their favourite annotation platforms and why
rrrjrz,0,is spectral clustering still useful my impression is that before the deep learning revolution spectral clustering was an incredibly powerful tool with the explosion in unsupervised deep learning techniques i was wondering if anyone still uses spectral clustering do they if so in what settings would i expect spectral clustering to be state of the art
rq9shn,0,project color detection for wound detection i have a project that detects the color of the wounds bruise or and cuts i already implemented hsv for the detection but i m not satisfied for the result or maybe my range is not good i research other colorspace to use on my program and the best colorspace i read is the use of lab colorspace is it good that hsv here some result of detection using hsv if lab is good there are any resources about this topic and how can i implement it on a efficient way
rse1fs,1,how do i know which columns to drop i use python and i m reading islr i learned the importance of checking the p values of each predictor to decide wheter its worth keeping or not since there s no straightforward way to do this in python without statistics libraries like statsmodels what do you usually do to decide whether a column of data is worth keeping do i have to learn statsmodels to make an educated decision rather than doing trial and error thank you
rt1vfy,0,play around with stylegan2 in your browser i built a little page to run and manipulate stylegan2 in the browser it was pretty fun learning about onnx and how to port gans to web you can play around with the random seeds and also distort the intermediate latents to produce some really wacky results you can check out a gif on twitter let me know if you come up with anything cool
rdw0zo,1,deep forest and diversity short tutorial hi folks just released a quick tutorial for newcomers junior mleng about the new framework from 2017 about deep forest ✅ feel free to share your thoughts 🔬 cheers
rhcwxh,1,multivariate grouped time series classification what are my options hi i m looking for some ideas on how to handle a multivariate time series classification problem specifically i m dealing with many hundreds of time series of varying length but within the same ballpark let s say 30 difference between the longest and shortest with the same features and which should behave similarly at the end of each time series is a binary outcome each time series is around 5000 observations of 32 features my challenge is that i want to be able to pass live data through a model say halfway through the time series and classify how likely the positive outcome is most material i ve seen relates to forecasting a single time series not learning characteristics from many historical individual time series to classify a new one midway through right now my approach is to handle each observation as independent with some manual feature engineering and use grouped cross validation to avoid horribly overfitting on the fact that i m training on multiple instances of the same time series and thus the same outcome i m using an lgbm which gives acceptable and even good results but i m sure this can t be the best approach and while the results work there s a lot of variance in the prediction across the time series ideally we d have more uncertainty at the start and then a clearer picture starts to form but right now there s a lot of jumping around in the probability score i m not very familiar with time series modeling i imagine deep learning could be a good approach with an lstm or something like that but i m not very experienced with dl either i m also looking into sktime to see if there s anything that would work for me out of the box any suggestions on reading material or approaches i could use any help is appreciated cheers
qm06ct,0,iris open source photos platform powered by pytorch this is my submission for pytorch annual hackathon 2021 a self hosted alternative to google photos currently it contains basic features built with short scope of hackathon the team will be continuing to work by adding new features explore section smart search go check out and support the project now from below links youtube devpost github x200b
qw2c3p,0,is bert the future of image pretraining bytedance team’s bert like pretrained vision transformer ibot achieves new sotas a research team from bytedance johns hopkins university shanghai jiao tong university and uc santa cruz seeks to apply the proven technique of masked language modelling to the training of better vision transformers presenting ibot image bert pretraining with online tokenizer a self supervised framework that performs masked prediction with an online tokenizer here is a quick read is bert the future of image pretraining bytedance team’s bert like pretrained vision transformer ibot achieves new sotas the paper ibot image bert pre training with online tokenizer is on arxiv
qvvsuk,0,category orthogonal object features guide information processing in recurrent neural networks trained for object categorization recurrent neural networks rnns have been shown to perform better than feedforward architectures in visual object categorization tasks especially in challenging conditions such as cluttered images however little is known about the exact computational role of recurrent information flow in these conditions this paper tests rnns trained for object categorization on the hypothesis that recurrence iteratively aids object categorization via the communication of category orthogonal auxiliary variables the location orientation and scale of the object using diagnostic linear readouts we find that a information about auxiliary variables increases across time in all network layers b this information is indeed present in the recurrent information flow and c its manipulation significantly affects task performance these observations confirm the hypothesis that category orthogonal auxiliary variable information is conveyed through recurrent connectivity and is used to optimize category inference in cluttered environments preprint code data tweeprint
rcbvnb,1,deepfashion mmfashion reading the getting started page on github says python demo test py input input image file can somebody explain how would i get to this point i want to create a rec system i usually go off of existing projects but there are none online
qs0eup,0,fine tuning and running gpt j made easy have you guys seen eleuther’s gpt j for nlp yet i feel like it’s on par with openai’s curie it s pretty good overall for generic language generation but you still need to fine tune it for custom tasks so i ended up putting together this project to simplify fine tuning and deployment to production after both can be done through a web interface also i added a default pre trained gpt j to use through an interface or api too please check it out and give me feedback if you can thanks project
r5hymj,1,is data structures and algorithms important to become a machine learning engineer hi i have started to prepare for machine learning roles and i am working on the maths and python required i see a few people say that learning data structures and algorithms is important as well any suggestions would be helpful
rdy6gz,1,what is the most fun way to learn calculus i m a programmer and i ve come to realize that i learn things better when i put them into practice as i learn so you can say that i am a person who learns by doing is there any way to learn calculus and math in general using this learning approach we use in programming i want to go deep in math because i m interested in machile learning and because i need to learn these things to graduate from cs college lol
qka6p0,0,does cuda latest version support all version of pytorch and tensorflow greetings sorry i could not think a better place to ask this question where i can get response regarding pytorch tensorflow and cuda version i want to to know if i install cuda 11 5 will it support lower version tensorflow or torch packages such as tensorflow 2 4 or pytorch 1 71 which is supported by 11 0 cuda version actually i want to install both tensorflow and pytorch the best option is to install cuda 11 0 or 10 1 but i want to know can i install latest version of cuda and whether will it support both frame works
r3h9rp,1,on what filter does the conv layers operate if the previous conv output filter is less than the current hi guys i have a question about filter and conv layer for the sake of clarity let s take a look at this simple model input layers input shape 224 224 3 layer1 layers conv2d 64 kernel size 3 input layer2 layers conv2d 256 kernel size 3 layer1 model keras model input layer2 model summary whose output is layer type output shape param input 1 inputlayer none 224 224 3 0 conv2d conv2d none 222 222 64 1792 conv2d 1 conv2d none 220 220 256 147712 total params 149 504 my question are 1 the conv layer 1 has as output 64 filter the image that take as input has 3 channels every filter works on these 3 channel and than merge together or some filters work on the first channel other in the second and so on if so how the network choose how to assign filters to channels 2 the layer 1 has as output 64 channels the layer 2 has as output 256 channels and as input 64 basically the question is the same as before an example which channel take into account the first filter of the layer 2 i e conv2d 1 thanks for the answers
rjvmw0,1,can machine learning a hobby or is it a full time commitment hey all i m asking this question today as i m quite torn about my future studies im thinking of doing a double major with microbiology or biomed with cs but i dont really want to put myself at more stress during my time at uni but i am prepared to do so i heard about not really needing uni to learn computer related stuff and can self learn these things but is it more appealing to a company for a individual with a degree i know there is more career prospects in computer science but i dont really want to start all over again at uni i m a 2nd year science student and plus i dont even know how to program yet i m committed because i want a good future but am i getting myself in some deep waters or should i just swim away while i can any advice would be appreciated cheers
rqm5y6,0,how do you measure fairness without access to demographic data hi all i m working on a paper about measuring algorithmic fairness in cases where you don t have direct access to demographic data for example if you want to see whether a lender is discriminating against a particular race but the lender is not collecting releasing race data of loan applicants if you have 10 minutes and work in the ethical ai space it would be a great help to hear from this community on whether how often you have faced this issue in practice and what you think should be done to mitigate survey link is here
qntbjh,0,arch net a family of neural networks built with operators to bridge the gap between computer architecture of asic chips and neural network model architectures key takeaways as it turns out the arch net is actually building a bridge that translates between computer architectures of asic chips and neural network model architectures by changing existing floating point dnns into hardware friendly quantized arch net the structure of archnet is made up of five operators 3×3 convolutions batch normalization concatenation 2×2 max pooling and fully connected layers the conversion to arch net is much simpler without labeled data as researchers employ blockwise model distillation on feature maps researchers did extensive experiments on image classification and machine translation tasks to confirm that arch net is both effective efficient and fast paper github
ra9jmh,1,how to apply feature selection if i have mixed inputs numeric and nominal how to apply feature selection if i have mixed inputs numeric and nominal
rvy222,1,free no code ai to learn on does anyone here have experience using no code ai models that are actually useful and versatile and cheap or free i want to learn ai without coding i don t plan on being an ai engineer i just want to use it in everyday life i won t sit down and learn to code python and then learn ai theory and then learn statistics and then experiment with all the tools and then learn experiment with all the algorithms it ain t gonna happen charlie
rbeq9o,1,projects for beginners that have to do with games hi all a few months ago i graduated with my ba in psych i recently applied for some phd programs in psych and other more interdisciplinary programs my primary research has to do with researching social cognition through games i took some calculus during my undergrad i also have a couple years of doing data analysis in python if there s things i need to learn in order to do the project highly likely i m more than happy to learn i d like to start doing ml projects for various reasons but i m interested in any beginner projects that let me mess with game data there are a few datasets on kaggle that i might mess with so far i m thinking sentiment analysis of chat logs from twitch sentiment analysis of dota 2 chat data i m really interested in analyzing toxicity within specific games communities so i think this would be a good starter project if anyone has any other ideas or resources i d love to hear them x200b thank you
rxijit,1,when should we log transform our data i was reading the book hands on machine learning and it said that skewed data can pose a problem for some machine learning algorithms when i looked up the internet i found that we log transform our data if it s distribution is skewed when is this crucial which algorithms need the data to be normally distributed
qv9ez4,0,tools for feature selection for deep learning let s say i have access to a feature store with pretty much every imaginable derived feature available is there a tool available specifically for testing feature combinations and feature scaling upsampling downsampling i know there s weights and biases but i feel like and i could be wrong please chime in if you know they are mainly about hyper parameter optimization this would be variations of the data itself where within each version you would want to possibly explore hyperparameter tuning even if the answer for feature selection is to dump them all in and use something like l2 regularization different thresholds and things like scaling class imbalance fixes imputing etc all create different versions of the input data are there any good approaches or tools to track experiments around the preprocessing and feature selection part
r9soc8,1,training accuracy vs test accuracy i’m a little confused as to whether or not the difference in the training dataset accuracy compared to the test dataset accuracy shows whether overfitting has occurred or not say i’m training a mlp using cross validation to stop the learning if the validation set accuracy does not increase by a tolerance value for a set number of epochs intuitively if i then look at the validation accuracy curve i can see it increases and then remains constant however when testing the model on training and test data the training accuracy is a few percentage points higher so my question is does this small difference indicate that some overfitting had occurred or not does a better score in the training dataset compared to the test dataset generally indicate overfitting has occurred or not
rgk8db,0,what are challenges that quantum machine learning can solve i am looking to study quantum machine learning in a ph d but i want to understand more about how it can solve problems i understand the bpp and bqp problems and it’s ability to speed up computation but how can it solve problems in common life usually when i need to understand something i go to job postings in this case quantum machine learning engineer and i see companies are using qml for chemistry and agriculture any help would be appreciated
rjeqln,1,fastai is killing me hey guys i ve been working through the fastai course for a while now i m currently on chapter 8 and it feels like i m retaining maybe 20 of the information that is being taught i m not rushing through it or anything i try to understand each and every topic but it feels like some things aren t quite explained to you and trying to search it up puts you through some large math rabbit hole is this a normal feeling for a new user that s taking the course in a few weeks i m going to start 2 courses that are supposed to teach the essential mathematics and stats for machine learning so i m hoping that with the completion of those two courses this stuff will all start to make sense to me what do you guys think should i go even slower should i start learning the math as soon as possible did anyone else have this sort of experience with fastai does it getter better later on in the course thanks in advance guys
rbp1e6,1,what are state of the art approaches for product matching with high accuracy my goal is to compare invoice product prices against a price catalog to qualify if the price is reasonable the information i do have is everything that is usually seen on an invoice e g product description unit quantity price here is an example of some product descriptions german kelit kelox windox u press t stk aus windox ppsu d20mm xl 2 ig messing messing muffe reduziert nr 3240 ig ig 3 4 x1 2 geberit silent pp rohr mit muffe länge 50cm d40 i have tried string similarity so far however this approach seems to be too slow and easily fails if the string length differs too much the main problem is that the available data which can be used for comparison become gradually more further i also tried to capture certain attributes of a product description e g “brand” “actual product” “material out of which product is made” … by looking for phrases that are present in the product description consequently comparison is done over these attributes this approach is also very cumbersome as these phrases need to be set up manually what other approach could i try thank you a lot
qksq6q,0,how to generate images from text with clip vqgan easy to follow 5 minute tutorial by casual gan papers cartoon village in a mushroom valley trending on artstation hey everyone have you been playing with gans for a while and want to create something yourself do you want to try out those text to image google colabs for generative art you have seen on twitter but are not sure where to get started then this tutorial is for you my name is kirill and i have been writing weekly ml paper summaries for almost 9 months over at casualganpapers com and while they are helpful to a lot of people already working in the generative modeling field i realized the digests are not as interesting to those just starting their generative ai journey this is why i am starting a new series of posts focused on quickly getting you started in the world of generative art 3d ai based image editing and more check out the first post on how to use the popular clip vqgan colabs to create beautiful generative art in just 5 10 minutes excluding the training time if you enjoyed the tutorial make sure to follow casual gan papers on telegram or twitter to get notified when the next post is released take care kirill
r0edbv,0,deviation analysis between two 3d meshes hi folks looking for some guidance places to start researching i m playing around with metal additive manufacturing using metal polymer filament basically you 3d print a model using the filament debind the part i e slowly burn out the plastic component then raise the furnace up to sintering temperatures the remaining metal particles sinter and bind together giving you a metal component these components suffer fairly severe shrinkage during the debinding and sintering process anywhere from 10 20 globally pre scaling the part will get you close to desired dimensions but individual features on the component can shrink more or less than expected e g long thin features shrink or warp more than thick features holes and infill can affect surrounding areas presence or absence of supports etc etc i d like to explore some ml techniques to scale the model more intelligently i m not sure the best way to turn this into a tractable problem though 1 print debind sinter part 2 3d scan the resulting part 3 convert the original model and 3d scan into something that can be fed to a network 2d depth maps from multiple angles or perhaps do a deviation analysis between the two meshes first and convert that into some kind of 2d representation slice the scan and compare each slice against the model 4 get result and iterate with the next version 1 in reality i ll probably print sinter multiple models at the same time in a batch format to help speed things up does this sound even remotely feasible my main stumbling block is getting the 3d data into something usable i m not sure how this is typically handled i assumed it would be better to translate into something 2d instead of dealing with meshes or point clouds but perhaps that s incorrect i m also assuming some kind of deep learning is the right approach here but happy to investigate something else including non nn techniques happy for any tips ideas papers techniques etc to start researching thanks
ru9xro,1,what are resources for learning ml without python or a bunch of frameworks here is my problem i am interested in learning machine learning and have some basic understanding of it but most of the tutoruals blogs books i found were using python using a bunch of frameworks but i hate this i am looking for going up from scratch for eaxmple i have gone through several tutorials and according to me its way more fun and learning experience to build a neural network frm scratch to be trained to evealuate a and b rather than using a bunch of frameworks to make a chatbot or image caption generator in n lines of python code is there any good resource like thatnwhere i can learn ml from scratch note what i said above is totally my opinion and if you think i am wrong i totally respect that
rawaur,1,want to get the top k important words from the sentence using infersent model i am exploring the infersent model developed by facebook researchers in that model there are a lot of methods and functions available and i am more interested in the visualize method which is showing the importance of the words from the sentence with the help of a bar graph now i am not getting any clue how to extract those words from the visualise methods i checked the official github page of infersent model and i did not find any clue to get it done i am totally clueless in this case x200b infersent model visualize method and the output i need is moving canada business meet if i define k 4 k is top number of words
r718bt,1,build a job recommender from scratch using networkx and streamlit hey guys check out my newest project where i built a job recommender from scratch using scrapy networkx and streamlit this is how it looks like i have public all the code and tutorial in my github project page here huynhnhathao job recommender a job recommender system using graph based data representation and hybrid recommender system algorithm github com and this is demo link the ultimate jobs recommender · streamlit job recommender
rwgk3l,1,implementation of the u net architecture in keras hello everyone this tutorial explains the working of the u net architecture and explains its benefits further we implement it in keras and visualize the final structure using one of keras s built in functions u net implementation is keras
rg2g5v,0,which cloud provider are you using for gpu inference we ve evaluated several options but they all come up lacking hostkey unreliable and shoddy service gcp doesn t perform as well as our expectations aws expensive
qzsgma,0,having a hard time finding a dataset for my project i am in need of a dataset which segments images into colours not classifying a whole image as one colour and am having a very hard time finding one this is especially true as i need for shadows and anti shadows or light sources to also be labelled in the dataset just posting this here before i go about having to create my own dataset any help is appreciated
rvy2u8,1,i made a tutorial on variational autoencoders with an intuitive explanation and code hey everyone variational autoencoders are a really awesome tool for data generation but i ve found that there s a lack of resources with simple explanations for how they work i made a guide on them which you can find here without going into heavy mathematics the guide goes through 1 a high level introduction link to section here 2 an ordinary autoencoder recap link to section here 3 an overview of variational autoencoders link to section here 4 intuitively understanding how variational autoencoders learn link to section here 5 building a variational autoencoder for the fashion mnist dataset link to section here at the end you ll be able to create a gif like the one below where we can see the vae learning to associate different regions of the plane with different types of clothing have you used vaes before how do you think vaes compare to gans what applications of generative models are most interesting to you today i d love to hear your thoughts and feedback also please let me know if you d be interested in a follow up post that goes into the mathematics behind vaes
rkvq1x,0,compute costs with machine learning a team of researchers from mit yonsei university and university of brasilia has launched a new website computer progress which analyzes the computational burden from over 1 000 deep learning research papers data from the site show that computational burden is growing faster than the expected rate suggesting that algorithms still have room for improvement more work is needed on algorithmic efficiency over brute force compute data strategies x200b this validates many of the concerns stated in this post
reohjf,1,backpropagation for beginners warning not for faint hearted beginners complain that they can t find posts videos for backpropagation and beginners sometimes have no idea how backpropagation works in most tutorials when it comes to backpropagation only equations are shown to beginners and tutorials directly jump to keras pytorch etc and most of the time these tutorials are from the documentation of keras or pytorch in these posts i have tried to explain backpropagation in very simple language with very neat codes building your own neural network backpropagation part 1 backpropagation part 2 if these posts are helpful to you and you think they will be helpful to others please share them you can join me on youtube are neuralthreads on reddit
rnnynt,1,combining two different neural models hey guys i have two different neural models that were trained on two different datasets and for different tasks i would like to adapt one of them using the dataset of the other one but i have no idea how can that be done i read about ensembling methods but i don t think they can be applied in this case since the datasets are different any help from you would be very appreciated
rs6bu8,0,does anyone know of any databases of political text which are labelled with the classes conservative liberal and neutral for supervised learning i d like to fine tune google s bert natural language processing machine learning model to a political domain many thanks
rb1urf,1,phd in machine learning if i want to do phd in ml is it going to give me more importance and which are the best topics for phd in ml
r6v7ic,0,paper explained sparse is enough in scaling transformers aka terraformer video walkthrough transformers keep pushing the state of the art in language and other domains mainly due to their ability to scale to ever more parameters however this scaling has made it prohibitively expensive to run a lot of inference requests against a transformer both in terms of compute and memory requirements scaling transformers are a new kind of architecture that leverage sparsity in the transformer blocks to massively speed up inference and by including additional ideas from other architectures they create the terraformer which is both fast accurate and consumes very little memory x200b outline 0 00 intro overview 4 10 recap transformer stack 6 55 sparse feedforward layer 19 20 sparse qkv layer 43 55 terraformer architecture 55 05 experimental results conclusion x200b paper code
qmrr7t,0,pairprogramming pair analysis in ml development teams to improve harmony hi i m gonna assemble a small team to work on an ml project which might lead to an ml first software and i was wondering about whether using pair programming can be beneficial in ml teams especially in early stages which is adventurous analysis and exploration what is your experience with pair programming in ml and in what stages do you think it can be good with what strategy and etc we are all working remotely so that s another aspect that is interesting what is your experience and how do you create harmony in a newly assembled team that is working remotely
rr0q7h,0,best resources or tools to draw nicer table for comparing different models frameworks performance hi all would you like to suggest or share some resources to draw the table to compare different deep learning model like minst cifar so on with it s performance i was thinking of latex but the way i was trying to do it its not the exact like what i was looking exactly hence looking for some suggestions to make it nicer actually
qlujgx,0,loss function that penalizes classification errors heavily or should i just modify log loss i m working on a classification problem where predictions that are good enough are actually good enough so i don t need my model to spend time optimizing a top 1 90 to become a 98 or a 99 however i really care when the model makes incorrect decisions i ve built a family of models of different sizes parameter counts using traditional log loss as my loss function and each model will make catastrophically bad decisions on occasion and for my domain a few catastrophically bad classifications can ruin tens of thousands of good classifications i m wondering if there s a different loss function i can use that penalizes errors even more heavily than log loss log loss squared the natural question to ask is if i have errors in my data pipeline or model configuration i ve debugged it quite a bit and i m sure that s not my problem my domain chess naturally has a manifold that is so complex and twisted with many sharp edges and saddle points it s a really difficult space to work in so any model smaller than gpt 3 is understandably going to have trouble
r130k1,1,beginners helpful guide to training deep learning models on the cloud a while ago a friend of mine contacted me here on linkedin and asked me if i could give him some guiding into how he can train his deep learning models on the cloud i realized that he was facing the same issue that i faced when i tried to train my models on the cloud for the first time the issue is that there are lots of resources online and it might take you hours and days to find exactly what you need after all you just want to take your training code and data and put them on the cloud in order to address this issue i wrote a guide on how to do exactly this it s titled beginners helpful guide to training deep learning models on the cloud link to article follow me on medium if you want more of this kind of articles
r8n2dr,1,how to go about exercises in ml textbooks hello i am trying to self study ml theory using the text ‘understanding machine learning from theory to algorithms ’ i can follow the content in the book pretty well but i’m having some difficulties solving the exercises so i was hoping to get some advice on 1 how long you should work on a problem before consulting the solution manual if at all 2 how to decide which questions to work on 3 what to do if you are stuck my short term goal is to get a deep enough understanding of ml to be able to contribute to research as an undergrad any advice would be very helpful thanks
r4e8he,0,machine learning wayr what are you reading week 126 this is a place to share machine learning research papers journals and articles that you re reading this week if it relates to what you re researching by all means elaborate and give us your insight otherwise it could just be an interesting paper you ve read please try to provide some insight from your understanding and please don t post things which are present in wiki preferably you should link the arxiv page not the pdf you can easily access the pdf from the summary page but not the other way around or any other pertinent links previous weeks 1 10 11 20 21 30 31 40 41 50 51 60 61 70 71 80 81 90 91 100 101 110 111 120 121 130 week 1 11 21 31 41 51 61 71 81 91 101 111 121 week 2 12 22 32 42 52 62 72 82 92 102 112 122 week 3 13 23 33 43 53 63 73 83 93 103 113 123 week 4 14 24 34 44 54 64 74 84 94 104 114 124 week 5 15 25 35 45 55 65 75 85 95 105 115 125 week 6 16 26 36 46 56 66 76 86 96 106 116 week 7 17 27 37 47 57 67 77 87 97 107 117 week 8 18 28 38 48 58 68 78 88 98 108 118 week 9 19 29 39 49 59 69 79 89 99 109 119 week 10 20 30 40 50 60 70 80 90 100 110 120 most upvoted papers two weeks ago u catalyzex code bot paper link besides that there are no rules have fun
qmw43e,0,best approach for noisy language detection i need to predict the language e g english portuguese russian from a few words sentences this is noisy real world data meaning that the words might be misspelled have poor grammar emojis language switching etc there s a bunch of different github repos out there but it s unclear which one works well especially for noisy real world data and not e g wikipedia i had hoped that websites like would have solved this by now but i don t see a relevant category for language detection i don t have strong requirements for the solution to be particularly efficient although a transformer approach seems overkill for this any advice on a simple python library to use
rbbd2u,0,convolution papers i have a question regarding convolution in the 3bluebrown video on neural networks it states that researchers initially misunderstood what convolution was doing they thought that each layer was finding a different edge of the image and that after multiple layers convolution would notice the entire image as a compilation of many important edges however in this video an interview with ian goodfellow he explained that this is incorrect it seems that convolution is rather a continual refinement of an image each layer does not look for a different edge but rather gives us a more precise understanding of what the image is representing i know i may have explained this wrong but i am interested in learning why convolution actually works do you know of any papers that explain this concept well appreciate any and all help x200b x200b here is the interview i was referring to 📷 preview 1 08 37ian goodfellow generative adversarial networks gans youtube · lex fridmanapr 18 2019
rtukp2,0,plug or integrate a gnn pytorch code base into spark cluster does anyone have a better explanation or resources to share for plug or integrate a pytorch based gnn models into pyspark or similar cluster services
rdl6ib,1,uncertainty estimation in the input space hi assuming my input is an array between 0 and 1000 and the output the corresponding system velocity and the training data is generated by randomly applying one of the input values between 0 and 1000 the corresponding system velocity is then saved as the output is there a way to estimate the uncertainty in my input data such as when the input area between 0 and 100 has not been applied to the system that i can measure this uncertainty
rjckcw,0,optimizing model input based on some desired output hey all would like to hear some of your opinions regarding my research in my lab we are working on a bio inspired small aerial vehicle resembles a fly and there has been a suggestion to use ml principles to enhance its performance one option was related to this framework we provide some input i to our motor via controller say a sine wave such input should maximize some measurable output y for example the robot s altitude the question is what would be the best i that maximizes y one could think of such a problem in a more mathematical form suppose our robot can be represented by some function r unknown to us such that r i y our goal would be to find arg max r i a somewhat trivial suggestion is to go over all options for i and find the maximum value of r i but such space of inputs can be very big anyway i was trying to classify this task to some known frame of ml related tasks but couldn t find the answer few last thoughts to maybe spark a discussion i thought of this problem as sort of cross validation of the input i but again checking for all i s sound like a bad idea another thing is that this problem doesn t seem to be supervised or even unsupervised the input changes perhaps rl also the input can be thought of as sequential but still i think that rnns aren t really suitable not supervised per se and if you ve read thus far thanks would appreciate your comment
rvzhnh,0,interpolation extrapolation and linearisation prof yann lecun dr randall balestriero special machine learning street talk episode yann lecun thinks that it s specious to say neural network models are interpolating because in high dimensions everything is extrapolation recently dr randall balestriero dr jerome pesente and prof yann lecun released their paper learning in high dimensions always amounts to extrapolation this discussion has completely changed how we think about neural networks and their behaviour in the intro we talk about the spline theory of nns interpolation in nns and the curse of dimensionality yt pod references learning in high dimension always amounts to extrapolation randall balestriero jerome pesenti yann lecun a spline theory of deep learning dr balestriero baraniuk neural decision trees dr balestriero interpolation of sparse high dimensional data dr thomas lux
rk7ffw,0,discussion was gpt 3 trained to achieve double descent phenomena question in title also are there any other language models that have attempted to re create this phenomena to aid in breaking sota benchmarks
ris3un,1,grouped bagging boosting in classifiers hey i was wondering if it s possible to have a classifier that relies on bagging boosting like a random forest lgbm or xgboost keep groups of observations together when doing the bagging for example let s say i have observations on a bunch of people throughout their teenage years and early adulthood and i want to predict whether they will eventually get married if i train a model on all of those observations the out of sample bag may get observations for the same person at a different point in their life and thus the same outcome leaking information and overfitting if i have data points that are very unique to each person and remain relatively constant that problem gets even worse how can i deal with this so far the solution was to just reduce the feature set to keep the most generic features and avoid overfitting but i know that can t be the best solution
r4k5lf,0,are you seeing any compelling use cases of semantic search being leveraged at scale in my org we are highly reliant on elastic search and i m currently investigating the merit of incorporating a semantic search component to our search pipeline like most i ve built prototypes leveraging faiss on our data and while the results are impressive i haven t come across any compelling use cases where teams are putting this to use at scale i want to note i don t come from a research background
rwqgyl,1,what topic would you like to see covered hey everyone i m just doing a quick survey to see what areas are of most interest here it can be an application or an architecture a discussion of computational methods theory focused or code focused how to use a package whatever any feedback is welcome the more specific the better as well once i get a sense of the most popular topics i ll run a poll
r05n9v,0,scaling law for recommendation models towards general purpose user representations
r9b2kp,1,public streaming datasets hi for personal research purposes i m looking for a tabular streaming data public datasets with two or more classes something along these lines would love to hear if you know of something similar thanks
rd3oby,0,yuno an ai search engine that recommends anime given a specific description yuno in action x200b yuno this is the search engine that i have been working on past 6 months working on it for quite some time now i am confident that the search engine is now usable source code yuno try yuno on both notebooks has ui 1 kaggle notebook recommended notebook 2 colab notebook my research on yuno what does it do basically you can type what kind of anime you are looking for and then yuno will analyze and compare more 0 5 million reviews and other anime information that are in it s index and then it will return those animes that might contain qualities that you are looking r animesuggest is the inspiration for this search engine where people essentially does the same thing how does it do this is my favourite part the idea is pretty simple it goes like this let says that i am looking for an romance anime with tsundere female mc if i read every review of an anime that exists on the internet then i will be able to determine if this anime has the qualities that i am looking for or n ot or framing differently the more reviews i read about an anime the more likely i am to decide whether this particular anime has some of the qualities that i am looking for x200b consider a section of a review from anime oregairu yahari ore isn’t the first anime to tackle the anti social protagonist but it certainly captures it perfectly with its characters and deadpan writing it’s charming funny and yet bluntly realistic you may go into this expecting a typical rom com but will instead come out of it lashed by the harsh views of our characters just by reading this much of review we can conclude that this anime has 1 anti social protagonist 2 realistic romance and comedy if we will read more reviews about this anime we can find more qualities about it if this is the case then reviews must contain enough information about that particular anime to satisfy to query like mentioned above therefore all i have to do is create a method that reads and analyzes different anime reviews but how can i train a model to understand anime reviews without any kind of labelled dataset this question took me some time so solve after banging my head against the wall for quite sometime i managed to do it and it goes like this let x and y be two different anime such that they don’t share any genres among them then the sufficiently large reviews of anime x and y will have totally different content this idea is inverse to the idea of web link analysis which says hyperlinks in web documents indicate content relativity relatedness and connectivity among the linked article that s pretty much it idea how well does it works x200b fig1 10k reviews plotted from 1280d to 2d using tsne x200b fig2 reviews of re zero and re zero sequel as you will able to see in fig1 that there are several clusters of different reviews and fig2 is a zoomed in version of fig1 here the reviews of re zero and it s sequel are very close to each other but in our definition we never mentioned that an anime and it s sequel should close to each other and this is not the only case every anime and it s sequel are very close each other if you want to play and check whether this is the case or not you can do so in this interactive kaggle notebook which contains more than 100k reviews x200b since this method doesn t use any kind of handcrafted labelled training data this method easily be extended to different many domains like r booksuggestions r moviesuggestions which i think is pretty cool x200b context indexer this is my favourite indexer coz it will solve a very crucial problem that is mentioned bellow consider a query like romance anime with medieval setting and with revenge plot finding such a review about such anime is difficult because not all review talks about same thing of about that particular anime for eg consider a anime like yona of the dawn this anime has 1 great character development 2 medieval theme 3 romance theme 4 revenge plot not all reviews of this anime will mention about all of the four things mention some review will talk about romance theme or revenge plot this means that we need to somehow remember all the reviews before deciding whether this anime contains what we are looking for or not i have talked about it in the great detail in the mention article above if you are interested x200b note please avoid doing these two things otherwise search results will be very bad 1 don t make spelling mistakes in the query coz there is no auto word correction 2 don t type nouns in the query like anime names or character names just properties you are looking for eg don t type anime like attack on titans type action anime with great plot and character development this is because yuno hadn t watched any anime it just reads reviews that s why it doesn t know what attack on titans is x200b if you have any questions regarding yuno please let me know i will be more than happy to help you here s my discord id i am paradøx 8587 thank you x200b edit 1 added a bit about context indexer edit 2 added things to avoid while doing the search on yuno
rewfbp,1,hardware assistance hello so far all training that i ve done was on cpu since i have radeon rx 590 and i want an upgrade not an expensive one so i want to match the new gpu properly with my current cpu motherboard i have prime a320m k with ryzen 7 2700x and was planning on getting zotac gtx 1070 8gb x gaming is that fisable also does it really require only one 8 pin slot and can i still use my old gpu as primary and dedicate zotac just for training thanks in advance
rkkqhn,1,feature selection advice i have recently been working on one of my way too many side projects this one is a for my current level of knowledge and ability slightly ambitious informal experiment regarding the comparative performance of various types of models for a specific task i am especially hoping to compare a precomputed batch learning nn with a reinforcement learning method though i m also hoping to expand on both of those categories with variations upon the base once i have one of each working reasonably well since i ve got the game pretty much fully implemented bar some refactoring for reasons of cleanliness i m now at the stage where i ll need to select what features might be relevant for my models i m ideally hoping to use a single universal feature set for all models both for comparability and also because i ll need to create all the training data by hand i ve had some ideas for this but i wanted to ask for advice before i miss out on something not immediately obvious that could be beneficial for refrence please consider this screenshot of the game it s a bit minimalistic i know the green square is the player character whereas the red bars are semi randomly generated platforms with varying widths the green number at the top is a score which is always equal to the number of platforms under the highest platform the player has reached so far the game also features an optional 20s timer which i m intending to use in conjunction with the score for benchmarking the performance of the various models though it s not on in the screenshot note that if the player leaves the screen to one side they ll emerge on the other the game is controlled using three keys only left right jump and i want to train each model to predict wheter or not each of these should be pressed on a given frame now the possible features i have so far considered include the following 1 position of player platforms this one is kind of obvious though thanks to the fact that we ve always got 7 platforms 1 player on screen each with x and y coordinates this means we already have 16 features by neccessity i was also considering wheter using a relative measure of position might be usefull since it helps generalise the dataset and eliminate the need for the player position features 2 current time remaining the models will be benchmarked in a fixed timeframe so this might be relevant 3 current score don t think it d be that relevant tbh but it s a number i have so it s a feature i have considered any and all advice is of course welcome though to reiterate i am mainly looking to select appropriate features at this stage especially anything that might be relevant to such problems that i hadn t considered and just in case this becomes relevant the game is implemented in python using pygame and i m intending to use tensorflow for the ml parts
