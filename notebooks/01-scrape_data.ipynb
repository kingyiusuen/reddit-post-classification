{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape posts from subreddits, you have to first put your reddit app's `client_id`, `client_secret` and `user_agent` in a `secrets.json` file in the project root directory. Here is [a blog post on the Reddit API](https://www.jcchouinard.com/get-reddit-api-credentials-with-praw/), in case you don't know what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../secrets.json\", \"r\") as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "CLIENT_ID = secrets[\"client_id\"]\n",
    "CLIENT_SECRET = secrets[\"client_secret\"]\n",
    "USER_AGENT = secrets[\"user_agent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some more configuration variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which subreddits to scrape\n",
    "SUBREDDIT_NAMES = [\"MachineLearning\", \"LearnMachineLearning\"]\n",
    "\n",
    "# The maximum number of posts to scrape per subreddit\n",
    "# Actual number may be smaller than this because some posts are link posts with no text\n",
    "LIMIT = 1000\n",
    "\n",
    "# Where the data should be saved\n",
    "OUTPUT_DIR = Path(\"../data/raw/\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_FILEPATH = OUTPUT_DIR / \"reddit_posts.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function for scraping a subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_subreddit(subreddit):\n",
    "    posts = []\n",
    "    for post in subreddit.new(limit=LIMIT):\n",
    "        # Skip if the post is not a text post\n",
    "        if not post.is_self:\n",
    "            continue\n",
    "        # Skip if the title is missing\n",
    "        if not post.title:\n",
    "            continue\n",
    "        entry = {\n",
    "            \"id\": post.id,\n",
    "            \"created_utc\": post.created_utc,\n",
    "            \"title\": post.title,\n",
    "            \"selftext\": post.selftext,\n",
    "            \"subreddit_name\": subreddit_name,\n",
    "        }\n",
    "        posts.append(entry)\n",
    "    print(f\"Scraped {len(posts)} posts from r/{subreddit_name}\")\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start scraping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 847 posts from r/MachineLearning\n",
      "Scraped 715 posts from r/LearnMachineLearning\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    user_agent=USER_AGENT,\n",
    ")\n",
    "\n",
    "data = []\n",
    "for subreddit_name in SUBREDDIT_NAMES:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    data += scrape_one_subreddit(subreddit)\n",
    "headers = [\"id\", \"created_utc\", \"title\", \"selftext\", \"subreddit_name\"]\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "df.to_csv(OUTPUT_FILEPATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb3a6367d16cad02d2d042fd82b960b1ba0c185ef92d229ea4e59c40b5593035"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
